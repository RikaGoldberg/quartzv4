---
title: "Decentralization, DAO Research Collective"
date: 2023-03-31
tags:
- seed
---
Source: https://daocollective.xyz/decentralization/

#### Highlights 

In spite of the obvious **benefits of decentralization regarding inclusivity, representation and personal freedom**, **human history has primarily been a study in centralized authority because of the benefits it provides in efficiency in making decisions and its ability to be effective over large geographic areas.**

However, recent technological advancements have allowed for decentralized principles to be utilized more effectively and many of the historical limitations are no longer applicable as robust mechanisms of governance utilizing decentralization are now available.

While the term decentralization is not explicitly found within the whitepaper, the ability to construct organizations and processes with “no central authority” absent a “trusted third party” for transaction or otherwise interacting with others has established a stand alone concept utilized within the industry.

The goal of this paper is to help clarify why people in the broader crypto community organize around the concept of decentralization. 

Although a unified comprehensive definition would undoubtedly provide more clarity than the current contextual definition, the reality is that decentralization within the blockchain is an evolving concept and at this time, its utilization must be examined situationally to determine how the underlying processes fit within its current application.

Kevin Owocki of Gitcoin discusses this in a Twitter thread where he points out that decentralization can refer to “decentralized governance via a permissionless token” rather than a “chaotic loose web of individuals”.

In Anticapture, Spengrah writes that “conflating decentralization with permissionlessness is one of the most common mistakes in the DAO space.” Spengrah discusses the concept of anti-capture, a framework for how networks of humans can design systems resistant to governance capture by bad actors. Capture-resistance governance is a more reasonable goal for decision-making for projects that can’t be reduced to completely non-human programmatic functions. 

In Anticapture, Spengrah writes that “conflating decentralization with permissionlessness is one of the most common mistakes in the DAO space.” Spengrah discusses the concept of anti-capture, a framework for how networks of humans can design systems resistant to governance capture by bad actors. Capture-resistance governance is a more reasonable goal for decision-making for projects that can’t be reduced to completely non-human programmatic functions. 

In particular, blockchains have emerged as an opportunity for the development of new systems that more effectively embrace the benefits of decentralization as both a mechanism for member representative governance models and as a choice for users to access and develop application functionality within a decentralized economy.

the term ‘decentralization’ itself has become synonymous with certain features of blockchain technology and a point of analysis in determining their technical, legal, economic and political function.

This paper will act as a TL;DR summarizing the concept of decentralization within its current usage, while providing linked resources throughout for those interested in digging deeper into specific areas.

Given the evolving nature of the space, we will publish updated versions of this document as the topic continues to evolve.

Coinbase engineer Yuga Cohler went so far as to say that Ethereum’s upcoming transition to a Proof of Stake consensus mechanism will, if successful, “prove the viability of decentralization as a social organizing principle.”

The core value proposition of many blockchains, including the Ethereum blockchain, is to act as a trustless infrastructure where developers can build immutable, decentralized applications. While other blockchains are working towards progressive decentralization, Ethereum’s first-mover advantage and wide adoption as the first smart contract platform — i.e, blockchains that natively enable smart contracts, allowing for a variety of composable applications to be built on top of the blockchain — makes Ethereum a natural benchmark for Layer 1 blockchain decentralization.

The underlying blockchain provides the execution layer for the on-chain components of the individual applications, but the applications themselves still require their own technical decentralization in the form of permissionless clients for interacting with the underlying smart contracts, user-owned data (and ease of data portability), and decentralized governance of the smart contracts by a broad group of participants in the form of a Decentralized Autonomous Organization (DAO)

Questions to ask when considering technical decentralization – how are these systems designed? How are upgrades made, if needed? What processes backstop the execution of upgrades (i.e, Compound’s 48 hour timelock)? What blockchain underpins the application, and what tradeoffs does that blockchain force onto the application? Can users easily ‘ragequit’ the system — i.e, can users exit the system and use (or build) different methods of interacting with the core protocol?

public blockchains create the opportunity for a reimagining of the economic interaction between the developers of an application and the users and adjacent stakeholders around that application. In the ‘traditional’ pre-blockchain world, companies are incentivized to view their users as a source of value extraction, primarily in the form of user-generated content or the corresponding data of the end user, which is then transacted between the company and willing advertisers behind the scenes.

Blockchains allow for systems that are not reliant on central leadership, allowing for the balancing of incentives between developers of the application, contributors to the application, and users of the application.

These economically-decentralized structures are basically a new generation of open-source software communities, but with embeddable, transparent economies. [In an economically-decentralized ecosystem, contributors can participate in the value-creation of the application while receiving compensation for their contributions.](/notes/In%20an%20economically-decentralized%20ecosystem,%20contributors%20can%20participate%20in%20the%20value-creation%20of%20the%20application%20while%20receiving%20compensation%20for%20their%20contributions..md)

Questions to ask when considering economic decentralization – how is the underlying token of the application designed and distributed? How was the airdrop designed, and what considerations were made by the early project developers to prevent centralized ownership of a majority of project tokens?

How are early investors and project contributors compensated, and what do token lockups for all parties look like? How do distributions of the DAO treasury work; i.e, how are funds distributed to initiatives and/or working groups intended to further the project’s mission? 

beyond the technical mechanics and the economic benefits of decentralization are matters of regulation and legality, including taxation, liability, ownership, intellectual property, reporting and privacy.

Although decentralization exists in the current legal system – most obviously in the form of general partnerships – there is significant question as to how the default rules established for participation and responsibility can be fairly applied to decentralized systems that are exceedingly dissimilar from the activity giving rise to existing law.

he decentralized activities available through the blockchain represent significant changes in concepts like equity, ownership and control.

As these activities are capable of creating taxable events and acting in a way giving rise to litigation, it is expected that taxation and liability will soon be matters of equal prominence with securities law when considering legal decentralization.  

Securities regulation stems largely from a desire to prevent information asymmetry amongst market participants – while there currently is no defined standard for the concept of legal decentralization, the levels of influence that early project contributors retain in the decentralization process, as well as the transparency of information amongst participants, will be pivotal to determining whether a project is legally-decentralized.  

Historically, coordination between humans has relied on some levels of trust. Trading goods between two people requires the trust that both parties will actually deliver their goods to the other, and agreeing to some sort of truce or treaty between conflicting nations requires trust that the other party will continue to abide by the agreed-upon treaty. 

Immutable code deployed on decentralized public blockchains sets the foundation for censorship-resistant, privacy-preserving innovation.

hese censorship-resistant systems are not yet completely un-coercible, but they act as a necessary foil to the institutions and platforms we’ve come to rely on outside of crypto (world governments, social media platforms, etc.).

If the infrastructure layers (the blockchains themselves) weren’t decentralized, it would be simple for a powerful government to shut it down – just find the party responsible for the network and coerce them.

Decentralization makes this difficult, as China’s Bitcoin ban demonstrated, because censoring sufficiently decentralized systems requires coordination outside of the scope of most governments; just a few months after the China Bitcoin mining ban, several underground mining operations emerged in China to fill the gap left behind by the ban.

NFTs have been used by individuals to preserve information in the face of authoritarian governments as well – however, these NFTs still required anonymity from the individuals to avoid direct coercion from their government

In fact, transparent, unopinionated rules to participation are by themselves a flavor of censorship-resistance that blockchain-based applications naturally inherit, since by default, code deployed to public blockchains is open-source

Vitalik Buterin argues that decentralized systems are more resilient to attack and less likely to accidentally fail than their centralized counterparts. Critically, decentralized systems are generally more expensive to attack due to the absence of sensitive central points of failure for attackers to target — an attacker couldn’t just infiltrate the Ethereum Foundation and press a big red “HALT” button (since there is no big red button), and an attacker couldn’t overpower Buterin and force him to shut down the blockchain (since Buterin doesn’t have that type of centralized power, despite being the initial founder and specwriter).

Underwriting systemic correlated risks is difficult and, in complex interconnected systems, can lead to disaster. Decorrelation of systemic risks via the open borders of blockchains can help mitigate these risks and reduce the surface area of attack vectors. 

Optimism emphasized the idea that funding public goods in the decentralization process is highly important, since without decentralization, public goods projects might not exist or might rely on a centralized entity to fund. Ultimately, while the participation of centralized entities in public goods funding should be applauded and encouraged, relying on only one central entity to fund public goods project leads to a risk vector – if funding for public goods is centralized, funding might only be distributed to projects that appeal to the centralized entity, which is by itself a form of censorship. 

Hop, a bridge for assets between different blockchains, also recently announced their plans for decentralization, which included a standard snapshot of participation in anticipation of a token drop to community members.

Uniswap is arguably the most decentralized application in the crypto world today and the best example of a hyperstructure.

In the midst of 2020’s DeFi Summer, Uniswap distributed 15% of tokens to past users, while reserving most of the remaining tokens for community member distributions. Governance of the Uniswap treasury was transferred to holders of the UNI token, who could decide the future of the protocol in a direct democracy governance process, and the Uniswap protocol is governed and upgraded by UNI token holders in the same process. 

Aaron Brown of Bloomberg Opinion said “The two basic problems with SushiSwap are too many opportunists in its initial creation and failure to align incentives carefully.” 

The project immediately became the most interesting story in crypto and skyrocketed to $200M in trading volume within 10 days. Loot became a case study in collaborative value creation, with projects like Loot Character, Loot Mart, and an entire ecosystem of other projects springing up around Loot.

But as described in detail throughout this piece, decentralized systems are not just completely horizontally-distributed systems and instead, there are several individual components to consider when judging the level of decentralization of a project. Crucially, the critique that “centralized entities within the system prove centralization of the system” often ignores the idea of data portability. Mudit Gupta, Chief Information Security Officer of Polygon, called data portability “the ability to be decentralized.”

he critique that decentralization will beget ineffective governance might be the most truthful critique of the ecosystem right now. As of early 2022, governance of decentralized organizations is largely ineffective across the board — participation is low, and pure coin-voting, as most decentralized organizations have trended towards, has a variety of embedded issues that might create more plutocratic systems than the prior status quo.

“Only by making technical systems that offer a variety of mechanisms for checking concentrations of power and by simultaneously building social ideologies constantly on the lookout for failure modes of these mechanisms can we hope to succeed where previous attempts at decentralizing authority have failed.”

To reach this next stage of refined, globally-relevant decentralized systems, we as users and community stewards need to remain intellectually honest towards the desired goals of decentralized systems, and we must hold accountable those who infringe on the ethos of the ecosystem. When centralized entities act in bad faith under the guise of decentralization, we have to critique them publicly, and we have to design systems that allow for centralized and decentralized organizations to participate side-by-side in the ecosystem while communicating to users the design trade-offs that both types of organizations have chosen.

Finally, we have to do better in terms of communicating the need for various implementations of decentralized systems to regulators, local representatives, and the broader public, with the goal of fostering credibly-neutral decentralized systems that can stand the test of time. 

[jokedao gets serious — jokedao](https://joke.mirror.xyz/a5Ab_t1BQwc2TMXgxgm6Ixe_XchoqmaZpTj8J_eyuuU)

joke.mirror.xyz

GAMES

3 weeks ago

4 highlights

Second, retention: so many DAOs lose members now because they don’t build relationships, have little to do, and go elsewhere. Gamified governance solves all three of these issues. Because it’s only possible to win contests by collaborating with others, contributors will have to form teams to win—leading not only to longlasting relationships but better consensus-building mechanisms to make decisions.

First, acquisition: DAOs can reward newcomers who propose decisions and work with DAO members to vote on winning options. Our contests become a DAO acquisition tool for people looking to get into web3, work on DAOs, and learn about the DAO itself as well as the process of on-chain governance.

Gamified governance operates on the principle that the best decision in a DAO isn’t necessarily the one that builds the most revenue or growth—but rather the one that builds social consensus among DAO contributors so that they remain excited and dedicated to pursue it. What about those who can end up penalized for disagreeing with consensus? Our hope is that they’re extra incentivized to find each other and rechallenge the winners or fork the DAO to build the vision they care about. Then again, we don’t pretend this system of incentivized collaboration is right for every DAO or every decision, and that’s why we’ll leave rewards and penalties optional. We want DAOs to have maximum modularity to build the contests they want to build.

In our case, we’ll be building a platform for gamified governance that enables DAOs to reward participants for working together and building relationships to come to the right decision for the group. Those who vote on winning options can win tokens.

[nguyen - gamification of Twitter - FD](https://philpapers.org/archive/NGUHTG.pdf)

philpapers.org

GAMES

3 weeks ago

13 highlights

And if we take up Twitter’s invitation and internalize those evaluations, we will be thinning out and simplifyi ng our own goals for communication

What is the impact of so much public discourse being shoveled through one plat- form?

I would like to focus on another basic feature of Twitter — one whose importance and impacts, I think, has not been adequately appreciated. Twitter gamifies comm unication by offering immedi- ate, vivid, and quantified evaluations of one’s conversational success.

Twitter is addictive, in part, because it feels so good to watch those numbers go up and up. In fact, the design of Twitter and its scoring mecha- nisms have been significantly informed by design strategies fostered in the Las Vegas gam- bling industry — strategies which overtly seek to increase the addictiveness of their prod- ucts.

Unlike conversation in the wild, I can know exactly how well each tweet did, and I can instantly compare my overall popularity with that of any other user. This can provide all sorts of pleasures: the thrill of victory, when we see those numbers tick up; and the sense of long - term achievement, presented in precise and unquestionable quantitative form.

Here, then, is an optimistic view of Twitter: by gamifying public discourse, Twitter increases overall participation, and so helps us to reap the rewards of p ublic discourse — such as a more fully politically engaged populace.

Games are more satisfyin g than ordinary life pre- cisely because game - goals are simpler, clearer, and easier to apply.

Pre - gamification, the aims of discourse are complex and many. Some of us want to trans- mit information or to persuade; some of us want friendship . Some of us want to join together in the pursuit of truth and understanding. Tw itter gamifies discourse and, in so doing, offers us re - engineered goals for our communicative acts. Twitter invites us to shift our values along its pre - fabricated lines .

Twitter is now one of our primary venues for public discourse. But it is not a neutral or transparent medium. Twitter shapes how we interact, who we interact with, and — perhaps most importantly — it suggests specific goals for those interactions.

Twitter shapes our goals for discourse by making conversation something like a game. Twitter scores our conversation. And it does so, not in terms of our own p articular and rich purposes for com- munication, but in terms of it s own pre - loaded, painfully thin metrics: Likes, Retweets, and Follower counts.

What’s more, the effect of Twitter’s gamification, across the community Twitter users, will tend towards levelling and flattening the diversity of valu e s . Insofar as Twitter’s gamifi- cation motivates its users, then it will drag all of its users ’ communicative values in the same direction – towards the same metric . Gamification homogenizes the value landscape. And th is phenomenon will help explain some of the more socially toxic aspects of Twitter.

Supporters of gamification say that it is a technology for increasing motivation. G amifi- cation can supposedly imbue everyday activities with all the fun and excitement of a game.

I do not accept the optimistic view. Crucially, I don’t think that gamification merely in- creases our motivation to perform an activity while preserving all the original goods of th at act ivity. Gamification increases our motivation by changing the nature of the activity. Often, the goals of ordinary activity are rich and subtle.

[The Gamification of Games — Real Life](https://reallifemag.com/the-gamification-of-games)

reallifemag.com

GAMES

3 weeks ago

15 highlights

If there were a common characteristic that defined all games, it would certainly not be the use of badges, achievements, and points as incentives for engagement. Games, if anything, share an embodiment of the spirit of play — a temporary suspension of the rules of life to make space for intensities of experience: levity, rivalry, concentration, joy.

If historian Johan Huizinga — whose 1938 book Homo Ludens is one of the pivotal works of game studies — had the opportunity to define gamification according to his theory of play, he might have reserved the term for a “temporary abolition of the ordinary world” where “inside the circle of the game the laws and customs of ordinary life no longer count.”

Now gamification evangelists like Jane McGonigal advocate for games to be understood as fundamentally productive, offering a set of tactics to make life under neoliberalism appear more fun and addictive — a “magic circle” we should never step out from, even if we had the choice. The concept first gained traction at the end of the 2000s within game development and marketing communities, which saw an opportunity to use aspects of games to monetize the web

In the Wharton School of Business’s popular online course titled Gamification, the instructor professes that “there are some game elements that are more common than others and that are more influential than others in shaping typical examples of gamification.” These elements are “points, badges, and leaderboards.” These offer scores that constitute “a universal currency, if you will, that allows us to create a system where doing one sort of action, going off on a quest with your friends, is somehow equivalent or comparable to doing some other sort of action, sitting and watching a video on the site.”

Many games have scores, of course, but typically they serve the limited purpose of determining a winner of a particular contest. Gamification takes scores as an exportable measure of qualities that are no longer internal to the game that has generated them. “Score” becomes just another word for data — a “universal equivalent” whereby life activity and behavior can be reckoned with in quantified terms. From this perspective, games are primarily a means of data production, not a more intense or rewarding form of experience. Accordingly, apps that convert activity into points are hardly concerned with improving the quality of engagement, nor are they limited to the task of encouraging it. Consider the data collection practices of prominent gamification apps such as Nike’s fitness tracker Nike+, the productivity role playing game Habitica, or the language training app Duolingo. Gamification gurus praise these apps for how they import game mechanics, while watchdogs condemn them for privacy violations.

The use of gamification for data collection is not a secret. The professor of the Gamification course openly celebrates it: “One of the aspects of gamification is that you’re going to get lots of information potentially about your players. Information about who they are, their profile and so forth, but also tremendously granular data about what they’re doing. Every action they take in the game, potentially can be collected, and that’s a great thing.” Points, badges, and leaderboards have always been about the data and not the play.

Achievements notifications were not features programmed by game developers to meet players’ demands, but as a requirement codified by platforms. Microsoft Xbox’s development kit defines an “Achievement” as a “system-wide mechanism for directing and rewarding users’ in-game actions consistently across all games.” [Emphasis added.] In other words, they are not conceived as part of an individual game but as part of the larger experience of “gaming” in general. Game developers in turn must design games with this logic of achievement in mind

This data can then be used for ends that have little to do with the games themselves — exemplifying what Shoshanna Zuboff, in The Rise of Surveillance Capitalism, called a “ behavioral surplus.”

The patent listed a number of heuristics — avatar choices, gameplay style, time spent gaming — as potentially relevant to advertisers. The system could, for instance, “display ads for pizza-hut” if “the user has been playing for over two hours continuously.” In addition to inferring pizza appetite, the system would assess players’ personality based on gaming behavior. Such metrics as the time spent bartering instead of stealing within a game would serve as a potential indicator of the player’s interest in “the best deals rather than the flashiest items.” The “time spent exploring rather than completing levels” could indicate interest in real-world vacations. The patent is careful not to claim that these correlations actually exist; instead, it merely describes a system that could collect in-game data and then discover predictors of a player’s extramural wants, needs, and desires.

Classifying gamers based on the data obtained through games is now a multibillion-dollar industry known as game analytics. The company GameAnalytics boasts the ability to collect and analyze data on 850 million monthly active players across 70,000 game titles. Such data can be used to segment players based on their services, playing styles, locations, and demographics. But harvesting data from gamers to make broader inferences about people has a long history. So long as there are winners and losers, players can be ranked by their ability to win

For a point of comparison, in this Wired article from 2007, the co-founder of the Soviet Arcade Museum, Alexander Stakhanov, describes public rankings in video games as distinctly western — and by extension, capitalist. In Soviet arcade games, public leaderboards were never a feature. Instead, Stakhanov says, “If you got enough points you won a free game, but there was no ‘high score’ culture as in the West.”

In fact, every gaming platform is now designed to collect numerous data points, as their privacy policies specify. This includes account information, payment information, user content, messages, contacts, device identifiers, network identifiers, location, achievements, scores, rankings, error reporting, and feature usage as well as maintaining the right to share or resell the data to third parties. It also includes common “key performance indicators,” or KPIs, such as virality, retention, active users, and revenue per user, as well as data specific to games such as user inputs and time spent completing tasks — which, according to this analysis from IBM, include “time to complete levels, solo versus interactive behaviors, avatar selection, interaction style indicators, gender of avatar, game strategy behavior variables, game-related tweets, social network activity, language, and more.”

Another strategy is to use in-game data to estimate a player’s “lifetime value” or LTV — the monetary value a user is expected to generate for the game developer — and adjust the game accordingly, focusing on players with the highest expected value, nudging them to continue buying game-world tokens, character modes, virtual materials, and other items. Such microtransactions not only milk profit from players through their purchases; they can also indicate what sorts of mundane virtual tasks gamers are willing to put up with and what tasks gamers are willing to pay to avoid. Intellectual-property-law scholars have argued that microtransactions can be used to estimate players’ “intertemporal discount factor,” a financial metric originally designed to assess an investor’s preference for immediate returns or delayed rewards. If a player proves willing to overspend for instant gratification, this data about the player can be sold to advertisers, and may prove especially useful when supplemented with the other data collected by platforms. Microtransactions, then, are more than transactions; they are data on top of money.

These efforts make it evident that the principles of gamification assume that humans are no different from algorithms in how they respond to rewards. Like machine learning algorithms, humans in algorithmically controlled spaces can be nudged and reprogrammed to have better habits. Far from making life more game-like, gamification makes human behavior more manageable and predictable, provoked by feedback loops and captured as data.

With psychological insight into the values, ideals, and fantasies that users are not so willing to admit in search queries, emails, and purchasing habits, games are valuable supplements to the data Google and Amazon already collect. Just as “hardcore” games have become more standardized with open worlds, achievements, and trophies, we can expect that the promised freedom and seamlessness of cloud gaming will come with increased surveillance and more penetrating monetization. If we accept the cliché “games are a series of interesting choices,” it is about time to start asking for whom.

[Enhancing Consumer Online Purchase Intention Through Gamification in China: Perspective of Cognitive Evaluation Theory - PMC](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7719710)

ncbi.nlm.nih.gov

GAMES

3 weeks ago

32 highlights

For instance, Alibaba has set up a game mechanism on its payment platform, on which the quantity of trees planted depends on individual walks, so as to fulfill its social responsibility and stimulate consumption through the platform

On the other hand, as gamification is heavily driven by information communication technologies, it is natural to address interrelations between gamification and online behavior of consumers

For example, JD.com, a large online shopping platform in China, enables people to gain points, known as beans, when they make purchases; these beans can then be exchanged for other commodities or planted on the game platform in order to obtain more beans and increase consumer willingness on this platform.

For this purpose, a theoretical model has been developed to predict the impact of consumers’ enjoyment in the game on their purchase intention by drawing on cognitive evaluation theory (CET) (Ryan and Deci, 2000a, b; Deci and Ryan, 2010; Mitchell et al., 2020). According to CET, when people are involved in certain activities, they have psychological needs such as autonomy and absorption. When individuals feel that their demands need to be met, they will trigger intrinsic motivation and feel a greater sense of enjoyment, which, in turn, will lead to more engagement in activities (Lee and Yang, 2011) and ultimately affect consumer behavior.

Since the main purpose of gamification is to develop willpower and high-quality forms of motivation, CET helps us understand the changes in consumer behavior in the context of gamification. Based on CET, a model has been developed and tested in this study to explore how game elements affect users’ psychological needs and increase consumers’ sense of enjoyment, thereby influencing their purchase intention.

(3) enriching applications of gamification for business and academics, particularly those that add new features and gameplay mechanics (Huotari and Hamari, 2017) to ensure both customer enjoyment and the success of business objectives

By extending such aspects of CET to this study, it is possible to consider the behaviors of extrinsic regulation to be motivated by external factors such as awards and competition, and the behaviors of intrinsic regulation to be motivated by internal factors such as absorption and autonomy.

When an individual realizes that the causation originates from the behaviors mentioned above, intrinsic motivation appears. An example of intrinsic motivation is enjoyment. When people are dominated by intrinsic motivation, they will stick to a task for longer and like it more (Deci, 1985).

Autonomy means the willpower or willingness to do a task; competence refers to the feeling of being effective (Silverman, 2011; Santhanam et al., 2016; Huang et al., 2017), such as getting rewards, being addicted to games, and participating in competition.

Curiosity, fun, or enjoyment can all be intrinsic motivations (Kim and Drumwright, 2016).

In other words, when a person’s basic psychological needs of competence, autonomy, and relevance are satisfied by an activity, greater enjoyment will be gained.

In a state of enjoyment, consumers tend to feel environmental stimuli and arousal impulses (Wang and Li, 2016). As the purpose of gamification is mainly to make consumers’ activities more enjoyable (Bunchball, 2010), enjoyment is a significant intrinsic motivation that determines whether consumers participate in designed gamified shopping environment and affects purchase intention. On this basis, we propose the following hypothesis: H1: Consumer enjoyment has a positive impact on online purchase intention.

Moreover, merely adding gamification mechanics such as challenge and fantasy in a smart interface is not enough to significantly enhance the quality of the perceived experience (Insley and Nunan, 2014; Mitchell et al., 2020). The purpose of gamification is to increase consumer motivation and facilitate consumers’ participation in gamification activities through intrinsic and extrinsic motivators, and to provide a pleasant experience (Von Ahn and Dabbish, 2008; Conaway and Garay, 2014; Xi and Hamari, 2020).

Reward, competition, autonomy, and absorption are the most common game dynamics in the literature on gamification (Agarwal and Karahanna, 2000; Gottschalg and Zollo, 2007; Liu et al., 2007; Hordemann and Chao, 2012; Kapp, 2012; Mullins and Sabherwal, 2020), these elements must be available in order for gamification to be used (Conaway and Garay, 2014). As a result, consumers are encouraged to further participate in the system (Gottschalg and Zollo, 2007), which ultimately affects purchase intention.

Playing a game means the player is in an environment where he/she has autonomy (Gagné and Deci, 2005), and people participate in the game of their own free will. This is an exact reflection of autonomy. Game activities, such as completing tasks, defeating other players, and developing strategies to achieve goals with other players, can help people meet their psychological needs of autonomy, competence, and relevance (Deci and Ryan, 2000; Beecham et al., 2008; Mitchell et al., 2020), and improve the inner experience of enjoyment.

Based on CET, researchers hold that consumer competence is an important prerequisite for triggering enjoyment. When a consumer feels that he/she is controlled or forced to do something (e.g., participate in an unpleasant competitive relationship), any external condition will reduce the intrinsic motivation and lessen the experience of enjoyment (Antin and Churchill, 2011). Players’ voluntary enjoyment is the key element of a game

According to CET, people have more fun when engaging in activities in which they are interested or in activities that can reflect their personal value (Ryan et al., 2006).

For consumers using gamification, absorption is a state of enjoyment. Under this state, players can be absorbed in these games. This can be seen as a process of high enjoyment. Gamification allows players to immerse themselves in a virtual world, helping them escape from some of the problems in the real world. Some players may be absorbed in a game, enjoy mental relaxation, and feel that time passes faster than usual. Some scholars call this state a “flow state,” under which people may only be aware of activities they participate in, or of the specific environment they are in Mauri et al. (2011). Some scholars believe that games can improve and regulate emotions, and that participants experience higher absorption after completing game tasks, thus generating more positive emotions (Yang et al., 2020) and stimulating more powerful motivations (Silic and Lowry, 2020). Therefore, consumers’ absorption in a game may have a positive influence on their enjoyment. Players who are obsessed with a game may have more enjoyment intentions. Therefore, we have developed our fourth hypothesis as follows:

H4: Absorption of gamification has a positive impact on the generation of enjoyment.

Given that our model covers different constructs, such as consumer absorption in games and self-control, we used a structural equation model to discover through path analysis whether the relationship between these variables is statistically significant

Finally, our study has found that competition has no positive effect on enjoyment. The competitive elements of a game may distract users and even lower their enjoyment (Lee and Yang, 2011). This result is similar to the argument that despite gamification comprising many game elements, not all these elements can successfully attract users

Other scholars have suggested that competition might have a negative effect on users’ psychological states when the competition is excessive or poorly designed such that it does not consider users’ characteristics

The present study verifies that competition does not have a positive impact on consumer enjoyment in the online marketing context; however, our analysis also reveals a positive correlation between competition and consumer enjoyment, implying that well-designed competition in gamification motivates consumers in experiencing enjoyment

In other words, the impact of each design element of gamification and the assessment of their impact on enjoyment are very important, and unreasonable design of competitive elements can reduce the degree of enjoyment.

This study makes important academic contributions. First, it extends CET by determining which antecedents among rewards, autonomy, and absorption can satisfy the need for enjoyment (Silverman, 2011; Santhanam et al., 2016; Huang et al., 2017). Researchers have found that CET can explain why people keep playing games (Deterding et al., 2011), but few studies have examined the impact of game-related factors on consumer online purchase intention

Secondly, this study explains four game elements that promote enjoyment and purchase intention. Our work shows that the design of gamification should be such that consumers satisfy their extrinsic and intrinsic regulation (autonomy, reward, and absorption) (Ryan and Deci, 2000a, b) and participate in the next action with the support of intrinsic motivation (Deci, 1985).

Thirdly, our conceptualization of structure and its measurement is beneficial for researchers as it enables them to more accurately monitor consumer behavior and analyze potential problems (Chen et al., 2015). In order to understand the impact of gamification on consumer purchase intention, researchers need to control and measure variables (Lee and Yang, 2011). To this end, and to make it more elaborate, the current work is conducive to the design of gamification.

Our theoretical extensions help researchers develop their theories (Webster and Ahuja, 2006; Sen et al., 2008; Seaborn and Fels, 2015) and explain that some gamification elements are able to attract consumers and thus influence consumer behavior when people’s psychological needs are satisfied.

This study contributes to the extant literature on practice in the following ways. First, it can enlighten system designers and administrators who are trying to influence consumer behavior through gamification.

This study also has a social significance. Many social media apps use reward and competition strategies that are common in games to make the utilization of apps more enjoyable for consumers (Silverman, 2011). Nevertheless, there is still a lack of prescriptive guidelines and design principles for successful application of gamification. The framework of this study has systematically explained how to help consumers enjoy themselves and make their online shopping more enjoyable. This, in turn, will pave the way for better gamified applications, and it will promote beneficial behaviors in the online society.

The second limitation of this study is that our data may contain bias in its market selection. Because the object of this study is consumers participating in gamification on Taobao.com, such consumers may be more positive than those who are not attracted by gamification. Subsequent research could expand the research objects to people who are not sensitive to gamification.

We appeal to researchers to study our model outside the field of the online shopping market, as there will be more developments and discoveries in research on gamification and consumer online purchase intention. For example, although we have found that competition has no positive effect on enjoyment, current studies have suggested that the impact of competition might vary according to skill levels and competitive structures (Liu et al., 2007). Therefore, in the future context of the development of gamification, further investigations are also required to be certain how different competitive structures affect enjoyment and online purchase intention.

[Matthew Jordan’s review of Games: Agency as Art](https://www.goodreads.com/review/show/5043770786?book_show_action=false)

goodreads.com

GAMES

3 weeks ago

7 highlights

I would summarize the arguments I took away from Games in one paragraph like this: when we play games, we get to try on new ways of thinking, acting, and being—in other words, new agential modes. We do this by immersing ourselves in environments consciously crafted by game designers. Playing a game is an amazing cognitive dance: we temporarily adopt goals within the construct of the game, and genuinely strive to reach those goals, even though the goals (like “move this piece to this square” or “climb this short wall”) are meaningless in our actual lives. Here’s the magic: oftentimes, the true purpose of gameplay is something totally outside the actual goals of the game. The goal of multiplayer board games is human connection; the goal of Twister is riotous chaos. But we don’t get connection and chaos by going after those things directly; we get those things by seriously pursuing the goals of the game. The clear-cut rules and constraints of games are also enormously satisfying because they are a reprieve from real life, with its plurality of conflicting values and goals. This value clarity is why it’s dangerous to over-gamify our lives: we strip our life of its rich and subtle values (e.g. “I want to feel fit and healthy”) and replace them with a shallow metric (“gotta get my steps in”).

Let me expand on some of these ideas. First, I want to talk about self-effacing ends, the idea that some things are best achieved by not striving for them directly. As soon as I was introduced to this idea, it spun my head around. If you want to make a lot of money, don’t focus on making money, focus on building a product or service that people like. If you want people to like you, don’t focus on getting people to like you, focus on expressing interest in others. If you want to be happy, don’t focus on being happy, focus on making meaningful relationships and pursuing fulfilling projects. If you want to change someone’s mind, don’t focus on changing their mind, focus on making them feel listened to.

But we never explicitly pursue any of those things. We sit around a table and talk about books that we read. If we sat around talking about “developing a self” (like one might do at, say, a leadership conference), it would be absolutely fruitless.

Ok, that’s enough examples. I promise that if you start looking around for self-effacing ends, you’ll find them everywhere.

Nguyen calls this phenomenon “value capture”. He describes it like this: #1) Our values are, at first, rich and subtle. #2) We encounter simplified (often quantified) versions of those values. #3) Those simplified versions take the place of our richer values in our reasoning and motivations. #4) Our lives get worse.

But in practice, what we get is steps #3 and #4 outlined above. “Doing good” is not a game. It’s a continuous battle over competing values and interests. It might mean different things to different people. It resists easy measurement. And yet, effective altruism—and indeed any worldview rooted in utilitarianism—gamifies the idea of doing good. Tradeoffs and nuance might disappear in the interest of value clarity: you get the most points by donating to malarial bednets, or becoming vegetarian, or working to prevent existential risks. In adopting this worldview, one runs the risk of instrumentalizing oneself—viewing our lives as being about the achievement of some game-like goal—which in my view can be psychologically damaging and is not the path to a rich and fulfilling life.

Life is not FitBit for hedons.)

[All Work and No Play - Dissent Magazine](https://www.dissentmagazine.org/article/all-work-and-no-play)

dissentmagazine.org

GAMES

4 weeks ago

1 highlight

The world of games media is populated (and paid for) by people who love video games; they tend not to ask, or be interested in, more fundamental questions about what games do—or what they might be doing to us. (The critics I’ve cited above are, unfortunately, not representative of the overall critical culture of gaming.) It’s obviously not the case that everyone who loves role-playing games is an obedient worker, nor are all games rote and uninspired. Every few years, a title comes out that genuinely delights and challenges me in the manner of a great novel or film, and does so by methods endemic to the interactive artform. (Disco Elysium was one of these.) But it’s rare. Usually I spend untold swaths of time playing games whose status as entertainment—much less as art—confounds me, even as I trudge on, checkpoint to checkpoint, level to level. What kind of subject am I being shaped into by these processes? And what kind of political economy demands that sort of subject? What, to be blunt, would I be spending my time doing otherwise?

[Vampire attack! LooksRare vs. OpenSea - Blog](https://www.coinbase.com/blog/vampire-attack-looksrare-vs-opensea)

coinbase.com

PLAYBOOK

2 months ago

4 highlights

enSe

However, usurp Uniswap they did not. Uniswap eventually launched a token of its own (there’s speculation that OpenSea may one day do the same) and has maintained its standing as crypto’s dominant DEX with over $7.5B in TVL today. It’s also worth noting that no contentious hard fork (Bitcoin Cash, Ethereum Classic, etc) or vampire attacker (SushiSwap, Swerve, etc) has ever supplanted an incumbent.

We can look to its vampire attacking predecessor, SushiSwap, for a glimpse into what the future may hold. SushiSwap by many measures has remained relevant after its initial rewards dried up. They continued to innovate and deploy across multiple chains, with nearly $5B in TVL today.

LooksRare’s trading rewards will wind down over the course of the next two years, at which point the marketplace will have to compete on its product and community alone. Whether it can continue to grow its market share without powerful incentives is up to the anonymous team behind it.

[Sufficient Decentralization - by Marc Boiron.docx](https://variant.fund/wp-content/uploads/2022/08/Sufficient-Decentralization-by-Marc-Boiron.docx.pdf)

variant.fund

PLAYBOOK

2 months ago

1 highlight

When implemented properly, they distribute that expectation across a broader group of people who do not have to coordinate with any other groups. This increases the expectation that crypto-asset holders will profit from the efforts of this broader group, and decreases the expectation that profit will come from the initial development team’s efforts, or from those of any other coordinated group. Protocol Development Although tight-knit teams often initially create protocols, they frequently open up protocol development to a willing community of coders after releasing the protocol. The community might modify the existing code or deploy upgraded versions of the protocol. They also may build software that integrates with the protocol, creating greater demand or different use cases for the protocol. To effectively decentralize protocol development, all deployed protocol code should be open source. If not, the community cannot continue building the protocol, or software to run on top of it. Since it is highly likely that the protocol’s initial developers understand the code better variant.fund

[Why Build in Web3](https://hbr.org/2022/05/why-build-in-web3)

hbr.org

PLAYBOOK

2 months ago

6 highlights

In these business models, locking in users and their data is a key source of competitive advantage. As a result, traditional internet platforms typically do not share data even in aggregate — and they make it difficult for users to export their social graphs and other content. So, even if users grow dissatisfied with a given platform, it’s often not worth it to leave.

This can be a valuable approach to sourcing content even for established platforms. Twitter recently introduced a feature whereby users can show NFTs they own in their profiles; Instagram is working on something similar. And for new platforms, the ability to integrate pre-existing digital assets can be critical in resolving what’s called the “cold-start problem” — the reality that it can be challenging for a platform to get momentum early on because of a lack of initial content.

This is a major shift, which could fundamentally change how digital companies operate: Users’ ability to take their data from one platform to another introduces new sources of competitive pressure, and likely requires firms to update their business strategies. If a platform isn’t creating enough value for its users, they might simply leave. And indeed, in Web3, new entrants can explicitly incentivize power users to move to them — for instance, the NFT (for “non-fungible token”) trading platform LooksRare recently launched through what’s called a “vampire attack,” rewarding people for switching over from the dominant platform OpenSea.

All of this means that — at least in theory — it can be much easier to launch a product in Web3

Web3 platforms also have the potential to unlock a novel and especially powerful form of network effect through community engagement and social cohesion. Ownership of digital assets fosters a sense of psychological ownership that can make consumers feel so invested in a product that it becomes almost an extension of themselves. A platform’s users literally become “fans” who form a bond through the shared platform experience — similar to how fans of a sports team or obscure band see themselves as a community.

In sum: Web3 has the potential to unlock a more valuable internet for everyone. New companies can build on Web3 infrastructure to create communities around their brands and product concepts much more easily than in previous iterations of the web. And even established platforms can leverage these forces by plugging into blockchain-based content networks and giving their users some ownership over their data. All of this means that the next era of the web will likely look a lot different — and more open — than the one we’re living with today.

[Progressive decentralization: a high-level framework - a16z crypto](https://a16zcrypto.com/progressive-decentralization-a-high-level-framework)

a16zcrypto.com

PLAYBOOK

2 months ago

4 highlights

Our intention is to help those interested in decentralization think about how to approach the challenge. There is, alas, no one-size-fits-all approach because the precise mechanics of decentralization are very much a function of the specific business context. So this is intended as an introduction – it isn’t a playbook for making decisions component-wise but rather a framework for how to start thinking about the overarching problem.

Our intention is to help those interested in decentralization think about how to approach the challenge. There is, alas, no one-size-fits-all approach because the precise mechanics of decentralization are very much a function of the specific business context. So this is intended as an introduction – it isn’t a playbook for making decisions component-wise but rather a framework for how to start thinking about the overarching problem.

1. Core team. Hire people who are able to set up their work so that it might be possible for external members to take over some of the responsibilities – for example, a community manager who designs the community in a way that allows members to start to self-manage and self-govern. Additionally, invest in upskilling your team with an eye toward decentralization as a long-term target, and of the new technologies and best practices that support those efforts.

And it’s not just about inviting community participation – you have to design the organization in a way that enables people to contribute and rewards them for doing so. This means building robust feedback and engagement channels, together with the accompanying structures and processes. 

[AI And Blockchain Have An Autonomy Problem](https://www.noemamag.com/ai-blockchain-human-autonomy-future/?utm_source=noematwitter)

noemamag.com

AUTONOMY IN GOVERNANCE

4 months ago

6 highlights

This vision elides the fact that political autonomy from external forces of influence cannot be implemented in a broader sociotechnical system without colliding with necessary trade-offs. There may be times, for instance, when the autonomy of one individual or group constraints the autonomy of others. There is no widely agreed-upon vision to fall back on for how to pursue autonomy. However, when the goal is frictionless coordination, the inherent friction of deliberation and feedback necessarily runs counter to the goals of the  system — the time and investment needed to referee unsolved political, ecological and social concerns simply slow the process down. 

On the other hand, blockchain communities imagine technologically mediated, decentralized, rational, voluntary and self-interested coordination games as a process of ongoing experimentation in autonomy via self-governance, with value determined by commodification and outcomes decided by individual benefit, rather than the collective good. 

Yet, both visions fall short, separately or combined, for one core reason: each takes for granted that the goal of autonomy thus presented is worth pursuing. Trustlessness, on the blockchain side, and automation, on the AI side, aim to subsume to the machine the strength and growth borne of cross-community dependence, space for disagreement and deliberation, and human higher-order critical thinking in cooperation and coordination.  

The failures of this approach are already bearing fruit. The more we aim for a future free from human messiness, the more we push humanity away in the present: cast aside data workers whose labor underpins AI systems, cover up knowledge of autonomous system bias and error, dissolve well-intentioned projects into asset speculation and obfuscate the misdirection of present trajectories in visions of future perfection. There is little reason to believe that persisting on this path will yield to better outcomes. 

This must be done by changing our modes of investment and prioritization in the technologies themselves. We can imagine futures that are both humanistic and powerful — and we can bend these technologies toward the actualization of those futures by reorienting toward technology supported by interdependence, rather than driving toward autonomy. 

Imagine AI capabilities instead deployed toward enabling human coordination and communication — activities which have opened up vast new frontiers of human flourishing already, but which clearly have far to go before reaching decreasing returns. Or distributed to communities, such that they are able to contribute to system design and training, to leverage human-machine cooperation to add to the store of human knowledge, rather than subjecting many to living under a centralized machine mandate. 

[Resilience of the Commons: observing “resilience” in the governance of decentralised technology communities](https://kelsienabben.substack.com/p/resilience-of-the-commons-observing?s=r)

kelsienabben.substack.com

AUTONOMY IN GOVERNANCE

4 months ago

13 highlights

I would like to propose here, that it is also a question of resilience, in asking, which social and technical components of a decentralised infrastructure must persist for it to be considered resilient?

Yet, this responsibility for funding “public goods” did not always lie with Gitcoin.

Gitcoin performs an important function in the Ethereum community, in providing a mechanism for the community to coordinate on funding projects, as shared infrastructures and commons goods that are perceived as important to the overall growth of public, decentralised blockchains

Bruno Latour describes all technology as having embedded “scripts” that set norms and mediate behaviours. The script of Gitcoin is “we are a fair, legitimate, public goods funding mechanism for the Ethereum community”. For Gitcoin, this sense of “fairness” is achieved through the transparency of the donation process and decentralisation of decision-making. Yet, socio-technical systems are inherently complex, meaning that behaviour can go “off-script”.

Gitcoin grants round 9 was subject to a “sybil attack”, in which users created “bots” to create multiple, fake identities and spam the grants round with numerous micro donations to some projects. This attack ruined the matched funding allocation mechanism, as donations no longer signalled genuine community interest in supporting the projects that they think are the most important.

It is thought by the Gitcoin team and the community that this motivated people to hijack the system, in the hopes of getting rewarded for each vote in cryptocurrency, after the round

We see the communities’ aspirations for “self-governance”, as independence from external influence emerging in conflict with the necessity of human interventions in crisis, to ensure the social and technical functioning of the system adapts and responds for the ongoing survivability of the funding mechanism itself.

The token delegation process heavily relies on GTC holders understanding the purpose of Gitcoin, and their role in governing it, to decide how best they should delegate their GTC tokens for the GitcoinDAO to be well stewarded.

“Ultimately, every mechanism for allocating resources, whether centralized, market-based, democratic or otherwise, must stand the test of delivering results, or else sooner or later it will be abandoned for another mechanism that is perceived to be better, even if it is less philosophically clean.”.

Gitcoin has undertaken a metamorphosis to transform from a project, into a more decentralised “DAO” institutional structure, yet it is the same ship.

This shifts the focus away from “becoming a DAO” or “decentralisation”, and towards legitimacy via participation and resilience as the ability for the community to continue to function.

The team and governance processes surrounding the funding mechanism have had to adapt significantly, with the entire project transforming into a “Decentralised Autonomous Organisation” to distribute decision-making responsibility away from the core team and into the wallet addresses of the community. Furthermore, technical adaptations have occurred with the introduction of governance tokens are being issued for on-chain voting to manage the allocation of on-chain donations, as well as the introduction of machine learning processes to flag what could be adversarial behaviour to detect and evaluate attacks in future.

It appears that the biggest threat that the Gitcoin team perceives is illegitimacy via being seen as centralised in their decision making and control over the project. Yet, the involvement of the Gitcoin team has been crucial in bootstrapping the project, and guiding its development and evolution towards more transparency, accountability, and community participation. 

[Cargo Cult Science](https://calteches.library.caltech.edu/51/2/CargoCult.htm)

calteches.library.caltech.edu

4 months ago

2 highlights

This man also speaks about a new institution, in a talk in which he was resigning as Director of the Institute of Parapsychology.  And, in telling people what to do next, he says that one of the things they have to do is be sure they only train students who have shown their ability to get PSI results to an acceptable extent—not to waste their time on those ambitious and interested students who get only chance results.  It is very dangerous to have such a policy in teaching—to teach students only how to get certain results, rather than how to do an experiment with scientific integrity.

So I wish to you—I have no more time, so I have just one wish for you—the good luck to be somewhere where you are free to maintain the kind of integrity I have described, and where you do not feel forced by a need to maintain your position in the organization, or financial support, or so on, to lose your integrity.  May you have that freedom.  May I also give you one last bit of advice: Never say that you’ll give a talk unless you know clearly what you’re going to talk about and more or less what you’re going to say.

[Ukraine Holds the Future: The War Between Democracy and Nihilism](https://www.foreignaffairs.com/ukraine/ukraine-war-democracy-nihilism-timothy-snyder?check_logged_in=1)

foreignaffairs.com

FOREIGN AFFAIRS

5 months ago

17 highlights

The basic weaknesses of tyrannies are generic and long known—recorded, for example, by Plato in his Republic. Tyrants resist good advice, become obsessive as they age and fall ill, and wish to leave an undying legacy. All of this is certainly evident in Putin’s decision to invade Ukraine. Fascism, a specific form of tyranny, also helps to explain today’s Russia, which is characterized by a cult of personality, a de facto single party, mass propaganda, the privileging of will over reason, and a politics of us-versus-them

Because fascism places violence over reason, it can be defeated only by force. Fascism was quite popular—and not just in fascist countries—until the end of World War II. It was discredited only because Germany and Italy lost the war.

Russia won the propaganda war the last time it invaded Ukraine, in 2014, targeting vulnerable Europeans and Americans on social media with tales of Ukrainians as Nazis, Jews, feminists, and gays.

tween the sly black suits of the Russian ideologues and propagandists and the earnest olive tones of Ukrainian leaders and soldiers calls to mind one of the most basic requirements of democracy: individuals must openly assert values despite the risk attendant upon doing so.

The ancient philosophers understood that virtues were as important as material factors to the rise and fall of regimes.

Late twentieth-century talk of democracy conflated the correct moral claim that the people should rule with the incorrect factual claim that democracy is the natural state of affairs or the inevitable condition of a favored nation. This misunderstanding made democracies vulnerable, whether old or new.

The current Russian regime is one consequence of the mistaken belief that democracy happens naturally and that all opinions are equally valid. If this were true, then Russia would indeed be a democracy, as Putin claims. The war in Ukraine is a test of whether a tyranny that claims to be a democracy can triumph and thereby spread its logical and ethical vacuum. Those who took democracy for granted were sleepwalking toward tyranny. The Ukrainian resistance is the wake-up call.

Among younger people and on the political left, a deeper unease arose from the lack of a national reckoning over the invasion of Iraq, justified at the time with the notion that destroying one regime would create a tabula rasa from which democracy would naturally emerge. The idiocy of this argument made a generation doubt the possibility that war and democracy could have something to do with each other. The unease with another military effort was perhaps understandable, but the resemblance between Iraq and Ukraine was only superficial. Ukrainians weren’t imposing their own vision on another country. They were protecting their right to choose their own leaders against an invasion designed to undo their democracy and eliminate their society.

But democracy demands “earnest struggle,” as the American abolitionist Frederick Douglass said.

The Greek playwright Euripides understood that the purpose of freedom of speech was to speak truth to power. The free speaker clarifies a dangerous world not only with what he says but by the risk he takes when he speaks.

Russia embodies fascism while claiming to fight it; Russians commit genocide while claiming to prevent it. This propaganda is not entirely ineffective: the fact that Moscow claims to be fighting Nazis does distract many observers from the fascism of Putin’s regime. And before North Americans and Europeans praise themselves for winning the battle of narratives, they should look to the global South. There, Putin’s story of the war prevails, even as Asians and Africans pay a horrible price for the war that he has chosen

Putin’s propaganda machine, like the rest of his regime, is funded by revenue from oil and gas exports. The current Russian order, in other words, depends for its existence on a world that has not made the transition to sustainable energy.

The weakest and the poorest will suffer first. And that is the point. When those who have no voice die, those who rule by lethal spectacle choose the meaning of their deaths. And that is what Putin may do.

Like Stalin in 1933, Putin has taken deliberate steps to risk the starvation of millions. Lebanon relies heavily on Ukrainian grain, as do Ethiopia, Yemen, and the fragile nations of the Sahel.

Nothing in the hunger plan is hidden. At the St. Petersburg International Economic Forum in June 2022, Margarita Simonyan, editor in chief of the state-run network RT, said that “all of our hope lies in famine.” As the skilled propagandist understands, the point of starving Africans and Asians is to create a backdrop for propaganda. As they begin to die, Ukrainians will be scapegoated. This might or might not work. All past fantasies about Ukraine and its foodstuffs were at one time believed by influential people.

Russian propaganda today has an edge in the global South. In much of Africa, Russia is a known quantity, whereas Ukraine is not. Few African leaders have publicly opposed Putin’s war, and some might be persuaded to parrot his talking points. Across the global South, it is not widely known that Ukraine is a leading exporter of food—nor that it is a poor country with a GDP per capita comparable to that of the countries it feeds, such as Egypt and Algeria

If Ukraine can win back its south, the sea-lanes that fed the ancient Greeks will be reopened, and the world will be enlightened by the Ukrainian example of risk-taking for self-rule. In the end, the olive tree will need the trident. Peace will only follow victory. The world might get an olive branch, but only if the Ukrainians can fight their way back to the sea.

[Cryptonetwork Governance as Capital — Placeholder](https://www.placeholder.vc/blog/2019/2/19/cryptonetwork-governance-as-capital)

placeholder.vc

TOKEN ENGINEERING

5 months ago

9 highlights

Capital is, in essence, the power to organize the economic resources of a social system, and its worth a function of how much of those resources can be directed to the holder’s benefit. This understanding reveals the inherent value of cryptonetwork governance as capital, and helps us understand tokens with governance rights as new kinds of capital assets.

Productive and human capital, for example, influence which goods and services are offered in the economy (and thus how income is ultimately distributed), financial capital determines the distribution of purchasing power, and equity capital presides over how a company’s resources are used. Intangible forms of capital also exhibit this quality: political capital, for example, governs the rules of markets, and social capital drives human attention (and thus behavior).

This insight, that capital is governance (and vice versa) leads to the source of its intrinsic value. Whoever has control over a pool of important resources also has the potential to direct some of those resources to their own benefit. So the value of a system’s capital is proportional to the value of the resources it governs.

The two pillars of trust of a cryptonetwork are its cryptoeconomic and governance models. The cryptoeconomic model defines ‘the rules’ of the system (what is the unit of work, how do users pay, how miners are compensated, the token supply model, etc.), while the governance model defines who has the power to change those rules, and under which conditions.

And when that power takes the form of a token, it can be traded, priced and modeled by market. In this context, a network’s ‘assets under power’ include (1) the token itself, which is controlled by the cryptoeconomic policy, (2) productive resources, as controlled by the definition of ‘work’ (e.g. the consensus protocol), and (3) flows of value, as controlled by regulating payment mechanics and other incentives for miners, users and investors. And as the value of these resources grows, so does the value of the capital which governs them.

For example, in Decred, 30% of the block reward is reserved for users who participate in its proof-of-stake consensus layer, and that reward pool is divvied up in proportion to how much DCR each participant has staked. Here, DCR is a form of capital as it has power over how some of the block reward is distributed. But because Decred also allows the PoS layer to vote on the use of its community pool (which is funded with 10% of each block), as well as on protocol upgrades, the value of DCR as a capital asset extends beyond what is connected to block-reward revenues. Such power is harder to quantify, and therefore difficult to price, but remains an important value driver that we might consider a kind of “governance premium”.

The basic principle behind power tokens is that they fuse the features of “utility tokens” and “governance tokens”, which really means the combination of currency and capital – with the capital function being the driver of long-term value.

But for now, the key insight is that what we’re dealing with in the creation of these new assets is the creation of new forms of capital, network capital, that is natively digital, and cheap to distribute – and that’s important.

And ultimately this is a form of governance, in the sense that staking is a mechanism for deciding how income should be allocated across miners. And so, as the value of that income grows with user demand, so does the value of stakeable tokens.

[Foundations+of+Cryptoeconomic+Systems.pdf](https://research.wu.ac.at/ws/portalfiles/portal/19008630/Foundations+of+Cryptoeconomic+Systems.pdf)

research.wu.ac.at

TOKEN ENGINEERING

5 months ago

15 highlights

The microeconomic study of cryptoeconomic networks, as pursued by Buterin and many others, is the most commonly used perspective, as it lies neatly within the overlap of mechanism design in economics and computer science

One weakness of such a computer science perspective is the tendency to view the technology as neutral and to downplay the creators’ responsibility for outcomes [Walch 2019]. This is in stark opposition to the systems engineering literature which places a large responsibility on engineers responsible for design and maintenance of critical infrastructure [Leveson 2016].

A more comprehensive view of cryptoeconomic networks is that they have enabled new types of institutional infrastructure to emerge and will likely continue to foster slow but lasting changes to our social and economic systems which will require legal innovations

However, while many researchers and developers seem to agree that cryptoe- conomic networks greatly expand the economic design space, comparatively few acknowledge that the economic models used to date are performative and their design is subjective, [Virtanen et al. 2018].

Systems theory [Von Bertalanffy 1969] [Meadows 2008] provides a means to describe any system by its structure, purpose, functioning, as well as spatial and temporal boundaries, including its interdependencies with its environ- ments

Complex systems differ from other systems in that the system level behaviour cannot be inferred from the local state changes induced by individual network actors

A cryptoeconomic system such as the Bitcoin network can be described as a special class of complex socioeco- nomic system that is dynamic, adaptive, and multi-scale. Cryptoeconomic networks are dynamic due to the flow of information and assets through the network. Cryptoeconomic networks are adaptive because their behaviour adjusts in response to their environment, either directly in the case of the Bitcoin difficulty controller or more broadly through decisions on the part of node operators. Cryptoeconomic networks are multi-scale because they are specified by local protocols but are defined by their macro-scale properties, as is the case with the local ”no double spend” rule guaranteeing a globally conserved token supply

The interdisciplinary research process includes: (i) identification of relevant disciplines, (ii) mapping research questions to identify the disciplinary parts, (iii) reducing the number of potentially relevant disciplines, (iv) lit- erature review in relevant disciplines and for relevant research questions, (v) developing adequacy in relevant disciplines, (vi) analyzing problems and evaluating insights, and (vii) integrating insights and creating common ground for insights

The interdisciplinary approach narrowed to the scope of economics brings the institutional perspective to the fore- front. Institutional economics is a subset of economics that intersects with political science, sociology, history, management science and cybernetics. It studies the role of formal or informal – and public or private institutions – that are represented by a set of rules, norms, procedure, convention, arrangement, traditions or customs to steer socioeconomic interactions [Chavance and Wells 2008] [Veblen 1973], [Fararo and Skvoretz 1986], [Williamson 2000], [Coase 1937]. Governments, markets, firms, physical infrastructure, and even social patterns such as mar- riage are institutions.

ugh platform economies and associated network effects have driven the internet toward more centralized power structures, platform cooperativism demonstrates that digitalization, when wielded by communities, can be a force for democracy [Scholz and Schneider 2017

Cryptoeconomic networks enable more fluid organizations to formalize over the Internet - around a specific economic, political, or social purpose - commonly referred to as a “Decentralized Autonomous Organizations” or “DAOs” by the crypto-community [Buterin 2014], [Wright and De Filippi 2015]. They reinvent the institu- tional composition of the Internet, allowing distributed Internet tribes to self-organize and coordinate in a more autonomous way - steered by purpose-driven tokens (read more on purpose-driven tokens in section 10.1). The network protocol and/or the smart contract code formalize the governance rules of the network, regulating and enforcing the behavior of all network participants

Tokens represent a part of the state of any cryptoeconomic system and can be seen as their atomic unit [Voshmgir 2020]. The term state refers to a unique set of data (the ledger) that is collectively managed by all nodes in the network. Tokens are a representation of an individualized state of an economic system, including a specific right to change the system state. The existence of a universal state makes tokens provable and durable, and is a solution to the double spending [Nakamoto 2008] of digital values over the public networks

Purpose-driven tokens are tokens that are programmed to steer automated collective action of autonomous network actors in a public network towards a collective goal in the absence of intermediaries [Voshmgir 2020]. They represent complex token systems and require complex system approach [Foster and Metcalfe 2012][Kurtz and Snowden 2003] to be modelled. Purpose-driven tokens that enable complex token systems differ from simple token systems in that they close the loop in so far as the system becomes autonomous and is not being steered by single institutions.

Cryptoeconomic systems are complex socioeconomic networks defined by (i) individual autonomous actors, (ii) economic policies embedded in software (the protocol or smart contract code), and (iii) emergent properties arising from the interactions of those actors with the whole network, according to the rules defined by that software

Cryptoeconomics is an emerging field of economic coordination games in cryptographically secured peer-to-peer network

[Token Engineering Case Studies. Analysis of Bitcoin, Design of Ocean… | by Trent McConaghy | Ocean Protocol](https://blog.oceanprotocol.com/token-engineering-case-studies-b44267e68f4)

blog.oceanprotocol.com

TOKEN ENGINEERING

5 months ago

8 highlights

In previous articles, I described why we need to get incentives right when we build tokenized ecosystems; and introduced ideas towards a practice of token engineering. We can use these tools to help analyse existing tokenized ecosystems, and design new ones. This article does exactly that with case studies in (1) analysis of Bitcoin, and (2) design of Ocean Protocol. Let’s get started!

Its objective function is: maximize the security of its network. It then defines “security” as compute power (hash rate), which makes it expensive to roll back changes to the transaction log. Its block reward function manifests the objective, by giving block reward tokens (BTC) to people who improve the network’s compute power.

Rather, in Bitcoin, it’s quite lumpy: just a single user is awarded in each block interval. But since their chance of getting the award is proportional to the hash rate they’ve contributed, then their expected value is indeed the amount contributed. The Orchid team calls this probabilistic micro-payments.

These are significant benefits. The biggest negative is the higher variance: to have any real chance to win anything at all you need significant hash rate, though if you do win, you win big. However, this higher variance is mitigated simply by higher level mining pools, which have the direct effect of reducing variance. This is cool because it means that Bitcoin doesn’t need even need to do that directly. As usual, we keep learning from Satoshi:)

Why would Bitcoin have this lumpiness (high variance), rather than award every player at every interval (low variance)? Here are some benefits: It doesn’t need to track how much each user contributed. Therefore lower compute, and lower bandwidth. It doesn’t need to send BTC to each user at each interval. Therefore far fewer transactions, and lower bandwidth. An efficiency tweak! In not needing the first two, the system can be far simpler and therefore minimizes the attack surface. Therefore simpler, and more secure.

How well does Bitcoin do towards its objective function of maximizing security? The answer: incredibly well! From this simple function, Bitcoin has incentivized people to spend hundreds of millions of dollars to design custom hashing ASICs and building ASIC mining farms. Others are creating mining pools with thousands of participants. Now the hash rate is greater than all supercomputers combined. Electricity usage is greater than most small countries, and on track to overtake USA by July 2019. All in pursuit of Bitcoin token block rewards! (Not all of it is good, obviou

Besides the ASIC farms and mining pools, we’ve also seen a whole ecosystem emerge around Bitcoin. Software wallets, hardware wallets, core developers, app developers, countless Reddit threads, conferences, and more. Driving much of it is BTC token holders incentivized to spread the word about their token. What’s driven all of this is the block rewards that manifest the objective function. That’s the power of incentives. You called it, Charlie:)

So, we took a step back and gave ourselves the goal of writing proper objectives and constraints. Then, things started to go smoother. With those goals written down, we tried other plug-and-play patterns (solvers). We found new issues that the goals didn’t reflect, so we updated the goals. We kept looping in this iterative process. It didn’t take long before we’d exhausted existing plug-and-play patterns, so we had to design our own; and we iterated on those.

[Towards a Practice of Token Engineering | by Trent McConaghy | Ocean Protocol](https://blog.oceanprotocol.com/towards-a-practice-of-token-engineering-b02feeeff7ca)

blog.oceanprotocol.com

TOKEN ENGINEERING

5 months ago

26 highlights

how do we design tokenized ecosystems? And, how do we analyze and verify them?

We can frame token design as optimization design, then use optimization design methodology. Inspired by software engineering patterns, we can document emerging patterns for token design. Simulation, verification, and design space exploration (CAD tools) for circuit design have helped engineers analyze, design, and verify wickedly complex chips. We can look forward to similar tools for tokenized ecosystems.

Game Theory is a scientific field that analyzes incentives, from an economic standpoint. It has a counterpart in economics for designing (synthesizing) incentivized systems, called Mechanism Design. In fact Mechanism Design is really the field for design of tokenized ecosystem, in theory. Researchers in that field have come up with a lot of great theory over the years, at literally Nobel prize levels of quality. Closely related is Economic Game Theory.

However, traditionally there hasn’t been a good way to reconcile that theory with practice

After all, how often does an academic economist (or anyone, really) get a chance to deploy an economy? Yet this is the exact problem we are confronted with in designing tokenized ecosystems. The closest are likely video game economies and public policy design.

People doing Optimization Design have a tremendous amount of practical experience deploying optimizer systems over the years. Myself included: my first and second startups (ADA, Solido) did exactly that, for use in industrial-grade circuit design.

Many other fields have something to say about token design as well; at the very least in the sense that experts from those fields will find that many of their skills translate well to token design. These include everything from electrical engineering to complex systems, from economics to AI. I list a few below. And of course many of them have roots in good ol’ cybernetics.

Engineering is about rigorous analysis, design, and verification of systems; all assisted by tools that reconcile theory with practice. Engineering is also a discipline of responsibility: being ethically and professionally accountable to the machines that you build, as illustrated by the Tacoma Narrows Bridge viewings and iron rings.

The tokenized ecosystem might give block rewards for an objective function of “maximize hash rate” whereas an EA objective might be “minimize error” in training a deep net.

To test / measure success against the goals (objectives & constraints), a tokenized ecosystem relies on proofs and an optimizer measures fitness using e.g. a simulator.

For example, a Bitcoin node proves that a user was hashing by verifying that the user’s supplied nonce solves the the cryptographic puzzle.

An optimizer might test the goodness of a circuit by running a SPICE simulation of the circuit’s differential equations; simulation results can be verified by testing whether they indeed solved Kirchoff’s Current and Voltage Laws.

In a tokenized ecosystem, network stakeholders such as miners (or users more generally) do whatever it takes to earn block rewards. They jostle about, doing what it takes to get more token rewards. For example, in Bitcoin some agents might design, build, and run ASIC chips to get higher hash rate.

Other agents might pool their existing compute resources. The system does not need to explicitly model all stakeholders in the ecosystem. For example, Bitcoin doesn’t have specific roles for banks or nations or companies; it’s mostly all about the miners.

The system itself cannot control how the agents behave. (Or at the very least, it shouldn’t need to control them.) As such, top-level behavior must be an emergent property of bottom-up actions by agents. This is necessary for tokenized ecosystems; otherwise they’d be centralized! It’s not an absolute must for EAs, but nonetheless a broad set of EAs take this approach for simplicity / elegance or meeting other design goals.

This means the system can only reward or punish behavior, aka carrots or sticks, aka incentives and disincentives. In designing the system, we design what rewards or punishments to give, and how to give them.

In tokenized ecosystems, rewards take the form of block rewards, and punishments by slashing stake. The former is typically the objective function; the latter is some (but not all) constraints.

In EAs, reward and punishment both come down to which individuals are selected to be parents for the next generation. Examples: randomly choose two individuals and keep the best, repeating until full (tournament selection); and chance of selection is proportional to fitness (roulette wheel selection). Crucially, the EA does not need to steer the individuals by e.g. providing a derivative. This is why a tokenized ecosystem is most like an EA, versus gradient-based optimizers that give top-down directives (using gradients to choose new individuals).

Software engineers often use integrated design environments (IDEs) that are free or relatively cheap.

But you can get much more sophisticated. In circuit design, the key tools are for simulation, verification, and design space exploration.

Another is modeling as a set of differential equations (DEs), then solving with a DE solver like SPICE.

Yet in the world of token design, we are building and deploying what we hope to be billion-dollar ecosystems, with barely any tools. It isn’t even 1970 yet. I look forward to the day when we get to this level for token engineering!

I acknowledge a key difference between complex chips and economies: humans in the loop. Chips are closed systems. Humans make the modeling of an economy a lot messier. However, I have hope that we can improve on the status quo of “nothing”, because we build systems every day that involve humans. Here are a few complementary ideas.

Simulation will never be perfect. So, we should ensure that the system itself is evolvable, towards the intent of the community. The tools for this are governance, staking, and more. Governance may be as simple as hard forks, for example to change the objective function or add constraints. Staking helps convert zero sum to positive sum for the community of token holders.

In this article, I’ve described how practices from optimization and other fields could help in designing tokenized ecosystems. It also means that experts from these fields could find their skills to be useful in the brave new world of blockchains. I’m hopeful that designers of video game micro-economies can port their skills. Furthermore, just like in blockchain: many folks from AI, complex systems and more are natural polymaths

I’ve seen this first hand. My own experiences in AI and optimization have been extremely helpful to grok blockchain. Also, I’ve found it easier to ramp up AI people by teaching them the delta between what they know, and blockchain. I simply describe tokenized systems as EAs! To the Artificial Life people, it’s life. To the electrical engineers, it’s feedback control systems. And so forth.

[Can Blockchains Go Rogue?. AI Whack-A-Mole, Incentive Machines… | by Trent McConaghy | Ocean Protocol](https://blog.oceanprotocol.com/can-blockchains-go-rogue-5134300ce790)

blog.oceanprotocol.com

TOKEN ENGINEERING

5 months ago

1 highlight

Arguably, the core feature of tokenized ecosystems, aka public blockchains, is getting people to do stuff.

[Applying Stafford Beer’s Viable System Model to Decentralized Organization | by Kelsie Nabben | BlockScience | Medium](https://medium.com/block-science/applying-stafford-beers-viable-system-model-to-decentralized-organization-ac42e17bf73)

medium.com

AUTONOMY IN GOVERNANCE

5 months ago

4 highlights

Rather than “inventing” organizational governance, the opportunity here is to apply existing frameworks that adopt a computer-aided governance approach to create more resilient, self-governing organizations.

In a recent working paper, we argue that decentralized technology communities are already practicing cybernetic principles without knowing it. The VSM is relevant to decentralized modes of self-organization as the goal is functional autonomy, which can enable a form of collective autonomy.

Stafford Beer articulated the “Viable System Model” (VSM) in his 1972 book ‘Brain of the Firm’ as a management tool to determine the viability of an organization. Applying the VSM is about structuring resilience in an organization — to adapt to changes in environment (variety) and survive, in line with its purpose.

In other words, cybernetics literature provides frameworks for self-governing.

[Engineering Ethics in Web3. Ethics as Mission and Motivation for… | by Michael Zargham | Token Engineering Commons | Medium](https://medium.com/token-engineering-commons/engineering-ethics-in-web3-18d981278018)

medium.com

TOKEN ENGINEERING

5 months ago

18 highlights

Our community is a technology-abled social organization committed to the application of web3 technologies to achieve human-centric outcomes

Much like traditional engineering societies we engage in research, education, and standard setting in addition to designing, building and maintaining technological solutions.

As with any emerging technology there is still a lot of uncertainty around the practice of engineering web3 enabled systems but it is already clear that these systems are deeply entangled with social and economic systems, and thus have the potential for a deep and long standing impact on social institutions.

While it remains unclear where the web3 technology stack will carry our society, we believe that this journey must be undertaken with a values first mindset.

Engineering Values according to Martin, M. & Schinzinger, R. Ethics in Engineering. NY: McGraw-Hill, 1983: (1) a primary obligation to protect the safety of and respect the right of consent of human subjects; (2) a constant awareness of the experimental nature of any project, imaginative forecasting of its possible side effects, and a reasonable effort to monitor them; (3) autonomous, personal involvement in all steps of a project; and (4) accepting accountability for the results of a project.

Engineering Values according to Pinkus, R. L. B, Shuman, L. J., Hummon, N. P., Wolfe, H. Engineering Ethics: Balancing Cost, Schedule, and Risk — Lessons Learned from the Space Shuttle. Cambridge: Cambridge University Press, 1997. “The ethical engineer is one who is competent, responsible, and respectful of Cicero’s Creed II. Cicero’s Creed, engineering’s oldest ethic, directed engineers to place the safety of the public above all else.”

Engineering Values according to Wike VS. Professional engineering ethical behavior: a values-based approach. 2001 “Instead, I prefer a third scheme that focuses squarely on what is to be valued and not on questions of methodology or technical expertise

This scheme proposes that professional engineers (and for that matter, any professionals) share a commitment to these six values: integrity, respect for persons, justice, compassion, beneficence/non-maleficence, and responsibility.”

Investors, Builders, and Early Adopters of web-based cryptographically secured social and economic infrastructure and applications have a wide range of beliefs and values but some key concepts form a common thread: privacy, transparency and agency.

However, the web3 value system is native to the internet, the social institution is extra-national and openly rejects the authority of the state to regulate it. Adherents to the web3 value system adhere to regulations out of pragmatism rather than in deference to those regulatory authorities.

Let us set aside for a moment the interpretation of the engineering profession as a social institution empowered by sovereign nations to design, build and maintain technological infrastructure. Instead let’s look at the engineering profession as a social institution empowered by the public to safeguard their well-being in the face of technologies so broad and deep that they cannot hope to understand it all, and thus cannot make educated judgements regarding their own individual safety.

This reconciles with the agency aspect of the web3 value system; in choosing which systems one opts into it is possible to select for those systems one believes have been created and maintained by persons adhering to a public-wellbeing-first values system.

hough it may take time, we believe history tells us that people want to enjoy the benefits of new technology while the underlying complexity is abstracted away from them. This is only practical if their interests are safeguarded through social institutions like the token engineering commons (TEC).

Upholding a value system is a journey not a destination; it can never be totally reduced to a set of methods and procedures but drawing on methods and procedures is a good place to start.

CPS involves transdisciplinary approaches, merging theory of cybernetics, mechatronics, design and process science

While CPS predates web3, it is also plagued by ethical questions as algorithms take the role of administering policies which directly impact human activities.

However, the growing crisis of AI explainability and prediction algorithms creating self-fulfilling prophecies shows us that a level of techno-reflexivity is required to uphold a public-wellbeing-first values system.

On an even grander scale, our existing public institutions have visibly failed to address systemic challenges such as global warming and acute public health crises.

[Aligning ‘Decentralized Autonomous Organization’ to Precedents in Cybernetics by Michael Zargham, Kelsie Nabben :: SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4077358)

papers.ssrn.com

AUTONOMY IN GOVERNANCE

5 months ago

4 highlights

Yet, literature review and analysis reveals that this particular entanglement of information systems and self-organization is consistent with longstanding conceptual development and practice in the field of cybernetics

Viability is a property of a system such that it has sufficient adaptive capacity to thrive in the face of change; adaptive capacity is characterized according to Ross Ashby's concept of 'variety'.

Purpose is the ability to define and collectively pursue a goal in the sense of feedback control systems.

Building on the control theoretic concepts of observability, controllability, and reachability, we examine the 'governance surface' of an organization and the associated trade-offs between resilience and robustness that emerge in governance surface design

[Tipping the Scale — Real Life](https://reallifemag.com/tipping-the-scale)

reallifemag.com

AUTONOMY IN GOVERNANCE

5 months ago

28 highlights

He believed that cybernetics (what he called “the science of effective organization”) represented a new frontier in institutional and organizational design, a powerful tool that would inevitably be taken up if not by the forces of democracy and freedom then by their enemies, authoritarians of either the corporate or government variety (if not both).

The “electronic mafia” is an evocative and not entirely inaccurate description of current tech company executives and the venture capitalists that fund them.

Their enforcement techniques are more subtle than broken kneecaps and concrete shoes, but nonetheless, in a relative blink of an eye, it has become nearly impossible for most people to live a normal life without paying a kind of protection money in the form of consenting to the control technologies of surveillance, algorithmic feeds, real-name profiles and the like.

“Technology is neither good nor evil, nor is it neutral,” the saying goes, but if the only people successfully dictating how to make use of it are evil, well, it’s not hard to see how that plays out.

A better debate is how we should decide to use communications technology. Rather than accept the status quo — where online behavior is funneled into easily manageable forms to be better captured by a handful of firms — can new social arrangements accommodate what the internet makes possible? Can they enhance human freedom rather than curtail it?

Instead, what matters to Beer is the relationships between different layers of a system: whether the actors at each level have appropriate, timely information from below and above, and the extent to which they are empowered to act. In other words, both capitalist and state socialist organizations can fail by reducing their human agents to mere machines, preventing the flow of information necessary to adapt to a complex and continually changing world.

During the Cold War, Western discussion of this topic was generally preoccupied by the grand debates between capitalism and communism, but the British military was still run on command-and-control principles. The key challenge it faced was timely information flow from the periphery to the command center so that it could effectively distribute resources and manpower across its sphere of engagement.

But Beer is perhaps most famous for orchestrating the Chilean economic experiment under socialist president Salvador Allende: Project Cybersyn, the effort to establish an electronic “nervous system” that could rapidly incorporate economic information from across the vast distances of Chilean geography. The goal was to enable economic planning without the informational gaps and ruinous time lags that had hampered Soviet-style organization.

For example, say a snowstorm destroys a factory: that means a shortage of machine tools, which delays tractor repairs, which causes a wheat shortage. A market economy (as Hayek famously argues in “The Use of Knowledge in Society”) uses prices to transmit and process the information that addresses this problem (the machine tools become more expensive, so other producers start to make more of it in order to make more money, addressing the problem “locally”), but a command economy requires all this information to somehow filter up to be processed by the center.

In a strict command system (either corporate or government), most workers are reduced to using only a fraction of their human capacities: The division of labor means restricting the scope of action. So we have the overnight security guard who contributes only their eyes to the regulation of society, or the call-center employee who can only use their voice, restricted to a tightly specified set of options.

Each of these people, Beer argues, is a complex system capable of an incredible range of information reception, mental processing, and physical action — not to mention specifically human qualities like empathy, creativity, and spontaneity — but the existing economic system ignores those capacities in favor of rendering the complicated and unpredictable world legible to the inefficiently designed organizations that run things.

From today’s vantage point, the language of cybernetics in the previous paragraph — humans understood as “complex systems” and in terms of “capacities” for society’s “regulation” — may appear unusual.

But from about 1950 to the mid-1970s, it was influential among both intellectuals and the general public. Norbert Wiener, the mathematician who coined the term cybernetics in his 1948 book of the same name, was then something of a household name. For Beer cybernetics was essential if human society were to be organized at the scale of something like the U.S. or Walmart, or even the British Army.

Rocketry provides a good analogy: There is a limit to how large and powerful liquid-fuel rockets can be because each additional booster stage adds more weight for the rest of the boosters to lift.

There is a fundamental trade-off between objective, transparent rules and an adversarial population of this size pursuing a range of radically disparate goals.

Beer’s work sought to address and mitigate that trade-off, in search of systems that could be scaled up without generating even bigger problems.

For instance, McDonald’s can produce massive quantities of a very small variety of foods, but with less ability to improvise than an average short-order cook; FDA bureaucratic systems can verify the safety of new medicines but cannot react quickly to rapidly changing threats.

So each human, unlike a bee in a hive or an ant in its anthill, is both a unique individual and a contributor to a robust society. Where the individual ant is essentially worthless and only the collective of ants really counts as an organism, humans and their society are co-equal and intertwined.

This is important because it establishes that human beings, in all our exquisite variety, are the ultimate source of complexity.

In a centralized bureaucracy, the electrician can spot an obvious problem with the plumbing that will flood the entire building and shrug: not my problem

In decentralized neoliberal precarity, the electrician can shut off electricity for non-payment, spoiling the food and rendering the family unable to work their way out of debt and shrug: not my problem. In both cases, the electrician is prevented from adopting a regulatory role, from making local adjustments that would ultimately help the system function better.

Beer’s early work saw big gains from allowing factory workers more opportunity to mingle casually and keep each other abreast of goings-on in different parts of the shop rather than kicking every problem up the command chain and requiring a centralized solution. To scale throughout society, though, some message about the problem and solution should be circulated: If many buildings are facing the same problem, a sectoral manager could take note and figure out what is causing this trend, perhaps some materials shortage facing plumbers.

When it comes to the internet, many of us have adopted a pose of helplessness or indifference. Disempowered from fixing obvious problems like the dozens of entities tracking our behavior or the ads we have to see to conduct standard professional networking, we have outsourced the responsibility to centralized actors. “Whoever opts out of his or her regulatory role is robbing the total system of its power to be stable,” Beer argues.

“We have robbed society of regulatory variety by our passivity.” The electronic mafia who have been pushing the “magnificent bribe” of convenience for technological dependency are more than happy to encourage that passivity. They’d like us all to spend our time buying things and consuming media. Beer would argue that it is key to stop doing that, and instead to take an active role in the regulation of the system.

There are, of course, already Twitter communities, Facebook groups, YouTube fan bases, but these are organized according to platform logic: ferocious competition for fast-twitch attention, with the goal of maximum audience segmentation to better target ads. These organizations are capable of coordinated online action (just go on Twitter and make fun of BTS), but platform affordances make sustained action and tactical diversity nearly impossible.

But some online communities — artist collectives, political activists, nerdy friend groups  — are experimenting with new technological and social possibilities like private Discords and DAOs to address longstanding collective action problems that plague organizations that try to scale up without explicit hierarchy.

Discord is one example of a platform where potentially large groups can break into smaller groups to discuss specific issues, to store information, and to flexibly devolve moderation with less risk of the context collapse and algorithmic attention gamification that happens on corporate platforms.

Similarly, a better society will not miraculously arise automatically through the processes of representative democracy. The only hope is to build it collectively through trial and error and the accumulated efforts of millions of wonderfully complex humans, rather than rolling out the welcome mat for the next generation of electronic mafia. Millions of young people around the world trying to build out alternative technological infrastructures seems like a better bet for improving the internet than voting for Joe Biden over Donald Trump. Our only hope is in our collective capacities to build and regulate a society empowered by modern communication technology. No one else is coming to save us.

[Intimations of a New Worldview - by Brett Andersen](https://brettandersen.substack.com/p/intimations?s=r)

brettandersen.substack.com

RANDOM

5 months ago

33 highlights

The large brain size in human beings was socially and sexually selected based on our ability and propensity to participate in the process of discovering and facilitating non-zero-sum games (which is equivalent to the process of complexification).

complexification

Ever since human beings evolved the ability to talk we have been telling stories about people who were best able to participate in this process. Over time, the general pattern underlying these stories was abstracted out and encoded into the hero mythologies found cross-culturally. 

physicist Lee Smolin

This means that the picture of the universe in which life, variety and structure are improbable accidents must be an outmoded relic of nineteenth-century science. Twentieth-century physics must lead instead towards the understanding that the universe is hospitable to life because, if the world is to exist at all, then it must be full of structure and variety. (p. 16)

He also reasoned that systems in nature must self-organize to this narrow window from the bottom-up, through the interactions of the parts of the system in relation to their environment

As cosmic evolution proceeds, the world is becoming increasingly organized, increasingly functional, and, because life and consciousness emerge from sufficient complexity and information integration, increasingly sentient. (p. 5)

Complexity requires both order and chaos

Once the mixture is completely stirred, however, there is now a state of perfect disorder (i.e., perfect entropy) and there is no longer any complexity.

We will need to know more in order to understand the emergence of hierarchical complexity, i.e., the fact that different patterns emerge at different levels of analysis (e.g., the atomic, molecular, organic, etc.) 

These competing interactions can be as simple as the competition between short- and long-range interactions in a molecular structure or as complex as the competing interaction between the interests of an individual and the interests of the group he is embedded in.

Both Stewart and Wright claim that biological and cultural evolution have a direction and that direction is towards the increasing scope of non-zero-sum games or cooperation

Rather, the scale of cooperation increases when groups find ways to put the selfish interests of individuals in alignment with the interests of the group. This can involve, for example, conferring status benefits onto people who display group beneficial behavior and/or punishing people who display behaviors that harm the group.

Leaders, then, are chosen based on their pro-social temperament and their intelligence.

Finding solutions to problems that satisfy the competing interests of these different groups is combinatorially explosive and evolutionarily important. 

Our ability to realize relevance is largely determined by our ability to properly formulate problems and to re-formulate them when necessary. This is the role of insight. We formulate problems by framing them in particular ways. This frame constrains the kind of solutions that seem viable to us. When we have an insight we break our current frame and adopt a new frame. The new frame allows us to reformulate the problem in such a way that better solutions become viable to us

Those who are best able to engage in the process of relevance realization will also be those who are best able to discover and facilitate non-zero-sum games among their group (i.e., joint utility improvement), as discussed in section 3. 

We use stories to regulate our emotions and govern our behavior; use stories to provide the present we inhabit with a determinate point of reference – the desired future.

The optimal “desired future” is not a state, however, but a process – the (intrinsically compelling) process of mediating between order and chaos;

The hero is narrative representation of the individual eternally willing to take creative action, endlessly capable of originating new behavioral patterns, eternally specialized to render harmless or positively beneficial something previously threatening or unknown.

The peculiar properties of critical systems enlightened in thermodynamics and statistical physics are at the roots of a conjecture stating that systems at the phase transition achieve the highest level of computational capability.

ordered regimes are too rigid to be able to compute complex tasks, as changes are rapidly erased and the flow of information among the units of the system is rather low

disordered regimes are too erratic to provide a reliable response to inputs, as perturbations and noise spread unboundedly, preventing effective information transmission and storage

What does it mean for an agent to “disrupt their own fixed-point attractors”?

Much of psychopathology consists of people getting stuck in ruts (i.e., fixed patterns of behavior) of one kind or another. This can refer to addictions, bad relationships, or a variety of bad habits.

Changing one’s way of life is always accompanied by uncertainty and anxiety. It is all-too-often the avoidance of this anxiety that causes people to get stuck in these various ruts.

The way forward requires the voluntary acceptance, and therefore transcendence, of the suffering that accompanies necessary changes. This voluntary acceptance of suffering is the implicit ideal represented by the mythological hero figure (e.g., Marduk’s voluntary confrontation of the dragon Tiamat, Horus’ voluntary descent into the underworld, the Buddha’s voluntary journey towards enlightenment, and Jesus Christ’s voluntary acceptance of crucifixion).

One of the most common sources of psychopathology is the refusal to pay attention to one’s own accumulating errors. It hurts to recognize that we have made a mistake. It means that we must let go of the part of ourselves that caused us to make that mistake. I have often witnessed people go to great lengths to avoid the pain of admitting to themselves that they made a mistake. This refusal to pay attention to errors can, of course, allow us to avoid suffering in the short term. But in the long term it only allows the problem to grow into something much worse. 

This is simply another way of saying that we must pay attention to our own errors (and equally our successes) so that we can adjust our behavior accordingly.

Paying attention to errors, and adjusting ourselves in response to them, is painful.

The more one engages with nonzero-sum activities the more opportunities for development emerge—new skills to hone, new qualities to develop, new people to engage and collaborate with. The pursuit of nonzero-sum activities is therefore likely to be conducive to maintaining metastable attunement, and therefore to living a flourishing life

In the Newtonian-reductionist worldview, human beings are insignificant players in an indifferent universe. We are small, short-lived specks of dust in comparison to the massive size and time-scale of the universe at large. But the new science of complexity has made clear that the Newtonian worldview has inappropriately privileged space and time. Why should size or longevity determine how important something is?

This means that what we do actually matters in the grand scheme of things.

[Permissionlessness | Internet Policy Review](https://policyreview.info/glossary/permissionlessness)

policyreview.info

AUTONOMY IN GOVERNANCE

6 months ago

16 highlights

This term is much more broadly applicable then just blockchain systems although it is relevant to decentralized systems. It can be conceptualised as a technical attribute, an ideology, and a cultural value, and links to the access, control, governance, entry and exit of an open information system.

A technosocial system is deemed permissionless if it is possible to participate in the use, development, and governance of that system or infrastructure without requiring permission from an authority, by adhering to publicly stated procedures.

The higher-level protocols for displaying websites also adhered to open specifications (“Hypertext Transfer Protocol” or HTTP). This innovation means that anyone is free to read, write, and share digital information across interactive links without needing to seek permission from a central authority or gatekeeper, whereas prior to this, people were limited to local intranets on private networks. A culture of open source software development whereby anyone can verify or modify the underlying codebase helped enable permissionless protocols and innovation

I

iological context, permissionlessness is also a cultural value that emerged in early internet culture. “Permissionless innovation” is a counterculture value from the 1960s and 1970s about no central ownership or control, and not having to ask anyone for permission

). Computer scientist and credited inventor of the World Wide Web, Tim Burners-Lee states that the internet is a force for free and open creativity outside of walled gardens: “It was all based on there being no central authority that you had to go to to ask permission”

These technical and cultural values were strongly amplified by adherents to influential technology communities, such as the free-software and open-source software movements (Stallman, 2002; Raymond, 2000). In these movements, the source code for computer programmes is available for users to modify it for their own use. Some principles of “permissionlessness” have also been defended against political and regulatory institutions by organizations such as the Electronic Frontier Foundation (EFF), which was formed in 1990 to define and protect internet based civil liberties, such as open access to “Pretty Good Privacy” (PGP) digital encryption to rallying against bans on cryptocurrencies (Electronic Frontier Foundation, 2021).

Although

. Although the foundation of permissionless systems is free access for anyone, permissionless systems still need to be governed at higher levels of the technology stack to manage unintended, negative consequences of free access. For example, the ‘World Wide Web Consortium’ (W3C), directed by Tim Burners-Lee, was founded in 1994 to develop open standards to ensure the long-term growth of the Web (W3C, 2021). These consensus-based standards offer recommendations to guide the technical specifications of how the system architecture should be developed. 

Although it involved institutions, some level of intervention, and in some ways partial censorship, this up-stack governance to manage the negative consequences of access to the system helps to ensure the ideal of permissionlessness can persist, as long as governance is polycentric, rather than monocentric.

Permissionless technological infrastructure was essential for the social evolution of the participatory systems that followed. The countercultural ideologies of the early internet influenced blockchain communities (Brunton, 2019). A resurgence of technical, cultural, and scholarly interest in ‘permissionless’ information infrastructures emerged in the wake of the Bitcoin whitepaper in 2008. Although the whitepaper does not mention “permissionless” directly, it makes numerous references to the ideals of the early internet and further develops these ideas of independence for “trust minimization” and “peer-to-peer” transactions without central intermediaries (Nakatomo, 2008). Bitcoin further mitigated the “Byzantine agreement problem”, for agreement in distributed open networks (Lamport, Shostak, & Pease, 1982; Sherman et al., 2018). The ability to coordinate payments without intermediaries inspired an explosion in distributed consensus mechanism research in the field of computer science and economics (Xiao et al., 2020; Neudecker & Hartenstein, 2019). The explosion in innovation and development of public blockchains has led to the resurgence of the technical attribute and cultural value of “permissionless” networks.

Permissionless is characterised by not needing permission to participate. These systems have a permissive boundary, meaning that no organisation mediates or controls access. Participatory systems are characterised by the ability to participate in a system in one or more ways. A common use of the term participatory is participatory governance, “which puts emphasis on democratic engagement, in particular through deliberative practices”

Anarchy: permissionless systems or communities does not mean the absence of rules of governance or lawlessness, but rather changing the architecture of a network to remove gatekeepers and hierarchy in accessing the network (Lessig, 2009). Activities in an anarchic network are still constrained within a surface of action and operate within the bounds of existing norms, including technical standards defined by the protocol, operational practices, and local laws (Daigle, 2014). Yet, being governed by norms and the rules of a protocol does not mean that selfish value-extraction is not possible if people can identify ways to exploit the system (Olson, 1965).

Censorship-resistance: permissionless at the technical level prevents banning someone from a digital network (or deplatforming) for any reason besides not adhering to the rules specified by the protocol (Ali et al., 2021). However, permissionless does not mean that you cannot be excluded for violating the protocol (e.g., when other nodes in a peer-to-peer network blacklist or drop connection to disconnect you from the network). In a social system, this equates to being kicked out of the community if the rules or norms of the community are violated repeatedly, through mechanisms such as graduated sanctions (Ostrom, 200

Exit: permissionless systems, whether cultural or technical, are defined by adherence to certain rules and norms. Those rules and norms themselves may change over time, or participants' preferences for following those rules or norms may change. In the presence of these changes a participant is faced with the options of Exit, Voice and Loyalty (Dowding, 2016). Permissionless systems that have a high cost of exit may be more effective at retaining participants, or this could work adversely, and retain undesirable participants. A particular manifestation of this concept as code is the ‘rage-quit’ mechanism popularized by MolochDAO, which allows participants to take their funds and exit the DAO if they disagree with a governance decision (de la Rouviere, 2021).


