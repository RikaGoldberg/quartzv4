{"Decentralized-Governance/A-Look-into-Autonomy-and-How-DAOs-Use-Working-Groups":{"slug":"Decentralized-Governance/A-Look-into-Autonomy-and-How-DAOs-Use-Working-Groups","filePath":"Decentralized Governance/A Look into Autonomy and How DAOs Use Working Groups.md","title":"A Look into Autonomy and How DAOs Use Working Groups","links":[],"tags":["published"],"content":"Read Full Article\nKey Insights\n\nWorking groups are an organizational structure born out of anarchistic organizations\nAnarchy in this context is not a society with no rules, but rather self-governance based on consensus\nWildfire DAO and Metafactory DAO are real-world examples of DAOs successfully implementing working groups\n\nIntroduction\nThis article is inspired byÂ a tweetÂ where I asked:Â What about DAOs do you want to learn more about? What are your burning questions?\nFrissonÂ replied that heâ€™s interested inÂ understanding how working groups are implemented from a Trustware and Socialware perspective.Â His response generated many likes, providing the social signal that I needed to start researching the topic.\nIf you donâ€™t know what is Trustware and Socialware, check out this simple to understandÂ TikTok videoÂ fromÂ Bankless. In short, Trustware is a term used to describe a DAOâ€™s code and tech (think Moloch and Governor contracts), while Socialware is used to describe the human coordination layer (think chat and emoji polls).\nCoincidentally, around the same time as my Tweet, I was getting ready to start writing an article forÂ BlockScienceÂ about the concept ofÂ Autonomy. The goal of the article was to unpack the term (which, not surprisingly, given its complexity, frequently gets muddled in Web3). I would be using established principles from the field ofÂ CyberneticsÂ â€” specifically a chapter fromÂ Anarchist Cybernetics, a book by Author and Political Theory Lecturer Thomas Swann.\nWhile reading through the Anarchist Cybernetics literature, working groups came up several times. I was surprised to learn that working groups are an organizational structure born out ofÂ anarchist organizations!\n\nAnarchy is a pop culture slogan\nIn the spirit of collaboration and positive-sum thinking, I decided to incorporate my learnings from the BlockScience article in this post.\nIn this post, you can expect to learn about Anarchism and Cybernetics in the context of DAOs, which are emerging self-organizing systems that experiment with organizational structures such as working groups.\nWildfire DAOÂ andÂ MetaFactory DAOÂ are two organizations that successfully use working groups. I reached out toÂ OmnistraMattÂ andÂ DAOFren, active contributors to Wildfire and MetaFactory, respectively, and they both generously agreed to be interviewed for this post.\nWithout further ado, letâ€™s dig in.\nIntroduction to Working Groups and Anarchy\nWorking groups are small teams of people with similar expertise and interests who work together on shared goals. Working groups go by many other names, such asÂ two-pizza teams,Â pods, andÂ swarms.\nAnarchy (and the associated philosophy, anarchism) is a really complex topic that I am not qualified to unpack in this post. However, I will leverage my learnings fromÂ Anarchist CyberneticsÂ to contextualize Anarchy, as an organizational theory, to working groups, emerging organizational structures, in DAOs.\nThe important thing to remember about anarchy is that it is very different from its depiction in popular culture.\nAnarchy, in pop culture, is a catchy slogan. In movies and TV shows, anarchy usually manifests as a belligerent society with no rules, where people swing pick-axes and yell at each other to get what they want.\nIn reality, anarchistic organizations have rules. The rules, however, are not created or enforced by an institution or hierarchical structure.Â Members of anarchistic organizations self-govern to establish rules that all members agree on, or, at the very least, can live with.\nThe rest of the post is structured as follows:\n\n\nFirst, I give a brief history of Anarchistic Organizations fromÂ CyberneticsÂ literature.\n\n\nThen, I present the concept of â€œAutonomyâ€ and how it applies to working groups, using The Occupy Wall Street Movement as an example.\n\n\nThen, I present two case studies (Wildfire DAOÂ andÂ MetaFactory DAO)Â to show real-world examples of how DAOs use working groups.\n\n\nFinally, in the conclusion, I tie it all together and answer the question:Â how are working groups implemented in DAOs from a Trustware and Socialware perspective?\n\n\nA Brief History of Anarchistic Organizations\nA Cybernetics Perspective\nCybernetics, a field that is concerned with Systems Theory and Design, provides useful insights into the structure of self-organized systems\nAutonomy is an important concept that appears frequently in Cybernetics and Anarchistic literature, and has even made its way into the name of the emerging entities that we are building: â€œDecentralized Autonomous Organization.â€\nWe can look to the late Anarchist and Writer,Â Colin Ward, and the Author and Philosophy Lecturer,Â Thomas Swann, to contextualize the concepts of Anarchy and Autonomy in self-organized systems.\nIn his 1966 essayÂ Anarchism as a Theory of Organization, Colin Ward writes:\n\nAnyone can see that there are at least two kinds of organisation. There is the kind which is forced on you, the kind which is run from above,Â and there is the kind which is run from below, which canâ€™tÂ forceÂ you to do anything, and which you are free to join or free to leave alone.Â We could say that theÂ anarchistsÂ are people who want to transform all kinds of human organisation into the kind ofÂ purely voluntary association where people can pull out and start one of their own if they donâ€™t like it.\n\nHe goes on to draw a parallel between Cybernetics and Anarchism:\n\nCybernetic theory with its emphasis on self-organising systems, and speculation about the ultimate social effects of automation, leads in a similar revolutionary direction [as anarchism].\n\nAutonomy\nThomas Swann proposes four different types of autonomy, that are outside the scope of this post. However, I want to present a key takeaway which is that autonomy is relevant to goal-setting. Members of self-organizing systems like a DAO need to have the ability to set their own goals.\nSwann stresses the importance of autonomy in his essayÂ Anarchist Cybernetics. He references Nicholas Walter, one of Colin Wardâ€™s close associates, when he writes this passage about how autonomy, specifically local autonomy, gives a self-organizing system stability:\n\nIn social and political systems,Â it is not through dictatorial command and authoritarian constraint but through freedom and democracy that forms of organization can best meet their goals and remain stable.Â While self-organization in mechanical or electrical systems looks quite different from self-organization in anarchist groups and communities, Walter suggested that there is a crucial parallel between them:Â decision-making must happen at the most local level possible, and cohesion comes through the interplay between the parts of the system, which are themselves fundamentally autonomous.\n\nApplying Autonomy to Working Groups\nAt their core, working groups provide a coordination layer for self-organizing autonomous organizations.\nAlthough we can debate how successful the Occupy Wall Street Movement was, it was nonetheless one of theÂ largest experiments in anarchistic organizationÂ and serves as a good example of working groups in action.\nWorking Groups in the Occupy Wall Street Movement\nIn the Occupy Wall Street Movement, groups of people self-organized and were given a high-level of autonomy. They coordinated with one another through formal and informal communication and were bound by decisions made at the General Assembly or Spokes Council. Very importantly, these institutions were not management oversight but rather forums for consensual agreement and negotiation. All members participated in these processes either directly (in the General Assembly), or through delegates (at the Spokes Council).\nWorking Groups in DAOs\nMichael Zargham, a data and decision systems engineer, and founder ofÂ BlockScience, andÂ Kelsie Nabben, a researcher in decentralized technology communities, write in their paper,Â Aligning Decentralized Autonomous Organizationâ€™ to Precedents in Cybernetics:\n\nThe term â€œDAOâ€ first appeared in relation to blockchain technology in an article by Ethereumâ€™s co-founder Vitalik Buterin in Bitcoin Magazine in 2013. â€œWhat is a corporation?â€ asks Buterin, â€œitâ€™s nothing more than people and contracts all the way down.â€ This conception of DAOs perpetuates the â€œcypherpunkâ€ ideology of anarchic self-organization.\n\nOlly.eth, a DAO Writer and Operator, takes self-organization a step further in his essayÂ DAOs as Novelty Search EnginesÂ where he explains why working groups are important.\nHe writes:\n\nDAOs are novelty search engines which can more efficiently explore a search space byÂ enabling many cooperating teams to collect and integrate stepping stones.\nThis capability suggests a unique and interesting role in the future of innovation.Â Where we end up is unpredictable, but predictably interesting.\n\nOlly goes on to write about local autonomy:\n\nSimilarly, in a mature DAO, individuals will be able to understand a part of the network (local context), but they will not be able to appreciate it as a whole (global context).\n\nI infer that when Olly refers to a mature DAO, he means an organization with more than 10 contributors because the rule of thumb in DAOs, as I have gathered from conducting the two interviews in this article, is that working groups areÂ not necessaryÂ if there are less than 10 contributors. DAOs of this small size need all-hands on deck to ruthlessly focus on their core mission and purpose.\nWorking Groups Case Study #1: Wildfire DAO\nWildfire DAOÂ is a meta-governance initiative that was born out of ğŸ”¥_ğŸ”¥DAO (FireEyes). Fire Eyes was started in July 2020 byÂ James Waugh,Â Cooper Turley,Â Lucas CampbellÂ andÂ Callum GladstoneÂ as aÂ Web3 governance DAOÂ that provides services like token design, incentive mechanisms, governance structures, and launch strategy.\nFromÂ Wildfireâ€™s launch post, itâ€™s clear that they value working groups. Here they write:\n\nWildfire is a meta-governance initiative to connect and align community members from across the ecosystem, creating new squads to tackle token design, governance, and coordination problems in an open and collaborative manner.\n\nI was eager to interview a Wildfire core contributor so I reached out toÂ OminstraMattÂ who kindly agreed to be interviewed for this article.\nThe Wildfire Story\nEarlier this year, Wildfire put out an open application for the genesis squad of core operators. Matt was selected to be one of sixteen core operators.\nNote: At launch, Wildfire used the term â€œsquadsâ€ to refer to working groups, but they have since started to use the term â€œworking groupsâ€ in their formal and informal communications.\nOne of the first things that Matt told me is that Wildfire intentionally did not define an initial plan. The four founders did not tell the working group operators what to work on or how to do their work. The intention was to have the working groups operate in a highly autonomous manner, which means operators could choose their own goals and approach.\nWildfire has four working groups:\n\n\nInfrastructure\n\n\nCreator Economy\n\n\nPublic Goods\n\n\nDeFi\n\n\nEach working group operates independently, but is nested under the umbrella of Wildfireâ€™s overall mission and purpose. As described in Wildfireâ€™sÂ Hello WorldÂ post, the DAOâ€™s mission is two-fold:\n\n\n\nto tailor the next wave of web3 growth [by having a continued voice in prominent governance conversations] in favor of the users and the builders, rather than further enriching the pockets of the few.\n\n\nmake members feel empowered for their contributions regardless of social status or capital holdings â€” creating a new paradigm for digital careers to proliferate.\n\n\n\nIn practice, it works like this: Fire Eyes delegates governance tokens(e.g. $ENS forÂ ENS DAO) to Wildfire Working Group Operators, who go off and participate in the projectsâ€™ governance, and cast votes.\nWhen I asked Matt how he knows which way to vote, he told me that itâ€™s based on a feeling of intuition, acquired through deep experience in DAO governance.\nTo understand why Mattâ€™s answer makes sense for DAOs, letâ€™s think about an ant colony which is a self-organized autonomous system found in nature.\n\nAn ant colony is a self-organized autonomous system found in nature\nAnts communicate with one another through a highly evolved scent mechanism. Individual ants follow their own intuition, which on a global scale creates a super organism that can accomplish great feats â€“feats that an individual ant alone cannot do.\nHowever, as Kevin Munger, Political Science Researcher at Penn State, points out in his articleÂ Tipping the Scale, ants and humans are not an apples-to-apples comparison.\n\nSo each human, unlike a bee in a hive or an ant in its anthill, is both a unique individual and a contributor to a robust society. Where the individual ant is essentially worthless and only the collective of ants really counts as an organism, humans and their society are co-equal and intertwined.\n\nUnlike ant colonies, humans in emerging self-organized systems (DAOs) can communicate with one another through story, lore, and chat platforms like Discord. This makes human intuition robust and complex. So the more experience that Wildfire operators acquire, the more fine-tuned their intuition becomes and the better governance decisions they can make.\nIn practice, Wildfire working groups are nested, operating both globally and locally to collect and disseminate knowledge. On a global level, operators develop their intuition by participating in discussions across the DAO ecosystem. They then share their acquired knowledge locally with their working group. This local knowledge then gets shared globally, and the feedback loop continues.\nMeta-coordinators likeÂ VengistÂ act like a bridge between the global DAO ecosystem and local working groups, helping to disseminate knowledge.\n\nFrom Wildfireâ€™s Discord\n\nFrom Wildfireâ€™s Discord\nShawn16400Â describes meta-coordinators as â€œroaming wizards who connect the dots across DAOs.â€\n\nFrom Wildfireâ€™s Discord\n\nFrom Wildfireâ€™s Discord\nWorking Groups Case Study #2: MetaFactory DAO\nMetaFactoryâ€™sÂ mission is to advance Ethereum by spreading and proliferating Web3 culture. Initially known as SwagDAO, MetaFactory manufactures and sells high-quality sustainable fashion apparel. On their marketplace, you can find drops for top Ethereum projects likeÂ Sushi,Â Bankless, andÂ Gitcoin. MetaFactory is not only innovating on apparel, itâ€™s also revolutionizing organizational structures, working styles, and incentives.\nThe content below is based on an interview withÂ DAOFren, an early contributor of MetaFactory,\nDAOFren told me that working groups at MetaFactory emerged out of necessity. First, there were only two working groups: Business development and Administrative. Then, a third working group spawned: Technical Development. As people started to experiment with drops, more working groups emerged.\nToday, MetaFactory has the following six working groups:\n\n\nBerlin Microfactory\n\n\nWorking Design\n\n\nAdmin/Business Development\n\n\nNYC Microfactory &amp; Fulfillment\n\n\nDevelopment\n\n\nDigital XR Metaverse\n\n\nInformation gets communicated across the working groups through documentation.\nDAOFren stressed the importance of setting good documentation practices and habits early-on (e.g, via designated scholars). Contributors like to use HackMD, Miro, Figma, and Notion. Notion was an important source of truth for project management, but is now being migrated to MFOS: MetaFactoryâ€™s custom developed solution for full-scale, Web3, and physical production needs.\nWhatâ€™s another key way for MetaFactory to communicate information? Memes! Always seize the memes of production and coordination.\nAs MetaFactoryâ€™s co-founderÂ Drew HardingÂ likes to say, â€œYou canâ€™t beat someone who is having fun.â€\n\nFrom MetaFactoryâ€™s Forum\nMemes are used to disseminate narratives and align members across local autonomous working groups, with the DAOâ€™s global shared values.\nThe above meme, for example, reminds contributors that MetaFactory is the real meta and has been leading innovation from the very beginning with projects like cryptographically verifiableÂ KongÂ chips embedded into â€œdigiphysicalâ€ products.\nConclusion\nWhen a DAO grows to more than 10 contributors, its goals also grow. Members need to break up into working groups to effectively coordinate locally, across working groups, and globally, across the broader DAO ecosystem, while maintaining tight communication.\nA DAO with working groups requires meta-coordinators, who act like information lifelines and build bridges across working groups and to the broader DAO ecosystem. Itâ€™s important to note that meta-coordinators are at risk of being spread too thin and, in turn, burning out, especially if the scope of their work is too broad.\nSocialware: peer-to-peer social communicationÂ â€”Â continues to be the primary way that working groups coordinate and share information and knowledge.Â Discord conversations, weekly status meetings, emoji polls, and information repositories like Notion, HackMD, and Figma serve as important feedback loops that enable DAO contributors to experiment and make progress on their autonomous goals.\nTrustware: code and infrastructure â€” is necessary to coordinate governance activities like proposal creation and voting, but it is just one part of the overarching DAO system.\nWithout socialware, DAOs become ineffective and fail.\nThanks for sticking around and job well done on making it to the end of this article!\nHereâ€™s a fun meme to keep in mind as you contribute to DAOs and play positive-sum coordination games!\n\nFrom MetaCartelâ€™s Telegram Group"},"Decentralized-Governance/A-New-Approach-to-Reward-DAO-Delegates":{"slug":"Decentralized-Governance/A-New-Approach-to-Reward-DAO-Delegates","filePath":"Decentralized Governance/A New Approach to Reward DAO Delegates.md","title":"A New Approach to Reward DAO Delegates","links":["Arbitrum","Delegate-Compensation-is-an-important-topic-that-already-has-a-few-case-studies","Delegate-Incentive-System-for-Arbitrum-DAO","Designing-an-incentive-system-for-Arbitrum-delegates-comes-on-the-heels-of-an-ongoing-initiative-to-design-a-grants-program","As-Arbitrum's-governance-scales,-delegate-activity-needs-to-be-maintained-by-incentivizing-them-with-constant,-predictable,-and-attractive-rewards","Delegates-in-a-DAO-are-in-charge-of-funding-public-goods-and-protocol-maintenance-and-upgrades","Arbitrum-can-learn-from-MakerDAO's-delegate-compensation-program,-an-early-and-robust,-albeit-imperfect-program","Optimism-pays-a-relatively-small-amount-for-retroactive-delegate-rewards-based-on-a-very-simple-framework","Arbitrum-needs-to-ask-itself-a-set-of-questions-as-it-designs-the-incentive-system"],"tags":["published"],"content":"Read Full Article\nIntroduction\nArbitrum governance is heating up!\nOn the heels of theÂ pluralistic grants funding frameworkcomes another decentralized governance experiment:Â an incentive (a.k.a. compensation) system for delegates.\nCattin, a representative ofÂ SEED Latam, an Arbitrum delegate, was the first to put pen to paper in early August, writing aÂ thoughtful postÂ in the governance forum about the need for a delegate incentive system.\nSince that post, I went down the rabbit hole of DAO delegate compensation, researchingÂ how several well-known DAOs (MakerDAO,Â Optimism, andÂ Hop) designed their delegate incentive systems. I also jumped on a few calls with Arbitrum delegates, exchanged DMs with the team who facilitated MakerDAOâ€™sÂ incentive system, and shared my learnings in public (here,Â here, andÂ here).\nEveryone whom I spoke to was extremely gracious with their time, offering important insights about predecessor delegate compensation systems, but many also exuded aÂ not insignificantÂ amount of hesitancy and caution.\nA few individuals even stated that they donâ€™t believe delegates should receive any compensation at all!\nInitially, I was taken aback by this sentiment because not paying people for their work seems inherently exploitative. However, as I continued to delve deeper into this topic while writing this article, I began to perceive their concern in a more nuanced light. I started to wonder if their sentiment stems from a fear, specifically, a fear of replicating the wild inefficiencies and bureaucracy of real-world governance systems, where bills areÂ endlessly debatedÂ andÂ senators often evade their responsibilities.\nPerhaps itâ€™s time to give earnest consideration to the skepticsâ€™ perspective and contemplate a fresh approach to designing and implementing a delegate incentive system for Arbitrumm DAO.\nIn this post, you can anticipate gaining insights into the existing DAO delegate incentive systems â€“ understanding their successes and shortcomings. Additionally, I will explore an innovative, unconventional approach for shaping a system tailored to the needs of Arbitrum DAO. This system will go beyond mere participation and communication tracking.\nDAO delegate incentive systems today\nExisting DAO delegate incentive systems occasionally exacerbate real-world issues rather than resolve them. When these systems primarily incentivize delegate participation and communication, neglecting the crucial aspect of executing towards the protocolâ€™s strategic objectives, delegates can inadvertently transform into corporate bureaucrats.\nItâ€™s reminiscent of the theme of the classic movie,Â Office Space.\n\nBill Lumbergh from Office Space\nMakerDAO, Optimism, and Hop all incorporate a substantial amount of procedural and digital documentation within their delegate incentive systems. This isnâ€™t inherently negative; indeed, a certain level ofÂ formal structureÂ is indispensable in DAOs. However, governance teams must deliberate on the fundamental purpose of this structure. In essence, they should consider what behaviors the system incentivizes and whether those behaviors truly serve the protocolâ€™s objectives.\nLetâ€™s look into how MakerDAO, Optimism, and Hop reward their delegates.\nMakerDAOâ€™s delegate incentive system\nMakerDAOâ€™sÂ delegate incentive system, aligned with its overarching governance framework exhibits robustness and a meticulous emphasis on process.\nA dedicated council, calledÂ GovAlpha, is tasked with monitoring delegate participation. This involves quantifying their voting frequency and evaluating the regularity with which they communicate their voting rationale through write-ups. To accomplish this, the council employs a sophisticated math formula in conjunction with customized software to perform these calculations on a monthly basis.\nOptimismâ€™s delegate incentive system\nOptimismâ€™sÂ delegate incentive systemÂ offers a more streamlined approach compared to MakerDAO. With each season, The Optimism Foundation retroactively rewards delegates for their participation in key votes and activities, a determination made by the Foundation itself.\nFor instance, inÂ Season 3, The Foundation designated specific votes and activities that would qualify delegates for compensation. These included participation in the Agora test vote, voting during the Reflection period, engagement in badgeholder elections, and the nomination of a final project for retroactive public goods funding.\nHopâ€™s delegate incentive system\nHopâ€™sÂ delegate incentive systemÂ is more similar to MakerDAO than it is to Optimism, also measuring participation across votes with a math intensive formula and predefined parameters. However, what sets Hop apart from both MakerDAO and Optimism is that delegates self-report their participation, eliminating the need for a committee tasked with monitoring delegate activity.\nA different approach to DAO delegate incentive systems\nAs mentioned in the introduction, the future of DAO delegate compensation is probably not to reward delegates exclusively based on participation and communication. AsÂ Ben Oâ€™NeillÂ points out inÂ his replyÂ to Cattinâ€™s forum post, the delegate incentive system in Arbitrum shouldnâ€™t exclusively incentivize the creation of thought leadership. Instead, it should focus on rewarding behaviors that advance the protocol.\nAn alternative approach would be to incentivize execution of Arbitrumâ€™s strategic priorities, aiming to truly engage delegates. Arbitrum has a community of intelligent and capable delegates, each with diverse expertise and interests spanning many domains. To address the pressing issue of low delegate engagement, it is crucial to create opportunities for delegates to work on solving real problems for the protocol, not just voting and engaging in discussions.\nFor delegates to be engaged, they need to work on initiatives aligned with their skills and interests. The effectiveness of their contributions should be assessed through relevant key performance indicators (KPIs).\nTo gauge the landscape of delegate interests and expertise, we can turn toÂ delegate platform statementsÂ on the governance forum. In particular, the question posed to all delegates seeking candidacy, â€˜What area are you most interested in contributing to?â€™ provides valuable insights.\nCommunity memberÂ inkymazeÂ already did some of this work andÂ postedÂ that he identified two main themes after reading several hundred delegate platform statements. The themes are:\n\n\ngrowth toÂ attractÂ builders, onboard newÂ users, beÂ efficient, andÂ sustainable\n\n\ndecentralization forÂ fairness,Â transparency, to fosterÂ educationÂ andÂ avoid conflicts of interest\n\n\nArbitrum can further refine its strategic priorities by following Benâ€™sÂ recommendationÂ toÂ  have the community outline its top strategic needs and then subsequently invite interested delegates to run in an election, forming groups of multiple delegates working together to execute these needs. Success would be determined by the effectiveness of the delegates in meeting KPIs related to strategic needs, in addition to their engagement in forums and consistent voting patterns.\nThe community doesnâ€™t need to start from scratch to identify strategic priorities. It can use the results from theÂ Jokerace contestÂ and theÂ Mural workspaceÂ from theÂ bi-weekly governance workshops. As well as theÂ four domainsÂ that Questbooks identified for grant funding: gaming, developer tooling on NOVA, new protocol ideas, and education, community, and growth. Delegates can self-select into one of the four domains, building on the skills and interests they shared in their delegate statement.\nConclusion\nIn order to evolve DAO delegate compensation, a new system should incentivize delegates to engage both with the protocol and with other delegates in order to better the protocol, helping it achieve its strategic needs.\nA delegate incentive system for Arbitrum should not exclusively track participation and communication because those metrics donâ€™t necessarily lead to protocol growth or decentralization: two important values for Arbitrum. Although delegates will become more informed and thoughtful about how they vote, they will also be faced with an abundance of paperwork and project management work. Governance will also need to create a committee for tracking delegate activity, adding a layer of bureaucracy.\nA potential approach could involve implementing a low-lift tracking system for delegate participation and communication, recognizing these as fundamental responsibilities. Some delegates may choose to exclusively focus on these aspects, while others may opt to delve deeper into addressing the protocolâ€™s strategic needs. A foundationalÂ nominal compensation levelÂ could be established to reward delegates engaging with the protocol through basic participation and communication. Meanwhile, those delegates dedicated to advancing strategic needs could receive exponentially higher rewards contingent upon their ability to meet Key Performance Indicators (KPIs) effectively.\nNote:Â The latest proposal for a delegate incentive system, as of the time of publishing, can be foundÂ here on Arbitrumâ€™s governance forum.\nResources\nDelegate Compensation is an important topic that already has a few case studies\nDelegate Incentive System for Arbitrum DAO\nDesigning an incentive system for Arbitrum delegates comes on the heels of an ongoing initiative to design a grants program.\nAs Arbitrumâ€™s governance scales, delegate activity needs to be maintained by incentivizing them with constant, predictable, and attractive rewards\nDelegates in a DAO are in charge of funding public goods and protocol maintenance and upgrades\nArbitrum can learn from MakerDAOâ€™s delegate compensation program, an early and robust, albeit imperfect program\nOptimism pays a relatively small amount for retroactive delegate rewards based on a very simple framework\nArbitrum needs to ask itself a set of questions as it designs the incentive system"},"Articles--and--Papers/Credible-Neutrality-and-Foundations":{"slug":"Articles--and--Papers/Credible-Neutrality-and-Foundations","filePath":"Articles & Papers/Credible Neutrality and Foundations.md","title":"Credible Neutrality and Foundations","links":[],"tags":[],"content":"balajis.com/p/credible-neutrality"},"Articles--and--Papers/Defining-Beliefs-on-Social-Media":{"slug":"Articles--and--Papers/Defining-Beliefs-on-Social-Media","filePath":"Articles & Papers/Defining Beliefs on Social Media.md","title":"Defining Beliefs on Social Media","links":[],"tags":[],"content":"www.researchgate.net/publication/363885159_Identity-Defining_Beliefs_on_Social_Media#read"},"Articles--and--Papers/Disambiguating-Autonomy":{"slug":"Articles--and--Papers/Disambiguating-Autonomy","filePath":"Articles & Papers/Disambiguating Autonomy.md","title":"Disambiguating Autonomy","links":["autonomy"],"tags":["Autonomy"],"content":"Published on Medium\nKey Insights\n\nThe concept of autonomy is often misunderstood due to variations in meaning in different contexts\nFunctional autonomy refers to the flexibility an individual or organization has to respond to complexity and achieve goals\nStrategic autonomy is the freedom to set goals, while tactical autonomy is the freedom of action required to achieve those goals\n\nThe term â€˜Autonomyâ€™ is a complex concept that often gets muddled due to variations in meaning in different contexts. In order to unpack and clarify its definition, BlockScience founder and Chief EngineerÂ Michael ZarghamÂ gave a talk onÂ Disambiguating AutonomyÂ in April 2022. Zarghamâ€™s talk draws on the bookÂ â€œAnarchist Cybernetics: Control and Communication in Radical Politicsâ€Â by Thomas Swann to decompose the concept of autonomy and outlines a common language for designing and validating healthyÂ cybernetic organizations.\nThe aim of this post is to clarify this important yet multifaceted concept, by breaking it down into two categories and four types of autonomy. Here, we examine these as relational concepts that have tensions and trade offs and their context in emergent, self-organizing systems such asÂ Decentralized Autonomous Organizations (DAOs).\n\nBreaking down the concept of autonomy, expanding on Thomas Swannâ€™s work in Chapter 5: Control Part II ofÂ Anarchist Cybernetics. Image by Michael Zargham &amp; Jeff Emmett.\nAutonomy is often defined as freedom from external control or influence.Â In practice, no person or system is free from external influence. The term is thus helpful to explore the distribution of power among individuals and groups, with an emphasis on where decision making power is situated and who is impacted by those decisions. The concept of autonomy can be broken down into two categories:Â Functional AutonomyÂ andÂ Political Autonomy. Functional Autonomy is the concept of autonomy that relates to the internal operation of a system, drawn from engineering â€œautonomousâ€ systems, whereas Political Autonomy is the concept of autonomy as freedom from external political influence, drawn from political science.\n\nFunctional AutonomyÂ refers to the degree of flexibility an individual or organization has to respond to complexity pursuant to its goal orÂ functionÂ in an operational sense. Functional autonomy may be described as theÂ autonomy toÂ do something; it relates to cybernetics and systems theory pioneerÂ William Ross Ashbyâ€™s concept of variety, and relates most directly to the actions an individual or group is capable of taking. Building on Thomas Swannâ€™s analysis, we can further distinguishÂ Strategic Autonomy â€”Â theÂ freedom to set goalsÂ â€” fromÂ Tactical AutonomyÂ â€” theÂ freedom of action required to achieveÂ those goals.\nThis may be seen as an analog of theÂ principal-agent relationÂ where the principle has Strategic Autonomy and agent has Tactical Autonomy. When it comes toÂ reasoning about functions, goals or purposes of organizationsÂ it is important to distinguish the authority to define or refine goals from the degrees of freedom exercised pursuing those goals.\n\nIn contrast,Â Political AutonomyÂ refers to an individual or organizationâ€™s authority to make its own decisions without interference by external individuals or organizations, and can thus be consideredÂ autonomy fromÂ outside forces. This can be confusing because an autonomous organization will nonetheless beÂ made up of constituents with diverse preferences, which can sometimes feel like â€˜outsidersâ€™ within the group. Therefore it is common to discuss autonomy as a relationship between actor(s), individual(s) or group(s), navigating the boundaries, constraints and degrees of freedom between them. Relationships within the same scale (individual to individual or organization to organization) are often easier to reason about. For example: when a teenager becomes an adultÂ they gain autonomy from their parents; or when a colony declares independence, it asserts autonomy from the colonizer.\n\nAs discussed inÂ Foundations of Cryptoeconomic Systems, a multiscale perspective is required to capture interscale effects in emergent, self-organizing crypto-economic systems. The concepts ofÂ Individual AutonomyÂ andÂ Collective AutonomyÂ help us to describe interscale relationships (organization to individual and individual to organization) andÂ their respective trade offs. As a member of an organization, an individual accepts a reduction in Individual Autonomy because the organization may place restrictions on those individualâ€™s choices (e.g. make rules or impose processes on the group). What those individuals lose in Individual Autonomy may be offset by an increase in Functional Autonomy; at the group level they may have actions available which were not available individually. When this group has the freedom to make decisions about how the group will act, according to their own processes, the members of that group have Collective Autonomy.\nCoordinationÂ amongst a group of individuals towardsÂ a shared purposeÂ necessitates holding tension between Individual and Collective Autonomy. Individuals who are coordinating can be considered part of an organization. For â€œdecentralizedâ€ organizations, an effective pattern is to associate Collective Autonomy with Strategic Autonomy, where the group sets goals, policies and an initial social contract or constitution, and Individual Autonomy with Tactical Autonomy, where an individual can decide how to pursue those goals within any constraints being enforced by the organization.\nThe next section builds on Swannâ€™s work to further delineate between the different types of Functional Autonomy â€” Strategic and Tactical.\nThe Relationship between Political and Functional Autonomy\nA general example that demonstrates Tactical versus Strategic Autonomy is an autonomous (self-driving) car. The â€œAutonomousâ€ car has Tactical Autonomy, meaning it can act and make decisions based on its environment. However, the car does not (and should not) have the ability to decide on its destination. The destination should be the decision of the passenger, which means the passenger has Strategic Autonomy.\nIn the context of cybernetic organizations, Strategic Autonomy is the ability to determine the primary goals of the organization, measurements or indicators for whether that goal has or is being achieved via performance metrics and KPIs, budgeting, compensation and policy making. Policy and rule setting includes, but is not limited to, processes enshrined in software such as smart contracts. In the context of DAOs, the organization does so as a group, exercising Collective Autonomy to make key decisions about resource distribution,Â algorithmic policyÂ orÂ the parameterization of the monetary policyÂ of its crypto currency for example.\nOnce goals have been established by the collective, members of an organization have the freedom to act within the constraints set, and have Tactical Autonomy â€” the discretion to pursue the group level goals according to their preferences. As long as they keep to the budgets, compensation, performance metrics and/or rules set forth (some of which may be algorithmically enforced), the member has Individual Autonomy. While over short time horizons members are bound to act within these constraints, there also mechanisms through which member adapt those constraints in future cycles or seasons.\n\nThe exercise of Collective Autonomy to make group-level decisions isÂ Governance, and the application of Individual Autonomy toÂ get things doneÂ isÂ Operations. An organization with governance but no operations can be fun but will not accomplish any achievements. Governance tends to evolve slowly and should provide clear expectations for members, whereas Operations move quickly in order to adapt to changes in the environment. An organization with operations but no explicit governance structure tends to fall into informal, unacknowledged, and unaccountable implicit governance structures (what is known in feminist literature and parts of web3 asÂ theÂ tyranny of structurelessness) or simply disperse with the fleeting attention of its erstwhile participants. An organization with governance but no operations can be an enjoyable social group but does not actually set or achieve goals â€” a bit like a community scale â€œArm-Chair Philosopher.â€\nIn the case of DAOs, it is also worth noting that it is not a given that all members have a uniform experience of Strategic Autonomy. For example, they may join after rules are set, and may not yet have access or earned the right to participate directly in the change process. The level of inclusivity with regards to collective decision making varies by organization and there may be different layers of access. You can read more about this in the example of Lido DAO in ourÂ governance assessmentÂ of the organization, where some members have â€œrootâ€ access to the DAO to change core rules via code or Strategic Autonomy, while others maintain only Tactical Autonomy. There is no one size fits all organizational configuration, the specific functions an organization aims to fulfill determines what kinds of governance actually make sense in practice â€” â€œin other words, form follows functionâ€, as discussed inÂ An Analysis of Wildlandâ€™s â€œUser Defined Organizationâ€ Concept.\nApplying Cybernetics to Governance Research in Decentralized Systems\nIn the emerging fields ofÂ cryptoeconomicsÂ andÂ Token Engineering, the notion of a Decentralized Autonomous Organization (or DAO) invokes â€œAutonomyâ€™â€™ in a nebulous way. Disambiguating Autonomy across the political and functional dimensions, as well as the group-level and individual dimensions by acknowledging these different types and functions of autonomy described, provides the language required to navigate important trade-offs in organizational structure â€” with special attention to distinguishing governance from operations.\nWhile DAOs may be a new concept in Web3 and how autonomy expresses and in what dimensions is still being studied, an established field from the 1940s offers a valuable lens through which to view these complex systems.Â CyberneticsÂ is the applied social science of control theory and dynamical systems concerned with â€œinteractions between group-level and individual level processes, as characterized by purpose-driven systems manifest through self-organizationâ€ (Zargham and Nabben 2022). It is a useful field to reason about how to engineer mechanisms and institutions through the construction of rules and is being applied by BlockScience in its work on programmatic mechanism design, as well as governance research and development for emerging self-organizing systems.\nIn our paperÂ Aligning the Concept of Decentralized Autonomous Organization with Precedents in CyberneticsÂ and previous postÂ Applying Stafford Beerâ€™s Viable System Model (VSM) to Decentralized Organization, we examined the balance (with respect to purpose) of operational efficiency with the concentration of political power. We looked at different scales and determined the goal of decentralized modes of self-organization is operational (Functional Autonomy) and group-level political autonomy (Collective Autonomy). Here, drawing from the bookÂ â€œAnarchist Cybernetics: Control and Communication in Radical Politicsâ€Â by Thomas Swann, we expounded the two categories and further outlined four types of autonomy and their relational aspects to support more precision and depth in the design and validation of complex systems such as DAOs.\nBy examining Tactical, Strategic, Individual and Collective Autonomy, how they relate to the existing literature on cybernetics, and how they are expressed in DAOs, we aim to foster more effective dialogue for designing and validating healthy and resilient socio-technical systems. In doing so, we can acknowledge the depth of the topic and understand the relational aspects and trade-offs that exist when designing and analyzing institutions and the construction of their rules.\nWe look forward to continuing research in this domain, documenting and sharing applied learnings from our work, and collaborating with leading experts to continue to expand the dialogue and improve systems design and analysis in these new and emerging fields.\nArticle written byÂ Michael Zargham,Â Jessica Zartler,Â Kelsie Nabben,Â Rika GoldbergÂ andÂ Jeff EmmettÂ with special thanks toÂ Thomas Swann, whose book â€œAnarchist Cyberneticsâ€ helped to inform this research, andÂ Eric AlstonÂ for his ideas and citations."},"Articles--and--Papers/Fully-Diluted-Value-(FDV)":{"slug":"Articles--and--Papers/Fully-Diluted-Value-(FDV)","filePath":"Articles & Papers/Fully Diluted Value (FDV).md","title":"Fully Diluted Value (FDV)","links":[],"tags":[],"content":"Source: www.coingecko.com/learn/what-is-fully-diluted-valuation-fdv-in-crypto\nWhat Is Fully Diluted Valuation (FDV)?Â \nFully diluted valuation (FDV) is the total value of a cryptocurrency project considering all of its tokens thatÂ are in circulation. It is used by investors to gauge the future potential of the project, just like the total number of issuable shares in the stock market.Â Â \n\nKey Takeaways\n\n\nFully diluted valuation (FDV) is the total value of a cryptocurrency project assuming all of its tokens are in circulation.\n\n\nThe total supply of tokens may change due to the minting of new tokens, or due to token burning, which removes tokens from circulation.Â \n\n\nFDV is calculated using the formula Token Price X Total Supply, which gives a projection of the cryptocurrencyâ€™s market cap when all tokens are in circulation.\n\n\n\n\nHow much a cryptocurrency projectâ€™s token grows in value is the result of its technological and marketing progress. The general idea is that a technologically far-reaching project is well on its way to exponential growth. While this might be true, the token generation and distribution scheme as well as other factors contribute tangibly to this progression, all of which could potentially hinder this progress if not done well.\nAn increasing token supply might offset the demand and supply conditions. When the supply increases against an unchanged demand, a decrease in price per token could occur as a result of new tokensÂ dilutingÂ the total market cap. To stay ahead of this situation, a projectâ€™s fully diluted valuation (FDV) is an important data point to consider.\nUnderstanding Fully Diluted Valuation (FDV) and Why It Is Important\nFully diluted valuation is a statistical representation of the maximum value of a cryptocurrency project, assuming all of its tokens are already in circulation. It gives investors a view of the project beyond the given point.\nFor most cryptocurrency projects, the total token in circulation could vary constantly. Total tokens in circulation increase as more tokens are generated through mining, rewards for staking or providing liquidity, the release of vested tokens, or minting of new tokens. For deflationary tokens, total tokens in circulation decrease as tokens getÂ burnt.\nThe practice of releasing a small portion of the maximum supply of its token at launch is becoming more popular in the crypto space. With a relatively small number of tokens in circulation, these projects are presumed to be â€˜undervaluedâ€™ considering the current market cap and fundamentals.\n\nSource:Â Dallas.Epperson\nAs more and more tokens are released and introduced into the market, the value per token may start to drop if there isnâ€™t a relative increase in demand. Investors who fail to consider these future supply changes might suffer losses as more tokens are sold into the market. The FDV is a simplified mathematical expression that presents data that averts this scenario.\nHow to Calculate Fully Diluted Valuation\nThe FDV considers all tokens in supply (totalÂ supply) and not only the circulating ones. The token in supply can be obtained from the projectâ€™s documentation or CoinGeckoâ€™s tokenomics page (more on that later). This data can also be obtained from the smart contract details of tokens minted on smart contract blockchains.\nA cryptocurrency projectâ€™s fully diluted valuation is obtained by multiplying the current price per token by the tokenâ€™s total supply.\nFully Diluted Valuation = Token Price X Total Supply\nThe total supply includes the tokens that are in circulation and the tokens pending distribution, excluding any coins that have been burned (removed from circulation). It is comparable to the total number of outstanding shares in the stock market. The fully diluted valuation gives a projection of the cryptocurrencyâ€™s market cap assumingÂ all tokens (except those burned)Â are in circulation.\nSource: CoinGecko\nFor instance, the value of eachÂ EVMOS tokenÂ is $2.70 (at the time of writing), and the maximum and total supply is 1 billion tokens. Taking this into consideration:\nEVMOS FDV = 2.7 x 1 Billion  \nÂ  Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  = 2.7 Billion\n\nSource: CoinGecko\nThe information from CoinGeckoâ€™sÂ EVMOS tokenomics pageÂ shows various token allocations including 32% of the total supply reserved for staking rewards and another 8% allocated for the EVMOS Rektdrop program (token airdrop). Some of these allocations are still vested and will be released in the future.Â \nStaking rewards are claimed over time by users who staked their tokens on the platform. As stakers claim their rewards, the supply of tokens will increase as more tokens are brought into circulation. The Rektdrop program runs until 30th September 2022. During this time, eligible members can claim tokens allocated to them, the circulating supply will increase as this happens.\n\nSource: CoinGecko\nThe supply schedule above gives a view of the complete token generation and distribution timeline. The market cap doesnâ€™t take the vested tokens into account. If the total supply was already in circulation and the price per token stayed the same, the market cap would vary considerably from the current figures.Â This is reflected in the fully diluted valuation (over $2.6 billion) shown on CoinGeckoâ€™s token page.\nCoinGeckoâ€™s Fully Diluted Valuation Toggle\n\nSource: CoinGecko\nPro tip:Â Toggle â€œShow Fully Diluted Valuationâ€ button on CoinGecko to make all tokenâ€™s FDV instantly accessible.\nCoinGeckoÂ introducedÂ FDV toggle that allows you to view the fully diluted valuation (FDV) of every cryptocurrency listed on its asset tracking platform. You can view the fully diluted valuation of a cryptocurrency by toggling â€œShow Fully Diluted Valuationâ€ as indicated above. The fully diluted valuation is also shown on the individual token pages.\nFor some cryptocurrencies, there are no FDV statistics because these tokens do not have a max supply.\nWeâ€™ve also recently released a new metric (circled in blue in the image above) called â€œMarket Cap / FDVâ€. This lets you track the proportion of current market capitalization compared to the FDV. The closer the Market Cap / FDV is to 1, the closer the current market capitalization is to its fully diluted valuation. Through this feature, youâ€™ll be able to tell how far (or near) the coin is from its full unlock with all coins available to the public."},"Articles--and--Papers/LVR-Quantifying-the-Cost-of-Providing-Liquidity-to-Automated-Market-Makers":{"slug":"Articles--and--Papers/LVR-Quantifying-the-Cost-of-Providing-Liquidity-to-Automated-Market-Makers","filePath":"Articles & Papers/LVR Quantifying the Cost of Providing Liquidity to Automated Market Makers.md","title":"LVR Quantifying the Cost of Providing Liquidity to Automated Market Makers","links":[],"tags":[],"content":"Source: a16zcrypto.com/posts/article/lvr-quantifying-the-cost-of-providing-liquidity-to-automated-market-makers/\nThere are two types of participants in an automated market maker (AMM): traders, who exchange one of the AMMâ€™s tokens for another (as a running example, say ETH and USDC); and ==liquidity providers (LPs), who provide tokens to the AMM in the first place, generally in exchange for a share of the trading fees.\nWhen does it make economic sense to participate as an LP? When does the benefit exceed the cost? The benefit side of this comparison is easy to understand: revenue from shared trading fees, plus in some cases additional token rewards. This post summarizes a new way to think about the cost side, which centers around a quantity that we call LVR (â€œloss versus rebalancing,â€ pronounced â€œleverâ€). Weâ€™ll say more about LVR and its implications for LPs and AMM designers below, but first letâ€™s review how AMMs behave as market prices evolve.\nArbitrage and adverse selection in AMMs\n==Liquidity providers in automated market makers suffer losses fromÂ adverse selection, which is part of the price of doing business as an LP. By virtue of offering to take either side (buy or sell) of a trade at a given price, every LP in an AMM runs the risk of taking the wrong side of a trade by a trader with better or more recent information about a tokenâ€™s market price. For example, if the price of ETH on the open market suddenly increases, a speedy arbitrageur may buy ETH from an AMM (at a stale, lower price) and resell it on a centralized exchange like Binance (at the new, higher market price), pocketing a profit. Because there are only two types of participants in an AMM, profit to traders must correspond to losses to LPs.==\nTo reason about the cost of liquidity provision, and thereby inform both LP participation decisions and AMM design, letâ€™s start with the simpler question of assessing the past. Suppose we just finished supplying liquidity to an ETH-USDC AMM. In hindsight, was this a good idea? Suppose we deposited 1 ETH and 1000 USDC into the AMM, and upon withdrawal received 0.5 ETH and 2000 USDC. (In most AMMs, what you get back may differ from what you put in, depending on how the market price of the AMMâ€™s tokens have moved in the meantime.) Suppose further that it was a really good month for ETH, with the market price jumping from 1000 to 4000 over the course of the month. In this case, the decision to provide liquidity would have doubled your money from a 2000-value portfolio on deposit to a 4000-value one upon withdrawal.\nThis may seem like a great move, but this is sloppy thinking. ==Providing liquidity to the AMM involved holding some amount of ETH for the month. Given that the price of ETH quadrupled during the month, pretty muchÂ anyÂ strategy that involved holding some ETH would look pretty great in hindsight.==\nThe sharper and more important question is: how did the specific strategy of AMM liquidity provision compare to all the other ways that you could have â€œgone long ETHâ€? Equivalently, how does the decision look after setting aside the profits (or loss) resulting purely from the evolution of the price of ETH?\nThe simplest way to bet on an increasing ETH price is to â€” wait for it â€” buy some ETH and hold it. And in our running example, that strategy would have resulted in an end-of-month portfolio (still 1 ETH and USDC 1000, but now with an ETH price of 4000) worth 5000, a full 1000 more than what was withdrawn from the AMM. ==This gap of 1000 is an example of what is often referred to as â€œimpermanent lossâ€ or â€œdivergence loss.â€==\nThe problem with impermanent loss\nWhile impermanent loss does at least compare LP profits to what could have been made under a reference strategy, it fails to isolate the adverse selection costs faced by AMM LPs. To see this, letâ€™s change our running example so that the price of ETH is 1000 at both the beginning and the end of the month. ==In this case, in most AMMs, youâ€™ll get back the same mix of tokens as in your initial deposit (holding, in effect), which means that the impermanent loss will be zero. ==This is true whether the ETH price stayed constant all month or jumped around before returning to 1000.\nThe independence of impermanent loss on the price trajectory (other than its initial and final values) should strike you as fishy. For example, weâ€™ve already discussed arbitrage on AMMs, whereby traders profit at the expense of LPs. It would seem, then, that LP costs should be increasing in the number of opportunities for AMM arbitrage. And the frequency of such opportunities is very different if the price stays the same (no arbitrage) versus if it jumps around a lot (lots of arbitrage).\nIntroducing LVR\nWe propose a new way to think about the costs suffered by the LPs of an AMM, which centers around a quantity that we call LVR (â€œloss versus rebalancing,â€ pronounced â€œleverâ€). LVR can be interpreted in several different ways (which is generally a good sign for a definition). The one we highlight here is as an alternative to impermanent loss that uses a more appropriate and nuanced reference approach, rebalancing. (Another interpretation of LVR is as the loss to an LP after appropriately hedging its market exposure to the price of ETH. Still another is as the best-case profits that could be made by arbitrageurs.)\nRebalancing is AMM-specific, so letâ€™s introduce it in the canonical special case of the constant-product market maker (CPMM) that was made famous by Uniswap (v1 and v2). The special case of a two-token CPMM â€” also known as an â€œxy=kâ€ curve â€” maintains reserves of two tokens, say x units of ETH and y units of USDC. The spot price â€” the price of an infinitesimal trade â€” is defined as y/x, which has the effect of equalizing the market value of the two reserves. (In this sense, such an AMM effectively carries out a rebalancing strategy.) In practice, this spot price is defined implicitly by allowing only trades that leave that product xy of the two token quantities invariant.\nLVR can be defined on a trade-by-trade basis, so letâ€™s look at a single trade. Consider a CPMM with 1 ETH and 1000 USDC, and suppose that the market price of ETH jumps suddenly from 1000 to 4000. We expect some arbitrageur to buy 0.5 ETH from the CPMM at an effective per-ETH price of 2000 USDC, thereby keeping x*y constant while moving the spot price to 2000/0.5=4000 USDC/ETH (and equalizing the market value of the two reserves at $2000).\nHereâ€™s the reference rebalancing, starting from the same initial portfolio of 1 ETH and 1000 USDC: copy the CPMMâ€™s trade (meaning sell 0.5 ETH, just like the CPMM) butÂ _execute it at the current market price of 4000_Â (e.g., on Binance). Because this alternative strategy results in a portfolio worth 1000 more than that of the CPMM (5000 vs. 4000), we say that the LVR of this trade is $1000.\nContinuing the example, suppose the price of ETH suddenly jumps back down to 1000. The CPMM will return (post-arbitrage) right back to its original state of 1 ETH and 1000 USDC, in effect buying back the same 0.5 ETH for the same per-ETH price of 2000 USDC. The rebalancing reference strategy copies the trade (buying 0.5 ETH) but executes it at the market price (1000). The market value of the rebalancing strategyâ€™s portfolio is now 1500 more than that of the CPMM (3500 vs. 2000), with the second trade contributing an additional 500 to the cumulative LVR.\nThis calculation is intuitively satisfying: unlike impermanent loss, LVR depends on the price trajectory (LVR is 0 if the price stays constant but not if it jumps up and then back down) and accumulates trade-by-trade (as every trade might be on the wrong side, leading to additional adverse selection costs).\nLVR: A general definition\nAfter seeing the preceding example, the general definition of LVR should not surprise you: given an arbitrary sequence of trades on an arbitrary AMM, the LVR of the sequence is the sum of the losses incurred by executing the trades via the AMM rather than on the open market. Each term of this sum is of the formÂ a(p â€“ q), whereÂ aÂ denotes the quantity of ETH sold in the trade (e.g., in our first and second trades above, 0.5 and -0.5),Â pÂ denotes the market price at that time (above, 4000 and 1000), andÂ qÂ denotes the per-unit price of the AMM trade (above, 2000 and 2000).\nA variant of the definition is to rebalance periodically (e.g., hourly or daily) rather than trade-by-trade, in effect batching transactions and copying the net trade of each batch. This variant can simplify the empirical analysis of LVR, and is arguably more natural in the hedging interpretation of LVR mentioned above.\nReasoning about the past â€¦\nLVR isolates the adverse selection costs borne by an LP. Was a decision to provide liquidity a good idea in hindsight? To first order, this question boils down to whether the fees collected exceeded the LVR suffered, and thus is typically easy to answer using publicly available data (e.g., the on-chain record of an AMMâ€™s trades and historical price data on Binance).\nâ€¦ and about the future\nTo reason about future rather than past LP decisions, we cannot rely directly on data and must adopt some mathematical model of how prices might evolve. (Remember that LVR depends crucially on the price trajectory.) We could use a variety of different models, but perhaps the most natural starting point is the standardÂ Black-Scholes modelÂ from finance, with the price of ETH evolving continuously according to a geometric Brownian motion (with respect to a suitable martingale measure).\nIf youâ€™re unfamiliar with this model, the key thing to know is that it has essentially only one important parameter, the price volatility Ïƒ. If Ïƒ=0 the price stays constant, while if Ïƒ is large, the price jumps around wildly. If youâ€™re thinking of returns as a random walk, Ïƒ can be loosely interpreted as the typical length of a step.\nLVR can be characterized in this model precisely. Because LVR accumulates trade-by-trade, and because this is a continuous-time model with trades happening all the time, LVR accumulates as an integral of the instantaneous LVR. Instantaneous LVR turns out to scale quadratically with Ïƒ and the current market price, and linearly with the marginal liquidity of the AMM at that price.\nThis mathematical characterization may sound slightly intimidating, but many of the common AMMs are so simple that LVR is given by an elementary closed-form formula.\nFor example, with a CPMM, the instantaneous LVR, when normalized by the CPMMâ€™s market value, turns out to be exactly ÏƒÂ²/8. Plugging in numbers, if a Uniswap v2 ETH-USDC pool has a daily volatility of 5%, then according to our model LPs lose 3.125 bps to LVR every day (for a roughly 11% loss annually). Will fee revenue compensate for this loss? The answer depends on the trading fees and trading volume. For example, if this AMM charges a fixed 30 bps trading fee, then LPs will break even provided the daily volume is roughly 10.4% of the AMMâ€™s assets. Had the daily volatility been 10%, the required volume would have been four times as high. (Remember that LVR scales quadratically with Ïƒ.)\nImplications for AMM designers\nLVR is important not only for potential liquidity providers but also for AMM designers. An AMM can be successful only if it has happy LPs, which means that fee revenues need to scale with LVR.\nOne implication of our work is that, because LVR depends on volatility and fee revenue on trading volume, AMMs should consider dynamic fees that adjust with volume, volatility, or empirically observed LVR. A second is that AMM designers should investigate methods for minimizing LVR (and hence the LP incentives required), for example by incorporating a high-quality pricing oracle to quote closer-to-market prices. Next-generation AMMs are already exploring these and related ideas, and we canâ€™t wait to see how it plays out.\n\nFor deeper technical analysis and discussion of LVR, please see our original paper, â€œAutomated Market Making and Loss-Versus-Rebalancing.â€ AndÂ hereÂ is Tim Roughgarden giving a talk on LVR atÂ SBCâ€™22.\n\nJason MilionisÂ is a Ph.D. student in the Computer Science Department at Columbia University, where he is advised by Christos Papadimitriou and Tim Roughgarden. He is broadly interested in Game Theory, especially in conjunction with Machine Learning, and Decentralized Finance (DeFi).\nCiamac MoallemiÂ is the William von Mueffling Professor of Business in theÂ Decision, Risk, and Operations DivisionÂ of theÂ Graduate School of BusinessÂ atÂ Columbia University.\nTim RoughgardenÂ is a Professor of Computer Science and a member of the Data Science Institute at Columbia University, and Head of Research atÂ a16z crypto.\nAnthony Lee ZhangÂ is an assistant professor of finance at the University of Chicago Booth School of Business. His research covers topics such as banking and financial intermediation, household finance, money markets, housing markets, and crypto/DeFi.\nEditor: Tim SullivanÂ @tim_org"},"Articles--and--Papers/Love-vs.-Fame":{"slug":"Articles--and--Papers/Love-vs.-Fame","filePath":"Articles & Papers/Love vs. Fame.md","title":"Love vs. Fame","links":["Love-social-media-products-enable-people-to-connect-more-intentionally-with-another-and-are-often-marked-by-bidirectional-relationships","Fame-social-media-products-are-one-directional-relationships-otherwise-known-as-\"followers\"","The-business-model-of-fame-products-is-to-keep-users-engaged-for-as-long-as-possible-by-continuing-to-show-them-new-content","The-dichotomy-between-love-and-fame-products-is-what-differentiates-social-networks-from-social-media","Crypto-enables-the-creation-of-new-types-of-networks-\"socioeconomic\"-networks-which-are-ownership-networks-(versus-purely-social-network)"],"tags":["decentralized_social_networks"],"content":"Summary\nLi Jin makes the argument that there are two types of social network products: love and fame. Love products, such as Whatsapp, iMessage, and Facebook allow you to talk to your existing connections, maintaining those connections. Fame products are those where you find new connections/discover new people.\nThe business model of love products is subscriptions. Eg. Discord or Twitch.\nIs Disord a love product? I think of Content Guild, Optimism, etc. I should feel like I know these people. Hmm the distinction btwn love &amp; fame seems to not be as black/white as Li Jin makes it. Bc I use â€œfameâ€ products such as Twitter for love as well. I actually know people. Hmm I know the influencers. Normies donâ€™t know influencers personally.\n(my two cents: Iâ€™ve heard that fame platforms like Twitter enable you to feel closer than ever to people who you admire/follow, but you donâ€™t actually know them. Like schoals research or the goodreads person, though the TG stream I actually feel close to him. Iâ€™m his fan.)\nNotes\nLove social media products enable people to connect more intentionally with another and are often marked by bidirectional relationships\nFame social media products are one directional relationships otherwise known as â€œfollowersâ€\nThe business model of fame products is to keep users engaged for as long as possible by continuing to show them new content\nThe dichotomy between love and fame products is what differentiates social networks from social media\nCrypto enables the creation of new types of networks â€œsocioeconomicâ€ networks which are ownership networks (versus purely social network)\nQuotes\n\nOn the love side of the spectrum are products that focus on deepening connections with others. Examples are iMessage, WhatsApp, early Facebook, and Discord. The value proposition is connecting more intentionally with others, cultivating existing relationships, and intensifying affinity. These products are often marked by bidirectional relationships, like friendships on Facebook or iMessage. When users use a product like Discord or WhatsApp, they usually do so for a particular community or personâ€”not to discover new content. These products reinforce this value proposition by featuring a deterministic algorithm (if person A sends something to person B, the other person will always receive it).\n\nFame products are where you can discover new people. Twitter has become more of a fame product.\n\nOn the fame side of the spectrum are products that help users get exactly that: fame or reach. These products are built around discovery of new content and creators. Examples of fame-centered social products include YouTube, Instagram, TikTok, and Twitch. ==These products feature one-directional relationships (or â€œfollowersâ€). Influential users professionalize, becomingÂ creatorsÂ and reaching ever-larger audiencesâ€”a dynamic thatâ€™s not present on bidirectional social networks==. Products on this side of the spectrum feature probabilistic algorithms, where content gets shown depending on the likelihood of engagement, so users arenâ€™t guaranteed to reach their followers.\n\n\nHowever, fame-based products have more uncapped network effects: users can be shown content from anyone, and utility continues to improve as more users join. Under the dominant business model of advertising, keeping more users engaged for more time is the north star goal, and the fame-driven model is more advantageous for scaling usersâ€™ attentionâ€”and revenue.\n\n\n==The dichotomy between these two ends of the spectrum could be summed up asÂ social networkingÂ vs.Â social media.\n\n\n==I often hear people say they feel that, on a broader level, social networking is moving toward social media; apps that once focused on friends now focus on entertainment, and everyone is expected to be a creator now. Instagram, once used for keeping up with friendsâ€™ lives, is now used in large part to follow creators and brands.\n\nA mix of both types creates retention.\n\nDoes volume matter for love products? Probs not?\n\n==Social networks featuring bidirectional social graphs hit a ceiling of network effects once users reach the limit of who they know.\n\n==Zooming out, the biggest outcomes in social have historically arisen from the creation of new networks: from IRL friend-based networks (Facebook) to interest-based (Reddit, TikTok) to knowledge-based ones (Quora).Â Thereâ€™s an opportunity for crypto to take a crack at building a new type ofÂ ownership-basedÂ network that leverages onchain assets as the basis for new communities.Â We refer to this idea as aÂ socioeconomic networkÂ (versus a purely social network).\n\n\n==I believe new business models will emerge to support different and smaller networks than what can viably exist under ad-based models, fulfilling humansâ€™ need for social status and connection in novel ways.\n"},"Articles--and--Papers/Love-vs.-fame,-A-framework-for-social-applications":{"slug":"Articles--and--Papers/Love-vs.-fame,-A-framework-for-social-applications","filePath":"Articles & Papers/Love vs. fame, A framework for social applications.md","title":"Love vs. fame, A framework for social applications","links":[],"tags":[],"content":"Source: www.lisnewsletter.com/p/love-vs-fame-a-framework-for-social"},"Articles--and--Papers/Measuring-Bitcoin's-Decentralization,-Coinmetrics":{"slug":"Articles--and--Papers/Measuring-Bitcoin's-Decentralization,-Coinmetrics","filePath":"Articles & Papers/Measuring Bitcoin's Decentralization, Coinmetrics.md","title":"Measuring Bitcoin's Decentralization, Coinmetrics","links":["The-three-verticals-of-bitcoin's-decentralization-are-distribution-of-wealth-(dispersion-of-wealth),-hashpower-distribution,-and-exchange-consolidation","Bitcoin"],"tags":[],"content":"Source: coinmetrics.io/measuring-bitcoins-decentralization/\nNotes\nThe three verticals of bitcoinâ€™s decentralization are distribution of wealth (dispersion of wealth), hashpower distribution, and exchange consolidation\nQuotes\nKEY TAKEAWAYS\n\nBitcoinâ€™s decentralization can be quantified in terms of ==supply dispersion, hashpower distribution, and exchange consolidation, among other metrics.\n==Key metrics like the number of active addresses and the networkâ€™s hashrate continue to rise.\n==Bitcoinâ€™s supply is becoming more evenly dispersed, and the mining and exchange markets remain competitive.\n\nINTRODUCTION\nOver the last eleven years, Bitcoin has managed to function relatively seamlessly in the face of a large number of threats, largely due to its lack of a single controlling entity. This trait, known as decentralization, encompasses a large number of loosely-coupled characteristics. Some of these traits are difficult to describe and measure, but others lend themselves well to direct analysis.Â \n==One directly observable feature is the dispersion of funds across addresses. The distribution of wealth is a critical factor in any economy, roughly coinciding to the distribution of economic influence. For cryptoassets, which often grant large token allocations to the founding team, itâ€™s also a severely underexplored one.\n==Another characteristic, the distribution of hashpower, is arguably even more important. Bitcoin relies on decentralization at this level in order to meet its goals of sustaining a secure, censorship-resistant payments and savings system.Â \n==Bitcoin is also highly exposed to the market share distribution of exchanges, which exercise an outsized influence on the networkâ€™s economy. The distribution of volume on fiat-quoted spot pairs is particularly important, since these represent on- and off-ramps to and from the world at large.\nIn this weekâ€™s feature, weâ€™ll quantify Bitcoinâ€™s decentralization along these three verticals and track how itâ€™s progressed over time.Â \nDISPERSION\n==The presence of whales, or users with large quantities of funds held in the asset, is a concern for the viability of many cryptocurrencies. A particularly unequal distribution of funds could grant a small set of users significant influence over the direction of an assetâ€™s markets and protocol development and call into question the assetâ€™s viability as a store of value or medium of exchange.\nSince Bitcoin balances are easily auditable, dispersion can be assessed with on-chain data. Because funds held by custodians inÂ omnibus accountsÂ cannot be attributed to their owner and address reuse is generally discouraged, these estimates are imperfect. However, the degree of transparency afforded is still unprecedented when compared to the legacy financial system.\nBitcoin still has whales, but since the networkâ€™s inception, its supply has become more evenly distributed, with smaller accounts comprising an increasing proportion of the aggregate supply.\nSource: Coin Metrics Network Data Pro\nIn addition to controlling an increasing proportion of supply, addresses with smaller balances continue to represent the majority of accounts. In the face of a fluctuating dollar-denominated price, most addresses still control less than $100 worth of Bitcoin.\nA closely related metric, the number of unique active addresses, also hints at usage by a broader set of network participants. Because a single user can control multiple addresses, this metric is not a perfect proxy for the number of participants, but is generally considered to be correlated. Recently, Bitcoinâ€™s active address count has begun to approach all-time highs.\nMINING\n==In addition to on-chain dispersion and activity, Bitcoinâ€™s effective decentralization depends on the distribution of computational power, or hashpower, among miners.\nBitcoin relies on miners to secure the network and add new blocks to the blockchain. These miners compete to find the next block by computing a large number of energy-intensive hashes, and often aggregate into loose coalitions known as mining pools.\nThe amount of hashpower securing the Bitcoin network has generally grown exponentially throughout the networkâ€™s history.\nSource: Coin Metrics Network Data Pro\n==In addition to the amount of raw hashpower securing the network, the distribution of hashpower is also important. A malicious actor who controls more than half of the networkâ€™s hashpower could 51%-attack the network and perform a double-spend, and an attacker with considerably less resources could censor transactions throughÂ feather forks.\nAn attacker would need to double-spend a large amount of money in order to make a 51%-attack profitable. In majority-hashpower ASIC-mined coins like Bitcoin, which require significant capital expenditure by miners, it would be difficult for a rational miner to perform a 51% attack, though these attacks are made somewhat more feasible by the presence of hashpower marketplaces.\n==Today, Bitcoinâ€™s mining industry is competitive. The plot below, which is subject to a degree of survivorship bias, shows mining to be a thriving, distributed ecosystem.\nWhile Bitcoin mining is distributed, itâ€™s still at risk of centralization through state-level coercion and vertical and horizontal integration. Several exchanges, including Binance, OKEx, and Huobi, operate mining pools. BitMAIN, a hardware manufacturer,Â ownsÂ both BTC.com and AntPool, and is the onlyÂ investorÂ in ViaBTC.\nEven a rational, well-resourced mining pool could have difficulty coordinating a 51% attack, since miners could leave the pool if the operator decided to attack the network. New coordination protocols likeÂ Stratum V2Â may significantly increase the networkâ€™s decentralization by shifting control over block composition from pool operators to miners.Â \nOne useful metric for gauging the decentralization of hashpower is the Nakamoto coefficient, which measures the number of pools that would need to collude in order to 51%-attack a network.Â  While Bitcoin has never been successfully 51%-attacked, in 2014 the mining pool GHash.ioÂ controlledÂ over half of the networkâ€™s hashpower for about a day. During this time period, Bitcoin had a Nakamoto coefficient of 1.\nToday, Bitcoin has a Nakamoto coefficient of 4, indicating a significant degree of decentralization.\nEXCHANGES\nExchanges have a less direct impact on Bitcoinâ€™s decentralization than miners, whose role is embedded in the protocol. As the primary markets on which Bitcoin is acquired and used, however, their influence on the network is significant.\nExcessive centralization among exchanges exposes the market to systemic risks in case of insolvency. In the cryptocurrency space, the most well-known example of this is the 2013 Mt. Gox crisis, discussed in depth inÂ SOTN Issue 35.\nConsolidation would also increase the potential for censorship, negating one of the primary benefits of using Bitcoin. As the primary on-ramp from fiat to Bitcoin, the BTC/USD market is particularly important in this regard. While stablecoinsÂ have recently emergedÂ as an alternative quote asset, fiat gateways remain a crucial way for new capital to enter the market.\nWhile several exchanges offer trading on the BTC/USD market, the field is generally dominated by a few large players."},"Articles--and--Papers/Measuring-Switching-Costs-and-the-Determinants-of-Customer-Retention-in-Internet-Enabled-Businesses.-A-Study-of-the-Online-Brokerage-Industry":{"slug":"Articles--and--Papers/Measuring-Switching-Costs-and-the-Determinants-of-Customer-Retention-in-Internet-Enabled-Businesses.-A-Study-of-the-Online-Brokerage-Industry","filePath":"Articles & Papers/Measuring Switching Costs and the Determinants of Customer Retention in Internet-Enabled Businesses. A Study of the Online Brokerage Industry.md","title":"Measuring Switching Costs and the Determinants of Customer Retention in Internet-Enabled Businesses. A Study of the Online Brokerage Industry","links":["tags/Resource","Quality"],"tags":["Resource"],"content":"Resource\nSource\n\nQuotes\n\nThe ability to create switching\ncosts and build customer loyalty has also been argued\nto be a major driver of success in e-commerce businesses\n(Reinchheld and Schefter 2000). However, it has been\nobserved that over 50% of customers stop visiting com-\npletely before their third anniversary (Reinchheld and\nSchefter 2000)\n\n\nIf switching costs are inherently low and\nfirms are unable to lock in customers, long-term prof-\nitability may be difficult to attain, especially in many\nB2C e-commerce environments with low entry barriers\n(other than customer acquisition costs) and limited dif-\nferentiation.\nCrypto has low barriers to entry. Permissionless for users. Low barriers for entrepreneur\n\n\nAs a result, it becomes critical for a firm to\nmanage its retention ability, which is determined by\nswitching costs and attrition rates. The first step for\nmanaging retention is to be able to measure the mag-\nnitude of switching cost and identify what factors affect\nswitching and attrition.\nAs Shapiro and Varian (1998) argue,\nYou just cannot compete effectively in the information economy unless you know how to identify, measure, and understand switching costs and map strategy accordingly\n\n\nAs classified by Klemperer (1987), there are\nat least three types of switching costs: transaction costs,\nlearning costs, and artificial or contractual costs. Trans-\naction costs are costs that occur to start a new relation-\nship with a provider and sometimes also include the\ncosts necessary to terminate an existing relationship.\nLearning costs represent the effort required by the cus-\ntomer to reach the same level of comfort or facility with\na new product as they had for an old product. Artificial\nswitching costs are created by deliberate actions of\nfirms: frequent flyer programs, repeat-purchase dis-\ncounts, and â€œclickthroughâ€ rewards are all examples.\nBesides these explicit costs, there are also implicit\nswitching costs associated with decision biases (e.g.,\nthe â€œStatus Quo Biasâ€) and risk aversion, especially\nwhen the customer is uncertain about the Quality of\nother products or brands.\n\n\nFirst, the market is large and sig-\nnificant and is considered to be one of the â€œkiller ap-\nplicationsâ€ in B2C electronic commerce (Varian 1998,\nBakos et al. 2000). There were over 140 online retail\nbrokers by the end of 1999 and they managed just over\n1 trillion in customer assets in 2000. By year-end 1999,\nthese accounts represented about 15% of all brokerage\nassets and 30% of all retail stock trades (Saloman Smith\nBarney 2000). Second, as noted in the Introduction, this\nindustry has very aggressive customer acquisition tac-\ntics, partially because of the high lifetime value of an\nactive account (\u00011000). Third, the complexity and fi-\nnancial significance of a stock trade makes it likely that\nconsumers generally face learning costs and other de-\nterrents to switching, including a difficult process of\neither transferring assets or liquidating stock positions\nin order to switch brokers\n\n\nIn our earlier analysis, we found that attrition (custom-\ners who have a brokerage account at some time but do\nnot return to any broker in the future) is a significant\nproblem.\n\n\nIt is also important to note that demographics typi-\ncally are not good predictors of behavior except for a\nfew isolated results on attrition. One notable result is\nthat women are found to be more likely to become inactive. This gender effect appears consistent with a\nrecent study by Barber and Odeon (1999) which found\nthat men trade online significantly more frequently\nthan women, so it is not surprising that women are\nmore likely to become inactive\n\n\nMoreover, to the extent\nthat systems usage encourages retention through\nsystem-specific learning, it would imply that firms\ncould improve retention by encouraging consumers to\nfrequently visit and use their sites. Our analysis also\nsuggests that systems design characteristics such as\npersonalization and ease of use should be reconsidered\nboth in terms of their measurement and in further eval-\nuation to determine whether they have the intended\neffects on long-term customer behavior.\n"},"Articles--and--Papers/Modems,-wArEz,-and-ANSI-art-Remembering-BBS-life-at-2400bps":{"slug":"Articles--and--Papers/Modems,-wArEz,-and-ANSI-art-Remembering-BBS-life-at-2400bps","filePath":"Articles & Papers/Modems, wArEz, and ANSI art Remembering BBS life at 2400bps.md","title":"Modems, wArEz, and ANSI art: Remembering BBS life at 2400bps","links":[],"tags":["toprocess"],"content":"Youâ€™ve almost certainly never seen the place where I grew up, and you never will because itâ€™s long gone, buried by progress and made unreachable by technological erosion and the fine grind of time. What I did and learned there shaped me, but that knowledge is archaic and uselessâ€”who today needs to know the Hayes AT command set, the true baud rates of most common connection speeds, or the inner secrets of TheDraw? I am a wizard whose time has passedâ€”a brilliant steam engine mechanic standing agape in the engine room of the starshipÂ Enterprise.\nI am a child of the BBS era. BBSsâ€”thatâ€™s â€œBulletin Board Systemsâ€â€”were sort of the precursors to the modern Internet, though thatâ€™s notÂ quiteÂ accurate, since the Internet evolved separately and in parallel. It would be more accurate to say that many people in their 30s and older today were introduced to the world of the Internet either through or because of the interlinked telephone universe of BBSs. That one experience begat the other.\n\nEnlargeÂ /Â The author near the twilight of his BBS days. Notice the lack of girl, in contrast to Matthew Broderick above.\nBBSs existed in a world that had yet to be soiled by smartphones and Facebook and Instagram; there was no Google, and indeed no World Wide Web at all. Up until 1992, the Internet was a thing primarily of text, and BBSs in many ways mimicked that. To get â€œonlineâ€ was to sit down at your computer, open up an application called a â€œterminal programâ€ (or just â€œterm programâ€ for short), pull up your carefully hoarded list of BBS phone numbers, and start dialing. Inevitably, most would be busy and youâ€™d have to wait, but eventually youâ€™d be treated to the sweet sound of ringing through your modemâ€™s speaker, followed by the electronic beeping and scratching of a modem handshake.\nOh, there were multi-line BBSs which could host more than one user at a time, but I didnâ€™t spend much time at thoseâ€”the truly popular ones almost invariably required membership fees to support the cost of so many phone lines. No, most BBSs consisted of a single computer at someone&#039;s house, connected to a single phone line, which users dialed into one at a time. That remote computer was typically dedicated to the BBS because in the 1980s and early 1990s, multitasking operating systems like we have today were less common and much more temperamental.So, one at a time, users would dial into the BBS, check their private messages, perhaps leave a message on the BBS&#039; &quot;wall&quot; for later callers, read and leave public messages in the message boards (called &quot;subboards&quot; or just &quot;subs&quot;), download and upload files, and then log off. If a modern Web-based forum is a crowded dinner party full of guests all yammering at the same time, a BBS was an entire house that you had all to yourselfâ€”one where you could enter, spend some time relaxing and reading books in solitude, write some letters, and maybe rearrange the furniture a bit.\nThe one who was\nI was 12 years old in the fall of 1990, full of bespectacled junior high awkwardness and hunting, as all preteens are, for identity. At the time, my father worked for a big savings and loan firm, and in order to be able to occasionally do some work from our home PC, he was loaned a Hayes Smartmodemâ€”a heavy external box that connected to our Acer 286/12 desktop via a thick RS-232 cable. I truly donâ€™t know if my dad ever used the device for work, but once the thing was plugged in, my world changed.\n\nEnlargeÂ /Â Chunky, heavy, and awesome: the Hayes Smartmodem 2400.\nRecycled Goods\nIt came with some janky business-oriented communications applicationâ€”likelyÂ Bitcom, but it was a long, long time ago and I donâ€™t remember the exact nameâ€”which was preprogrammed with a big list of (useless, to me) access numbers for business services. Seeing how interested I was in the device, my dad got the IT folks at his job to write down a few local BBS numbers for me to dial into.\nThe first BBSs I called, courtesy of that list, were hosted on Commodore computers running theÂ SpiceWareÂ BBS hosting software. If you happened to be using a Commodore computer with aÂ semigraphicalÂ term program, it was a colorful and sound-filled experience (thereâ€™s a video on the linked blog post of what a SpiceWare BBS looked like). For me on my IBM-compatible PC without even ANSI graphics, all I remember is a lot of red text.\nI didnâ€™t care. It was absolutely incredible. It was like the computer in front of me had gained another dimensionâ€”it had become TARDIS-like, suddenly containing far more than its physical dimensions seemed to be able to allow. My computer could talk to other computers, and it felt like the boundaries of the world had just been blown out, like a cardboard box stuffed with dynamite. After I registered for an account on that first BBS, the remote systemâ€™s menu showed me cryptic but exciting things I could do. Post messages? Download files? Play door games? Chat with the sysop? Whatâ€™s aÂ sysop?\nLearning the lingo\nWhen it came down to it, there were three major activities one could do on a BBS: read and post messages, upload and download files, and play games. I quickly came to realize that me being on an IBM-compatible system meant that the files on these Commodore-hosted BBSs were useless to me, but I immediatelyÂ fell in love with the message subboards. People were talking to each other! Inside the computer! And I could talk to them!Â And they would sometimes talk back!\nThese werenâ€™t multi-line BBSs, though, so the communication was very much serial. Youâ€™d call in, check your private messages to see if anyone had left you any, maybe take a peek at the public â€œwallâ€ to see if anyone had scrawled anything funny, then flip over to the subboard of your choice and check for new posts there. For me, this was all done in text, though for Commodore users there were colors, semigraphics, and even sounds.\nA â€œsysop,â€ I quickly found out, was short for â€œsystem operatorâ€â€”the person who ran the BBS. The sysop had administrative power and could do anything. On some BBSs they were jovial benefactors; on others, they were message-editing, power-abusing tyrants.\nâ€œDoor gamesâ€ were games that could be played through the BBSâ€™s text interface. They ranged from simple things (like maybe a Blackjack game) to deep, rich, complex simulations likeÂ Tradewars 2002. They were called â€œdoorâ€ games because they were usually self-contained external applications, and the BBS application accessed them through an interface colloquially called a â€œdoor.â€\n\nThe Pit, a BBS door game. In this shot, Iâ€™m attacking these guys. Or maybe theyâ€™re attacking me.\nFor most BBSs, the message subboards were the main reason people called in, and many BBSs tried to keep users active in those boards by enforcing a â€œPCRâ€â€”that is, a â€œpost/call ratio.â€ Users who wanted to download files had to post a certain number of messages in the subboards to keep their PCR up in order to be given access to the files areas. This often backfired, with some people posting useless â€œPost to get my PCR up!â€ type messages. On the other hand, you didnâ€™t want people hogging the board up, so users could only call in for a limited amount of time each dayâ€”often an hour. You could also bank your extra, unused time, sort of like rollover minutes. If you were done with a board for the day after only 20 minutes, you could stuff the other 40 into your time bank and use it later.\nAnd the filesâ€”oh, the files. Once I started calling IBM-PC boards instead of Commodore-hosted boards, the files sections started to get more and more interesting. BBSs had different kinds of files depending on what the sysop wanted to do with his or her BBS; some boards had lots of programs to download and run, like screensavers or graphical demos, while some focused on amassing and distributing tremendous libraries of text files. It was rare to find a board without an ASCII copy ofÂ The Anarchistâ€™s Cookbook;Â the Cult of the Dead CowÂ orÂ SubGeniusÂ texts were also heavily traded.\nThere were three other things you might see in a BBSâ€™s file area as well, and they were all weirdly linked togetherâ€”ANSI art, MOD files, and warez. But before I could find out about any of those things, I had to escape from Commodore BBSs and start dialing into PC-run boards.\nSpeedâ€”or lack thereof\nBut beforeÂ that, we need to take a moment and put all of this modem stuff in perspective because you canâ€™t understand what it was like back then without understanding exactly howÂ slowÂ 2400bps is. We are accustomed these days to rich webpages and files delivered to us over always-on multi-megabit-per-second Internet connections, but that was the stuff of universities and governments back then. To put 2400bps in some perspective, thatâ€™s 2.4Kbps, meaning that the last generation of 56Kbps modems were about 23x faster than poor old 2400bps. And everyone knows how â€œslowâ€ 56K was.\nAt 2400bps and typical encoding, a single character took 10 bits of transmission (a start bit, a stop bit, and eight bits for the character itself, though other encodings were also used), and so the character rate maxed out at 240 characters per second. This was slow enough that you could actually see the screen fill with text, line by line. At 1200bps, fast readers could find themselves waiting on the remote computer; at 300bps (rare but not unheard of in the early 90s), fast typists could at times out-type their connection speed.\nFor text, 2400bps was perfectly adequate, but downloading binary filesâ€”images, large text files, compressed binary files, whole applications spread across floppy-sized disk imagesâ€”took a long time. Exactly how long? The general rules of thumb to quickly estimate how long your download would take at 2400bps were that 1KB took about five seconds; 100KB took about eight minutes; and 1MB took about an hour and a half.\nFor someone whoâ€™s never used a BBSâ€”or for someone whoâ€™s never had anything other than a broadband connectionâ€”itâ€™s hard to really explain just how different that is from today. Even downloading a single 256-color GIF usually meant several minutes of waiting, and a large multi-megabyte download was almost always an overnight commitment. There were a few ways to eke out more speed from your downloadâ€”some download protocols like Puma and Lynx played games with the packets and sent them in batches rather than waiting for acknowledgments, and a few even used compressionâ€”but for the most part, you simply put up with it. Or you shelled out hundreds of dollars for a faster modemâ€”not an option for my broke junior high self.\nHow bad was it then compared to how fast things are now? About this bad:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDOWNLOAD SIZE &amp; SPEED2400BPS9600BPS10MBPS CABLE1KB:5 seconds1 secondInstant10KB (a text file):About a minuteAbout 10 secondsInstant50KB (a single .gif):About 4 minutesAbout a minuteInstant200KB (a large .gif):About 15 minutesAbout 3 minutesInstant836KB (Wolfenstein 3DÂ shareware):About an hourAbout 15 minutesInstant2393KB (DoomÂ shareware):About 3 hoursAbout 80 minutesAbout 1 second100MB (your whole hard drive):About a weekAbout a dayAbout 80 seconds\nThe comparison is so unbalanced itâ€™s almost meaningless, and itâ€™s the last line that puts it over the cliff of ludicrousnessâ€”a modern broadband connection matches and in some cases exceeds the bandwidth available to an earlyÂ 1990s hard disk driveÂ (the comparison becomes even more insane at 50 or 100 Mbps).\nHow could we possibly stand it without rioting? The answer is simple: you canâ€™t miss what youâ€™ve never had before. 2400bps was as fast as most of us hadâ€”most of us who werenâ€™t rich or actively distributing warez, anywayâ€”so 2400bps was what we used. It was slow, but it was simply the way things were.\nTerm programs, World War IV, and the golden age\nI acquired more BBS numbers from each boardâ€™s public phone list, and I quickly found out that when calling into PC BBS systems, I needed something far more powerful than the default terminal program. There were many choices, but everyone I talked to recommended something calledÂ ProComm Plus, which massively improved on my default program by offering things like an extensible phone book and the ability to display ANSI â€œgraphicsâ€â€”colored text and extended characters that could be strung together to make rudimentary images.\n\nTelemateâ€™s dialer screen. I was incredibly excited to see that the copy of Telemate I had sitting in my archive directory was my actual old version, complete with the last two Houston BBSs I used to call (and my actual last two connection times!). Also, Telemate apparently isnâ€™t Y2K-compliant, because it thinks itâ€™s 75 oâ€™clock.\nHowever, the term program I used more than anything else was the venerableÂ Telemate, by White River Software. Telemate had it all: it was a multi-threaded application and could actually do a lot of neat things simultaneously. It had a configurable â€œback bufferâ€ so that you could go back and look at things that had scrolled off your screen (remember, this was MS-DOSâ€”cut-and-paste and scrolling were both a big, big deal), a text edit window you could open and close, functional cutting and pasting, and a rich macro language that could be used to do things like automatically enter your username and password on certain BBSs. It also had a powerful, extensible dialing listâ€”great for automatically finding that one BBS without a busy signal on a Sunday afternoon.\n\nConfiguring Telemateâ€™s main comm options. Note that awesome extended init string! At the time I was rocking a USR Courier V.Everything, so I had all kinds of extra registers to control.\nJust as there were different terminal programs for users, there also was a plethora of BBS host applications, too. Different areas of the country tended to have different BBS applications that dominated; here in the Houston area, most of the boards I ended up frequenting for many years used a program called TAG (properly styled â€œTAG!â€), which shared many similarities with the vastly popular WWIV BBS application (which in turn had spawned other similar-looking BBS applications likeÂ Telegard and Renegade).\n\nThe secret magic screen TAG sysops stared at while waiting for someone to call.\nAlthough TAG was by no means the only BBS application in general use around Houston, the majority of the BBSs I called into in the 1990s used it. When I think of furtively downloading a pirated version ofÂ DOOM, in my head I see the TAG download interface. When I think of those very first arguments I ever had about Macs versus PCs or who the superior captain of theÂ EnterpriseÂ was, itâ€™s in the ANSI colors of the TAG message board composition window.\n\nPosting and reading messages on a BBS looked pretty much like this.\nThat was truly the prime draw of it allâ€”all that talking and arguing with fellow geeks. Through the computer, we were all democratizedâ€”we transcended social stigmas and the crushing weight of the high school popularity pecking order. Our voicesÂ _matteredâ€”_to each other, anyway. On the whole, no one really cares about a bunch of geeks talking about geek things, but to us, the reality of owning a medium was profoundly empowering. No one was going to make fun of anyone for arguing over whether attack matrices were a superior system to THAC0. YourÂ viewpointÂ might be mocked, but not the fact that you were having the conversation. Not as long as you were posting in the appropriate sub.\nEach BBS was an island (relay mail between BBSs was a thing, but I rarely used it), and each board included its own cliques and pecking order. A sysop on one board might be a â€œco-sysopâ€ on another (effectively an assistant system administrator with most of the sysopâ€™s powersâ€”banning users, reading other usersâ€™ private messages, and so on). Or he might not beâ€”just because you had your own BBS didnâ€™t automatically give you any rights on someone elseâ€™s board. Particularly trusted users might be made â€œsubopsâ€ of particular discussion subboards, granted powers much like a forum moderator of today. To be a subop or a co-sysop was a mark of high status, and it was pretty common for folks to try to beg and wheedle their way into those roles merely to hold it over other users.\nLong distance fees kept most BBS users confined to their local area codes; I stayed local for fear of invoking my parentsâ€™ wrath (and, later, when I started paying for my own phone line, I was even less inclined to call a board outside my area code). Youâ€™d see the same nicknames pop up over and over again on different boardsâ€”it was common for a user you knew on one board to appear on another, too, since there were at most a hundred or so really popular local BBSs at any given time. In-jokes flourished in our semi-closed ecosystem, and things felt downright cozy.\nOf course, there was a whole world outside of the 713 area code. Game manufacturers in particular had BBSs that glittered like jewels, just outside of my reach, promising hints and mysterious fixesâ€”â€œpatches,â€ they called them. Once, after begging and begging, I was given permission by my parents to dial into Sierraâ€™s BBS so that I could download a patch to fix a game-breaking bug inÂ Quest for Glory 4. Calling that faraway BBS felt a little bit like making a holy pilgrimageâ€”after playing Sierraâ€™s games for so many years, I was going to actuallyÂ talk to their computers!Â (The patch ended up fixing the issue but also made it impossible to reload any of my saved games. I never finishedÂ QFG4.)\nIÂ learnedÂ things in this world, things that teenagers these days have to pick up from the infinite multitude of Web-based discussion boards and social media. Back then we didnâ€™t have to worry so much about our parents finding our smartphones and our snapchats and our Facebook posts, though, because barriers to entry were higher. Our world was cloaked not just in passwords, but in incantations and ASCII arcana. Even dialing into a BBS required a bit of understanding of how the term program you were using worked. Without some idea of what you wanted to accomplish, it would have been difficult to puzzle out how to do it.\n\nCanâ€™t figure out your terminal program? No worries! Hereâ€™s your help screen! ALL BETTER NOW, RIGHT?\nXmodem! Ymodem! Zmodem!\nEven downloading filesâ€”something that today is done almost without thought by clicking links on a webpageâ€”took some thought and know-how. You didnâ€™t just â€œdownloadâ€ something from a BBS; you had to actually tell your terminal program that the data it was about to receive was a file and not text to display. This meant configuring and using a download protocol. The three mostÂ common protocolsÂ were Xmodem, Ymodem, and the sophisticated and widely used Zmodem; each of them let you download files, but Zmodem was far and away the easiest to use.\nPoor old Xmodem didnâ€™t know anything about what you were downloading. Youâ€™d pick a file from the remote BBS to download, but then you had to hit the â€œdownloadâ€ key in your term program, select the Xmodem protocol, supply a file name to save the download as, and wait. The remote computer didnâ€™t transmit anything except dataâ€”no error correction, no size, no time remaining, nothing. Ymodem introduced a bit of error correction, but it wasnâ€™t much better.\nZmodem, on the other hand, was the protocol of kings. It was fastâ€”it streamed rather than requiring an acknowledgment after each packet. It was smart, tooâ€”it even let you restart aborted downloads, which was a huge bonus when each megabyte downloaded represented almost 90 minutes of real time, and a large interrupted download could mean a whole day wasted.\nOther more exotic protocols were around too if you wanted to download their binaries to set them up (and if the BBS you were calling supported them). Of particular note was Hilgraeve Softwareâ€™sÂ HyperProtocol, a streaming protocol which included a bit of compression. You might not ever have used it, but anyone who worked in IT has almost certainly used the terminal emulator Hilgraeve produced a few years later: HyperTerminal.\n\nRemember this thing? Itâ€™s got a surprisingly complex history.\nMOOOOM, DONâ€™T PICK UP THE PHONE!\nIn a time when my family only had a single landline, time on BBSs had to be carefully negotiated. Every moment I was living in that world was a moment where the phone was off-hook and no one could call our house. Relatives began to complain about always getting a busy signal when they dialed us, and I received more than one talking-to from my parents about always being on the phone. In that respect, I suppose I was like most teenagers.\nModems work by encoding digital information into an analog signal, and most people have heard the static-y â€œHISSSSSSSâ€ of modem communication. Noise was data, and extraneous noise in a connection between two modemsâ€”noise from a bad connection, or noise introduced by someoneâ€™s mother picking up the phoneâ€”caused errors. As modems grew more sophisticated, error correction techniques likeÂ MNPÂ andÂ V.42bisÂ began to appear on consumer-priced modems, but when I first began dialing into BBSs, error correction wasnâ€™t common on 2400bps modems that normal people could afford.\nMinor bouts of line noise looked like random characters injected into the flow of thingsâ€”annoying, but easily fixable. However, sometimes a relative innocently picking up the phone while you were online would cause your connection to drop, which could be terribly frustrating if you had managed to dial in to a popular BBS that was normally busy.\nOur familyâ€™s computer was located in an add-on room to the house, and that room had no phone jack. For years, I stretched a 50â€™ (about 15 meter) phone cord across half the house in order to get online. This meant that connections were spoiled not only by the occasional picking up of a phone, but also by the occasional tripping over the cord. One of the first things I did when I turned 16 andÂ got a jobÂ was pay for the installation of my own phone line and a jack in the computer room. It cost me about $50 a month for a number that could call most of Houston (a 332 exchange number rather than the cheaper 554 exchange), and back then I actually spent more on my phone lineâ€™s monthly bill than I did on gas for my blue 280-Z.\n\nEnlargeÂ /Â A high speed (V.90 or V.92) modem handshake, annotated. 2400bps handshakes were much less complex.\nOona RÃ¤isÃ¤nen\nTalking to your modem\nRegular BBS users became skilled in theÂ Hayes AT command setâ€”the language for configuring and using the majority of modems. Term programs hid a lot of the complexity by automating the process of dialing and using a modem, but to tweak the modemâ€™s parameters it was necessary to dive in and start directly changing settings. That meant using AT commands.\nWhen you first started up your term program, it passed a long bunch of commands called the â€œinitialization string,â€ or just â€œinit stringâ€ to your modem. This set parameters in the modemâ€™s nonvolatile RAM so that the modem would function in the way you expected or wanted. Though my init strings got more complex as I got newer and newer modems, Iâ€™ll forever remember the string I used with my beloved old Hayes 2400 Smartmodem:\nATE1S7=255S11=35V1X4S0=0\nAll commands started with â€œAT,â€ for â€œattention,â€ to tell the modem it should expect commands. E1 set local echo on (so that I could see what I was typing in the term programâ€™s main view). Then the command set several â€œS registersâ€â€”NVRAM locations that held specific settings. â€œS7=255â€ set the number of seconds after going off-hook that the modem would wait for a connection to 255. â€œS11=35â€ set the DTMF tone length to 35 millisecondsâ€”so when the modem dialed, it would use 35 ms for the length of each dialed digit (shorter DTMF tones meant faster dialingâ€”through experimentation, I found 35 to be the shortest that would work with my localÂ POTSÂ exchange). â€œV1â€ told the modem to give me result codes in plain English rather than as numbers (so it would print â€œBUSYâ€ in the terminal window if it detected a busy signal rather than just printing a number), and â€œX4â€ told the modem that it should use as many result codes as it knew how to useâ€”in other words, it should be as smart as possible and respond to dial tones and busy signals rather than blithely dialing away. Finally, â€œS0=0â€ set the auto-answer register to 0; setting â€œS0=1â€ would cause the modem to automatically pick up the line after the first ring if it heard an incoming call. That would be great if I were running a BBS, but not so great on a line used primarily for voice.\nYou could also send commands directly to the modem. The most useful was â€œATA,â€ which you could type at any point to cause the modem to pick up the line and start trying to connectâ€”great if a friend was going to call to upload a file directly to you. Also useful was quickly typing â€œ+++ATH0â€â€”the â€+++â€ would pull the modem out of data mode and into command mode when you were connected, and â€œATH0â€ would cause the modem to instantly hang up.\nOnline gaming\nWe played games in that lost world, too, and some of them were amazing. I spent more time than I care to admit playingÂ The Pit, an arena fighting game where you move your little ASCII character around in an ASCII arena and fight other ASCII characters for loot and fame. I would bank all my excess time on BBSs throughout the week, then make huge time bank withdrawals on the weekends so that I could tie up phone lines for hours bashing imaginary text-mode monsters.\n\nMore ofÂ The Pit. I might be in a little bit over my head here.\nOne of the most long-lived and popular door games wasÂ TradeWars 2002.Â TW2002Â dropped players into a large persistent universe and gave them a certain number of turns per day to trade, explore, fight, and get rich. It was sort of like a cross betweenÂ EliteÂ andÂ Galactic Civilization, though the multiplayer competitive aspect of it was absolutely entrancing.\n\nI tried to set upÂ Tradewars 2002Â in DOSBox so I could take some pictures, but I couldnâ€™t make it work. However, the game pretty much looked just like this anyway.\nThat multiplayer, though, was â€œserialâ€ instead of parallel. Most BBSs were single-line, so the game was much more like a huge multi-sided game of chess rather than a modern MMORPG. And that persistentÂ TW2002Â universe was really only persistent on single BBSsâ€”yourÂ TW2002Â game on one board was a different game from yourÂ TW2002Â game on another board (because, remember, few BBSs were connected together). These were most often single computers being run by a sysop out of his or her house with a single phone line. (AlthoughÂ TW2002Â itself did support multi-line BBSs for simultaneous play and even multi-BBS play via relay for sysops who wanted a universe that spanned boards.)\nA pirateâ€™s life for me?\nAnd, of course, there was pirated softwareâ€”which even back then was called â€œwarezâ€ (pronounced like â€œwares,â€ not like â€œJuarezâ€), though it was the style in the mid-â€™90s to soMeTiMeS wRiTe iT liKe â€œwArEz.â€ I canâ€™t believe I used to write like that, but we all did for a while.\n\nEnlarge\nPirated file areas were sort of like secret bars in the 1920sâ€”everyone knew where they were, but you didnâ€™t really talk about them in public. Saying â€œHEY GUYS ANYONE GOT ANY WAREZâ€ on a BBSâ€™ message boards might get you immediately kicked and blacklisted; quietly approaching the sysop in chat and mentioning that you heard from another board user that there were â€œprivateâ€ files for download, on the other hand, might get you accessâ€”provided someone could vouch for you.\nThrough BBSs, I came to know the world of pirate release groupsâ€”theÂ Scene. As I downloaded applications I wanted to use but could never pay for (like the incredible, inimitableÂ XTree Gold) I quickly became familiar with the legendary names: groups likeÂ iNC,Â THG,Â Fairlight, and the still active seemingly immortalÂ RAZOR 1911. These were the people actively cracking software and distributing it, and they were mythical creatures in my teenage eyes.\n\nEnlarge\nPirated software in the BBS days was very different from its modern timesâ€™ equivalent. Grandparents tell stories of how back when they were young, they didnâ€™t even have to lock the doors of their houses because crime was so low, and that same golden-age recollection applies here. You simply didnâ€™t have to worry about viruses from a scene release. The cracking groups all competed viciously for reputation and popularity, and no one would sign their name to a release tainted by a virus. They put out clean software, and like hippies at Woodstock, we rarely worried about viruses or protection.\nIntros, cracktros, and ANSI art galore\nOddly, the pirated software scene and the digital art and music scene were closely intertwined. BBSs were primarily a textual medium, but â€œtextâ€ can mean many things beyond the alphabet and basic punctuation. Skilled artists existed who could take extended ANSI characters and colors and create not just recognizable artwork, butÂ legitimately amazingÂ images.\n\nEnlargeÂ /Â â€œAnsi Blondie,â€ by Reanimator of iCE. This is all made out of colored ASCII characters.\nAssembly Archive\nMany of these artists were also either tied to or directly members of big cracking groups, and their services were very much in demand. A piece of pirated software would always have a file in it that contained information about the release, including who released it; those files would typically have embedded ASCII or ANSI art in them. Further, the BBSs where cracking groups directly communicated and hung out needed to be decorated, and these often featured incredibly elaborate logon screens and backgrounds.\nANSI art remained intertwined with the cracking scene, but it also evolvedÂ its own elaborate scene, with its own conventions and stars. Art groups likeÂ ACiDÂ andÂ iCEÂ flourished in the 1990s, releasing incredible art often made out of nothing more than colored characters.\nThe mass of skilled coders and artists did far more than simply crack software and make images taunting rival groups; it became popular for pirate groups to include musical and graphical â€œintrosâ€ alongside their releases. An â€œintroâ€ (or â€œcracktro,â€ since the intro would often accompany a cracked piece of software) was a small self-contained musical calling cardâ€”typically, it would be a set of stills or animated images with a 4-channel digital audio song (like a .MOD) playing in the background. There would almost always be a list of â€œgreetsâ€ in the intro, where the coders shouted out praise to their friends and talked smack about rival groups.\n\nI fired up TheDraw to make some bitchinâ€™ ANSI art myself, but discovered that I cannot art any better today than I could back then. So, this is the best I can doâ€”going for kind of an ironic statement, I think.\nIntros moved beyond simple calling cards and evolved into massive applications designed to push computers of the day to their limits, and many of the players that started out in the demoscene are still active today in one form or another. For example, Future Crew, creators of arguably the two most famous demos of all time (UnrealÂ and the mind-blowingÂ Second Reality) are still codingâ€”you might recognize their work at Remedy Entertainment and FutureMark.\nSpeeding upâ€”9600, 14400, and beyond\nIn early 1994, after years and years of 2400bps, my dad bought me a high-speed modem. I graduated to 9600bps. At that time, the fastest thing you could buy was aÂ USRoboticsÂ HST modem, which operated at 16800bps using USRâ€™s proprietary HST communications scheme. After that, 14400bps was widely popular and became what the elite used.\nI was thrilled to have my 9600bps modem, though, since it represented a five-fold increase in speed over poor old 2400bps. I still remember the absolute joy of watching my download rate jump to 1KB per secondâ€”it was magical, watching those numbers tick away so quickly. I could download 100KB in a little over a minute and a half! A megabyte in a bit over 15 minutes!Â I could download anything.\nOf course, all that speed led to me downloading a lot more stuffâ€”mainly pirated software and music. By that point, our 286/12 had long been replacedâ€”we got a 386/25 with a Soundblaster Proâ€”and I fell headlong into the world ofÂ .mod filesÂ and more complex digital audio files. I filled expensive hard drives with applications and music, trying to see and discover everything.\nThe end of all things\nBy the time I bought myself a 28800bps modem in 1996, my BBS use had faded to nothing thanks to a new and much more addictive thing: the Internet. Thanks toÂ Netcom Netcruiser, I left behind my door games and file areas and quaint local subboards for the mid-â€™90s Internet, which was itself still a relatively young and wild thing (especially the nascent World Wide Web, which was at the time only a few years old).\n\nEnlargeÂ /Â Sadly, this thing right here killed BBSs for me.\nBut even as my online world gained width and breadth, it lost a magical sense of depth. There are soÂ manyÂ things to do on the modern Internet; even the Internet of 1995 and 1996 was a vast ocean of destinations and information. Gone, though, was the intimacy of the BBSâ€”it was all fine and good to speak of visiting someoneâ€™s homepage on the Web as a personal experience, but the ephemeral loading of a webpage is nothing in comparison to dialing into a BBS that a person has specially crafted for visitors. Itâ€™s the difference between reading a billboard on the side of someoneâ€™s home and actually entering that home to sit down for tea.\nIt seems crazy that the text-based world of BBSs could still resonate so much with me, but what I learned there underpins most of how I use the Internet today. I learned how to talk with other people in a forum, how to quote replies, and how to construct an argument. I learned how private messages work. I learned about compressed files and archivesâ€”would it surprise younger Internet users to learn that we used PKZip and ARJ back then, just as we do now? I learned how to flame someone and how to respond to being flamed. I learned about analog communication and modems and hard drives and how computers workedâ€”IÂ hadÂ to learn, because that was the only way to get â€œonlineâ€ back then.\nAnd I miss it. There was an innocence then thatâ€™s absent now from the online world. Youâ€™d never see an ad on a BBS; youâ€™d never get spam in your inbox or have to worry about your parents or your boss finding out about a picture youâ€™d posted (because, really, â€œpostingâ€ that picture involved a whole hell of a lot of steps). You worried that â€œthe governmentâ€ might find out you downloaded a text file telling you how to build aÂ blueÂ orÂ redÂ box, but you didnâ€™tÂ reallyÂ worry about it.\nWhat we have now is quantifiably better in just about every wayâ€¦ but you love the things you grew up with. Some BBSs are still around, though most are accessible via telnet, and thatâ€™s just not the same. My generation is in a perfect spot to have experienced it in the mid-1990sâ€”those older than I were in college at the time and were cutting their teeth on the actual for-real Internet, using USENET and FTPing files around with abandon. Those even a few years younger than I missed all of it and likely got their first introduction to a modem through nascent services like America Online or Prodigy.\nTheyâ€™ll never know what it was like to prank-call friendsâ€™ BBSs late at night, whistling into the receiver to trick the remote modem into trying to train against your whistle and lock up. They canâ€™t recall the thrill of discovering the full registered version ofÂ Wolfenstein 3DÂ on a private board for the very first time or the joy in slaving overÂ TheDrawÂ for hours to produce the perfect ANSI signature to append to your messages.\nChildhood ends for everyone, but Iâ€™m glad I spent mine online.\n+++ATH0\n!@^^Â§Â¡Â©Â£Â¡)\nNO CARRIER\nPromoted Comments\n\n\npath0sSmack-Fu Master, in training\nJUMP TO POST\nLinked to Darrellâ€™s Spiceware BBS blog post! The video there is what I created to demo the old software. I used the VICE emulator for the Musicterm client running on linux, and a real C= 128 running the BBS software. I have the only known copies of the disks in my possession. Iâ€™ve been (slowly) working on removing the identifiable user account information and cleaning up the disks so I can release them to the rest of the Commodore â€œsceneâ€.\nItâ€™s good to see SpiceNet getting an honorable mention somewhere, it was by far the coolest of the BBS programs for the Commodore. Itâ€™s a shame that it never really got much farther in distribution than the southern states. There might have been one or 2 up north, but most were in Texas.\nMr. Spice sold the BBS soft to another sysop back in the day, who later passed away. His wife pitched all of his Commodore stuff. It took me years to track down another sysop who had still managed to hang onto his BBS disks all these years, and he was able to send me the disks. Thereâ€™s a Net64 and Net128 version.\n1 post | registeredÂ Jan 23, 2014\n\n\nribald_eddieÂ Ars Scholae Palatinae\nJUMP TO POST\nAs a late-night follow up to my post up the pageâ€” I mentioned the idea of a generational cohort (you can look it up on Wikipedia) and it got me thinking about our collective experiences and just how valuable they really are.\nWe are the generation that came of age during the transition of information networks from niche nerd activity to widespread, mainstream adoption. Witnessing this change is something that will never happen again, and that also means that I think we have a special responsibility to educate and lead when discussing how these technologies should be used given their current pervasiveness.\nI say this because we are the first generation to have intimate knowledge of both the â€œoldâ€ world and the â€œnew worldâ€. People born later donâ€™t have intimate knowledge of the old world, and people who were much older than us donâ€™t have intimate knowledge of the new world.\nOr something. snore.\n1451 posts | registeredÂ 9/2/2005\n\n\nPromoted Comments\n\n\npath0sSmack-Fu Master, in training\nJUMP TO POST\nLinked to Darrellâ€™s Spiceware BBS blog post! The video there is what I created to demo the old software. I used the VICE emulator for the Musicterm client running on linux, and a real C= 128 running the BBS software. I have the only known copies of the disks in my possession. Iâ€™ve been (slowly) working on removing the identifiable user account information and cleaning up the disks so I can release them to the rest of the Commodore â€œsceneâ€.\nItâ€™s good to see SpiceNet getting an honorable mention somewhere, it was by far the coolest of the BBS programs for the Commodore. Itâ€™s a shame that it never really got much farther in distribution than the southern states. There might have been one or 2 up north, but most were in Texas.\nMr. Spice sold the BBS soft to another sysop back in the day, who later passed away. His wife pitched all of his Commodore stuff. It took me years to track down another sysop who had still managed to hang onto his BBS disks all these years, and he was able to send me the disks. Thereâ€™s a Net64 and Net128 version.\n1 post | registeredÂ Jan 23, 2014\n\n\nribald_eddieÂ Ars Scholae Palatinae\nJUMP TO POST\nAs a late-night follow up to my post up the pageâ€” I mentioned the idea of a generational cohort (you can look it up on Wikipedia) and it got me thinking about our collective experiences and just how valuable they really are.\nWe are the generation that came of age during the transition of information networks from niche nerd activity to widespread, mainstream adoption. Witnessing this change is something that will never happen again, and that also means that I think we have a special responsibility to educate and lead when discussing how these technologies should be used given their current pervasiveness.\nI say this because we are the first generation to have intimate knowledge of both the â€œoldâ€ world and the â€œnew worldâ€. People born later donâ€™t have intimate knowledge of the old world, and people who were much older than us donâ€™t have intimate knowledge of the new world.\nOr something. snore.\n1451 posts | registeredÂ 9/2/2005\n\n\n[\nREADER COMMENTS\n](arstechnica.com/gadgets/2014/01/modems-warez-and-ansi-art-remembering-bbs-life-at-2400bps/)"},"Articles--and--Papers/On-Writing-Well":{"slug":"Articles--and--Papers/On-Writing-Well","filePath":"Articles & Papers/On Writing Well.md","title":"On Writing Well","links":[],"tags":[],"content":"Unity is the anchor of good wriitng.\n\nUnity of prnonoun\nUnity of mood - casual or formal\n\nAsk yourself some basic questions before you start.\n\nIn what capacity am I going to address the reader?\n\nReporter? Provider of information? Average man or woman?\n\n\nWhat pronoun?\n\nfirst person as a participant or third person as an observer?\n\n\nWhat tense?\n\nPast tense, present\nNeed to choose a tense that you will principally address the reader in, but you can go backwards and forwards in time.\n\n\nWhat style?\n\nImpersonal reportorial? Personal but formal? Persona and casual?\n\n\nWhat attitude am I going to take towards the material?\n\nInvolved? Detached? Judgmental? Ironic? Amused?\n\n\nHow much do I want to cover?\n==What one point do I want to make?\n\n==Every successful piece of nonfiction should leave the reader with one provocative thought that he or she didnâ€™t have before.\n==One point will give you a better idea of what route you should follow and what destination you hope to reach\n==One point will affect your decision about tone and attitude\n\n==Some points are best made by earnestness, some by dry understatement, some by humor\n\n\n\n\nIt often happens that youâ€™ll make prior decisions and then discover that they werenâ€™t the right ones. The material begins to lead you in an unexpected direction, where you are more comfortable writing in a different tone.\n\nTrust your material if it takes you into a terrain you didnâ€™t intend to enter but where the vibrations are good.\nDonâ€™t become the prisoner of a preconceived plan. Writing is no respecter of blueprints.\n\n\n"},"Articles--and--Papers/Online-Governance-Primer,-Yak-Collective":{"slug":"Articles--and--Papers/Online-Governance-Primer,-Yak-Collective","filePath":"Articles & Papers/Online Governance Primer, Yak Collective.md","title":"Online Governance Primer, Yak Collective","links":[],"tags":["article"],"content":"Source:\nwww.yakcollective.org/projects/yak-online-governance-primer.html\nSummary\nAn excellent collection of, at the least, canonical and inspirational quality well-written essays. The time required to sift through them is immense, but, more importantly, the attention requirements are vast.\nI suspect that reading through the essays mentioned in the bibliography would be a joy if my head is clear and my mindset is right.\nThe Yak Online Governance Primer\nHow do you do online governance?Â This primer is intended as a guided tour through a curated set of readingsâ€”based on a year of study by theÂ Yak Collective*â€”that can help groups and organizations navigate this question. In selecting the readings we cast a wide net, but in our discussions we made an effort to consider them from the specific perspective of online governance challenges. We believe the ideas surveyed here are applicable to groups and organizations with widely varied purposes, levels of autonomy, degrees of decentralization, and technological sophistication.\nHow should online communities and virtual organizations be governed?Â Every organization that has gone virtual to even a small degree should be interested in this question. ==The range of possible answers spans the gamut from conservative to radical. Online digital technologies allow you to either make incremental tweaks to selected bits and pieces of an organization, or radically rethink every part of it. The fate of your organization depends on making the right choices for the specific challenges it faces\nStarting in mid-2020, a Yak Collective study group has been meeting weekly to explore the question of online governance, one reading at a time. ==This paper is based on 49 readings we studied in our first year. The full list is included in theÂ Annotated BibliographyÂ section at the end of this paper.\n==At one extreme of the range of answers we find organizations that seek to evolve their traditions in minor, cosmetic ways; they run the risk of digital transformation being pure theater.\n==At the other extreme, the adoption of genuinely radical organizational forms such as DAOs (decentralized autonomous organizations) forces the deep redesign of traditional governance mechanisms. Such innovation leads to the risk of failure of initiatives that might have succeeded had they been organized along more conventional lines.\nWe believe this primer will be of value whether youâ€™re part of a mature traditional organization just beginning to develop significant online operations, perhaps due to the impetus of the Covid pandemic, or a web3 native decentralized organization just starting out, propelled by revolutionary spirit.\nThe readings surveyed are not meant to be exhaustive or even representative. ==Our goal is to teach you to fish in the waters of online governance traditions for yourself.== To the extent that we succeed, after reading this primer you will have developed a basic literacy around the topic, and an awareness of several major trailheads for further exploration.\nWhile we have not entirely avoided conventional sources of wisdom on management and organizations, such as academic management literature, we have deliberately and consciously cast a much wider net. ==Our Year 1 readings ranged from academic papers and excerpts from classic books to corporate presentations and blog posts. We read about Paleolithic farming cultures and medieval guilds, and about modern open-source movements and platform ecosystems. We read thought-provoking bits of fiction, sampled manifestos, and even discussed essays about biology and wildlife management.\nThis primer doesÂ notÂ include readings that explicitly discuss blockchain-based governance models such as DAOs. While these are both a current focus of study for our group and a possible future governance direction for the Yak Collective itself, ==we feel a thoughtful and critical appraisal of received traditions of governance is a necessary prerequisite for getting the most out of the rapidly emerging blockchain-focused literature. While blockchain-aware readings will likely feature prominently in a future paper, our intent here is to distill the best of the pre-blockchain past.\nAs we worked our way through the readings, we began developing an idiosyncratic internal lexicon for talking about online governance, drawn both from the readings and our own discussions. We believe this lexicon, a subset of which can be found at the end of this primer, has helped us level up the sophistication, immediate practical utility, and interestingness of our discussions. We encourage you to use our lexicon to jumpstart your own. We also welcome your suggested additions to ours.\nThe remainder of this primer is organized as follows. ==In the next section, we provide overview commentary on the 49 readings, organized around a conceptual map of four governance regimes. We then briefly discuss the challenges of synthesizing an online governance strategy for a particular organization from this universe of disparate, sometimes contradictory ideas. Finally, we offer some notes on our own experiences, along with suggestions for using this primer to guide your own further explorations.\nWe conclude with our lexicon and the annotated bibliography.\nGovernance Regimes\nThe studies in our first year led us to develop a shared map of the territory. Toward the end of the first year we carried out a six-week collaborative sense-making exercise to discuss, sort, cluster, and summarize our readings. Through that exercise we identified two principal axes that seemed the most helpful in sorting the readings:\n\n==fromÂ lowÂ toÂ _high alignment_Â in terms of theÂ intentions and interestsÂ of the participants\n==fromÂ managedÂ toÂ _wild_Â in terms of theÂ structures and processesÂ of interaction\n\nThe 2x2 diagram that results suggests that there are four relatively distinct regimes of online governance, which we have dubbedÂ Hobbesian,Â Gaia,Â Muddler, andÂ Citadel.\n\nIn the following sections we discuss each of the four regimes in turn, roughly in order of strength of governance forces:\n\n==Hobbesian:Â Governance ideas that assume wild defaults and low alignment, and attempt to foster progress despite conflict and chaos (readings 1â€“11)\n==Gaia:Â Governance ideas that assume wild defaults and high alignment, and attempt to foster progress by drawing on natural patterns and harmonies (readings 12â€“26)\n==Muddler:Â Governance ideas that assume managed defaults and low alignment, and attempt to foster progress by adding some process structure (readings 27â€“33)\n==Citadel:Â Governance ideas that assume managed defaults and high alignment and attempt to foster progress through top-down coordination (readings 34â€“49)\n\n\nHobbesian Regimes: Wild and Low Alignment\nThe Hobbesian regime, the lower right quadrant of the 2x2, is the least governed regime and can be explored through readings 1â€“11.\nThe eleven readings in this section reveal that where a group with wild defaults and low alignment has emerged and thrived, ==it has typically been founded by contrarians who found high-alignment cultures antithetical to their goals and personalities.\nThe Hobbesian governance regime is personified by the archetype of the anarch, explored in the writings of Ernst JungerÂ 1. ==The ideal anarch is an individual whose identity cannot be tied to an organization or ideology, and whose actions and principles are driven by a pragmatism that serves both him and the common good.\nHobbesian groups tend to be relatively low in energy and cohesion. As a result, a functional Hobbesian regime takes time to build and faces many risks along the way. ==One major risk is of individuals being isolated, scapegoated, and persecuted. Junger himself was persecuted by both the Allies and Nazis through World War II.\nEarly in its history, a wild and low alignment governance regime has to solve forÂ trustÂ andÂ common knowledge.Â ==TrustÂ is generally low among individuals who are suspicious of prevailing ideologies and exhibit an inclination towards doing their own research.Â Common knowledgeÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#02)Â is needed for a governance regime to be functional and Hobbesian regimes typically suffer from a strong deficit.\n==Many online communities limit their goals to adopting tools for gathering and communicating and fail to work on building trust and common knowledge, making them vulnerable to Hobbesian failure modes. As a result, a key risk of wild and low alignment organizations is that emergent adversarial behaviors can destroy them. A symptom of such destruction in progress is the presence of multiple charismatic figures competing for influence, especially in heavily politicized contexts. The Intellectual Dark Web, QAnon, and the Occupy movement are good examples from the culture wars of the past decade.\nThe town of Grafton in New HampshireÂ [4], which was taken over by Libertarians over the last two decades, is an example of an organization that began with a goal of being in the Gaia quadrant (wild and high alignment) ==but turned Hobbesian due to lack of alignment with existing residents of the town. Unmanaged emergent effectsâ€”bears running amok in Graftonâ€™s caseâ€”can be traced to insufficient levels of institutionalized common knowledge.\nA more enlightened way to handle Hobbesian conflict might have been to take the approach of Musical.ly founder Alex ZhuÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#05)Â who analogizes joining a new social network to moving to a new cityâ€”â€œcome for the utility, stay for the community.â€\n==Hobbesian patterns of governance tend to work during the early years of a subcultural scene or organization, but tend to fail as they scale. David ChapmanÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#06)Â attributes this to an invasion of people seeking social status, or worse, seeking to exploit the chaos for personal gain. This particular pattern of hostile entryism in young Hobbesian organizations or scenes has co-evolved rapidly, over the last century and a half, with technologically mediated mass culture. Anarchists in early 20th-century China, for example, were infiltrated by communists operating within a more effective top-down structure (www.yakcollective.org/projects/yak-online-governance-primer.html#07). Operating relatively under the public radar (a strategy sometimes called security through obscurity) can help protect a Hobbesian group from being overrun by sociopaths or invading ideologies.\nOne way to mitigate such effects is to simply eschew growth and the hierarchical structures it tends to induce. ==Contemporary organizations have inherited the twentieth-century bias toward growth for the sake of growth, typically measured through metrics such as number of members, revenue, and impact on the zeitgeist. Eschewing growth, however, comes at a cost. Nonhierarchical cultures tend to be poorer, as Sarah ConstantinÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#08)Â points out in an essay on the relationship between hierarchy and wealth. Hierarchy is expensive because it requires systems and people to manage it. It also tends to incentivize the creation of wealth to pay for itself.\n==Emerging forms of nonhierarchical organization could potentially offload many of the traditional functions of hierarchical structures to low-cost automation, allowing relatively Hobbesian organizations to cohere and persist at larger scales. Web3 technologies such as DAOs are a development worth watching in this evolutionary direction.\nHobbesian regimes work sustainably if individuals manage to arrive at a high level of shared common knowledge and a shared understanding of the common good before they are undermined by the many risks. More commonly, however, they transition to one of the other three regimes depending on which internal dynamics predominate:\n\n==If a Hobbesian organization produces enough common good that effective ongoing management is induced, it starts to have the characteristics of an organization withÂ MuddlerÂ governance characteristics.\n==Where charismatic influence drives higher alignment, a Hobbesian group can transform into one withÂ **Gaia**Â governance characteristics.\n==Where a more organized, hierarchical group invades and takes over at the top, it can turn into a group withÂ CitadelÂ governance characteristics.\n\nGaia Regimes: Wild and High Alignment\nThe Gaia regime, the upper right quadrant of the 2x2, is the second-least governed regime and can be explored through readings 12â€“26.\nGaia, the Greek goddess who personified the Earth, also personifies the fifteen readings in this section. The goddess Gaia was the inspiration for James Lovelockâ€™s Gaia Hypothesis (www.yakcollective.org/projects/yak-online-governance-primer.html#12), which holds that living things adapt to and transform their environments. Lovelock speculated that the complex process of wild coevolution implies that ecosystems are always optimizing for the continued existence of life. Groups of people who gather in pursuit of a common goal with wild sensibilities can be said to constitute a Gaia governance regime.\nThe overarching governance question in a Gaia regime is this: will the strong tendency toward organic coevolution make the organization resistant to any form of designed structure, even when it improves functioning or addresses possibly fatal weaknesses? ==In contrast to the Hobbesian regime, which shares the basic suspicion of formal structure, the presence of high alignment makes different outcomes possible.\nIt is important to understand the distaste for designed structures that drives organizations in the Gaia quadrant. Ivan Illich, arguably a Gaian philosopher, exhibited a particularly refined form of this distaste. Illichâ€™s work was marked by a tension between progressive, libertarian, and anarchist impulses.\nDave Pollard offers an accessible overview in his post,Â Ivan Illich: The Progressive-Libertarian-Anarchist PriestÂ [13]. Illichâ€™s work can be understood as a response to the designed institutions which make up modern societies, especially in fields like education and medicine. ==These institutions are a result of the drive to organize large groups of specialists in industrial modes, with a narrow focus on metrics such as productivity. But there is a dark side to this process: the progressive erosion of individual dignity.\n==Jerry Pournelleâ€™s Iron Law of BureaucracyÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#30)Â suggests that industrial-mode institutions are doomed to eventual capture by cults of expertise, which leads to cartel-like organizational behaviors. Complex education and training pipelines emerge, to sustainably produce the narrow specialists needed to perpetuate the captured condition. The result is progressive loss of dignity for all participants.\n==In an effort to reclaim their dignity, individuals often gravitate to anarchist ideas as a response to the burdens of institutional life. Jo Freemanâ€™s essayÂ The Tyranny of Structurelessness(www.yakcollective.org/projects/yak-online-governance-primer.html#31)Â outlines what can happen next. First, informal structures will emerge, with unclear norms and unwritten rules. The authority within the group will be concentrated to a select few elites and status games will ensue as individuals in the group jockey for position. Once this happens, the group loses focus on its original goals, making progress next to impossible.\n==The challenge of the Gaia governance regime is to overcome both the tyranny of systems of control and the tyranny of structurelessness. If individuals can agree on both the mission and the means of accomplishing that mission, they can then decide if theyâ€™re willing to give up a certain amount of freedom in order to reap the benefits of being in the group. This alignment is often achieved through a temporary period of charismatic leadership, though such leadership risks becoming a benevolent dictator for lifeÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#36).\nThe most important task in governing a Gaia organization is to clearly define measures of success in a way that manages the tension between the goals of individuals and the goals of the organization. When the tension is too great, imbalance threatens the stability of the organization. Another advantage of defining the measures of success is that it provides a simple criteria to filter potential additions to the organization. Once everyone has an idea of what success looks like, it is possible for individuals to understand how they fit into the bigger picture.\nThe case of Morning Star, a large tomato processing company, illustrates what wild and high alignment conditions look likeÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#14). Each Morning Star employee creates aÂ colleague letter of understandingÂ (CLOU) which outlines their personal responsibilities and means for being held accountable. Their CLOU is renegotiated every year. Each person in the company gets an opportunity to define how they contribute to the companyâ€™s success.\nTransparency is a key enabler in Gaia governance regimes. GitLabÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#15)Â models itself after open-source software projects. With employees distributed across the globe, the company has to impose some structure to induce order in the chaos. The GitLab employee handbook stresses the importance of documenting decisions, communicating in public spaces, and breaking work down into the smallest pieces possible. Combined, these elements provide individuals with a holistic view of the companyâ€™s operations and their own role within it.\nGaian organizations are sensitive to the limits to structure. Things will not always work as intended. Even the most aligned teams will have dissent. In their famous â€œculture deck,â€ ==NetflixÂ [16]Â recognizes this and provides employees with a process for resolution: they must be willing to voice their dissent and be able to articulate why they disagree. AnÂ informed captainÂ then reviews the issue from all sides and makes a decision. This captain, who often will have to tease out these frustrations, documents the decision for review by the entire organization. Captains are trusted to make informed decisions and donâ€™t need consensus to move forward. The team is expected to rally around the final decision so that the outcome is as successful as possible.\nGaia governance regimes tend to discriminate against candidate members who donâ€™t have a shared understanding of organizational values. In theirÂ Handbook for New Employees, ValveÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#17), for instance, asserts that their Gaia model is scalable, as long as they remain particular about the people they add to the company. Making the wrong hire can be a particularly expensive mistake in Gaia regimes: either you let a promising potential hire get away, or you miss key warning signs and a new team member wreaks havoc on the organization.\nMany general principles are revealed by these specific cases. ==Gaia organizations delegate tasks and authority and demand strong commitment from individuals in return. With such delegation come respons dibilities for meeting criteria for success. Over time, individual responsibilities must be switched around to avoid the hoarding of knowledge. Information must be made freely available. All decisions must be documented to provide context to the rest of the team.\nWhen these principles are successfully adopted and practiced, organic coevolution is possible, and the system can operate with high energy and tempo. ==Where they fail, Gaia organizations can drain energy and migrate into the Hobbesian quadrant, through unmanaged dissent and unraveling alignment. Or they might lose variety and distributed autonomy, adopt stronger, more overt organizational forms, and move into the Citadel quadrant.\nMuddler Regimes: Managed and Low Alignment\nThe Muddler regime, the lower left quadrant of the 2x2, is the second-most-governed regime and can be explored through readings 27â€“33.\nThe Muddler governance regime represents a condition of shared and commonly acknowledged ignorance rather than common knowledge, with expectations set accordingly. ==The critical insight regarding the Muddler regime is that self-deprecating humility and a sense of humor in approaching decentralized orgs is a superpower.\nWhen a group sees itself asÂ ordinary people muddling through in ignorance, doing their mediocre best rather than asÂ Chosen Ones constructing a utopia, things are seen in realistic proportions. The seven readings of this section help foster and anchor the attitudes necessary to govern in the Muddler regime.\nThe quadrant label comes from Charles Lindblomâ€™s 1959 article,Â The Science of Muddling ThroughÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#27). In it, Lindblom identifies the method of successive approximations (which bears a strong resemblance to modern agile management methods) as a characteristic of successful organizations. The muddling-through organization is the opposite of the efficient, machine-like organization. Frederick LalouxÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#28)Â characterizes this condition in terms of loosened optimality criteria, and heightened appreciation for the benefits of â€œfatterâ€ unoptimized systems. An example can be found in the interview with Tobi LÃ¼ttke, founder of Shopify www.yakcollective.org/projects/yak-online-governance-primer.html#29). The key is understanding the organization as a complex system, and being non-deterministically in harmony with, and attuned to, whatâ€™s going on. But this posture must also be oriented toward a purpose, and resist simply surrendering to the systemâ€™s natural evolutionary tendencies.\n==You can tell youâ€™re in the Muddler quadrant if you seem to be making progress, but in a confused, near-random-walk way, with many misunderstandings between people due to misalignment at the level of information rather than values. Over time you notice net positive movement emerging. Forbearance and patience achieve a lot. There is a sense of inefficient and sloppy relentlessness. Knowledge retention and transmission will be lossy, naturally producing the muddling-through process and killing any attempt to do a rational planning process.\n==A key risk in the Muddler quadrant is bureaucratic capture. Jerry Pournelleâ€™sÂ Iron Law of Bureaucracy(www.yakcollective.org/projects/yak-online-governance-primer.html#30)Â and Jo Freemanâ€™sÂ Tyranny of StructurelessnessÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#31)Â both argue that â€œmanagementâ€ effectively emerges, for better or worse, even if things look unmanaged. Anarchy in the sense of chaos is unstable.\nThe tempo of the muddling-through regimeâ€”staccato stop-go janky progressâ€”is captured by two short readings. The Hurling Frootmig principleâ€”derived from a passage inÂ The Hitchhikerâ€™s Guide to the GalaxyÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#32)â€”states that most work gets done by random people wandering in at lunchtime and seeing something worth doing. The Wind in the Willows principleÂ [33Â asserts that people can vanish abruptly and reappear at any time, and that the system should be able to make use of their unpredictable availability anyway. ==These two principles suggest a key tension between being, on the one hand, open to the serendipity of creative contributions from unexpected new participants and, on the other hand, forgiving of unreliable and unequal participation by existing participants caused by the uncertainties and resources limits of individual lives. This idea harmonizes with whatâ€™s become known as Postelâ€™s Law, fromÂ The Tao of the IETFÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#35), which advocates, â€œbe conservative in what you send and liberal in what you accept.â€ Applied to governance, muddling through requires being conservative in what you police and liberal in the patterns of participation you accept.\n==Muddling through is a low-energy condition because there is a lot of acknowledged uncertainty and decisions/actions happen despite this uncertainty. Time is spent in experimentation and rework, as well as in sorting out tactical confusions and dealing with shifting patterns of participation.\n==At the Yak Collective, the Muddler regime tends to be the default quadrant. Other quadrants are inhabited by exception. For example, within a well-defined project we might drive up to Citadel or Gaian levels of energy or alignment; around a contentious issue we might briefly inhabit the Hobbesian quadrant. But much of the time we are muddling through.\n==What makes the Muddler regime a stable place is that things actually tend to live up to expectations based on good-humored cynicism. The challenge, though, is that these expectations are typically low. The Muddler regime can yield somewhat desultory, stop-go progress. Without spikes of more energized action, staying permanently in a Muddler regime can equal a slow death.\nCitadel Regimes: Managed and High Alignment\nThe Citadel regime, the upper left quadrant of the 2x2, is the most strongly governed regime and can be explored through readings 34â€“49.\n==The sixteen readings in this section revolve around organizations that are usually discussed in terms of platforms and ecosystems.\nPlatforms and ecosystems are ubiquitous today, but are still confusing even for their participants. An ecosystem can be defined as â€œa dynamic group of largely independent economic players that create products or services that together constitute a coherent solutionâ€Â (www.yakcollective.org/projects/yak-online-governance-primer.html#20). ==The significant questions in the Citadel quadrant revolve around why and how exactly these independent players can collaborate, what keeps them together, and how their products and services compete.\nOne of the problems most platform builders face is that intuitions developed while running a traditional organization frequently fails them. For example, hoarding power and value is often adaptive in traditional organizations but can drive platforms to failure. Intelligent ways to distribute power and value can be hard to discover.\nMetaphors derived from traditional organizations can be misleading as well. For example, the nameÂ CitadelÂ selected for this governance regime, while generally reflective of the underlying aspirations, implies strong walls to protect an ecosystem or a marketplace from external threats. While the metaphor highlights some of the logic of this regime, it misses a key point. Ecosystems and marketplaces need dynamic, rather than static, protection. ==It is their openness that makes them stronger. What needs protection might be an economic engine defined via network effects, rather than a geographic perimeter or traditional market boundary. It may not be possible to hide such an engine behind walls. And unintended consequences from network effects can break even the strongest of walls.\nThreats can also emerge internally in a citadel ecosystem. For example, there is a tension between attempts to ensure that hierarchical control is tractable and the need to respond to novel circumstances in novel ways, leading to the proliferation of new rules, new teams, and unconventional ways of working.\nThese forces operate at different tempos. ==Hierarchical forces operate on linear time scales, according to designs and plans. Emergent ones operate on a more organic tempo, characteristic of the the organizations discussed in the Gaia quadrant. These emergent forces are typically weak in the beginning, but can strengthen rapidly as the organization learns. Uneven tempos are a feature, not a bug, but the hierarchical regulation forces that they trigger can fail by being too slow or too fast. The most likely outcome of such misregulation is a ghost town, where serendipity has been squashed.\nWhen this tension is palpable, it is a clear sign that youâ€™re in the Citadel quadrant. It is precisely this tension that produces ecological surprises. An ecological surprise is a turn of events that canâ€™t be predicted based on traditional logic. This happens when people are either wrong about the future, mismanage the system, or discover something surprising about it.\nSurprises are inevitable. You can either fight them or learn from them. ==Some organizations successfully turn this process of constant discovery into an element of their economic engines. In such cases the creative tension drives what can be called â€œa serendipity engine.â€ An example is the Pinduoduo marketplaceÂ 34. Individuals with well-developed platform thinking mindsets are able to see most surprises in a serendipitous light. But for people with strongly traditional hierarchical mindsets, every surprise can seem like a threat.\nEcosystem governance is about nurturing and protecting network effects by responding appropriately to surprises. But there are few universally applicable governance principles. Due to winner-take-all effects, every successful example tends to be one-of-a-kind. Lessons from specific examples tend to be hard to generalize.\nAs a result, attempts to accurately describe whatâ€™s going on inside a sufficiently developed citadel ecosystem usually fail. You can, of course, study the principles sincerely articulated by insiders, but they are difficult to port to other settings.\nPrinciples derived from successful examples like the IETF (an organization with both Citadel and Muddler characteristics), make complete sense only in the context of the original circumstances. Furthermore, these circumstances are not static, but change with the development of an ecosystem. For example, the authors of The Tao of the IETFÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#35)Â acknowledge that the principle â€œthe IETF recognizes leadership positions and grants power of decision to the leaders, but decisions are subject to appealâ€ only makes sense in the context of specific historical details, but the details themselves are meaningless to outsiders, making the principle hard to port to other contexts.\nDue to the uniqueness of successful platforms, the only general principles available are broad-strokes ones. One such principle can be found in a speech delivered in 2014 by Frank ChimeroÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#36).\nIn it, Chimero contrasts the cases of managing wolves in farming regions of the Western United States and managing bear populations within Yellowstone National Park. In the former case, which played out early in the history of the region, the interests of the organized ranching industry led to a failed attempt to manage the wolf population through large-scale slaughter, aimed at eradication. In the latter case, a similar problem involving the bear population was successfully addressed through investment in long-term sustainable population management processes. Chimero uses the two cases as motifs of two very different approaches to problems in complex systems emerging from the collision between structured interests and wild ecosystems: â€œshooting the source of the problemâ€ versus â€œinvesting in a process to keep things open and adaptable.â€œ\nThis is perhaps the essence of managing Citadel-like systems that attempt to create islands of order and civilization within essentially wild ecosystems.\n\nThe Synthesis Challenge\nWe see two primary challenges in designing an online governance strategy for an organization.\nThe first challenge is to introspect on levels of alignment and management capability to identify the prevailing regime and adopt appropriate mental models, reference precedents, and heuristics. Trying to run a citadel-like environment with a Hobbesian approach, or vice versa, is a recipe for disaster.\n==Assessing any organization, especially a young one with poorly developed characteristics and a short history, is a highly subjective exercise. Our studies suggest that paying attention to three key attributes can help locate organizations in the vast space of possibilities and orient toward the most important problems and potential challenges:Â temporality,Â energy, andÂ common knowledge:\n\n_temporality:_Â the seasons, cadences, events that are unique to the group or organization\nenergy:Â the energy level of the group, which shapes the type of projects and work it will engage in\n_common knowledge:_Â the shared knowledge in the organization\n\nWhile the four regimes and associated readings from the previous section provide a starting point for modeling any online governance situation, we recognize that all such taxonomies are arbitrary. No organization is purely in one regime or the other or stays in a stable location. No taxonomy can capture all the salient features of a particular situation. The two axes that we have chosen for our frameworkâ€”alignment and managementâ€”may not foreground the most important aspects in a particular case.\nDeveloping appropriate mental models for the unique circumstances of a given organization requires imagination. We hope the framework and readings we have introduced provide you with good fodder and a starting point.\nThe second challenge is to avoid common traps. In our studies and discussions of various cases, two traps stood out in particular:\n\nover-indexing on technologyÂ and\nover-indexing on traditional institutions.\n\nOver-indexing on technology, driven in part by the sheer excitement around new technologies, leads to what weâ€™ll callÂ the techno-utopia trap.\nMany who participate enthusiastically in online communities approach online governance as though the mere use of the newest mediaâ€”whether it is messaging apps or blockchainsâ€”changes almost everything, creating a blank slate where ideal visions of organization can be realized. To the extent historical experiences (including older online experiences over the past forty years) inform or inspire governance ideas at all, they tend to do so in the form of biases inherited from particular romanticized historical eras favored by early members of a given community. Favored historical reference points include medieval guilds, the Hanseatic league, 60s counterculture, and early 90s USENET culture.\n==While this blend ofÂ tabula rasaÂ thinking and romantic cherry picking of reference points can occasionally lead to refreshing new insights and much-needed shedding of historical baggage, it can also lead to naive idealism and wishful thinking, and governance attempts that fail through inevitable disillusionment.\nOver-indexing on traditional institutions, driven in part by the sheer abundance of scholarship and historical information about them, leads to what we callÂ the grand-old-institution trap.\nThose invested in long-running traditions of scholarship and research relating to questions of governance and management (often from academia) often approach the question as though the context of new digital tools, information ubiquity, algorithmic mechanisms, and unusual patterns of organizing changes almost nothing. Such individuals often have limited experience of deep, extended, skin-in-the-game participation in online, virtual groups. They often assume that any new governance principles can be inferred through relatively shallow â€œfield researchâ€ in a conventional anthropological mode, coupled with the application of well-known ideas. ==Perhaps most importantly, they are often blind to the biases they inherit from their own home institutional forms such as universities, corporations, nonprofits, or public sector institutions.\nWhile such a tradition-bound approach can occasionally cut through simplistic utopian thinking and introduce much needed sophistication to active online governance efforts, it can also lead to entirely missing the essence and power of online modes of gathering, organizing, and doing. The result is often governance attempts that fail through lack of imagination.\n==Online governance is a challenge where â€œthe medium is the messageâ€ effects are particularly strong, and tradition casts a very long shadow. This makes organizational synthesis a wicked problem at the intersection of tradition and technology. New technologies might offer powerful and novel affordances in one area, while rendering familiar ones unworkable. Old traditions might bring much-needed thoughtfulness in one area, while crippling the potential of new technologies in another.\nSynthesizing an effective governance strategy in the face of these challenges is not easy. ==The principals must cultivate imaginative mental models that embody inspiring, generative, and elegant ideas, as well as an aliveness to practical concerns, historical baggage, and well-known risks that can derail attempts to actually execute on them. The cost of failure is wasted time, energy, and resources, but the reward of success is that your organization just might inherit the future.\nConclusion\nFor the Yak Collective, the ideas we have surveyed in this primer are not mere stimulating fodder for intellectual curiosity. They shape our own ongoing attempts to govern ourselves better and doÂ moreÂ things, and moreÂ interestingÂ things, both individually and collectively.\nThe current broad mission of the Yak Collective is to create an online network and community for collaborating on independent projects in a welcoming, friendly context. Our mission continues to evolve, guided by our ongoing studies and the needs of our latest projects. Week by week, we continue to muddle through, with periodic excursions into Hobbesian, Gaia, and Citadel regimes. Currently we are exploring how to adopt web3 technologies in creative ways and pursuing ambitious projects in other areas.\nOur own studies and readings continue in our weekly online governance meetings which are free and open to all our members. You are welcome to join us. You are also welcome to reach out for help and consulting support for your own online governance challenges.\nYou can join the Yak CollectiveÂ here. The online governance chats happen on our Discord server Fridays at 11 CST (UTC-6).\n\nSuggestions for Next Steps\nThe format of this primer is loosely inspired by the format used at Amazon meetingsâ€”the well-known Amazon 6-pager. If you are part of a group or organization learning to govern itself online, we highly recommend reading this paper as intendedâ€”in a small group of 8-10 and at the start of a meeting to discuss it. Allow about 20 minutes for a quick first read. If youâ€™re interested, reach out and one of us will be happy to join you for your session.\nWe believe the primary value of this document lies in our lexicon and the curated list of readings. To get the most out of it you should at least browse the lexicon and sample a handful of the readings.\nWe recommend the following lighthouse readings as being particularly valuable since they articulate foundational ideas:\n\nJo Freemanâ€™sÂ The Tyranny of StructurelessnessÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#31)\nCharles E. Lindblomâ€™sÂ The Science of Muddling ThroughÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#27)\nSteve Yeggeâ€™sÂ Platform RantÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#37)\nDonna Harawayâ€™sÂ Anthropocene, Capitalocene, ChthuluceneÂ (www.yakcollective.org/projects/yak-online-governance-primer.html#23)\n\n\nLexicon\nBirds of a Feather:Â People with the same interests who might do things together. From glossary ofÂ The Tao of the IETF.\nBest Current Practice:Â A type ofÂ request for commentsÂ (RFC), a documentation of the best way to do something.\nClark Principle:Â â€œWe reject kings, presidents and voting. We believe in rough consensus and running code.â€\nâ€”David Clark, fromÂ The Tao of the IETF.\nCRiSP:Â â€œcontinually regenerating its start positionâ€â€”a form of governance embedded within the idea of an open participatory organization. A learning organization that reproduces itself. From Bonnita Royâ€™sÂ Open Architecture for Self Organization.\nDecentralized Control:Â A system of governance in which there is no single member has overall control of resources or decisions. Principle fromÂ The Tao of the IETF.\nDynamic Capability:Â â€œThe firmâ€™s ability to integrate, build, and reconfigure internal and external competences to address rapidly changing environments.â€\nâ€”David J. Teece, Gary Pisano, and Amy Shuen\nDogfooding:Â Eating your own dogfoodÂ is the practice of an organization using its own product. FromÂ Steve Yeggeâ€™s Platform Rant.\nEedies:Â Player types that can do damage to a guild. Notable examples are the Greedy, the Needy, the Leety, and the Cheaty. FromÂ Nonhuman Resources: Recruiting Players and Evaluating Recruits.\nYak-Etiquette:Â â€œMole recollected that animal-etiquette forbade any sort of comment on the sudden disappearance of oneâ€™s friends at any moment, for any reason or no reason whatever.â€\nâ€”Wind in the Willows\n(see also: Postelâ€™s Principle)\nEdge-User Empowerment:Â A principle in the IETF that edge users of the internet should be empowered; can be generalized to any decentralized system. Also applied to devices at the edge (or client end) of the network. Applied to the Yak Collective, implies prioritizing individuals attached to the edge of the social graphâ€”e.g., new members just joining or people who occasionally participate in small waysâ€”over those at the core who are heavily involved. Principle fromÂ The Tao of the IETF.\nExternalizable:Â A means of characterizing service interfaces designed for more public and externally oriented forms of consumption; often implemented through a broad set of case-specific rules. FromÂ Steve Yeggeâ€™s Platform Rant.\nFault-Tolerant Byzantine Sharding:Â â€œI realize Iâ€™ve been unconsciously operating with this heuristic for a while. I am going to try and make it more rigorous. Something like â€˜it should always take minimum 3 people to construct a global state snapshot even approximately, and there should be no MECE subgroupâ€¦ any group with global state awareness should also have minimum 2x redundancy. For example, if there are 3 logical bits in a state, p, q, and r, and 3 people, A, B, and C, who each know max 2 bits, you can have: A knows (p, q), B knows (q, r), C knows (p, r). The full state is known with 2x redundancy by the group.â€™ Iâ€™m guessing thereâ€™s an infosec or distributed computing idea like this. If not, Iâ€™m calling it fault-tolerant Byzantine sharding.â€\nâ€”Venkatesh Rao on the Yak CollectiveÂ Discord\nFlash Teams:Â Flash teams advance a vision of expert crowd work that accomplishes complex, interdependent goals such as engineering and design. The goal is to enable experts and amateurs alike to contribute skills they enjoy, on a set of tasks that they find interesting, and at scale. Flash teams require small atomic actions called blocks. Flash teams exhibit distributed leadership. FromÂ Expert Crowdsourcing with Flash Teams.\nFree Rider:Â Classic economics concept pioneered by Mancur Olson. It refers to people who make use of public goods without contributing to their upkeep and renewal. Related toÂ Tragedy of the Commons. FromÂ Wikipedia.\nHurling Frootmig Principle:Â Things are best done when random people wander into workplaces at lunchtime when actual employees are out to lunch. FromÂ The Hitchhikerâ€™s Guide to the Galaxy.\nIron Law of Bureaucracy:Â There are two types of people in an organizationâ€”people who are dedicated to the goals of the organization and people who are dedicated to the organization itself. The Iron Law of Bureaucracy is that people who are dedicated to the organization will eventually take control of it. FromÂ Iron Law of Bureaucracy.\nLand-Grab Mode:Â Once there isÂ minimum viable happinessÂ andÂ tipping loopsÂ in marketplaces, look for other opportunities that are adjacent to the values of the brand/community. FromÂ Hierarchy of Marketplaces.\nLeety:Â Players that treat themselves as elite. Think that they have to win every argument no matter how trivial. FromÂ Nonhuman Resources.\nLibrary-shelf system:Â A form of common knowledge where organizational functionality is maintained as self-contained and interoperable packages. FromÂ Steve Yeggeâ€™s Platform Rant.\nMurmuration Principle:Â Ad hoc groups form, move, and disperse as needed to feed and evade predators. An individual can make good decisions for the group with situational awareness of a few other nearby individuals. FromÂ An Open Architecture for Self-Organization.\nMinimum Viable Happiness:Â Platforms that create meaningfully more happiness in the average transaction than any substitute,Â notÂ how many transactions you accumulate, will dominate the market. FromÂ Hierarchy of Marketplaces.\nMuddling Through:Â An approach to decision-making based onÂ successive limited comparisons. CompareÂ Rational-Comprehensive. FromÂ The Science of Muddling Through.\nPostelâ€™s Principle:Â â€œBe conservative in what you send and liberal in what you accept.â€ FromÂ The Tao of the IETF.\nPlatforms:Â An underlying basis of operations from which functionality is executed, often through a service interface. FromÂ Steve Yeggeâ€™s Platform Rant.\nPlatform Business Models:Â A process of creating value by an array of players whose specific roles and responsibilities are geared toward generating and sustaining network effects. FromÂ A Systemic Logic For Platform Business Models.\nRational-Comprehensive:Â Also called theÂ root method. An approach to complex decision-making based on logical root-cause analysis and comprehensive modeling. It is contrasted to the method calledÂ muddling throughÂ or theÂ branch method, from Lindblomâ€™s T_he Science of Muddling Through_Â (seeÂ Muddling Through). In general, the branch/muddling through/successive limited comparisons method is preferred by the Yak Collective and the root method is only appropriate in limited bounded problem domains where comprehensive perfect information is available. FromÂ The Science of Muddling Through.\nService Interface:Â A means of exposing knowledge or functionality independent of underlying operations in a fashion that accounts for user accessibility. FromÂ Steve Yeggeâ€™s Platform Rant.\nService-Oriented Architecture:Â A style of designing systems where component pieces are wrapped in service interfaces such that they are self-contained, interoperable, and repeatable. FromÂ Steve Yeggeâ€™s Platform Rant.\nSlime Mold Principle:Â Creating affordances for simple exploratory behaviors in a group leads to fruitful developments. â€œThere is nothing magic that humans (or other smart animals) do that doesnâ€™t have a phylogenetic history. Taking evolution seriously means asking what cognition looked like all the way back. [â€¦] From this perspective, we can visualise the tiny cognitive contribution of a single cell to the cognitive projects and talents of a lone human scout exploring new territory, but also to the scoutâ€™s tribe, which provided much education and support, thanks to language, and eventually to a team of scientists and other thinkers who pool their knowhow to explore.â€ FromÂ Cognition all the way down.\nSuccessive Limited Comparisons:Â An approach to complex decision-making, also calledÂ muddling throughÂ or theÂ branch method, based on Lindblomâ€™sÂ The Science of Muddling ThroughÂ (seeÂ Muddling Through) that relies on systematic trial and error starting from limited, local solutions to a larger problem. Contrast with theÂ root method. FromÂ The Science of Muddling Through.\nTheory of the Firm:Â An approach to economics pioneered by Ronald Coase, based on the idea that firms emerge when internalizing activities within an organizational boundary minimizes coordination and transaction costs.\nTipping Point:Â Point at which the core goal of the platform or community becomes easier and not harder. For a marketplace platform this could mean lower acquisition cost, doing fewer non-scalable things. Tipping loops are happiness loops + loops related to growth of the platform (e.g., for the Yak Collective it is the number of projects active/in pipeline, etc.). FromÂ Hierarchy of Marketplaces.\nTragedy of the Commons:Â Classic game-theoretic formulation of the problem of too many people making use of public resources and too few contributing to its upkeep. Often used as the explanation for why public goods get appropriated for private benefit over time and often modeled with the prisonerâ€™s dilemma game. See alsoÂ Hurling Frootmig PrincipleÂ which is a sort of reverse tragedy of the commons.\nVersioned-Library System:Â A form of maintaining common knowledge where the state of common knowledge and state changes are kept track of through an incrementally increasing naming heuristic. FromÂ Steve Yeggeâ€™s Platform Rant.\nWeberâ€™s Iron Cage:Â Peer Production (communities, open source projects) is generally seen as a utopian upgrade to bureaucracy but as complexity of peer production grows, peer production could also become similar to bureaucracy. FromÂ The limits of peer production.\nYak:Â A large bovine native to the Tibetan plateau.\nAnnotated Bibliography\n1 Ernst Junger: Core ideas of Ernst Junger. TheÂ anarchÂ can take any form, does not actively resist tyranny, is pragmatic, and sees what can serve him and the common good, but is closed to ideological excess.Â \n2 Common Knowledge Problem: Working in groups requires common knowledge to be built and dissipated across time. New members find it harder to join a group when they donâ€™t have the common knowledge of the rest of the group.Â â®¨\n3 Nakatomi Space: Breaking out of common understanding of barriers and standard processes enables greater degrees of freedom toward achieving a desired goal or outcome. Principle explored via an architectural close-reading of the movieÂ Die Hard.\n4 The Town That Went Feral: Libertarians flock to small New Hampshire town to live as they please, but the lack of organization and alignment made life worse for all.Â â®¨\n5 Notes on Interview with Alex Zhu: It is very hard to change human nature. We should follow it instead of fighting with it. â€œCome for the utility, stay for the community.â€Â â®¨\n6 Geeks, MOPS, and sociopaths in subculture evolution: Subcultures are subject to forces that put them on a predictable trajectory, which can be managed if the subculture is willing to see their thing for what it is and Be Slightly Evil to defend what is good.Â â®¨\n7.Anarchists in China: A history of the Chinese anarchist movement in the 1900s with strong parallels to current times. This movement coincided with late stage industrial revolution, and surfaced tensions between individual freedom and a uniform moral code that is imposed top-down.Â â®¨\n8.Relationship between hierarchy and wealth: Structurelessness in organizations is hard to maintain. There are examples of stateless anarchies which possibly built bronze-age level cities in Iceland, Harappan civilization, etc., but there are no examples of it in industrial societies. Hierarchy is expensive, more freedom causes poverty.Â â®¨\n9.The Limits of Peer Production: The authors take a skeptical view of utopian claims about the vision of peer production and argue that it has less revolutionary potential than claimed, and requires more critical scrutiny. They see it primarily as an extension of existing modes of production, with all the baggage that entails.\n10 Doctorow Metacrap article: Barriers to making useful metadata (c. 2001).\n11.Picking the Right Approach: About trust and common ground: There are a lot of tools being developed for collaboration but many of them donâ€™t solve the problem. The main problem seems to be lack of knowledge about where the expertise lies and how to find it.\n12.Gaia Hypothesis: James Lovelockâ€™s Gaia hypothesis proposed that living organisms interact with their inorganic surroundings on earth to form a synergistic and self-regulating, complex system that helps to maintain and perpetuate the conditions for life on the planet.Â â®¨\n13.Ivan Illich: The Progressive-Libertarian-Anarchist Priest: Blog post by Dave Pollard. â€œInstitutions create the needs and control their satisfaction, and, by so doing, turn the human being and her or his creativity into objects. Illichâ€™s anti-institutional argument can be said to have four aspects: a critique of the process of institutionalization, a critique of experts and expertise, a critique of commodification, and the principle of counterproductivity.â€Â â®¨\n14.Morning Starâ€™s Success Story: Self-managing principles of worldwide market leader in tomato processing. Uses a format they call the Colleague Letter of Understanding (CLOU)â€”a short document that details an employeesâ€™ personal commercial mission and all the commitments they have made with employees who are affected by their work. All employees also go through an onboarding process which seems to involve unlearning previous habits.Â â®¨\n15.GitLabâ€™s Approach to All-Remote: A whitepaper examining GitLabâ€™s asynchronous work model and the main practices that are implemented to create an effective environment for work. Primary thrust seems to be premised around a strong shared culture of self-contained, legible communications and how operational autonomy can be attained at the cost of lower strategic autonomy a la modeling workflows after CI/CD.Â â®¨\n16.Netflix Culture Deck: Netflix deck on being an individual contributor without a lot of centralized management and avoiding chaos with increasing complexity. Key tenets include functioning like a pro sports team, and operating in highly aligned loosely coupled ways.Â â®¨\n17.Valve Employee Handbook: Valve, the video game studio, provides principles for employees to operate without managerial oversight. Topics include choosing projects, performance reviews, self-improvement, and growing the company.Â â®¨\n18 Ingroup Contrarian: Assuming a Durkheim-Girard approach to analyzing group dynamics in terms of mimesis and effervescence, this article explores the phenomenon of the scapegoating of the ingroup contrarian.\n19.Free-rider problem: Classic principle (Mancur Olson) of collective action that develops a model of free-riding behavior in primarily a game-theoretic way as a problem to be solved.\n20.Do you need a business ecosystem?: The authors defined a business ecosystem as â€œa solution to a business problem, as a way to organize in order to realize a specific value proposition,â€ and aimed to flesh out that definition by examining how it differs from other governance models, basic types of business ecosystems when it is an effective governance model and the associated drawbacks.Â â®¨\n21.Technology, Innovation, and Modern War: Examined the ways new operational or organizational doctrines are created, and the factors that contribute to the timing of such a change. Especially in the public sector, doctrinal changes are aimed toward gathering buy-in from a large bureaucracy of politically motivated executives. When implemented from the top-down, such directives are at risk of being out of touch with the realities of those on the front line. This divergence then causes innovative pressure to build from the bottom-up in the form of hacked together solutions, and when the tension is no longer sustainable conditions become ripe for an organizational sea change.\n22.Carrier Bag Theory of Fiction: Ursula Le Guin claims that fiction is predominantly hero-centric: it begins with struggle and ends in triumph or tragedy. But she also believes that thereâ€™s another way: telling the stories of ordinary people instead of heroes, which we can store in our own containers to reflect upon in the future.\n23.Anthropocene, Capitalocene, Chthulucene: Donna Haraway proposes an alternative concept of the anthropocene called the Chtuhlhucene, based on a local-global entanglement with nature, and contrasts the concept with the Lovecraftian cosmic-horror version of Cthulhu (different spelling, same Greek root inspiration).Â â®¨\n24.Introduction to Kropotkin: Kropotkin wanted to base anarchist theory around biologyâ€”the idea that animals have a higher chance of survival by collaborating than being competitive. His ideology was reactionary to the growth of centralized governance. His theory was that â€œmutual aidâ€ was responsible for the growth of mankind till the medieval ages when centralized ideas such as that of the church and state started to take hold.\n25.Hoe Culture: Hoe culture maximizes production per hour of labor, and is not physically demanding. This leaves lots of time for leisure, and also enables women to be economically productive and enjoy other freedoms. Plow culture maximizes production per unit of land, which has historically required the strength of a man to quickly turn over fields. Men support women, and culture becomes deferential to the producers. The author makes no claims of right and wrong, but uses this model as proof that non-patriarchal societies have worked in the past.\n26 Cognition All the Way Down: Authors look at parts of organisms as agents, detecting opportunities and trying to accomplish missions. They admit that it can be risky, but it is a worthwhile thought experiment. â€œTreating cells like dumb bricks to be micromanaged is playing the game with our hands tied behind our backs and will lead to a â€˜genomics winterâ€˜ if we stay exclusively at this molecular level.â€\n27.The Science of Muddling Through: Charles E. Lindblom contrasts two methods for working through complex, messy problems: rational-comprehensive orÂ rootÂ method, and successive limited comparisons orÂ branchÂ method. The latter isÂ muddling through. He argues that the latter is both more effective and more used in practice.Â â®¨Â â®¨\n28.Frederic Laloux on what lies ahead for business:Â PlatformsÂ andÂ ecosystemsÂ are more robust in turbulent times but can become fragile when everything is steady.Â â®¨\n29.Tobi LÃ¼tke on Organization Design and Gaming: Founder of Shopify, LÃ¼tke spoke about how he has designed Shopifyâ€™s culture to be generative and led from the bottom-up, as informed by his background in playing games such as Starcraft and Factorio. His emphasis has been on creating effective structures to manage peopleâ€™s time and attention in a way thatâ€™s just-in-time.Â â®¨\n30 Pournelleâ€™s Iron Law of Bureaucracy: Short assertion by Jerry Pournelle: people dedicated to perpetuating an organization will eventually overwhelm those who want to pursue its stated mission.Â â®¨Â â®¨\n31.The Tyranny of Structurelessness: Classic article by Jo Freeman. Womenâ€™s movements in the 1970s era viewed structure as a form of tyranny, so they prided themselves on being structureless. That worked well to bring people together, but fell apart when it was time to take action. Informal political structure begins to take hold and distracts the group from being productive. This classic article advocates for experimentation and willingness to have structure and some provides principles â€œthat are essential to democratic structuring and are also politically effective,â€ includingÂ delegation,Â rotation, andÂ diffusion of information.Â â®¨Â â®¨Â â®¨\n32.Hurling Frootmig Principle: Develop work processes that are sufficiently granular that group members can grab a task and contribute as they are able. The group doesnâ€™t need tight control for the project to continue: â€œâ€¦the role of the editorial lunch-break which was subsequently to play such a crucial part in the Guideâ€™s history, since it meant that most of the actual work got done by any passing stranger who happened to wander into the empty offices on an afternoon and saw something worth doing.â€Â â®¨\n33.Wind in the Willows Principle: Create group norms that allow for showing up when you can without guilt: â€œâ€¦and the Mole recollected that animal-etiquette forbade any sort of comment on the sudden disappearance of oneâ€™s friends at any moment, for any reason or no reason whatsoever.â€ Suggests making explicit a group norm of joining when you can for voluntary alliances.Â â®¨\n34.Defining interactive e-commerce: Pinduoduo pioneered a new kind of social e-commerce based on serendipity and discovery. It was built around team buying but more personal than things like Groupon. Middleman layers were removed by substituting social interactions where there would traditionally be sales. People convince each other and their friends to get deals. There is explicit modeling on â€œCostco+Disneylandâ€ and inspiration from older models like tupperware parties, but the basic experience is online+mobile and genuinely social. Inspired by IRL patterns like â€œnight market,â€ â€œsushi boat,â€ and â€œgirlsâ€™ day out.â€Â â®¨\n35.The Tao of IETF: Describes the â€œways of IETFâ€ and how a newbie could contribute to RFC. Founding belief embodied in an early quote about the IETF from David Clark: â€œWe reject kings, presidents and voting. We believe in rough consensus and running codeâ€ and what became known as Postelâ€™s Law, â€œbe conservative in what you send and liberal in what you accept.â€Â â®¨Â â®¨\n36.Only Openings: A discussion by Frank Chimero of two contrasting approaches to managing wildlife in the American West and the resulting lessons for complex system design. â€œSome designers want to shoot the wolves, others want to manage the bears. One is trying to make an antidote, the other invests in a process to keep things open and adaptable.â€Â â®¨Â â®¨\n37.Steve Yeggeâ€™s Platform Rant: A famous rant, contrasting technology management practices at Amazon with corresponding practices at Google. Despite the comparison favoring Google in many small ways, Yegge argued that Amazon gets one big thing really right, making up for deficiencies in other areasâ€”doing platform-oriented management effectively.Â â®¨\n38.Benevolent Dictator for life (BDFL): Open source software leaders who have the final say in settling disputes. Famous examples: Guido Van Rossum (Python), Vitalik Buterin. Closely related to the idea of aÂ single wringable neckÂ in a software development project.\n39.Expert Crowdsourcing with Flash Teams: The authors describe a system called Foundry designed to create block-structured workflows allowing automated management and clean handoffs to allow expert teams to do paid, coordinated work at scale.\n40.Guilds Reappraised: Guilds in pre-industrial Italy helped improve productivity, innovation, and quality of output. They were controlled by the most competent master-craftsman, who did a lot of the economic organizing, but also set up apprenticeship systems to pass on knowledge. Industrial changes and consolidation of government power led to the decline of the guild system.\n41 Underutilized Fixed Assets: Kevin Kwok argues that it is very hard to find a marketplace thatÂ wasnâ€™tÂ built on an underutilized fixed asset, which suggests that finding and leveraging underutilized assets is key to marketplaces.\n42.The Dynamic Capabilities of David Teece: â€œTeece originated the theory of â€˜dynamic capabilitiesâ€˜ to explain how companies fulfill two seemingly contradictory imperatives. They must be both stable enough to continue to deliver value in their own distinctive way and resilient and adaptive enough to shift on a dime when circumstances demand it.â€ Dynamic capabilities are unique to an organization and can enable it to thrive under changing conditions. Contrasted with ordinary capabilities which enable a company to reliably produce a particular outcome. Organizations need the skills for sensing, seizing, and transforming to take advantage of dynamic capabilities.\n43.A Systematic Logic for Platform Business Models: An ontology of business models based on three major categories: firm-centered networks, solution networks, and open networks. A forward-looking normative view based on S-D logic (service-dominant) is proposed as the best way to build platform business models.\n44.The Future of Platforms: There are two types of platformsâ€”transactional and innovation, with some hybrids. Hybrids are increasing. The article analyzes platforms from a conventional business lens in terms of market performance, but doesnâ€™t say much about their intrinsic nature or how to manage them.\n45.An Open Architecture for Self Organization: Bonnitta Royâ€™s view of anÂ open participatory organization, based on a metaphor of a fractal network place, with two zonesâ€”coreÂ andÂ networkâ€”and four functionsâ€”access,Â incubation,Â support, andÂ adaptationâ€”that create a architecture for a fluidly evolving governance that isÂ continually regenerating itâ€™s starting position. The key insight is that embodied thinking about change as in Stewart Brandâ€™sÂ How Buildings LearnÂ can be applied to org-chart abstractions via the place metaphor.\n46.Single wringable neck: Who is the scapegoat when it comes to the success/failure of a software development project? Closely related toÂ BDFL. Success has many authors but failure only one.\n47.Do we need a business ecosystem: A blog post from BCG Moscow defines aÂ business ecosystemÂ as â€œa solution to a business problem, as a way to organize in order to realize a specific value proposition. To this end, a business ecosystem is a governance model that competes with other ways of organizing the creation of a product or service, such as a vertically integrated organization, a hierarchical supply chain, or an open-market model.â€ â€œUnpredictable but highly malleable business environmentsâ€ lend themselves to this ecosystem governance model. The key benefits of business ecosystems include access to a broad range of capabilities, the ability to scale quickly, and flexibility and resilience.\n48.2020 Letter to Shareholders: Jeff Bezosâ€™ annual public letter to Amazonâ€™s shareholders included â€œbe originalâ€ and â€œcreate more than you consume.â€ â€œYour goal should be to create value for everyone you interact with. Any business that doesnâ€™t create value for those it touches, even if it appears successful on the surface, isnâ€™t long for this world. Itâ€™s on the way out.â€\n49.The Hierarchy of Marketplaces: Sarah Tavel makes a case that marketplaces scale by creating happinessâ€”figuring out â€œhow to make their buyers and sellersÂ meaningfullyÂ happier than any substitute.â€ AchievingÂ minimum viable happinessÂ means more customers and more transactions.\n\n*Â The Yak Collective started in early 2020 as an online network of indie consultants and people interested in new modes of collaboration. The principles and patterns discussed in this paper shape how we govern and make decisions within the Yak Collective.Â â®¨\nThe Yak Collective // Online Governance Study Group\nProject editorsÂ /Â Sachin BennyÂ andÂ Venkatesh RaoÂ //Â Project writersÂ /Â Sachin Benny,Â Bryan King,Â Grigori Milov,Â Venkatesh RaoÂ //Â IllustrationsÂ / Grace Witherell //Â MembersÂ /Â Patrick Atwater,Â Jenna Dixon,Â Scott Garlinger, Oliver King,Â Phil Wolff"},"Articles--and--Papers/PAPER-Ecosystem-as-Structure-An-Actionable-Construct-for-Strategy":{"slug":"Articles--and--Papers/PAPER-Ecosystem-as-Structure-An-Actionable-Construct-for-Strategy","filePath":"Articles & Papers/PAPER Ecosystem as Structure An Actionable Construct for Strategy.md","title":"Ecosystem as Structure An Actionable Construct for Strategy","links":[],"tags":[],"content":"Summary\nEcosystem is the new platform wherein the focal point is on interdependence rather than finding competitive advantage. Porterâ€™s 5 forces are outdated. An ecosystem participant wants to innovate and change the structure of relationships.\nAbstract\nOver the past 20 years, the term â€œecosystemâ€ has become pervasive in discussions of strategy, both scholarly and applied. Its rise has mirrored an increasing interest and concern among both researchers and managers with interdependence across organizations and activities. This article presents a structuralist approach to conceptualizing the ecosystem construct. It presents a clear definition of the ecosystem construct, a grammar for characterizing ecosystem structure, and a characterization of the distinctive aspects of ecosystem strategy. This approach offers an explicit examination of the relationship among ecosystems and a host of alternative constructs (business models, platforms, coopetition, multisided markets, networks, technology systems, supply chains, value networks) that helps characterize where the ecosystem construct adds, and does not add, insight for the strategy literature.\nIntroduction\nOver the past 20 years, the term â€œecosystemâ€ has become pervasive in discussions of strategy, both scholarly and applied. Its rise has mirrored an increasing interest and concern with interdependence across organizations and activities. Along with a cohort of related ideasâ€”business models, platforms, coopetition, multi-sided markets, networks, technology systems, supply chains, value networksâ€”the notion of ecosystems has raised awareness and focused attention on new models of value creation and value capture. A consequence of this cornucopia of constructs, however, has been confusion regarding how these ideas relate to each other in terms of boundary, overlap, redundancy, applicability, and unit and focus of analysis. This lack of clarity regarding where an ecosystem perspective does and does not add value has hampered the usability of these important ideas.\nIn this article I consider a number of issues around ecosystems and ecosystem strategy. I introduce a specific view of the ecosystem construct that hinges on the structure of the interdependent activities that underlie a value proposition. I contrast this â€œecosystem-as-structureâ€ approach, which takes an activity-centric view of interdependence, with the actor-centric â€œecosystem-as-affiliationâ€ approach that characterizes much of the literature.\nBy starting with a clear definition of â€œecosystemâ€â€”_the alignment structure of the multilateral set of partners that need to interact in order for a focal value proposition to materializeâ€”_I am able to be explicit about its implications, its boundaries, and its relationship with alternative perspectives. In so doing, I identify the conceptual white space that gives rise to the need for the ecosystem-as-structure perspective, and suggest a new set of questions for strategy research in the context of ecosystems.\nI present a grammar for the characterization of ecosystem structureâ€”the alignment of activities, actors, positions, and linksâ€”and apply it to a short case study of an innovative effort to revolutionize the tire industry with run-flat tire technology. This example, explicitlyÂ notÂ drawn from the world of high technology, illustrates a set of interactions that arises in multilateral settings and that can only be described with reference to the specific structure of interdependence. As such, it offers a useful context in which to illustrate the key principles of a structuralist approach to ecosystems, as well as an opportunity to contrast the perspectives of alternative interdependence constructs regarding ventures characterized by joint value creation.\nAs an approach to resource allocation in the context of interdependence, this ecosystem-as-structure perspective highlights partner alignment as a critical strategic challenge that introduces a new dimension of consideration for traditional strategy. Taken together, the characteristics of ecosystem strategy approached in this way suggest it as a distinct complement to established schools of thought around competitive strategy and corporate strategy.\nConceptualizing Ecosystems: Affiliation vs. Structure\nThe term â€œecosystemâ€ has itself grown to encompass an ecology of meanings. A helpful distinction can be made between two general views: (a) ecosystem-as-affiliation, which sees ecosystems as communities of associated actors defined by their networks and platform affiliations; and (b) ecosystem-as-structure, which views ecosystems as configurations of activity defined by a value proposition. It is this latter approach that I will focus on in this article because I find it more clearly distinguishable from other available strategy constructs, because it offers a more actionable perspective on interdependence, and because it more clearly opens up a host of new and distinctive questions for the field of strategy. As the contrast below will show, however, while the perspectives of ecosystem-as-affiliation and ecosystem-as-structure are conceptually distinct, they are mutually consistent. One does not rule out the other, and a given setting may illustrate features of both.\nEcosystem as Affiliation\nOriginating as a biological metaphor, the notion of a business ecosystem highlighted the need for strategy to extend its consideration beyond rivals competing within industry boundaries. Moore, who introduced the term to the business literature, defines the business ecosystem as\n\nAn economic community supported by a foundation of interacting organizations and individuals â€“ the organisms of the business world. This economic community produces goods and services of value to customers, who are themselves members of the ecosystem. The member organism also include suppliers, lead producers, competitors, and other stakeholders. Over time, they coevolve their capabilities and roles, and tend to align themselves with the direction set by one or more central companies. Those companies holding leadership roles may change over time, but the function of ecosystem leader is valued by the community because it enables members to move toward shared visions to align their investments, and to find mutually supportive roles. (Moore, 1996: 26)\n\nIn a similar vein,Â Iansiti and Levien (2004)Â define business networks as ecosystems, organized around a keystone species, and â€œcharacterized by a large number of loosely interconnected participants who depend on each other for their mutual effectiveness and survival.â€ (2004: 8) Such definitions of ecosystems as networks of affiliated organizations are echoed in many recent treatments (e.g.,Â Autio &amp; Thomas 2014;Â Jacobides, Cennamo, &amp; Gawer, 2015;Â Rong &amp; Shi, 2014).\nThis perspective, which I callÂ ecosystem-as-affiliation, places emphasis on the breakdown of traditional industry boundaries, the rise of interdependence, and the potential for symbiotic relationships in productive ecosystems. It focuses on questions of access and openness, highlighting measures such as number of partners, network density, and actorsâ€™ centrality in larger networks. In the business context, analyses held at the level of the â€œhealthcare ecosystem,â€ the â€œMicrosoft ecosystem,â€ the â€œSilicon Valley ecosystem,â€ or the â€œentrepreneurial ecosystemâ€ fall easily into this category.\nStrategy in the ecosystem-as-affiliation realm tends to focus on increasing the number of actors that link to a focal actor or platform, increasing its centrality and expected power. By increasing the number and intensity of participants in its ecosystem, the focal actor increases its bargaining power (e.g.,Â Brandenburger &amp; Nalebuff, 1996;Â Jacobides, Knudsen, &amp; Augier, 2006), increases system value through direct and indirect network externalities (Parker, Van Alstyne, &amp; Choudary, 2016), and increases the likelihood of serendipitous interactions between partners that may unlock new interactions and combinations that will in turn increase the overall value creation of the system.\nEcosystem-as-affiliation offers an appealing metaphor and a helpful description for interactions at a macro level. However, it is often hard to disentangle its characterizations and recommendations from those of other approaches to interdependence (e.g., networks, platforms, multisided markets). Moreover, because of its tendency to look at aggregates, the strategy guidance offered by this perspective tends to focus on general governance and community enhancements, with limited insight into the specifics of value creation.\nEcosystem as Structure\nAn alternative perspective, which I callÂ ==ecosystems-as-structure==, offers a complementary approach to considering interdependent value creation. This approach, which underlies much of my own work on ecosystems (e.g.,Â Adner, 2000,Â 2006,Â 2013;Â Adner &amp; Feiler, 2016;Â Adner &amp; Kapoor 2010,Â 2016a,Â 2016b), starts with a value proposition and seeks to identify the set of actors that need to interact in order for the proposition to come about.\nI offer the following definition of an ecosystem and consider its implications:\n\nThe ecosystem is defined by the alignment structure of the multilateral set of partners that need to interact in order for a focal value proposition to materialize.\n\nI find this definition to help because it clarifies where the ecosystem construct is of relevance, and where it is not. Here I discuss the components of this definition and their implications. In a later section, I will consider how this definition gives rise to a specific view on ecosystem strategy.\n1. â€œAlignment structure\nMembers of an ecosystem have defined positions and activity flows among them. Alignment is the extent to which there is mutual agreement among the members regarding these positions and flows. Different actors may have different end states and end goals in mind. Such cases illustrate the difference between participation and alignment. A successful ecosystem is one in which all actors are satisfied with their positions (i.e., one that achieves, at least temporarily, a Pareto equilibrium). Alignment, thus, refers not only to compatible incentives and motives but also raises the question of actorsâ€™ consistent construal of the configuration of activities.1\nIn contexts in which other actors do not need to be alignedâ€”either because no partners are necessary for the focal firmâ€™s value creation, or because they are already in alignment and do not need to shift (e.g., the case introducing an incremental product variant into an existing supply chain; the case of bilateral exchange where roles such as buyer and supplier are clear and well accepted)â€”there is no particular value to invoking an ecosystem logic. That is, when the ecosystem is latent, as it is in most of our classic product-based examples of competitive strategy, it can be ignored until such time as conditions change and the alignment of actors (whether new or old) again becomes an issue.\n2. â€œMultilateralâ€\nAn ecosystem is inherently multilateral. This means not only a multiplicity of partners, but also a set of relationships that are not decomposable to an aggregation of bilateral interactions. We already have rich language to discuss bilateral relationships, ranging from the market versus hierarchy decisions that underlie transaction cost economics (e.g.,Â Coase, 1937;Â Williamson, 1975) to modern refinements addressing relational contracts (e.g.,Â Dyer &amp; Singh 1998). Similarly, multilaterality that can be fully decomposed simply along the lines of direct and indirect ties also does not require an ecosystem approach. For the ecosystem construct to matter, it must be the case that there is a critical interaction across these relationships. Multilateral interdependence that can be decomposed into an aggregation of bilateral relationships does not require a new construct. For example, for parties A, B, and C, nondecomposability would be exemplified by a case in which a successful contract between A and B is undermined by the failure of the contract between A and C: Analyzing the relationship of A and B in isolation from C would lead to a false conclusion. In this regard, an observation of multiplicity of alliances within a firmâ€™s alliance portfolio (e.g.,Â Lavie &amp; Singh, 2012) is antecedent to, but not sufficient to characterize, multilaterality among these relationships.\n3. â€œSet of partnersâ€\nBeing a set, membership is defined (i.e., it is not open-ended). Different actors may have different plans and perceptions regarding the composition of the set. Thus,Â definedÂ does not mean complete, unvarying, or uncontested; rather, it means that the participating actors in the system have a joint value creation effort as a general goal. The goal may or may not be ultimately achieved. The defining attribute of partners is that they are actors on whose participation the value proposition depends, regardless of whether or not they have direct links to the focal firm.\n4. â€œFor a focal value proposition to materializeâ€\nInherent in this definition is an argument that the productive level of analysis for ecosystems in strategy is the value proposition and that the concern is with bringing about the activities required for its instantiation. Focusing on the value propositionâ€”the promised benefit that the target of the effort is to receive, as opposed to what a firm is to deliverâ€”expands the analysis in a natural way to explicitly incorporate partners. Focusing on materialization raises the requirement that partners reach a threshold level of coordination. Framed in the converse, this lets us consider the extent ofÂ divergenceÂ that the ecosystem can sustain and still bring about the promised value. Thus, because different actors may have different views on the value proposition, an analysis of an ecosystem must account not only for divergence in interests (traditional notions of competition and value capture) but also divergence in perspectives (expectations of value creation and value distribution to third parties).\nThis definition places the value proposition as the foundation of the ecosystemâ€”it is the proposed value proposition that creates the (endogenous) boundary of the relevant ecosystem. The definition also highlights the centrality of the structure of alignmentâ€”as illustrated in the PAX case below, the same set of actors, structured in two different configurations, constitutes two different ecosystems.\nElements of Structure\nFour basic elements underlie a structuralist approach to ecosystems. Collectively they characterize the configuration of activities and actors required for a value proposition to materialize.\n\n\n\nActivities, which specify the discrete actions to be undertaken in order for the value proposition to materialize.\n\n\n\nActors, which are the entities that undertake the activities. A single actor may undertake multiple activities; conversely, multiple actors may undertake a single activity.\n\n\n\nPositions, which specify where in the flow of activities across the system actors are located and characterize who hands off to whom.\n\n\n\nLinks, which specify transfers across actors. The content of these transfers can varyâ€”matÃ©riel, information, influence, funds. Critically, these links need not have any direct connection to the focal actor.\nBecause of their different starting points, the ecosystem-as-affiliation (focused on actors) and ecosystem-as-structure (focused on activities) perspectives differ in their treatment of these elements. For the affiliation approach, positions are derived from links, leading to characterizations such as platforms, brokers, and hub-and-spoke. For the structural approach, links are derived from the alignment requirements that give rise to positions in the overall value blueprint.\nIndeed, the two perspectives follow opposite directions of strategic construction: The ecosystem-as-affiliation approach begins with the actors (usually defined by their ties to a focal actor), considers the links among them, and ends with the possible value propositions and enhancements that the ecosystem can generate. In contrast, the ecosystem-as-structure view begins the value proposition, considers the activities required for its materialization, and ends with actors that need to be aligned (Table 1). Which approach makes more sense to pursue will depend on the question at hand. Of note, however, is that whereas the affiliation approach is focused on actors with direct ties to the focal organization, the ecosystem-as-structure approach explicitly extends the strategic view to include activities and actors over which the focal organization may have no control, and with whom they have no direct contact. As elaborated below, the need to develop strategies that recognize and manage indirect links is one of the key distinctions between traditional strategy and ecosystem strategy.\nTable 1Â Elements of Ecosystem Structure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElements of Ecosystem StructureEcosystem-as-Structure PerspectiveEcosystem-as-Affiliation PerspectiveActivitiesDiscrete actions to be undertaken in order for the value proposition to be createdNot applicableActorsEntities that undertake activitiesEntities that are tied to the focal actorPositionsSpecified locations in the flow of activities across the systemDerived from links to other actorsLinksTransfers across positions, which may or may not include the focal actorTies between the focal actor and other actors\nOpen in viewer\nThese four elements characterize the blueprint for how value is (expected to be) created in the interdependent collaboration that is the ecosystem underlying a value proposition.2Â In mature industries, much of the ecosystem is latent most of the time. The activities, actors, positions, and links are stable; to the extent that there is change, it is at the level of individual actors or dyads (e.g., new products launched through established channels; rivalry among actors in the same positions) rather than affecting the structural alignment of multilateral positions. In such settings, the ecosystem has the taken-for-granted character of routine-as-truce (i.e.,Â Nelson &amp; Winter, 1982). It is when innovation requires a change in the configuration of these elements that the ecosystem becomes apparent and where consideration of ecosystem dynamics becomes critical for crafting and understanding strategy.\nAn Illustrative Case: Michelinâ€™s PAX Run-Flat Tire Innovation\nIt is always helpful to ground ideas in real-world cases. A comparison of two innovations from the tire industry offers both a helpful illustration of ecosystem structure and principles, as well as an opportunity to contrast the ecosystem construct with other approaches to interdependence discussed in the management literature.\nConsider the case of Michelinâ€™s PAX run-flat tire system. The value proposition of the PAX run-flat tire, as suggested by its name, was the promise that it would allow drivers with punctured tires to continue driving for 125 miles, at speeds of up to 55 miles per hour, before having to stop for repair. The innovative construction of the PAX, in which the tire edge was clamped to the wheel hub, eliminated the danger of blowouts and the frustration of roadside tire changes, without sacrificing performance or comfort (the bane of earlier run-flat approaches).\nThe PAX innovation entailed a structural departure from the long history of tire innovations (e.g., radial tires, high-traction tires, all-weather tires). In contrast to this historical stream that fit neatly into existing strategy constructs, characterizing and assessing the PAX innovationÂ requiresÂ an ecosystem perspective.3\nFor over a century, regardless of the specifics of the given tire innovation, the basic activities, actors, positions, and links of the automotive tire ecosystem remained unchanged: A tire maker would innovate a new tire and then work to convince automobile manufacturers to install the new tire on their vehicles. The automobile manufacturers would then work with their dealers to sell the new vehicles to end consumers. In case of a puncture, garages would repair the tires, agnostic as to type, using specialized equipment that had not changed in decades.Â Figure 1aÂ plots the key elements that characterize the traditional ecosystemâ€”production of the tire, production of the wheel hub, production of the automobile, sale of the automobile, repair of punctured tires, and production of the repair equipmentâ€”identifies their positions relative to one another, and shows the links among these activities.\n\nFigure 1Â Blueprints for the Traditional Tire Ecosystem and the Run-Flat Tire Ecosystem\nOpen in viewer\nAlthough multiple actors were involved in the proposition, each relationship between the actors can be (largely) treated as a bilateral dyad, in isolation from the rest. Some of these bilateral relationships were active (black inÂ Figure 1a, e.g., tire makers lobbying car makers for adoption) and some passive (grey italics inÂ Figure 1a, e.g., the relationship between wheel hub manufacturers and car makers is unaffected by the introduction of a new all-weather tire). Because this situation lacks multilateral relationships and because there is no need to consider shifts in partner alignment, there is no need to employ an ecosystem logic to understand its dynamics.\nIn contrast, the PAX value proposition depended on reconfiguring activities and relationships and, as such, requires consideration of ecosystem dynamics, as plotted inÂ Figure 1b. The PAX system entailed Michelin delivering not just an innovative tire, but the tire-wheel system, with rims specially designed to clamp onto the tire. Hence, beyond the required co-innovation of the rims, the PAX value proposition entailed a shift in position of a key activity: the rim was now integrated with the tire-by-tire manufacturer, and then handed off to the automobile manufacturer. The innovation of clamping rims reverberated throughout the system to create new requirements and new links among activities and actors in other positions as well. First, it required the development of a new generation of tire repair equipment that could unclamp and reclamp the rims onto the tires. While this was relatively straightforward from a technology, manufacturing, and distribution channel perspective, it gave rise to a second requirement: It required garages to choose to adopt this repair equipment. As a result, garages shifted from being latent members of the ecosystem to being actors whose participation would be a matter of their own choice.\nBy placing garages in the role of active adopters in the ecosystem, the PAX value proposition gave rise to two new links. The first was a new interaction between consumersâ€™ adoption of PAX equipped vehicles and garageâ€™s incentives to adopt the new repair equipmentâ€”absent sufficiently high demand for PAX repairs, garages would not invest in the equipment. The second was a link between garage adoption decisions and automaker adoption decisionsâ€”if garages were not equipped with the PAX repair equipment, the consumers would not benefit from (or be willing to pay for) the PAX run-flat feature, and automakers would not see benefit from the added cost and complexity of incorporating PAX into their vehicles instead of traditional tires.\nContrasting the blueprints ofÂ Figures 1aÂ andÂ 1bÂ clarifies the structural differences between the ecosystems that underlie the value propositions of the all-weather tire innovation and the PAX tire innovation. A need for an ecosystem approach arises in the contexts that require change in underlying relationships ofÂ anyÂ of the four elements of structure. Even though the PAX proposition did not introduce new actors or even, in a general sense, new activities to the tire ecosystem, its impact on positions and links gives rise to a new set of interactions and, hence, the need for an ecosystem characterization. Indeed, even as the position of the garage did not shift, the creation of new links inherent in the PAX proposition dramatically changed its impact on value creation.\n==When a value proposition depends on a shift in ecosystem structure, the additional strategic question that is raised concerns alignment:Â How will the innovator create the impetus for other actors, who may not be directly linked to the innovator, to change==?Â Crafting an ecosystem strategy hinges on a clear understanding of what the relevant pieces are and where the boundaries of dependence and independence lie. In the PAX case, for example, it would be easy to implicitly assume that since automakers have close relationships with dealerships, and since dealerships have garages, then automakers can dictate the adoption of repair equipment and, hence, garages will be aligned as a matter of course. This assumption, however, is wrong. Dealers, while affiliated with automakers, are independent organizations; and within a dealership, sales and service largely operate as separate businesses with separate bottom lines. Explicit recognition of the independence of the garages (and the critical dependence of the PAX proposition on the garagesâ€™ adoption choices) would mean that any strategy for the PAX innovation would be similarly explicit about how to ensure their alignment and participation. Managing the changes in interdependence highlighted by these shifts in structure give rise to the need for an ecosystem strategy.\nFrom Ecosystem Structure to Ecosystem Strategy\nValue propositions that rely on shifts in ecosystem structure directly raise the question of what elements need to be (re)aligned. This, in turn, raises the question of how this alignment will occur: Who will attempt to guide the transition, taking on the role ofÂ leaderÂ and shaping the ecosystem, designing the alignment structure, and crafting the strategy to get the other actors into place? Who will accept the role ofÂ followerÂ and agree to act in accordance with the leaderâ€™s plan? What rivalries need to be managed within and across ecosystems?\nBuilding on the definition of an ecosystem as â€œalignment structure of the multilateral set of partners that needs to interact in order for a focal value proposition to materialize,â€ we can now define a firmâ€™s ecosystemÂ strategyÂ as:\n\n==Ecosystem strategy is defined by the way in which a focal firm approaches the alignment of partners and secures its role in a competitive ecosystem.==\n\nAs before, this definition holds a number of implications.\n1. â€œA focal firm approachesâ€\nAlthough the ecosystem is composed of multiple firms, every firm defines its own ecosystem strategy, which encompasses a view on ecosystem structure, ecosystem roles, and ecosystem risks.4Â Across participants, these strategies can range from consistent to contradictory. The greater the consistency in strategy among the relevant actors, the higher the likelihood that their actions will be convergent, but there is no requirement of consistency. Just as critically, there is no presumption that inconsistency will necessarily be recognized within a given time frame.\nFirms may invest and pursue value propositions under mistaken beliefs that their partners are pursuing the same end goals with the same level of motivations as they themselves are. In the PAX case, it took years for tire manufacturers and car manufacturers to fully recognize the garagesâ€™ mixed motivations regarding the attractiveness of offering PAX tire repairs (more profitable than traditional tire repairs) compared to PAX tire replacements (more profitable than PAX tire repairs).\n2. â€œThe alignment of partnersâ€\nIn the context of a given firmâ€™s ecosystem strategy, partner alignment is assessed relative to the focal firmâ€™s ability to bring its partners into the positions and roles that its ecosystem strategy envisions. An approach to partner alignment thus entails, first, recognizing gaps; and second, creating conditions (whether through resource allocation or revision of strategy) for closing these gaps.\nGaps can arise from partnerâ€™s activity-based challenges and from partnersâ€™ expectations. I distinguish between two kinds of alignment risks that arise from activity-based challenges:Â co-innovation risks, which relate to the challenge partners face in developing the ability to undertake the new activities that underlie their planned contributions; andÂ adoption chain risks, which relate to partnersâ€™ willingness to undertake the required activities and raise questions of priorities and incentives for participation. A meaningful ecosystem strategy will be explicit in assessing, and proactive in managing, these risks.\nSeparate from these activity-based challenges is the challenge of partner expectations about structure and roles. Structural expectations regard what are the positions, and who hands off to whom; who faces the end customer, and who takes an upstream role. Role expectations regardÂ leader-followerÂ roles: which actor(s) will take responsibility for leading the systems towards alignment, and which will follow the guidance of these leaders and accept a nonleadership role.\nRecognizing gaps that arise from inconsistent expectations for positions is often more straightforward than recognizing gaps in expectations of roles. Some roles are dictated by the flow of activitiesâ€”since it is Michelin that is integrating the wheel and tire into a system, it is clear that it falls on Michelin to manage this integration. Others, however, are more ambiguous: Whose job is it to make sure the garages adopt the equipment? How should different parties account for the new interactions in the system? How should these affect their resource allocation priorities?\n3. â€œSecures its roleâ€\nTaking on the role of leader or follower depends on the focal firmâ€™s aspiration andâ€”no less criticallyâ€”on the agreement of the actors on which the value proposition depends. The ecosystem leader is the firm to whose vision of structure and roles others defer. It sets, and often enforces, the governance rules, determines timing, and often reaps the lionâ€™s share of gains after the ecosystem is aligned. An ecosystem follower is a firm that agrees to these terms, and cedes the leadership role. Successful leadership is thus contingent on willing followership.5Â Moreover, leadership is contestableâ€”even when firms agree on structure, they can still disagree on roles (e.g., Google and Visa in mobile payments; Cisco and Philips in smart-city lighting, where each of the partners has credible claim for leadership, and has shown a reluctance to embrace a follower role). Note that leadership need not be the purview of a single firm, and examples of collaborative consortiums (e.g., SEMATECH in the context of semiconductor manufacturing) and transition planning (e.g.,Â Davis, 2016) demonstrate the potential of shared leadership. Bounding the likelihood that different firms can assume different roles, however, are the traditional advantages that come from size and bargaining power, which are reflected in a hierarchy of influence and contribution that maps on to members with more versus less influence on structure, choices, and timing of value creation.\nIn situations where vying for leadership entails risk, where it is seen as a burden, or where candidacy is unclear, systems and subsystems may be left leaderless (e.g., the lack of clarity in the PAX case as to who will bring garages into line, whether it is the tire maker or automobile manufacturer who could and should take on the aligning role).\nFollowership, too, can become contestable over time, as firms may need to secure their role in terms of relative uniqueness and expected tenure, since, even if their activities and positions maintain criticality, the specific actors can be changed and challenged by others inside and outside the partner initial set (cf.Â Kapoor &amp; Agarwal 2016;Â Altman, 2016).Â Gawer and Hendersonâ€™s (2007)Â analysis of Intelâ€™s strategy to secure followersâ€™ positions offers a valuable perspective on how these relationships can be managed.\n4. â€œIn a competitive ecosystemâ€\nJust as traditional strategy is guided by a concern with the competitiveness of individual firms, ecosystem strategy is guided by concern with the competitiveness of ecosystems and their participants.\nOne distinction between competitive strategy and ecosystem strategy lies in the explicit consideration of actors who lie off the critical path to the end consumer. Hence, beyond focusing on bargaining dynamics with buyers and suppliers (e.g.,Â Porter, 1980), here, the focus is expanded to include partners who play a critical role in determining value creation (and who may influence value capture) but who may not have direct links to the focal firm. Similarly, beyond focusing on competition for acquiring key resources (e.g.,Â Barney, 1986;Â Wernerfelt, 1984), here competition can extend to aligning key partners. The view of competition here expands from consideration of rival firms, potential entrants, and substitutes to rival ecosystems that compete to offer rival value proposition through ecosystem structures that may look more (e.g., Uber vs. Lyft in on demand transport) or less (Uber vs. municipal taxi service) similar to each other.\nCompetition thus operates at two different levels: within the ecosystem, regarding the security of activities, positions, and roles, which affects the distribution and capture of value across positions; and across ecosystems, regarding collective advantages in creating and capturing value relative to rival constellations of actors. Although these levels are distinct, they do interact: There can be a tension between increasing competitiveness of partners in order to enhance the value creation advantage of the ecosystem, and maintaining a (leadership) position in the face of competitive partners, the importance of whose contribution is increasing, and who may desire to change roles or revenue capture.\nIf the heart of traditional strategy is the search for competitive advantage, the heart of ecosystem strategy is the search for alignment. The value, rarity, and inimitability of resources finds its analog in multilateral partnerships, and sustainability of advantage has as much to do with maintaining relationships as it does with keeping rivals at bay. While the status, size, and capabilities of firms will clearly impact their ability to act and shape interdependence, status, size, and capability can only take an organization so far. Asymmetric interdependenceâ€”in which an innovatorâ€™s success depends more heavily on a partner breaking away from business as usual than does the partnerâ€™s continued success in its usual business depends on the innovatorsâ€™ choicesâ€”can upend expectations of size and authority. In this regard, world-renowned multinational Michelinâ€™s challenge in shifting the adoption choices of unremarkable local garages offers compelling testimony that ecosystem challenges must be addressed with ecosystem strategies.\nContrasting Alternative Approaches to Interdependence\nInterdependent value creation has been a concern of the fields of management and strategy since their inception. The flow of activityâ€”the distinction between upstream and downstreamâ€”has shaped strategy debate from the outset. Activity flow is apparent in the context of industry analysis, with the clear distinction between supplier power and buyer power; in the context of firm boundaries, with the attention paid to the make-or-buy decision; in the context of the market for resources, with attention paid to terms of acquisition and integration.\nDespite its presence, however, this distinction has tended to remain contextual, with little impact on the central questions of strategy. For example, as noted inÂ Adner and Kapoor (2010), while Porterâ€™s classic 5-forces analysis is articulate about the difference between buyer and supplier interactions, bargaining power residing with the one is treated as identical to the other. Similarly, the constructs of complements, complementors, and complementary assets (e.g.,Â Milgrom &amp; Roberts, 1990;Â Teece, 1986) have suffered from a conceptual blending as improvements in any of these are treated as improving the focal firmâ€™s offer in the same general way. Put another way, the distinctiveness of these distinctions has remained underexplored.\nThe rise in coordination possibilities, enabled by the rapid progress of information and communication technologies, have spurred a boom of interest in, and conceptualizations of, strategy in the context of interdependence. While these have surfaced a multitude of important strategic choices, the impact of the structure of value creation has remained outside their focus.\nHow does the ecosystem-as-structure approach presented here relate to these other perspectives, and what is the extent to which it offers a distinct view? Here I consider the different perspectives according to the core questions they raise and the features they highlight, as well as the strategic guidance they offer in multilateral settings of interest here.\nThe purpose of this contrasting exercise isÂ notÂ to diminish the value of these alternative approaches. Nor is the purpose to suggest that they become redundant or subsumed within the ecosystem view presented here. Rather, the point of the exercise is to compare the different points of focus that arise from the varying perspectives, and to confirm that there is a conceptual gap left in the field that an ecosystem-as-structure lens can help close.\nPlatforms and Multisided Markets\nPlatforms (e.g.,Â Gawer &amp; Cusumano, 2002;Â Parker et al., 2016) and multisided markets (e.g.,Â Hagiu &amp; Wright, 2015) approach a similar problemâ€”that of intermediating an interface among different kinds of actorsâ€”with a focus on technology and transaction, respectively. The platform/broker holds a hub position in a network of interactions, exercises power through centrality, but does so wisely through appropriate governance choices regarding terms of access, incentives, and control. A challenge with hub-and-spoke imagery is that it presumes agreement on the identity of the hub. At times this is indeed clearâ€”Intelâ€™s position as the hub, or platform leader, for microchip architecture in personal computers (e.g.,Â Gawer and Cusumano, 2002); at other times it is less clearâ€”who is the platform in the PAX case, Michelin or Honda; while at other times it is aggressively contested (e.g., the roles of Google, Home Depot, and J.P. Morgan in mobile payment systems; Intel and Ford in the connected car).\nA key strategic priority in platforms and multisided markets is to grow the relevant sides of the market in order to increase value through direct and indirect network externalities. In the absence of communities on either side of the market, the characterization would devolve into a regular supply chain with the platform playing the role of distributor.\nNetworks and Alliances\nNetwork approaches (e.g.,Â Gulati, 1999;Â Powell, Koput, &amp; Smith-Doerr, 1996) focus on patterns of connectivity. Whether at the level of individuals (social networks) or firms (networks of alliances), the network is delineated according to actor ties, rather than according to a value proposition per se. In terms of strategies for value creation, this is often an incomplete approach: While actor ties inform information flows, they do not reveal purpose. For example, from a network perspective, Merckâ€™s collaboration with Pfizer in oncology and Merckâ€™s collaboration with Pfizer in dermatology involve the same to actors with repeated interactions, and so reinforces their network ties; in contrast, the perspective advanced here places these two collaborations in two distinct ecosystems with very different partner sets and very different alignment challenges.\nBusiness Models\nBusiness models (e.g.,Â Osterwalder, Pigneur, &amp; Tucci, 2005;Â Zott, Amit, &amp; Massa, 2011) characterize the focal firmâ€™s plan for its value creation and capture. Thus, the focus is on a focal firm, rather than the constellation of actors, and the level of analysis is firm strategy, rather than value proposition. While these may coincide, this need not be the case. The successful ecosystem is composed of multiple firms acting in concertâ€”an ecosystem strategy can be thought of as one that takes partner firmsâ€™ business model to be as critical to address as the focal firmâ€™s.\nFor example, Zipcarâ€™s business model of renting cars by the hour to service subscribers is well known. While it has a single business model, its ecosystem strategyâ€”its approach to aligning critical actorsâ€”varies by geography. In Boston, Massachusetts, its blueprint includes the municipal parking authority as a critical adopter, which needs to grant permits for on-street parking stations. In Hanover, New Hampshire, the municipality is not in the ecosystem; rather, Zipcar aligns the local college to permit parking spots on its campus. Thus, in contrast to a business model, which is highly extendible, the boundaries of a given ecosystem determine the boundaries of the ecosystem strategy.\nProject Management\nThe ecosystem blueprints look very much like the process flow diagrams from operations and project management (e.g.,Â Kerzner, 2013). A difference, however, is the explicit focus on alignment in the ecosystem view. Where project management focuses on how to coordinate multiple activities towards an end goal, it takes a number of key issues for granted. First among these is that all participants agree that they are part of the project. Related to this is the presumption of leadershipâ€”there is an official role of project manager, and there is agreement among participants as to who the project manager is; and, in turn, agreement that everyone other than this anointed leader isÂ notÂ the manager. It is precisely the need for driving alignment that gives rise to the need for ecosystem strategy and distinguishes it from the challenges of operational concerns. Activity systems (i.e.,Â Porter, 1996) evoke the notion of ecosystems internal to the firm, and clearly highlight multilateral interdependence through the effect of complementarities (Milgrom &amp; Roberts, 1990). Like project management, however, the framing is one of a design challenge for a central planner, rather than one of aligning independently minded actors that may not be aware or in agreement that they are even a part of the value proposition.\nThe unexpected shift in garage participation in the PAX case (the preference for replacement over repair, which undermined the overall value proposition even as it maximized garagesâ€™ short-term gains) highlights how the absence of central authority and disagreement on end goals creates challenges that fall outside the realm of (traditional) project management.\nSupply Chains and Value Chains\nSupply chains (e.g.,Â Simchi-Lev, 2005) and value chains (e.g.,Â Porter, 1985) are constructs that clearly involve multiple parties. Often, however, these relationships are treated as decomposable into bilateral relationships (i.e., in considering make vs. buy decisions). When multiparty interdependence is present, it is usually in the context of fragility along the chain. Throughout, however, the flow of activitiesâ€”the positions of actorsâ€”along the supply chain follow a critical path that is well determined. While there is active bargaining on terms, there is acceptance of positions: Who is upstream (supplier) and who is downstream (buyer) is not contested. Michelin delivers tires to Ford to sell on cars to customers; a realignment such that Ford delivers cars to Michelin to sell on tires to customers is out of scope. Put another way, the focus is on managing and securing supply, not shifting positions, as was the case in PAX when the integration point for the wheel hub shifted from automakers to tire makers.\nIndustry Structure\nRole of structure has long been a concern of industrial organization economics, exemplified by the structure-conduct-performance paradigm (e.g.,Â Bain, 1959;Â Scherer &amp; Ross, 1990). Structure here, however, refers to industry features that govern the intensity of rivalry and producersâ€™ ability to capture value. Value creation is implicit and its details are outside of the scope of concern.\nIndustry Architecture\nDiscussions of industry architecture focus on factors and strategies that determine the location of make versus buy choices within the value streamâ€”the vertical integration and disintegration of industries.Â Jacobidesâ€™s (2005)Â study of the mortgage banking industry shows how the interactions of information flows, routines, and gains from trade across activities enable their separation. The realignment of positionsâ€”shifting around the vertical chain, adding and moving elements off the focal critical path to marketâ€”are outside the scope of this perspective.\nValue Nets (I)\nThe value net label has been used to mean two very different things. Within the economic stream, forÂ Brandenburger and Nalebuff (1996), the value net represented the broad set of parties (the firm, its rivals, its suppliers, its customers, and its complementors) in the economic game, with an eye towards bargaining over value capture. This approach is silent on the specific structure of interdependence. The innovation stream interpretation is discussed below.\nSystems of Technology\nInterdependence is at the very heart of the systems of technology literature, which considers the interaction of technical and social factors to shape outcomes (e.g.,Â Hughes, 1993). Missing from this perspective, however, is an explicit view on structure and its implications. Thus, while this perspective has the importance of understanding bottlenecks in affecting outcomes, its lack of a structured view leaves it silent on how differences in the positions of bottlenecks can drive diametrically different outcomes for focal innovators in the system (i.e.,Â Adner &amp; Kapoor, 2010).\nOpen Innovation\nThe concern of open innovation (e.g.,Â Chesbrough, 2006;Â von Hippel, 2006) is with the sources of innovation and organizationsâ€™ willingness to exercise flexible control, as either innovators or innovation adopters, over their innovation pipelines and processes. Hence, while it is explicitly concerned with interactions across firms (innovation producer and innovation consumer), and takes the question of governance as key, the concern of open innovation is with the terms of creation and exchange. As such, it is quite separate from the ecosystem construct in that questions of multilateral coordination lie outside the scope.\nValue Nets (II)\nThe value net label has been used to characterize two different perspectives on interdependence. The economic perspective was discussed above. Within the innovation-based stream,Â Christensen and Rosenbloom (1995)Â see the value net as comprised of the extended supply chain that determined a focal firmâ€™s cost structure. This approach is quite sensitive to structure but ignores two issues. First (because it is outside the focus), it ignores complementors that are not directly linked to the firmsâ€™ supply chain. Second, it conceptualizes the structure as rigid and inert (the mechanism that hampers incumbentsâ€™ ability to respond to lower cost threats) and, hence, does not consider change, reconfiguration, or alignment strategies among partners.\nAs summarized inÂ Table 2, each of these perspectives sheds a light on the question of interdependence, but does so with a focus on a different set of strategic dynamics, choices, opportunities, and challenges from that presented here.\nTable 2Â Extant Approaches to Interdependence in the Strategy Field\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstructCore IssueClassic ExampleOutside of Scope/Missing ElementPlatforms (e.g.,Â Gawer &amp; Cusumano, 2002;Â Parker et al., 2016)Access, incentives, and control with focus on technologyIntelInterdependence is not always platform based. Whereas platforms are concerned with the governance of interfaces, ecosystems are concerned with the structure of interdependence.Multisided markets (e.g.,Â Hagiu &amp; Wright, 2015)Access, incentives, and control with focus on transactionse-BayMultilateral arrangements that do not have a broker role; contestability roles among partners. Indirect links.Networks and alliances (e.g.,Â Gulati, 1999;Â Powell et al., 1996)Observed patterns of connectivityBiotechnology alliance networksExplicit design and alignment strategies; flow of valueâ€”who hands off to whom (vs. collaborating on invention; building on knowledge); focus on specific value proposition.Business models (e.g.,Â Osterwalder et al., 2005;Â Zott, Amit, &amp; Massa, 2011)Plan for value creation and capture for focal firmZipcarIndirect links among partners; boundary logic; necessary consistency of models across all partner firms.Project management (e.g.,Â Kerzner, 2013)Coordination of project members and componentsConstruction sitePresumption of hierarchy and exogenous appointment of project leadership roles. Mutual recognition and agreement among members that they are involved in same the project.Supply chain and value chain (e.g.,Â Porter, 1985;Â Simchi-Levi, 2005)Make vs. buy decisions; bargaining; partner reliabilityToyotaPartners off the critical path; multilateral dynamics; alignment strategies.Industry structure (e.g.,Â Bain, 1959)Nature, sources, and management of rivalryAirlinesSpecifics of value creation; innovation and changes to the industry value proposition.Industry architecture (e.g.,Â Jacobides, 2005)Vertical division of laborMortgage bankingNew dependencies that arise and lie outside the traditional value chain.Value net (e.g.,Â Brandenburger &amp; Nalebuff, 1996)Competing with complementorsDeBeers; NintendoStructure: how the arrangement of actors affect value creation and value capture.Systems of technology (e.g.,Â Hughes, 1993)Social and technological dimension of systems; bottlenecksElectrificationAbsence of explicit structure.Open innovation (e.g.,Â Chesbrough, 2006;Â von Hippel, 2006)Sources of innovation; governance and quality of communities and participantsXerox; LinuxIntegration of multiple actors; multilateral dynamics.Value net (e.g.,Â Christensen &amp; Rosenbloom, 1995)Lock in to cost structure of supply chainDisk DrivesDynamics: the emergence and evolution of the network.\nOpen in viewer\nEcosystem Perspective: Neither Necessary Nor Sufficient, but Increasingly Critical\nConsideration of ecosystem strategy may not be necessaryâ€”and is never sufficientâ€”to understand firmsâ€™ actions, choice, and outcomes. In the same way that we can understand a single-business firm without need to consider corporate strategy, we can look at initiatives where value creation does not require aligning or realigning multilateral partners without need to consider ecosystem strategy.\nHowever, just as there are potential interactions between competitive strategy and corporate strategy (e.g., Appleâ€™s launch of its iPod digital music player being aided by its ownership of its own Apple Store distribution channel), there can be strong interactions between competitive strategy and ecosystem strategy, such as leveraging partner relationships in one setting to advantage position in a different setting (e.g., Appleâ€™s using its position in music players to align operating network partners in the mobile phone space). Similarly, we can observe interactions between corporate strategy and ecosystem strategy such as acquisitions undertaken to facilitate repositioning and alignment within ecosystems (e.g., General Motorâ€™s acquisitions in the self-driving vehicle space).\nEcosystems matter when the multilateral relationships that underlie a value proposition are not decomposable into multiple bilateral relationships. In such cases, approaching a situation as an agglomeration of bilateral relationships would lead the observer to miss something important in the situation.\nSeparate from the question of boundaries for applying the logic is the question of how to approach the boundaries of a given ecosystem. If the critique of traditional approaches to strategy is that they do not take enough notice of the structure of interdependence, a critique of an ecosystem approach is that it risks drowning in the almost infinite web of interdependences that characterizes the modern economy. If drawing a value blueprint is the approach to characterizing the ecosystem, how do we decide what to leave out? On what basis do we decide to include or exclude activities and positions from considerationâ€”should my complementorâ€™s supplierâ€™s supplier be part of my plan?\nThis critical question is informed by the way I have defined the ecosystem: around the focal value proposition, not a focal firm; and in terms of elements that need to be brought into alignment, thus excluding those that are already in place and can be expected to stay put. While this does not eliminate the need to exercise judgment (which is the case for bounding systems of any sort, i.e.,Â Scott, 2002), it does offer clear guidance for the exercise (cf.Â Tanev, Tzolov, &amp; Apiafi, 2015). Thus, for example, while every new data center product relies on electricity, whether or not we include the electric utility as an active member of the ecosystem will depend on whether it needs to change its activity (e.g., agree to increase capacity, change provision terms, etc.).\nFurther, because the units of the ecosystem are expressed in terms of activities, this also means that multiple activities housed within a single organization may require different efforts for alignment. Thus, if the production division and the service division of a partner firm operate with some independence, they may appear as separate positions in the ecosystem.\nSimilarly, if the same group of partners pursues multiple value propositions, the ecosystem-as-structure approach would place those initiatives in different ecosystems becauseÂ the alignment structure of the multilateral set of partners that need to interact in order for a focal value proposition to materializeÂ includes other partners in different positions and raises different alignment challenges across the initiatives. Thus, when IBM partners with Apple for two initiatives, one targeting at enterprise software and the other targeting digital healthcare, they encounter each other as members of two different ecosystems. Indeed, even with the same set of actors in the same industry, alternative value propositions can give rise to different ecosystems, as was illustrated in the contrast between the blueprints of the run-flat tire and all-weather tire ecosystems.\nNote that this is a departure from casual references to ecosystem boundaries that are set at the levels of firms (e.g., Appleâ€™s ecosystem vs. IBMâ€™s ecosystem), sectors (e.g., healthcare ecosystem; payments ecosystem), or regions (e.g., Silicon Valley). Such ecosystem conceptualizations create an illusion of focus and consistency that can mask highly inconsistent views on almost every aspect (who, what, where, when, how, why) of the interdependence to be managed under their heading. The coherence of a structuralist view arises precisely because its focus on the value proposition gives rise to a coherent set of decisions regarding where and how to draw the boundaries of the system.\nNew Questions and New Directions\nExplicit consideration of the structure of interdependence that underlies the effort of joint value offers a lens through which to consider new questions, as well as to revisit answers to long-standing debates. These range from the macroâ€”what defines industry boundaries and groups; how to consolidate competitive dynamics across multiple levels of interactionâ€”to the microâ€”how the perceptions of risk are impacted by the addition of partners; how the exercise of authority changes in settings where internal partners (within the organizational hierarchy) interact with external partners (outside formal control).\nThe multiplicity of actors that comprise the ecosystem create new trade-offs that impact the nature of strategy. These trade-offs apply not just vis-Ã -vis the focal firm and its direct partners (i.e., traditional bilateral bargaining power), but also vis-Ã -vis direct partners and their own partners to whom the focal firm may have no direct links. This extends consideration, beyond the question of value creation and capture, to the question of value distribution across the broader ecosystem and the extent to which is treated as a matter of bargaining or as a strategic lever in ecosystem construction.\nExplicit recognition of the structure of interdependence and the question of alignment raises new questions even when focusing on dyadic relationships. There is still much to learn about the management of complementors not only from the perspective of the leader, but also from that of the follower (e.g.,Â Altman, 2016;Â Kapoor &amp; Agarwal, 2016). At the multilateral level, there are key open questions regarding coordination and sequencing (e.g.,Â Hannah &amp; Eisenhardt, 2016;Â Jacobides, MacDuffie, &amp; Tae, 2015;Â Li &amp; Garnsey, 2013). Similarly, the role of institutions, regulators, and influencers such as professional associations in creating context can be revisited to consider not just the content of policy but the location of its application to better understand the difference between efforts and actions that are more or less conducive to efforts of alignment (e.g.,Â Kahl, King, &amp; Liegel, 2016).\nBeyond new theoretical questions, ecosystems also raise new empirical opportunities. The multiplicity of relationships within interdependent structures give rise to a multiplicity of approaches to recharacterizing and measuring core constructs such as performance, investment, and capability. At the same time, they also raise the challenge of capturing data on a broader set of actors than is the case in traditional strategy research. Further, understanding multilateral structure can require a deeper level of contextual knowledge. These investment requirements, however, are balanced by a great opportunity to develop new ideas and productively revisit established wisdom.\nEcosystems as arrangements of interdependent value creation will only grow in prevalence and in importance in the years to come. In the world of practice, the embrace of the notion of ecosystems has been enthusiastic and, at the same time, chaotic. This has created a opportunity for the world of research to shed lightâ€”both positive and normativeâ€”on a critical set of questions. However, a litmus test for knowing where an ecosystem approachâ€”or any approachâ€”adds value is having clarity on where it does not add value. Critical to the task is a clear set of definitions, concepts, relationships, and boundaries. My hope is that the elements of an ecosystem-as-structure approach articulated here will be of help in making further progress with this important construct. The opportunity for further research in this vein is vast, and I am excited in anticipation of progress to come."},"Articles--and--Papers/Pipelines,-Platforms,-and-the-New-Rules-of-Strategy,-Harvard-Business-Review":{"slug":"Articles--and--Papers/Pipelines,-Platforms,-and-the-New-Rules-of-Strategy,-Harvard-Business-Review","filePath":"Articles & Papers/Pipelines, Platforms, and the New Rules of Strategy, Harvard Business Review.md","title":"Pipelines, Platforms, and the New Rules of Strategy, Harvard Business Review","links":["content/","A-platform-orchestrates-resources-whereas-a-pipeline-controls-resources"],"tags":["untagged"],"content":"index\nSummary\nExecutives must learn the new rules of platform businesses or plan their exit. A platform doesn&#039;t create a moat. Porterâ€™s five forces are still relevant but the factors are different. Instead of creating a moat and keeping out external forces, a platform focuses on network effects. Producers and consumers must be close and incentivized to use the platform. Execs must understand the core value interaction and measure that. It&#039;s not about revenue or sales --that&#039;s the old pipeline way.\nNotes\nA platform orchestrates resources whereas a pipeline controls resources\nQuotes\nAs Apple demonstrates, firms neednâ€™t be only a pipeline or a platform; they can be both. ==While plenty of pure pipeline businesses are still highly competitive, when platforms enter the same marketplace, the platforms virtually always win. Thatâ€™s why pipeline giants such as Walmart, Nike, John Deere, and GE are all scrambling to incorporate platforms into their models.\nThe move from pipeline to platform involves three key shifts:\n1 From resource control to resource orchestration.\nThe resource-based view of competition holds that firms gain advantage by controlling scarce and valuableâ€”ideally, inimitableâ€”assets. In a pipeline world, those include tangible assets such as mines and real estate and intangible assets like intellectual property. ==With platforms, the assets that are hard to copy are the community and the resources its members own and contribute, be they rooms or cars or ideas and information. In other words, the network of producers and consumers is the chief asset.\n2 From internal optimization to external interaction\nPipeline firms organize their internal labor and resources to create value by optimizing an entire chain of product activities, from materials sourcing to sales and service. ==Platforms create value by facilitating interactions between external producers and consumers. Because of this external orientation, they often shed even variable costs of production. The emphasis shifts from dictating processes to persuading participants, and ecosystem governance becomes an essential skill.\n3. From a focus on customer value to a focus on ecosystem value\nPipelines seek to maximize the lifetime value of individual customers of products and services, who, in effect, sit at the end of a linear process. ==By contrast, platforms seek to maximize the total value of an expanding ecosystem in a circular, iterative, feedback-driven process. Sometimes that requires subsidizing one type of consumer in order to attract another type.\n==These three shifts make clear that competition is more complicated and dynamic in a platform world. The competitive forces described by Michael Porter (the threat of new entrants and substitute products or services, the bargaining power of customers and suppliers, and the intensity of competitive rivalry) still apply. But on platforms these forces behave differently, and new factors come into play. To manage them, executives must pay close attention to the interactions on the platform, participantsâ€™ access, and new performance metrics.\nThe Power of Network Effects\nThe engine of the industrial economy was, and remains, supply-side economies of scale. Massive fixed costs and low marginal costs mean that firms achieving higher sales volume than their competitors have a lower average cost of doing business. That allows them to reduce prices, which increases volume further, which permits more price cutsâ€”a virtuous feedback loop that produces monopolies. Supply economics gave us Carnegie Steel, Edison Electric (which became GE), Rockefellerâ€™s Standard Oil, and many other industrial era giants.\n==In supply-side economies, firms achieve market power by controlling resources, ruthlessly increasing efficiency, and fending off challenges from any of the five forces. The goal of strategy in this world is to build a moat around the business that protects it from competition and channels competition toward other firms.\n==The driving force behind the internet economy, conversely, is demand-side economies of scale, also known as network effects.\n==These are enhanced by technologies that create efficiencies in social networking, demand aggregation, app development, and other phenomena that help networks expand.\nIn the internet economy, firms that achieve higher â€œvolumeâ€ than competitors (that is, attract more platform participants) offer a higher average value per transaction. ==Thatâ€™s because the larger the network, the better the matches between supply and demand and the richer the data that can be used to find matches.\nGreater scale generates more value, which attracts more participants, which creates more valueâ€”another virtuous feedback loop that produces monopolies. Network effects gave us Alibaba, which accounts for over 75% of Chinese e-commerce transactions; Google, which accounts for 82% of mobile operating systems and 94% of mobile search; and Facebook, the worldâ€™s dominant social platform\n==The five forces model doesnâ€™t factor in network effects and the value they create. It regards external forces as â€œdepletive,â€ or extracting value from a firm, and so argues for building barriers against them.\n==In demand-side economies, however, external forces can be â€œaccretiveâ€â€”adding value to the platform business. Thus the power of suppliers and customers, which is threatening in a supply-side world, may be viewed as an asset on platforms. Understanding when external forces may either add or extract value in an ecosystem is central to platform strategy.\nForces within the ecosystem.\n==Platform participantsâ€”consumers, producers, and providersâ€”typically create value for a business. But they may defect if they believe their needs can be met better elsewhere.\nThe new roles that players assume can be either accretive or depletive. For example, consumers and producers can swap roles in ways that generate value for the platform. Users can ride with Uber today and drive for it tomorrow; travelers can stay with Airbnb one night and serve as hosts for other customers the next. In contrast, providers on a platform may become depletive, especially if they decide to compete with the owner. ==Netflix, a provider on the platforms of telecommunication firms, has control of consumersâ€™ interactions with the content it offers, so it can extract value from the platform owners while continuing to rely on their infrastructure.\n==Finance,Â which historically has recorded its activities on private internal accounts, now records some transactions externally on public, or â€œdistributed,â€ ledgers. Organizations such as IBM, Intel, and JPMorgan are adopting blockchain technology that allows ledgers to be securely shared and vetted by anyone with permission. Participants can inspect everything from aggregated accounts to individual transactions. This allows firms to, for example, crowdsource compliance with accounting principles or seek input on their financial management from a broad network outside the company. Opening the books this way taps the wisdom of crowds and signals trustworthiness.\n==Competitive threats tend to follow one of three patterns. First, they may come from an established platform with superior network effects that uses its relationships with customers to enter your industry. Products have features; platforms have communities, and those communities can be leveraged. Given Googleâ€™s relationship with consumers, the value its network provides them, and its interest in the internet of things, Siemens might have predicted the tech giantâ€™s entry into the home-automation market (though not necessarily into thermostats).\nFocus\n==Managers of pipeline businesses focus on growing sales. For them, goods and services delivered (and the revenues and profits from them) are the units of analysis. For platforms, the focus shifts to interactionsâ€”exchanges of value between producers and consumers on the platform. The unit of exchange (say, a view of a video or a thumbs-up on a post) can be so small that little or no money changes hands. Nevertheless, the number of interactions and the associated network effects are the ultimate source of competitive advantage.\nWith platforms, a critical strategic aim is strong up-front design that will attract the desired participants, enable the right interactions ==(so-called core interactions), and encourage ever-more-powerful network effects.\n==In our experience, managers often fumble here by focusing too much on the wrong type of interaction. And the perhaps counterintuitive bottom line, given how much we stress the importance of network effects, is that itâ€™s usually wise to ensure the value of interactions for participants before focusing on volume.\nAccess and governance\nIn a pipeline world, strategy revolves around erecting barriers. With platforms, while guarding against threats remains critical, the focus of strategy shifts to eliminating barriers to production and consumption in order to maximize value creation. ==To that end, platform executives must make smart choices about access (whom to let onto the platform) and governance (or â€œcontrolâ€â€”what consumers, producers, providers, and even competitors are allowed to do there).\nPlatforms consist of rules and architecture. Their owners need to decide how open both should be. AnÂ open architectureÂ allows players to access platform resources, such as app developer tools, and create new sources of value.Â Open governanceÂ allows players other than the owner to shape the rules of trade and reward sharing on the platform. ==Regardless of who sets the rules, a fair reward system is key. If managers open the architecture but do not share the rewards, potential platform participants (such as app developers) have the ability to engage but no incentives. If managers open the rules and rewards but keep the architecture relatively closed, potential participants have incentives to engage but not the ability.\n==These choices arenâ€™t fixed. Platforms often launch with a fairly closed architecture and governance and then open up as they introduce new types of interactions and sources of value. But every platform must induce producers and consumers to interact and share their ideas and resources. Effective governance will inspire outsiders to bring valuable intellectual property to the platform, as Zynga did in bringing FarmVille to Facebook. That wonâ€™t happen if prospective partners fear exploitation.\n==However, unfettered access can destroy value by creating â€œnoiseâ€â€”misbehavior or excess or low-quality content that inhibits interaction.\nOne company that ran into this problem was Chatroulette, which paired random people from around the world for webchats. It grew exponentially until noise caused its abrupt collapse. Initially utterly openâ€”it had no access rules at allâ€”it soon encountered the â€œnaked hairy manâ€ problem, which is exactly what it sounds like. Clothed users abandoned the platform in droves. Chatroulette responded by reducing its openness with a variety of user filters.\nMost successful platforms similarly manage openness to maximize positive network effects. Airbnb and Uber rate and insure hosts and drivers, Twitter and Facebook provide users with tools to prevent stalking, and Appleâ€™s App Store and the Google Play store both filter out low-quality applications.\n==Finally, platforms must understand the financial value of their communities and their network effects. Consider that in 2016, private equity markets placed the value of Uber, a demand economy firm founded in 2009, above that of GM, a supply economy firm founded in 1908. Clearly Uberâ€™s investors were looking beyond the traditional financials and metrics when calculating the firmâ€™s worth and potential. This is a clear indication that the rules have changed.\nThe failure to transition to a new approach explains the precarious situation that traditional businessesâ€”from hotels to health care providers to taxisâ€”find themselves in. ==For pipeline firms, the writing is on the wall: Learn the new rules of strategy for a platform world, or begin planning your exit."},"Articles--and--Papers/Protocols-As-Minimally-Extractive-Coordinators":{"slug":"Articles--and--Papers/Protocols-As-Minimally-Extractive-Coordinators","filePath":"Articles & Papers/Protocols As Minimally Extractive Coordinators.md","title":"Protocols As Minimally Extractive Coordinators","links":["Whereas-businesses-are-meant-to-be-maximally-extractive,-protocols-should-be-minimally-extractive","Bitcoin"],"tags":["untagged"],"content":"Summary\nA protocol is not a business, meaning it should not make a profit from its service. Although it should add value, it should be minimally extractive from a money point of view. A protocol is part of an ecosystem that includes the market, consumers, distributors, suppliers, and consumers\nNotes\nWhereas businesses are meant to be maximally extractive, protocols should be minimally extractive\nQuotes\nProtocols provide structure for businesses, but are not businesses themselves; they are systems of logic that coordinate exchange between suppliers (businesses) and consumers of a service.Â Â ==As coordinators of exchange, protocols should be minimally extractive, whereas businesses are incentivized to be maximally extractive (thatâ€™s profit, and a business is valued as a multiple of its profit).\n==To avoid confusion, I should note minimal extraction doesnâ€™t mean crypto assets that capitalize protocols will capture minimal value; if something is minimally extractive, but globally produced and consumed, the coordinating asset can capture a significant amount of value.\nÂ To further unpack protocols as coordinators of exchange, weâ€™ll investigate the:\n\n\nProtocol\n\n\nSuppliers\n\n\nDistributors\n\n\nConsumers\n\n\nMarket\n\n\nProtocol\n==Protocols encode the rules of engagement that coordinate the exchange of a service between a global supplier and global consumer.\n==Both the supplier and consumer must strictly abide by the rules of engagement; if they donâ€™t, they wonâ€™t get paid (supplier) or wonâ€™t receive the service (consumer). Thereâ€™s no special deal for any suppliers, distributors or consumers. The flatness with which a protocol treats everyone that interfaces with it is part of what drives its efficiency as a coordinator of exchange (no room for human corruption or capture).\n==While a protocol allows for fluid exchange between a supplier and consumer, the logic that makes up the protocol is just code that has no cares about profitability. If you want to argue that protocols are a business, show me Bitcoinâ€™s income statement.\nSuppliers\n==The suppliers (or supply-side) of a crypto network are businesses.\n==Supply-siders include miners, stakers, voters, judgers, transcoders, location-providers, and any other supplier of a networkâ€™s core service. Right now, protocols mostly coordinate suppliers of machine work, but I expect them to shift to be increasingly human work (think Lyft, Doordash, etc) as crypto matures.\nIn the short to medium term, suppliersâ€™ margins may remain elevated for two separate reasons, depending on whether theyâ€™re producing a novel service or existing service. In cases where a novel service is provided, thereâ€™s no preconception of what should be paid. Itâ€™s then easy for the consumer to overpay in the process of price discovery, and the situation is further muddied by the use of inflation as a supply-side subsidy in the early days.\nIn cases where an existing service is produced, but the costs of production are much lower than what exists outside of crypto, then the protocolâ€™s suppliers can offer it to consumers at much lower prices than non-crypto forms of production can, while still maintaining healthy margins. One could argue that fat margins early is one way suppliers are compensated for the risk theyâ€™re taking as pioneers in cryptoland.\nDistributors\n==While suppliers can be thought of as sitting beneath a protocol, producing the discrete service(s) that the protocol specializes in, distributors can be thought of as sitting on top of the protocol and delivering those services to the consumer. Often, distributors bundle protocol services and provide extra-layers of insurance and customer protection.\nConsumers\n==The consumers (or demand-side) of a cryptonetwork pay in one way or another to use the networkâ€™s service. They can pay via transaction fees, inflation, staking, or any number of to-be-invented mechanisms. Some mechanisms are less obvious than others (e.g., inflation), hiding the cost from the consumer, but they all require the consumer to pay.\nMarket\n==The market allows for global consensus on the pricing of the service(s) and the worth of the networkâ€™s native cryptoasset.Â \n==The pricing of a protocolâ€™s service has been contentious from as far as I can remember, dating back to early Bitcoin â€œfee marketâ€ debates. It has since spread to the rest of crypto as other networks mature and have enough demand to price some consumers out.\nAt a minimum, consumers have to be willing to pay enough to cover a supplierâ€™s cost, and if using a distributor, also covering the distributorâ€™s cost. If the service is highly valued by its consumers, and in short supply, then consumers will bid up the price to pay suppliers and distributors well above cost, making them a healthy profit. ==However, as stated in the sections on suppliers and distributors, open-market forces will be ruthless on margins over time.\n==That said, running a business is not the only way for a core team to fund development. Already we see plenty of experimentation, such as inflation funding (e.g., Decred, Zcash) and volunteer funding (e.g., MolochDAO, Grin). I expect future experiments around transaction fee funding or ongoing capital raises through community-approved mini-dilutions."},"Articles--and--Papers/Quantitative-Token-Model,-A-data-driven-approach-to-stay-ahead-of-the-game":{"slug":"Articles--and--Papers/Quantitative-Token-Model,-A-data-driven-approach-to-stay-ahead-of-the-game","filePath":"Articles & Papers/Quantitative Token Model, A data-driven approach to stay ahead of the game.md","title":"Quantitative Token Model, A data-driven approach to stay ahead of the game","links":["tags/toread"],"tags":["toread"],"content":"toread\nSource: outlierventures.io/article/quantitative-token-model-a-data-driven-approach-to-stay-ahead-of-the-game/\nIntroduction\nWeb3 is a fast moving space with high volatility in user migrations and price charts. Existing Web2 businesses and startups that aim to transition into the Web3 area encounter a new world of complexity, challenges, and opportunities. Once they have decided to embark on this journey, there are many uncertainties and questions that need to be answered. Previous articles discussÂ the reasons why an initiative might need or want to have a cryptographic tokenÂ and why quantitative approaches are essential to build aÂ sustainable token business. This report iterates on the quantitative aspect by introducing a generalized Quantitative Token Model (QTM). Instead of explaining the detailed mathematical relationships, it provides a methodological overview along with a case study of a generalized token economy. The QTM is a spreadsheet based tool to model and forecast a majority of known token designs on a higher level where it leverages aggregated stakeholder representation. Even though code-based solutions, such asÂ cadCAD, provide more flexible and sophisticated ways to model the complexity of token ecosystems, the spreadsheet implementation of the QTM has one major benefit:Â It is accessible to a wider audience and serves a variety of different token business concepts all in one tool.\nThis document starts with presenting the input and internal structure of the QTM. Afterwards a case study is carried out for a strong and weak user adoption scenario of a fictional Web3 business. Note that the presented token design is not recommended and should not be seen as a benchmark token design for similar businesses. A conclusion at the end wraps up the major findings.\nStructure and relevance of the QTM input components\nThe structure of the QTM consists of 3 main blocks: (1) The ecosystem input section, (2) the utility modules section, and (3) the analysis section. The ecosystem input section is subdivided into the following fundamental subsections:\nBasic Token Parameters\n\nDecision making regarding token supply dynamics / fixation\nAmount of initial token supply\nLaunch date of the token (liquidity deployment)\n\nThe decision between a dynamic or fixed token supply is fundamental for the whole ecosystem. In the case of dynamic supply the quantitative analysis can be used to adjust the emission for improved token valuation sustainability, while in the fixed supply case it can be used to ensure the project bucket token sustainability. See thisÂ articleÂ to understand the difference between these two types of sustainability.\nFundraising Module\n\nFundraising parties\nMonetary allocations\nToken discounts\n\nFigure 1 shows the exemplary token prices for different early investor groups. Traditionally more early contributors will receive a cheaper effective token price while they have to commit for longer time vesting schedules. Note that extreme discrepancies between early VC discounted token prices and public sale prices can have a negative impact on future marketing and reputation efforts for the business. Note that not all the different fundraising stages need to be used, the template should be adapted to an individual teamâ€™s strategy.\n\nFigure 1: Exemplary resulting effective token prices for different early investor groups\nInitial Token Allocations &amp; Vesting Schedules\n\nToken allocations to initial investor groups, supporting parties, team, protocol buckets, and liquidity\nIndividual vesting schedules for each of these entities\n\nFigures 2 and 3 below indicate some exemplary token allocations and vesting schedules. Note that the given numbers are not optimized, but rather represent historic and experience based allocation magnitudes. Also note that some project buckets are not used in this example. The low share of tokens for liquidity is a problem for many projects if there are not enough token sinks holding the rest of the supply back from being sold into the liquidity pool (LP). This leads often to drastically decreasing token valuations. Performing forecasts with the QTM has the benefit of identifying those sustainability issues before the token has even launched and increases the probability of a supply and price sustainable token circulation.\n\nFigure 2: Exemplary token allocation\n\nFigure 3: Exemplary token vesting schedules\nLiquidity Pool Module\n\nToken launch price\nMonetary allocation to the LP\nPaired token information\n\nThe amount of money that is allocated to the LP is known as liquidity depth and is essential for the price velocity. A deep LP will require more capital to move the price than a LP with less capital. At deployment the LP will consist of the projectâ€™s native token and a paired token. The paired one is most often a stable coin or a reputable high market cap token, such as $ETH. In cases where teams canâ€™t afford deep initial liquidity, they have to incentivize other parties to provide it.\nUser Adoption Module\n\nInitial user number\nInitial investment per user\nRegular capital inflow per user per month\nShare between product and token buys of user funds\nUser behavior in terms of token selling and token utility adoption\n\nFigure 4 shows an exemplary chart of user growth over the course of 10 years of a Web3 business. This module is essential for the whole ecosystem forecast and based on assumptions regarding the market adoption. The team has to perform market research to estimate the input user growth numbers and the corresponding capital the users will contribute to the ecosystem. The QTM distinguishes further between general users of the whole ecosystem, including off-chain offers and the users that interact with the token. Note that the user adoption must always be treated in different scenarios and can be based on previous similarity market studies.\n\nFigure 4: User adoption for the business as a whole and just for the token\nBusiness Assumptions\n\nOne time fundraising\nAvg. monthly income streams\nOne time investments &amp; expenditures\nAvg. monthly expenditures\n\nThe business assumptions are used to forecast the financial sustainability of the business by balancing the initial raised capital/expenditures and regular income/expenditure streams. Figure 5 shows the business funds growth for an exemplary case. The business funds are equivalent to the equity that is owned by the business, which might be originated by raised investor capital and revenues.\n\nFigure 5: Exemplary business funds growth curve for Web3 business case with growing user count\nUtility Modules\nAll previously mentioned aspects are part of the fundamental token ecosystem input section. Another QTM section is dedicated to potential utilities for the token. Note that one can distinguish between different definitions of utility. Instead of â€œtoken utilityâ€ being exclusively tied to the product interaction, in this article â€œtoken utilityâ€ refers to a broader spectrum on which a token can be used. This includes liquidity provision, staking, payments, burning, and holding of the token. In the QTM the utilities are built in a modular way, so that project teams can not only activate or deactivate certain utilities, but also set their assumed weighting with respect to token allocations and specific parameters for each individual one. Figure 6 shows the 5 generalized utilities that are implemented in the current QTM version (1.8).\n\nFigure 6: Generalized utilities in the QTM\nHolding\nThe â€œHoldingâ€ utility is for projects that want to pay out token rewards to wallets that hold the token to incentivize further holding.\nLocking\nThe â€œLockingâ€ utility can be used as representation for staking or play to earn concepts, where users lock their tokens into a smart contract to receive more tokens as rewards.\nLiquidity Mining\nThe â€œLiquidity Miningâ€ utility is created to incentivize other parties to provide liquidity through additional token rewards.\nBurning\nThe â€œBurningâ€ utility has to be used to account for token burnings.\nTransfer\nThe â€œTransferâ€ utility is used whenever tokens will be transferred from token holders back to project buckets. E.g. this can be used for a shop where users can buy items in exchange for the token or to pay for services / fees.\nAnother optional utility mechanic not mentioned in the above list is an off-chain point system that can be used to have more control over value emission to the stakeholders. It leverages off-chain points that can be reused for the products or can be converted into the token and thereby being sold or used for the other utilities. Optionally users that stake the token can get a multiplier on their token issuance rate. Figure 7 illustrates the point issuance with and without multiplier along with the resulting token emissions through the conversion from points to tokens.\n\nFigure 7: Off-chain point issuance and token issuance from point conversions. Points with multiplier are only issued to token stakers\nFigure 8 shows an overview of all previously mentioned input modules for the QTM. Note that all of the subsections need to be fed with the most accurate data available, since the quality of the output depends mainly on the quality of the input data and assumptions made in the QTM.\n\nFigure 8: Input modules of the QTM\nQTM Structure\nThe QTMâ€™s abstracted structure is shown in Figure 9, where the rough processing order for one timestep is from the top to the bottom. The QTM is a time-domain model with a fixed timestep of one month and a simulation range of 10 years. Each timestep starts with the token distribution from the vesting schedules of the different early investor groups. These â€œfreeâ€ tokens will be categorized into three meta buckets. One is used for selling tokens into the LP. The liquidity is implemented as an Automated Market Maker (AMM) LP with the widely knownÂ constant product relationship. Another meta bucket for the vested tokens is used to distribute the tokens to all enabled utilities, specified in the utility modules input section. The last meta bucket is for all tokens freely held by the users and other ecosystem participants. Note that â€œHoldingâ€ can also be defined as an utility, such as outlined before. The distribution shares for all meta bucket categories and the individual utilities have to be set by the designer using the QTM. Every timestep users can join or leave the ecosystem with their capital. This is represented by varying user growth, capital spending for the product or buying the token, selling the token, and utility allocations or removals. Rewards are defined within the individual utilities and will be paid out to stakeholders, while the transfer utility can be used for a refilling of the project buckets. Note that the off-chain business can also buyback tokens to further sustain the project token buckets and issue off-chain points as another layer of value feedback. The model doesnâ€™t leverage Monte Carlo simulations since it already represents the arithmetic mean of all inputs and outputs. Furthermore, it doesnâ€™t include any Markov decision making trees options since all decisions are preset by the designer through average token allocation shares that are constant for the whole course of the simulation. Hence aggregated representative stakeholders are assumed. Note that transient events can be implemented through manual manipulation of the input tables. These simplifications are not sufficient for comprehensive and realistic ecosystem analyses, but they are made as a tradeoff to mitigate complexity for the model to increase accessibility for a wider audience while serving as many different Web3 concepts as possible through its generalized modular framework. Even though predictions wonâ€™t be accurate they can provide a first quantitative approximation.\n\nFigure 9: Input modules of the QTM\nCase Study\nIntroduction\nTwo of the main goals for the ecosystem modeling token engineer is to maintain token value and supply sustainability. Choosing a dynamic token design will mitigate the token supply sustainability issue, since tokens can be minted infinitely, but this mechanic has to be counterbalanced through burning, buybacks, and/or increasing demand for the token to maintain value sustainability.On the other hand a fixed supply token can be attractive for investors since they know that they can own a fixed share of the represented business without getting diluted through potential token inflation. ==A fixed supply of tokens requires token sustainability, since there must always be enough tokens left in the reserves to pay out rewards for the stakeholders of different utilities. In any case the token has to capture and accrue value to be attractive for investors.\nThe presented case study considers a token design with moderate token emissions for two different user adoption scenarios and discusses the implications of main ecosystem parameters.\nCase Study â€“ Base Setup\nThe following case study illustrates the difference between a strong user adoption and a lower user adoption for a Web3 business that sells a product or service in exchange for their token. ==The product requires a subscription fee of 3 worth of token per month per user. Also users can stake their tokens or participate in a liquidity mining program to receive token rewards. The business has to sell the received tokens from the subscription fees to cover their costs and to make a profit==. The initial supply is set to 100,000,000 tokens, the early investor groups, token distribution and vesting is defined as in the example inputs given in Figures 1 to 3. It is assumed that the protocol raises a total amount of 3.9m before the token generation event (TGE). The token has a launch price of $0.50 and 15 % of the raised capital is used to purchase the paired token for the DEX LP. This results in the initial valuations given in the following table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLP$1,170,000MC$25,957,500FDV MC$50,000,000\nThe user adoption is shown in Figure 10, where the amount of token users equals the amount of overall business users, since they need the token to participate for every provided offer. In the case study an additional scenario with one negative growth year and growth stagnation is assumed, represented by the curve in Figure 11. The strong user growth curve ends with 106,167 users and the weak growth scenario ends with 25,412 users after the simulation period of 10 years.\n\nFigure 10: Scenario I â€“ user adoption curve for the business without any negative growth periods\n\nFigure 11: Scenario II â€“ user adoption curve for the business with one year having -2 % user growth per month\nSince the main utility for the token is either spending it for the product subscription or letting it produce yields within the staking or the liquidity mining program, it is assumed that 75 % of the free supply is used for utilities, 20 % will be sold and 5 % will be held in the wallets. Besides this 3 % of the utility allocations will be removed every month as an average assumption. The utility allocations are assumed to be distributed as shown in Figure 12 for every timestep. The rewards for staking and liquidity mining are 15 % and 30 % APR respectively and are generated through a minting function. The majority token utility allocation of 70 % is assumed to be used to pay for the product subscription. 1 % of all utility allocated tokens will be burned per month. Those tokens are subtracted from the product subscription.\n\nFigure 12: Token utility allocations per month\nFor the business a one-time investment of 50k is assumed to cover initial debts. Furthermore regular costs of 84k per month are assumed for the salaries, software licenses, and other expenditures. The income for the business is set to a constant amount of $100k per month and gained from token sales starting two years after the TGE. The resulting funds development without consideration of business token holdings is shown in Figure 13.\n\nFigure 13: Business fund development for the case studies\nSince the income is a $-denominated fixed value, it is not affected by the two different user growth curve scenarios. However, the different user growth assumptions affect other case study specific metrics, discussed in the following sections.\nScenario I: Strong User Adoption\nThe strong user growth scenario is based on the numbers given in Figure 10. The project buckets and the supply numbers of the token are the first important metrics to analyze. Figure 14 shows their development over the course of the simulation. The initial investor vesting ends 3.5 years after the TGE. The circulating supply increases through this vesting period to around 100m tokens and continues to rise slightly due to the token minting for payouts to staking and liquidity mining participants. The token reserves also increase over time, since they are filled from the customers transferring their tokens to pay for the main product subscription.\n\nFigure 14: Project bucket and supply development for the strong user adoption curve\nThe strong user growth creates demand for the token so that its price starts to appreciate after the bottom of 0.12 per token is reached after one year. The initial decrease of the token price is caused by the sell pressure from the vested tokens from initial investor groups combined with the comparatively low user count of just 9,537 at the end of the first year. One big advantage of the QTM simulation tool is that input parameters can be changed without much effort. In this case it is of interest to examine the effect of another vesting schedule. E.g. changing it to double vesting time for all early investors would result in an initial token price drop to just 0.19.\n\nFigure 15: Token price development for the strong user adoption curve\nFigure 16 shows the -denominated value flows from and to the different utilities respectively. They show the expected healthy growth coinciding with the user growth. At the end of the simulation period, the transferred amount of tokens from the users approaches 1m, while around 400k worth of tokens are issued to stakers and liquidity miners as reward and 14k worth of tokens are burned per month.\n\nFigure 16: Utility rewards / burnings / transfers for the strong user adoption curve given in $-denomination\nScenario II: Weak User Adoption\nThe weak user growth scenario is based on the numbers given in Figure 11. The token supplies in Figure 17 reveal that the reserve bucket will run out of tokens after around 8 years, since too few users counterbalance the constant token selling from the business. Note that even the dynamic setup of the token canâ€™t sustain the strong sell pressure in terms of token supply.\n\nFigure 17: Project bucket and supply development for the weak user adoption curve, where the reserves running out of tokens after around 8 years\nSimilarly the token price experiences a massive drop in the negative growth year, which coincides with the start of the regular massive token sales from the business. Overall the applied business setup is not sustainable in terms of the token valuation and the supply for this low user adoption. The QTM can be leveraged to find settings that might change this unsustainable situation into a sustainable one.\n\nFigure 18: Token price development for the weak user adoption curve\nReducing the monthly token sales from 100k to 85k worth of tokens is already enough to reach a sustainable token valuation and token price. These numbers will not lead to strong business fund growth, but let the business sustain, such as indicated in Figure 19.\n\nFigure 19: Business fund development with reduced regular token sales for the business to counter a lower user adoption\nFigures 20 and 21 show the corresponding token supply and valuation curves for this survival mode scenario. Now the reserves supply is sustainable over the simulation period and the price starts rising again after the negative growth year. Note that external market psychological factors are not accounted for in these simulations, which means that the appearance of the price chart doesnâ€™t affect the behavior of the users and investors in the model. This simplified assumption is a limitation of the QTM.\n\nFigure 20: Project bucket and supply development for the weak user adoption curve and lowered token sales from the business\n\nFigure 21: Token price development for the weak user adoption curve with lowered token sales from the business\nConclusion\nThe case study shows some capabilities of the QTM, where fundamental token business aspects are evaluated within seconds after parameter definition. This specific analysis revealed the impact of different user adoption scenarios and showcased how small changes in the base parameters can cause the difference between a sustainable and an unsustainable Web3 business. The QTM is a powerful and accessible tool with a clean UI to perform high level forecasts for many different kinds of token ecosystems. It is built in a modular structure so that token designers and engineers can turn on and off whatever functionality they want. The QTM leverages customizable token supply designs, fund raisings, token allocations, vesting schedules, liquidity pool designs, user adoption scenarios, (static) user behaviors, business assumptions, buyback strategies and on- and off-chain utilities. The tool is programmed in a spreadsheet so that everyone can use it without any coding knowledge and simulates each given setup within a few seconds. It is the ideal tool for new Web3 businesses and existing businesses to create a first quantitative iteration for their token design while allocating low time resources for setting the simulation up.\nOutlook\nEven though this model is suitable for most of the Web3 businesses, some concepts are too complex to be represented by a generalized tool. Therefore we are building more sophisticated tools in the background that will leverage state-of-the-art high performance token engineering approaches and combine them with new on-chain data-driven decision making processes."},"Articles--and--Papers/What-Are-Blockchains,-Computers-That-Can-Make-Commitments":{"slug":"Articles--and--Papers/What-Are-Blockchains,-Computers-That-Can-Make-Commitments","filePath":"Articles & Papers/What Are Blockchains, Computers That Can Make Commitments.md","title":"What Are Blockchains: Computers That Can Make Commitments","links":[],"tags":["untagged"],"content":"Notes\nBlockchains are computers that make commitments, meaning there are programmed rules.\nCommitments can be useful in finance. Bitcoin, for example, has a rule, making a commitment, which says only 21 million bitcoins can ever be created.\nThese rules enable developers to make a commitment to the protocol too, and to get tokens as a reward, because the user knows the rules will not change on them like with Web2 protocols.\nTheoretically, a blockchain can make a commitment like a government makes a commitment with for example monetary scarcity from precious metals (now, of course, the govt. prints an unlimited amount of money.)\nBlockchains give 3rd party developers trust. Regain trust that they lost in Web3.\nQuotes\n\nA game theoretic mechanism â€” a so-called consensus mechanism â€” makes blockchains resilient to modifications to their underlying physical components, effectively making them resilient to human intervention.\n\n\nComputers that make commitments can be useful in finance. The most famous example of this is Bitcoin, which makes various commitments, including that there will never be more than 21 million bitcoins, a commitment that makes bitcoins scarce and therefore capable of being valuable. Without a blockchain, this commitment could have been made by a person or a business, but it is unlikely that other people would have really trusted that commitment, since people and businesses change their minds all the time\n\n\nÂ Prior to Bitcoin, besides precious metals which are naturally scarce, the only credible commitments to monetary scarcity came from governments.\n\n\nThird-party developers can safely invest in their businesses knowing that the rules are baked into the network and canâ€™t change, protecting them fromÂ platform risk. Using the financial features of blockchains, users and developers can receive tokens in order to participate in the upside of the network as it grows.\n\n\nBlockchains have arrived at an opportune time. Internet services have become central to our economic, political, and cultural lives, yet the trust between users and the people who run these services is breaking down. At the same time, industries like finance that have traditionally depended on trust have resisted modernization. The next few years will be exciting â€” we are only beginning to explore theÂ idea mazeÂ unlocked by this new capability of computers.\n\n"},"Articles--and--Papers/What-is-Blockchain,-Computers-that-Make-Commitments-by-Chris-Dixon":{"slug":"Articles--and--Papers/What-is-Blockchain,-Computers-that-Make-Commitments-by-Chris-Dixon","filePath":"Articles & Papers/What is Blockchain, Computers that Make Commitments by Chris Dixon.md","title":"What is Blockchain, Computers that Make Commitments by Chris Dixon","links":[],"tags":[],"content":"Source: a16zcrypto.com/posts/article/computers-that-make-commitments/\n#processed\nNotes\nBlockchains are computers that make commitments, meaning there are programmed rules.\nCommitments can be useful in finance. Bitcoin, for example, has a rule, making a commitment, which says only 21 million bitcoins can ever be created.\nThese rules enable developers to make a commitment to the protocol too, and to get tokens as a reward, because the user knows the rules will not change on them like with Web2 protocols.\nTheoretically, a blockchain can make a commitment like a government makes a commitment with for example monetary scarcity from precious metals (now, of course, the govt. prints an unlimited amount of money.)\nBlockchains give 3rd party developers trust. Regain trust that they lost in Web3.\nQuotes\n\nA game theoretic mechanism â€” a so-called consensus mechanism â€” makes blockchains resilient to modifications to their underlying physical components, effectively making them resilient to human intervention.\n\n\nComputers that make commitments can be useful in finance. The most famous example of this is Bitcoin, which makes various commitments, including that there will never be more than 21 million bitcoins, a commitment that makes bitcoins scarce and therefore capable of being valuable. Without a blockchain, this commitment could have been made by a person or a business, but it is unlikely that other people would have really trusted that commitment, since people and businesses change their minds all the time\n\n\nÂ Prior to Bitcoin, besides precious metals which are naturally scarce, the only credible commitments to monetary scarcity came from governments.\n\n\nThird-party developers can safely invest in their businesses knowing that the rules are baked into the network and canâ€™t change, protecting them fromÂ platform risk. Using the financial features of blockchains, users and developers can receive tokens in order to participate in the upside of the network as it grows.\n\n\nBlockchains have arrived at an opportune time. Internet services have become central to our economic, political, and cultural lives, yet the trust between users and the people who run these services is breaking down. At the same time, industries like finance that have traditionally depended on trust have resisted modernization. The next few years will be exciting â€” we are only beginning to explore theÂ idea mazeÂ unlocked by this new capability of computers.\n\n"},"Articles--and--Papers/Why-Decentralization-Matters":{"slug":"Articles--and--Papers/Why-Decentralization-Matters","filePath":"Articles & Papers/Why Decentralization Matters.md","title":"Why Decentralization Matters","links":["Decentralized-platforms-win-because-unlike-their-centralized-counterparts-they-don't-exploit-users-and-they-don't-bait-and-switch-builders-and-creators","Decentralized-platforms-tend-to-come-half-baked-unlike-their-polished-and-bundled-centralized-counterparts","Typical-lifecycle-for-centralized-platforms-is-to-extract-from-users-and-market-participants-(businesses,-creators,-developers)-as-they-go-up-the-S-curve-of-adoption","Regulation-is-effective-for-centralized-platform-monopolies-that-create-hardware-(telecom,-phone,-radio,-tv)-but-less-necessary-for-the-Internet-(software-stack)-because-it-can-be-rearchitected","Decentralized-protocols-use-two-mechanisms-to-prevent-bait--and--switch-of-their-centralized-counterparts-(1)-open-source-code-and-(2)-checks-and-balances-with-voice-and-exit","Graphics/Dangers-of-building-and-using-centralized-platforms"],"tags":["decentralization"],"content":"Summary\nDecentralization matters for builders, creators, and users because centralized platforms have proven to eventually exploit as they seek profit. Centralized platforms change up the rules on 3rd parties. Crypto networks are better because they create incentives via crypto economics that make it better for people to build and stick around for the long term. \nCentralized platforms bait and switch builders and creators. And create social tensions like privacy issues, fake news, de-platforming, for users. They have a predictable lifecycle as they go up the S-curve and start to extract users and compete with developers, creators, and businesses. \nDecentralized platforms tend to come half-baked, unlike their polished and bundled counterparts, which creates skepticism amongst the experienced. But decentralized platforms get ahead as they attract more developers. \nNotes\nDecentralized platforms win because unlike their centralized counterparts they donâ€™t exploit users and they donâ€™t bait and switch builders and creators\nDecentralized platforms tend to come half-baked unlike their polished and bundled centralized counterparts\nTypical lifecycle for centralized platforms is to extract from users and market participants (businesses, creators, developers) as they go up the S-curve of adoption\nRegulation is effective for centralized platform monopolies that create hardware (telecom, phone, radio, tv) but less necessary for the Internet (software stack) because it can be rearchitected\nDecentralized protocols use two mechanisms to prevent bait &amp; switch of their centralized counterparts (1) open source code and (2) checks and balances with voice and exit\nQuotes\nThe first two eras of the internet\nDuring the first era of the internet â€” from the 1980s through the early 2000s â€” internet services were built on open protocols that were controlled by the internet community. ==This meant that people or organizations could grow their internet presence knowing the rules of the game wouldnâ€™t change later on. Huge web properties were started during this era including Yahoo, Google, Amazon, Facebook, LinkedIn, and YouTube. In the process, the importance of centralized platforms like AOL greatly diminished.\nDuring the second era of the internet, from the mid 2000s to the present, for-profit tech companies â€” most notably Google, Apple, Facebook, and Amazon (GAFA) â€” built software and services that rapidly outpaced the capabilities of open protocols. ==The explosive growth of smartphones accelerated this trend as mobile apps became the majority of internet use. Eventually users migrated from open services to these more sophisticated, centralized services. Even when users still accessed open protocols like the web, they would typically do so mediated by GAFA software and services\nThe good news is that billions of people got access to amazing technologies, many of which were free to use. ==The bad news is that it became much harder for startups, creators, and other groups to grow their internet presence without worrying about centralized platforms changing the rules on them, taking away their audiences and profits. This in turn stifled innovation, making the internet less interesting and dynamic. Centralization has also created broader societal tensions, which we see in the debates over subjects like fake news, state sponsored bots, â€œno platformingâ€ of users, EU privacy laws, and algorithmic biases. These debates will only intensify in the coming years.\nâ€œWeb 3â€: the third era of the internet\nOne response to this centralization is to impose government regulation on large internet companies. This response assumes that the internet is similar to past communication networks like the phone, radio, and TV networks. But the hardware-based networks of the past are fundamentally different than the internet, a software-based network. Once hardware-based networks are built, they are nearly impossible to rearchitect. ==Software-based networks can be rearchitected through entrepreneurial innovation and market forces.\n==The internet is still early in its evolution: the core internet services will likely be almost entirely rearchitected in the coming decades. This will be enabled by crypto-economic networks, a generalization of the ideas first introduced inÂ BitcoinÂ and further developed inÂ Ethereum. Cryptonetworks combine the best features of the first two internet eras: community-governed, decentralized networks with capabilities that will eventually exceed those of the most advanced centralized services.\nWhy decentralization?\n==Centralized platforms follow a predictable life cycle. When they start out, they do everything they can to recruit users and 3rd-party complements like developers, businesses, and media organizations. They do this to make their services more valuable, as platforms (by definition) are systems with multi-sided network effects. As platforms move up the adoption S-curve, their power over users and 3rd parties steadily grows.\nDangers of building and using centralized platforms\n](cdixon.org/static/6acb0932610c3553e96e9b2e7766cc29/e1c95/07lrwGIDbAYk6q7zG.png)\n==When they hit the top of the S-curve, their relationships with network participants change from positive-sum to zero-sum. The easiest way to continue growing lies in extracting data from users and competing with complements over audiences and profits. Historical examples of this are Microsoft vs. Netscape, Google vs. Yelp, Facebook vs. Zynga, and Twitter vs. its 3rd-party clients. Operating systems like iOS and Android have behaved better, although still take a healthy 30% tax, reject apps for seemingly arbitrary reasons, and subsume the functionality of 3rd-party apps at will.\n==For 3rd parties, this transition from cooperation to competition feels like a bait-and-switch. Over time, the best entrepreneurs, developers, and investors have become wary of building on top of centralized platforms. We now have decades of evidence that doing so will end in disappointment. In addition, users give up privacy, control of their data, and become vulnerable to security breaches. These problems with centralized platforms will likely become even more pronounced in the future.\nEnter cryptonetworks\n==Cryptonetworks are networks built on top of the internet that 1) use consensus mechanisms such as blockchains to maintain and update state, 2) use cryptocurrencies (coins/tokens) to incentivize consensus participants (miners/validators) and other network participants. Some cryptonetworks, such as Ethereum, are general programming platforms that can be used for almost any purpose. Other cryptonetworks are special purpose, for example Bitcoin is intended primarily for storing value,Â GolemÂ for performing computations, andÂ FilecoinÂ for decentralized file storage.\nEarly internet protocols were technical specifications created by working groups or non-profit organizations that relied on the alignment of interests in the internet community to gain adoption. This method worked well during the very early stages of the internet but since the early 1990s very few new protocols have gained widespread adoption.Â ==Cryptonetworks fixÂ these problems by providing economics incentives to developers, maintainers, and other network participants in the form of tokens. They are also much more technically robust. ==For example, they are able to keep state and do arbitrary transformations on that state, something past protocols could never do.\n==Cryptonetworks use multiple mechanisms to ensure that they stay neutral as they grow, preventing the bait-and-switch of centralized platforms. First, the contract between cryptonetworks and their participants is enforced in open source code. Second, they are kept in check through mechanisms forÂ â€œvoiceâ€ and â€œexit.â€Â Participants are given voice through community governance, both â€œon chainâ€ (via the protocol) and â€œoff chainâ€ (via the social structures around the protocol). Participants can exit either by leaving the network and selling their coins, or in the extreme case by forking the protocol.\n==In short, cryptonetworks align network participants to work together toward a common goal â€” the growth of the network and the appreciation of the token. This alignment is one of the main reasons Bitcoin continues to defy skeptics and flourish, even while new cryptonetworks like Ethereum have grown alongside it.\n==Todayâ€™s cryptonetworks suffer from limitations that keep them from seriously challenging centralized incumbents. The most severe limitations are around performance and scalability. The next few years will be about fixing these limitations and building networks that form the infrastructure layer of the crypto stack. After that, most of the energy will turn to building applications on top of that infrastructure.\nHow decentralization wins\nSoftware and web services are built by developers. There are millions of highly skilled developers in the world. Only a small fraction work at large technology companies, and only a small fraction of those work on new product development. Many of the most important software projects in history were created by startups or by communities of independent developers.\nAn illustrative analogy is the rivalry in the 2000s between Wikipedia and its centralized competitors like Encarta. If you compared the two products in the early 2000s, Encarta was a far better product, with better topic coverage and higher accuracy. ==But Wikipedia improved at a much faster rate, because it had an active community of volunteer contributors who were attracted to its decentralized, community-governed ethos. By 2005, Wikipedia was the mostÂ popularÂ reference site on the internet. Encarta was shut down in 2009.\nThe lesson is that when you compare centralized and decentralized systems you need to consider them dynamically, as processes, instead of statically, as rigid products. Centralized systems often start out fully baked, but only get better at the rate at which employees at the sponsoring company improve them. Decentralized systems start out half-baked but, under the right conditions, grow exponentially as they attract new contributors.\nIn the case of cryptonetworks, there are multiple, compounding feedback loops involving developers of the core protocol, developers of complementary cryptonetworks, developers of 3rd party applications, and service providers who operate the network. These feedback loops are further amplified by the incentives of the associated token, which â€” as weâ€™ve seen with Bitcoin and Ethereum â€” can supercharge the rate at which crypto communities develop (and sometimes lead to negative outcomes, as with the excessive electricity consumed by Bitcoin mining)\nThe question of whether decentralized or centralized systems will win the next era of the internet reduces to who will build the most compelling products, which in turn reduces to who will get more high quality developers and entrepreneurs on their side. ==GAFA has many advantages, including cash reserves, large user bases, and operational infrastructure. Cryptonetworks have a significantly more attractive value proposition to developers and entrepreneurs. If they can win their hearts and minds, they can mobilize far more resources than GAFA, and rapidly outpace their product development.\nCentralized platforms often come bundled at launch with compelling apps: Facebook had its core socializing features and the iPhone had a number of key apps. ==Decentralized platforms, by contrast, often launch half-baked and without clear use cases. As a result, they need to go through two phases of product-market fit: 1) product-market fit between the platform and the developers/entrepreneurs who will finish the platform and build out the ecosystem, and 2) product-market fit between the platform/ecosystem and end users. This two-stage process is what causes many people â€” including sophisticated technologists â€” to consistently underestimate the potential of decentralized platforms.\nThe next era of the internet\nCompare the problem of Twitter spam to the problem of email spam. Since TwitterÂ closedÂ their network to 3rd-party developers, the only company working on Twitter spam has been Twitter itself. By contrast, there were hundreds of companies that tried to fight email spam, financed by billions of dollars in venture capital and corporate funding. Email spam isnâ€™t solved, but itâ€™s a lot better now, because 3rd parties knew that theÂ email protocolÂ was decentralized, so they could build businesses on top of it without worrying about the rules of the game changing later on.\nOr consider the problem of network governance. Today, unaccountable groups of employees at large platforms decide how information gets ranked and filtered, which users get promoted and which get banned, and other important governance decisions. In cryptonetworks, these decisions are made by the community, using open and transparent mechanisms. As we know from the offline world, democratic systems arenâ€™t perfect, but they are a lot better than the alternatives.\n==Centralized platforms have been dominant for so long that many people have forgotten there is a better way to build internet services. Cryptonetworks are a powerful way to develop community-owned networks and provide a level playing field for 3rd-party developers, creators, and businesses. We saw the value of decentralized systems in the first era of the internet. Hopefully weâ€™ll get to see it again in the next"},"Graphics/Dangers-of-building-and-using-centralized-platforms":{"slug":"Graphics/Dangers-of-building-and-using-centralized-platforms","filePath":"Graphics/Dangers of building and using centralized platforms.md","title":"Dangers of building and using centralized platforms","links":[],"tags":[],"content":"\n"},"Lore/YODA-Story-1-MetaCartel-DAO":{"slug":"Lore/YODA-Story-1-MetaCartel-DAO","filePath":"Lore/YODA Story 1 MetaCartel DAO.md","title":"YODA Story #1: MetaCartel DAO","links":["[https:/MetaCartel's](https:/metacartel's/)-forum"],"tags":["published"],"content":"Read full story\nKey Insights\n\nThis is the story of Metacartel DAO, which has served as a pioneer in the DAO space\nRika shares their personal journey from the corporate world to discovering DAOs and cryptocurrency\nThis story discusses the mission, values, and manifesto of Metacartel DAO\n\nHello, friends. Welcome to a short story about Decentralized Autonomous Organizations (DAOs). This short story will become part of an anthology of short stories: a book.\nPrologue\nThe book is for you if you have started to peek inside the DAO rabbit hole. Perhaps DAOs are still a black hole for you, or maybe you have started to see the light but feel overwhelmed. Either way, you are curious and want to explore.\n\nThe book is an offer.\nI am asking that you allow me to take you on a journey through DAOs, as we uncover the mystery together.\nFor some context on what to expect, this current release includes one story: the story ofÂ MetaCartel DAO. I have also started working on the next release: the story ofÂ MetaFactory and iRobot DAO.\nAs you may already know, there are hundreds, if not thousands, of DAOs on the Internet today, so how did I choose which DAOs to write about?\nChoosing the first DAO to write about, MetaCartel DAO, was simple. I have witnessed MetaCartel grow and evolve into one of the most impactful DAOs in the space - and itâ€™s a pretty damn good story. MetaCartel is also the earliest DAO, preceded only by Moloch DAO.\nAs a DAO pioneer, MetaCartel has served as a pathfinder for new DAOs. It has set the foundation for DAOs likeÂ MetaFactory,Â MetaGammaDelta,Â RaidGuild,Â DAOhaus, and others.\nChoosing which DAOs to write about was a matter of following the rabbit hole.\nWith all that said, Iâ€™m really excited to share with you the story of MetaCartel. As you learn about MetaCartel, you will also learn about my story, one that I have written in piecemeal before, but never in entirety and never from the lens of community.\nIntroduction\nI want to start by addressing the elephant in the room:Â DAO is a kitschy acronym that has been used and misused and is becoming trite.\nWhat the heck doesÂ Decentralized Autonomous OrganizationÂ even mean? It sounds like some sentient being that may or may not run away with your money; and it sounds like it might be some corporate jargon.\nNeither of these things are true.\nDAOs are, generally, made up of well-intentioned people who do not want to steal your money.\nDAOs are also not corporate. Many people who join DAOs have previously worked for a corporation and are frustrated with the inequities of the corporate system. They then discover DAOs and experience a sort of spiritual awakening.\nWith that said, how about changing the name to YODA?\nImagine this:\n\nYouâ€™re at a bar and you get to talking to a cool person sitting next to you.\nAs you take a sip of your drink, you say:\nâ€œHey, are you interested in learning more about this dope YODA community?â€\nYou then pull out your phone and show them this photo:\n\n\n\nBoth of you have a good laugh, and you begin to tell your new friend what DAOs actually are:Â a community of like-minded, good-hearted, people who work on impactful projects together and also have fun.\nYou then say:\nâ€œHeeyyy, let me tell you about MetaCartel!â€\n\nMetaCartel\nMetaCartel, as one of the earliest DAOs, has set the precedent for DAO culture, memeing its way into existence.\nLetâ€™s meet MetaCartelâ€™s logo: ChiliMan.\n\nChiliMan\nChiliMan is anthropomorphic. Heâ€™s not human, but he has human traits. He has a mustache, he makes music with maracas, and he brings good vibes wherever he goes.\nChiliMan also loves people. He believes that if you bring a bunch of great people together who want to change the world for the better, and give them tools and resources, you can solve big problems.\nBut first, you need to bring people together and you need to spread the vibes.\nIn the past, corporations would do this. Society relied on the structure of corporations to bring people together and give them money and resources to solve problems in society.\nToday, we also have DAOs to do this. Society relies on DAOs to coordinate groups of people and give them money and resources so they can solve problems. DAOs enable a fairer system by aligning incentives better than corporations, resulting in more people acquiring wealth while working on problems that they care about with people whom they care about.\nThe Red Pill: My Story\nNever in a million years did I think it would be possible for me to write a book full time.\nFor many years, I was deeply entrenched in the corporate world. As I look back at my experience, I realize that I was a corporate slave. But, I was also a rebel and a misfit, who discovered a path into cryptocurrency and DAOs.\nHereâ€™s how my path unfolded.\nIn 2017, I quit my secure, safe, and stable consulting job at Deloitte, where I worked for six years, to join the Ethereum startup, ConsenSys.\nConsenSysÂ is a start-up founded by Joseph Lubin, the co-founder of Ethereum. The company builds Ethereum products - like infrastructure, tooling, and applications - that power the Ethereum blockchain and cryptocurrency components of Web 3.\nNote: Web 3 is a somewhat hazy and overused concept. It seems to include not only blockchain and cryptocurrency, but also artificial intelligence, and 3D graphics. People are still trying to answer what exactly Web 3 is supposed to be. Perhaps the point is that we donâ€™t know yet, in the same way that no one knew exactly how the Internet would unfold.\nHereÂ is a good website that explains Web3, Web2, and Web1.\nDuring my time at ConsenSys, I experienced mind expansion and a shift in values. In the ConsenSys headquarters in Brooklyn, I spent a lot of time in a conference room namedÂ red pill.\n\nIf you have seen any of The Matrix movies, you know that theÂ red pillÂ symboilizes embracing the sometimes painful truth of reality, and theÂ blue pillÂ symbolizes remaining in the blissful ignorance of illusion. Neo, the main protagonist, chooses the red pill.\nOne day, I sat in on a product team meeting.\nFive people were sitting in the conference room at a long glass table with chairs, and three people were on Zoom, video calling from various global locations.\nThe meeting started with a five-minute meditation. Everyone closed their eyes and silently took deep breaths.\nWhen the five-minutes was up, we did a mood check-in. Everyone went around the room, and around Zoom, sharing what emotions came up.\nIt was an opportunity to connect, and people didnâ€™t hold back.\nAfter the first person shared a vulnerable emotion, the Zoom chat exploded with heart emojis and messages like, â€œI love you,â€ and â€œThank you so much for sharing. I am here for you.â€\nAfter the meeting, the team leader, an early ConsenSys employee, shared with me that this exercise helped her team to build empathy. If someone was struggling with an interpersonal problem, at home or at work, or maybe they were just having a bad day, the team could help support that person emotionally, and also reallocate their work to minimize disruptions.\nAnother time, in the red pill conference room, I joined a conversation about salary transparency.\nThe discussion was open to anyone at the company. The discussion leader, an early ConsenSys employee, was an advocate for social equity, diversity, and inclusion. He cared deeply about salary transparency, where employees openly disclose their salaries to colleagues.\nA handful of people were in the conference room, seated at the long glass table with chairs, and others were on Zoom, video calling from various global locations.\nThe discussion leader shared a few powerpoint slides on the benefits of salary transparency. For example, one slide said that salary transparency creates a culture of equity and shines a light on pay gaps. It becomes a way to spark conversation and ultimately fix pay gaps.\nAs he was sharing slides, participants on Zoom were actively commenting in the chat. Some vulnerable emotions were shared, and once again the chat was flooded with heart emojis.\nI was quickly learning that people at ConsenSys brought their whole selves to work. Empathy and trust building were ingrained in the early ConsenSys culture.\nHowever, things would soon start changing for the worse.\nConsenSys started to hire more people from the corporate world - people like me, except, unlike me, these new people didnâ€™t want to absorb the ConsenSys culture. Instead, they wanted to make it more corporate.\nTensions began to grow between early ConsenSys employees and the corporates. The former liked the culture they built, and the latter were trying to destroy it by enforcing strict timelines, revenue goals, and hierarchy.\nEventually, tensions got too high and rumors began to circulate that there would be layoffs. My colleagues told me that layoffs were normal for startups. Many of them had been through several layoffs already, and were handling the news valiantly.\nBut this was my first reorganization. And I knew that I would soon be cut.\nI knew that I would be laid off because I was not able to find a home at ConsenSys. I was hired onto the corporate team, but I vibed more with the early ConsenSys employees, the non-corporates; however, my lack of experience and company politics prevented me from working with the people who I wanted to work with.\nLooking back at my time at ConsenSys, I am most proud of the writing that I did. For example, I interviewed the founder ofÂ Truffle, one of the earliest Ethereum infrastructure products, and IÂ shared good vibesÂ after an uplifting experience at a company retreat.\nI now realize that I was most fulfilled when I could write and share stories. I even got hired for a job after I wroteÂ thisÂ blog post about crypto and product management. But, it would take me two more failed jobs at Ethereum startups, and a Sabbatical, to accept that I was working in the wrong role with the wrong people.\nIn September 2020, I decided to take a Sabbatical.\nSuddenly, I found myself with tons of free time and the ability to literally do anything I wanted. (As long as I was socially distant and not around big groups, since we were in a global pandemic).\nAs a nerd, I of course joined virtual communities. I felt stifled by crypto and I wanted to explore new spaces, so I exclusively joined non-crypto virtual communities.\nThese are some of the communities that I joined:Â Ness Labs,Â Roam Research,Â Interintellect,Â The Stoa, andÂ Foster.Â And I continued be active in one of my favorite and fun crypto communities:Â Mochi.\nI also started using Twitter more to connect with people and to share my writing.\nI then wrote a Tweet where I shared my positive experience with online communities, and I received a lot of positive signal. This showed me that others were experiencing these good vibes too, and that online communities are the real deal.\nOnline communities are transforming peopleâ€™s lives.\nPeter Pan: Keep Wandering\nPeter Pan, the founder of MetaCartel DAO, says that the biggest lesson he has learned from crypto is this:\n\nTake a leap of faith. Be willing to wander and be lost. Follow an important cause and mission. Back yourself and something interesting will happen.\n\nBefore founding MetaCartel, Peter was rejected from a bunch of jobs in crypto.\nHe was starting to run out of money and out of options so in September 2018, he attended EthBerlin, a large annual Ethereum conference, to meet new people and look for jobs.\nAs a UI/UX designer, Peter spotted some design problems with Ethereum meta transactions, identifying areas of friction for new users who wanted to start using Ethereum apps.\nTo spread the word, he created a Telegram group (which would later become the foundation for MetaCartel DAO) and invited conference attendees.\n\nPeterâ€™s intention with the Telegram group was to build his reputation from a nobody in crypto to a somebody who can solve Ethereum UI/UX problems, and land a job.\nPeter wanted the working group to be serious, because he thought seriousness would help him land a job.\nBut, little did he know, the working group that he formed had members with a completely different mindset. These were crypto OGs and they knew how to have fun.\nSo when as a joke, Peter (an undercover jokester), created the ChiliMan logo and shared it with the community, the working group, people loved it and voted to make it the official logo of the working group.\nPeter, luckily, was outnumbered. He now says, in retrospect, that the logo helped attract a lot of cool people to MetaCartel.\nPeter achieved one of his goals: to attract cool people to the working group and work on some interesting design problems, but he still didnâ€™t land a job.\nSo he started to apply to a bunch of companies, but no one would respond to his applications.\nSerendipitously, James Young, one of the members who joined Peterâ€™s working group, was yapping Peterâ€™s ear off about Moloch DAO.\nMoloch, soon to become the first-ever DAO, was launching and they were in the process of giving their first grant. Vitalik Buterin, the founder of Ethereum, and Joseph Lubin, the co-founder of Ethereum, gave $4M dollars to help launch Moloch DAO.\nPeter wanted to become a member of Moloch DAO. But, he was rejected. He didnâ€™t have enough money to pledge membership.\nSo Peter confronted the Moloch DAO founders, who suggested to Peter that he turn his working group into a DAO. They even encouraged him to fork (copy) Molochâ€™s codebase.\nYou can think of Moloch DAOâ€™s codebase like a set of smart contracts that creates the technical backbone of a DAO. The purpose is to set up a DAO that will operate transparently on the Ethereum blockchain. This means the smart contracts have code that enables basic DAO functionality, like share distributions, vote casting, and proposal creation.\nI know this is a little technical, so if itâ€™s over your head, donâ€™t worry about it. But if youâ€™re technically inclined, you can learn more on Moloch DAOâ€™s Github.\nWith the encouragement of Molochâ€™s founders, Peter created the application layer for Moloch DAO. At the time, Moloch DAO was just a bunch of smart contracts without a front-end for users to interact with. Peter created that front-end, the application layer, making MetaCartel DAO user friendly.\nNow, Peter needed more people to join MetaCartel so he could execute on his vision of creating an altruistic grant giving DAO, kind of like an incubator for Ethereum projects. The DAO would pool money from members and give grants to people building on Ethereum. The DAO would not take a percentage of revenue or profits - it would be completely altruistic.\nPeter initially struggled with getting people to join MetaCartel. He also still didnâ€™t have a job or money, but he continued to conscientiously spread the word about MetaCartel.\nDuring this troubled time, Peter referred to himself as MetaCartelâ€™s lead slave.\nBut then the tides started to turn.\nPeter was accepted to the Binance Tech fellowship where he was paid $5k USD/month, enough to sustain him and pay for conferences so that he could spread the message of MetaCartel.\nFinally, Peterâ€™s hustling was starting to pay off. More people started joining the DAO and some early supporters even took a leap of faith and contributed as much as 100 ETH.\nWhy did people contribute so much money?\nPeter says itâ€™s because these early supporters knew that the cool thing about Web3 &amp; Ethereum is that we have found ways to generate wealth sustainably, and the more wealth we share, the more wealth we can generate.\nAnd this is done by nurturing a community of good natured rebels and misfits who feel a responsibility to help and support others while also having fun.\nAs the African proverb and MetaCartelâ€™s motto goes:\n\nIf you want to go fast, go alone. If you want to go far, go together.\n\nThe other day I saw this meme in the MetaCartel DAO Telegram group.\n\nMetaCartel: Mission, Values, and Manifesto\nA shared mission and common values is super important in a decentralized environment. When there is no hierarchy, when there are loose timelines, and when power is evenly distributed, people need to be self-motivated.\nThe most effective form of motivation is intrinsic, meaning you work because you want to; because you believe in the mission, because you align with the values, and because you se the impact your work is making.\nClearly communicating mission and values is super important for DAOs. It should be front and center and always top of mind for members. And if youâ€™re thinking about joining a DAO, you should pay close attention to its mission and values.\nMetaCartelâ€™s mission is to:\n\nAccelerate the creation of Web3 with the belief that it will make the world a richer, fairer place.\n\nMetaCartelâ€™s values are:\n\nWe are people first and take chances on people.\nWe are action oriented and move fast.\nWe thrive in chaos and are comfortable with pressure.\nWe back ourselves and believe in the work we are doing.\nWe do not believe in cynicism, we watch for opportunities\nWe have a dancing chilli as a logo, we have fun. YOLO.\n\nIn December 2019, Peter Pan wrote aÂ Web3 manifestoÂ that was edited by MetaCartel memberÂ Drew Harding.\nHere are some highlights:\n\nThereâ€™s a future where Web3â€™s open markets, DAOs and micro-economies will unbundle governments, changing their role in society, localizing economies to digital schelling points.\nAs our finances, assets and data are enhanced with self sovereign properties, the power imbalances enabled by centralized systems and violence-enforced governance will rebalance, ultimately creating a more fair global society.\nEthereum and the world of Web3 has enabled us to coordinate in a new internet of open value.\nIndividuals will be able to invest and participate in the governance of their local infrastructure and community businesses. Universities and educational institutions will be disrupted and replaced by communally-owned, for-profit DAOs.\n\n\nWeb3 will enable the ultimate MMO RPG (Massive Multiplayer Online Role Playing Game) that transcends entertainment or gaming, as a natural extension of everyday life, consuming the world. Not only will individuals be able to make a living in these digital ecosystems but they will also provide new economic opportunities, reshape dating and the family unit, and completely revolutionize education.\n\nProposal and Grant Process\nProposals and grants are the bread and butter of MetaCartel. Members who have an idea for a project write up a proposal and post it to the forum. Then, thereâ€™s a discussion phase where members make comments on the proposal. If consensus is reached, the proposal becomes official, meaning it is put on-chain using the DAOHaus platform, and a grant is awarded.\nIf the proposal is aligned with MetaCartelâ€™s mission and values, the discussion is usually very positive and inspiring.\nFor example, one proposal that I am super excited about is from Ann at Meta Gamma Delta, a DAO that supports women led projects.\nHere are some highlights:\n\nMeta Gamma Delta would love to partner with MetaCartel on a real meta issue! The basic idea: if we want to fund more women-led initiatives, we need to actively bring more women in the door\nWe propose an end-to-end solution to recruit women from adjacent industries, provide educational opportunity and mentorship, with basic income for an onboarding period of 3-6 months. This all leads to help with job placement and start-up initiatives\n\n\nAnd here is some more context from Ann:\n\nWe all jumped into this space because we were inspired and we could see the opportunities opening out before us. But many of us bootstrapped our way in by working a day job, then working at night on our passion; by getting financial support from family &amp; friends; by being lucky in early investments; or by whatever means we had to buy the time to learn.\nThere will be more like us. But who are we missing? Who is out there who lives on what they earn week-to-week and canâ€™t stop for a learning curve? What would their contribution bring? Would they surprise us?\n\nYalor: Listen To Your Heart Space\nIf youâ€™re still with me, congrats on making it this far! I hope youâ€™ve been enjoying the ride.\nWeâ€™re about 75% done with the journey, and Iâ€™d like to tie up some loose ends.\nBefore Peterâ€™s story, we left off with my story, at the end of my Sabbatical when I tweeted about how online communities make peopleâ€™s dreams come true.\nRemember this Tweet?\n\nI tweeted this because something really special unexpectedly happened.\nRemember when I said that I never thought I would be writing a book full-time?\nHa-ha, well - here I am. And hereâ€™s how it happened.\nItâ€™s August 23, 2021 and a gorgeous summer day in Berkeley, California.\nI am finishing a cup of coffee and getting ready to go on a hike.\nI decide to check my email.\nI see a message fromÂ YalorÂ Jackson.\nWho dat? I think to myself.\n\nI had never met Yalor (you can tell from his misspelling of my name).\nBut, no worries, Iâ€™m not offended. We all make mistakes. Plus, Yalor is a MetaCartel member, so we share the value of:Â we are people first and take chances on people.\nOf course, I took a chance on Yalor.\nI had not been active with MetaCartel and I was curious what the squad was up to. I also had really good memories about MetaCartel, back from the days when I was more active.\nI joined MetaCartel in 2019 when Peter messaged me on Twitter. He knew that I was working in crypto, and he was looking to increase female membership in MetaCartel. He told me that the community voted and they would reduce the pledge size from 10 ETH to 5 ETH.\nAnyway, I had not been active in MetaCartel for over 6 months, but I was approaching the one-year mark of my Sabbatical, and I was ready to maybe re-enter the crypto space.\nSo I quickly responded to Yalorâ€™s email and we set up a time to chat.\nTwo weeks later, Yalor and I connect over Zoom.\nI am at my favorite coffee shop in Berkeley, Way Station Brew, and Yalor is at a Whole Foods in Arizona.\nAfter some pleasantries, we start to go deeper.\n\nWhy are you no longer active in MetaCartel? Yalor asks.\n\n\nI am taking a Sabbatical - I was burnt out from crypto and I donâ€™t know if I want to work in crypto again.\n\n\nThis is common, he says.\nCrypto can be very intense, he continues. For me, I need to always reconnect to my heart space. I do this while surfing.\n\nI tried surfing for the first time a few months ago and I was too busy wiping out to be reconnecting to my heart space, but I knew exactly what he meant. I could imagine the exhilarating feeling of catching an unpredictable wave, and riding it out. Nothing else matters at that moment - itâ€™s just you, the board, and nature.\nYalor continues to share with me that he and his partner just had their first baby.\nI ask him how itâ€™s going.\nHis brown eyes light up. He says something like, itâ€™s a lot of work but itâ€™s totally worth it.\nItâ€™s fascinating how this anonymous person is becoming more human.\nI feel myself connecting more and more with his values and life philosophy.\n\nWhat have you been working on during your Sabbatical? Yalor asks.\nWriting. I started a newsletter and joined several writing communities.\nCrypto really needs more writers, he says. The existing writing is too technical and dry. Thereâ€™s not enough storytelling. Crypto is not approachable.\nWow, yes! He is speaking my language. I know that crypto has a narrative problem.\nSo, if you could wave a magic wand and do anything right now, what would it be? he asks me.\nI hesitate.\nWell, in a perfect world, if I could wave a magic wand, I would be a writer and share stories.\nThis is not possible, I think to myself. There is no way that writing can be a sustainable career.\nPerfect! Yalor exclaims. There is so much interesting stuff happening in DAOs right now. The world needs to know, and we need some good storytelling. Are you interested in submitting a grant proposal to MetaCartel?\nI hesitate again. I canâ€™t tell yet if this is for real.\n\nI look at Yalor through my laptop. Heâ€™s smiling.\nThis seems real. He seems real. MetaCartel is real.\nâ€œYes!â€ I yell. â€œI would love to!â€\nSome people at the coffee shop turn and look at me. Whoopssss.\n\nWoop woop!\nMetaCartel Gets Things Done\nLetâ€™s keep the excitement going and talk about how MetaCartel gets shit done.\nIn MetaCartel, roles are much more interesting than in the traditional work world, and theyâ€™re modeled after multiplayer role playing video games.\nPeter and Drewâ€™s Web3 Manifesto is a testament to how entrenched gaming culture is in crypto and DAOs. Recall this line from the Manifesto:\n\nWeb 3 will enable the ultimate MMO RPG [massive multiplayer role playing games] that transcends entertainment or gaming, as a natural extension of everyday life, consuming the world. Not only will individuals be able to make a living in these digital ecosystems but they will also provide new economic opportunities, reshape dating and the family unit, and completely revolutionize education.\n\nInstead of traditional role names, like â€œnote takerâ€ or â€œpeople managerâ€ or fundraising managerâ€ MetaCartel has role names inspired by RPG games.\nHere is a list of MetaCartelâ€™s roles and their descriptions:\nWarden (Funding + People)\n\nFundraising / making sure we have more incoming funds in the Guild Bank Funds management and spending input/output + making sure we are funding things critical to our goals and mission within MetaCartel (providing the voice of focus in group environments)\nRecruiting and training up more DAO summoners within MetaCartel Organizational process design and implementation\n\nAstrologist (communications &amp; scribe):\n\nWeekly newsletter compilation\n\nNote-taking during calls (optional)\nPaladin\n\nStarting new community development initiatives &amp; leading troops forward (eg. DAO rush week)\nTaking on ownership over key community objectives (from strategy to execution) Examples: Running &amp; organizing hacker houses (this was prior to coronavirus lol)\nDeveloping &amp; planning out the DAO migration to v2\nMoloch Making sure vital battle information flows smoothly across the Cartel\nGathering an agenda of items for the weekly DAO meeting call\nPartnerships and diplomacy with other organizations + getting more funding pledged\n\nMetaCartel Grantee Showcase\nWeâ€™ve come to the end, friends, but remember that this is just the beginning of the book of stories about DAOs.\nThanks for sticking around. I am grateful for you ğŸ™\nIâ€™d like to close by highlighting several projects that MetaCartel has funded, and also leave you with some next steps for how to get involved with MetaCartel. The list below is just a very small subset of the many amazing projects that MetaCartel has funded. For a comprehensive list, check outÂ MetaCartelâ€™s page on DAOHausÂ and MetaCartelâ€™s forum.\nThere is a big push right now in MetaCartel, and within the broader DAO ecosystem, to fund young builders: high school and college age kids.\n\nFund young builders\nDAOHaus\nDAOHausÂ is building the infrastructure for DAOs. It is a no-code open source platform for launching and running DAOs. DAOHaus provides community managers the ability to summon a DAO, aka create a DAO. Thereâ€™s also the ability to explore DAOs, so itâ€™s like an app store for DAOs - making it easy for people to find DAOs, look at their treasury, members, and proposals. DAO finances are transparent.\nZapper Finance\nZapper FinanceÂ (originally called DeFi Zap) is one of the earliest, and most successful, MetaCartel grantees. Zapper is a DeFi project that allows users to lend, pool, stake, and access leveraged liquidity pooling. Education is at the core of the product.\nGelato Finance\nGelato FinanceÂ is the backend for many DeFi applications. It ensures that all transactions get executed when tokens are sent to different platforms, really helping with the reliability of and consistency of DeFi apps. Gelato automates smart contract executions on Ethereum and other protocols. Itâ€™s underlying infrastructure, enabling automated flows of value between all smart contracts.Â Set it and forget it, so your trades can execute automatically.\nLoft Radio\nLoft RadioÂ is a free 24/7 radio station where listeners can tip artists directly in ETH. Artists receive 100% of every tip directly into their Ethereum wallet.\n88 MPH\n88 MPHÂ is a crypto savings account with upfront fixed-rate interest. Users can lock their Dai/USDC for a certain length of time in a lending protocol like Compound, and sell out the interest stream to someone else for an upfront payment. In effect 88mph allows the user to earn a fixed-rate interest on their savings, and they get the interest upfront. The user could also choose to only lock a portion of their money in this manner, and put the rest directly into Compound (where they can withdraw their money at any time), in order to satisfy their liquidity needs.\nMetaGame\nMetaGameÂ is gamifying building on Ethereum. It makes boring &amp; repetitive tasks feel exciting and fun.Â  Think of it like social media meets freelancing meets role playing games. Itâ€™s a massive coordination game.\nKickback\nKickbackÂ is solving the problem of no-shows at events. Participants need to put some skin in the game when they sign up for an event, so if they donâ€™t show up, they are penalized. Participants commit a small amount of ETH when they RSVP and it gets refunded after the event check-in.\nMintbase\nMintbaseÂ allows developers to create a marketplace for NFTs. Basically, you create your own smart contract for minting, selling, and developing NFTs.\nWant to get involved with MetaCartel?\nThat would be stupendous!\nYou can submit aÂ membership proposal. Please make a note that you read this story!\nIf you have any questions or want to learn more, feel free to drop me a note onÂ Twitter. My DMs are open.\nAcknowledgements\nIt takes a village to write a book. And I am very thankful to my village of editors.\nWhen I submitted my very earliest draft for editing, the consensus was that itâ€™s confusing and hard to follow. I feel proud to say that this story has come a long way!\nAnna HavronÂ Adam DavidsonÂ Beccy LeeÂ Bruno WinckÂ David BurtÂ Harry GoldbergÂ Lyle McKeanyÂ Peter PanÂ Sara CampbellÂ Yalor Mewn\nAnd shout out to a few peeps in MetaCartel who seem to always go above and beyond:\nCryptoAccordÂ Drew HardingÂ James YoungÂ JosephÂ MetaDreamerÂ NichananÂ Peter PanÂ Ven GistÂ YalorÂ Zayi"},"Lore/YODA-Story-2-DAO-Wei-and-MetaFactory":{"slug":"Lore/YODA-Story-2-DAO-Wei-and-MetaFactory","filePath":"Lore/YODA Story 2 DAO Wei and MetaFactory.md","title":"YODA Story 2 DAO Wei and MetaFactory","links":[],"tags":["published"],"content":"Key Insights\n\nThis story follows MetaFactory, a DAO in the MetaCartel family\nThe DAO Wei is a set or principles for navigating DAOs, influenced by the philosophy of the systems theorist Donella Meadows\nMetaFactory is used as a case study of a DAO that follows the DAO Wei. It is a decentralized brand that creates both digital and physical goods\n\nRead Full Story\nDownload for free on Gumroad\n"},"Lore/YODA-Story-3-Meta-Gamma-Delta-DAO":{"slug":"Lore/YODA-Story-3-Meta-Gamma-Delta-DAO","filePath":"Lore/YODA Story 3 Meta Gamma Delta DAO.md","title":"Yoda Story 3 Meta Gamma Delta DAO","links":[],"tags":["published"],"content":"Read Full Story\nKey Insights\n\nMeta Gamma Delta (MGD) DAO was a grants-giving DAO that supported and empowered women builders in Web3\nThis story commemorates the winding down of MGD\nThe remaining funds in the treasury have been allocated for grants\n\nPreface\nWith a heavy heart, I bear the news that Meta Gamma Delta (MGD) will be winding down its operations. After three years of supporting women building in Web3, and disbursing approximately $100k+ in grants, MGD will be bidding adieu.\nIn the spirit of being a public goods and grants-giving DAO, MGDâ€™s main priority today isÂ  to allocate the remaining $20k+ in the DAO treasury to grants.\nThere is an official DAOHaus proposal to end operations, so please vote if you are a member. And for those who are members, feel free to pop into the Discord and say hi! The Discord will remain available to members indefinitely to stay connected for years to come.\nAs the DAO comes to a close, I am excited to share with you this story: a final piece of content to commemorate the trailblazing women of MGD, the impact they made, and the legacy they leave behind.\nIntroduction\nWith the growth of blockchain and cryptocurrency, many â€œwomen-in-cryptoâ€ groups have emerged to address the industryâ€™s significant under-representation of women. The majority of these groups, however, function solely as social clubs for women to connect and promote industry events.\nMeta Gamma Delta (MGD) was created to fill this gaping gap.\nWith a primary focus on grants-giving, MGD was able to differentiate itself from other female social clubs at the time. MGDâ€™s founders planned from inception to progressively evolve the social club into a Decentralized Autonomous Organization (DAO).\nIn 2020 â€“when Internet meme culture was at its peakâ€“ the founders of MGD branded themselves as a parody online sorority and took to Twitter to proliferate this meme in hopes of gaining followers and â€œrushingâ€ new members.\nEarly on in the history of MGD, there was a lot of cross-pollination between founding MGD members and MetaCartel DAO members. This meant that the women of MGD were already red-pilled on how DAOs were an important component of an internet-native global organization.\nWith the help of friends at MetaCartel, MGD members were able to successfully transform a social club that started on Twitter and Telegram into a legitimate organization that supports women-led projects building with blockchain technology.\nOrigin Story\nThe online parody sorority\nMeta Gamma Delta emerged in February 2020, at EthDenver, a popular Ethereum conference, when a group of women decided to start a Telegram chat to connect with other women also attending the conference.\nA dedicated Telegram group would help women at ETHDenver â€œfind the othersâ€ and give them exclusive access to women-organized side events. This had the potential to fuel social connections with cool, like-minded ladies and open doors for future careers, similar to how professional business sororities function at universities.\nEvery sorority needs a cheerleader, someone capable of amplifying the groupâ€™s message and attracting new members. For Meta Gamma Delta, this individual was Mahoney Turnbull. A tall, blonde hailing from New Zealand, she was gregarious and had an extensive, far-reaching network in the Ethereum ecosystem.\nWith unwavering determination, Mahoney wasted no time recruiting women and encouraging them to become part of the vibrant Telegram group. Her infectious energy radiated through exchanges within the group, a phenomenon evident in the screenshots below:\n\nMGD Telegram group message\n\nMGD Telegram group message\nSupercharging the social club\nSeveral weeks after the conference, a looming pandemic was creating chaos around the globe.\nBut the world seemed to be in perfect order for MGD. With stay-at-home orders going into effect, ETHDenver conference attendees had a lot more time on their hands. Many turned to Twitter and chat platforms for a sense of human connection and stability.\nAn increasing number of women joined the Telegram group, including the likes of Samantha Stein, the founder of Hacktivision and former Director for Special Projects at TechCrunch; Hsin-Ju, a Venture Partner at HackVC and co-founder of Dystopia Labs; Ariana Fowler, a researcher and former Blockchain Strategist at UNICEF; and Meltem Demirors, Chief Strategy Officer at Coinshares.\nMen and allies were equally embraced and encouraged to join, a move that attracted prominent members from MetaCartel such as James Waugh, Ven Gist, Pet3r Pan, Alex Masmej, Yalor Moon, and 0xJoshua. These men would later play pivotal roles in the early stages of MGD, offering invaluable mentorship, unwavering support, and helpful resources.\nHarnessing this momentum, the group of women wrote a manifesto that breathed life into the essence of MGD- skillfully balancing a serious mission with playfulness.\n\nMeta Gamma Deltaâ€™s initial manifesto\nCreating an early structure\nAn early structure took shape through grassroots efforts by several women who emerged as the groupâ€™s torchbearers. These women orchestrated community calls and created rules and procedures for being part of the organization.\nJuliana Passos took the initiative of spreading the word about MGDâ€™s Genesis Community Call, which took place virtually on February 21, 2020. She urged members to whitelist their names on a Google form to preemptively safeguard the event from the disruptive presence of trolls, an unfortunate yet rampant phenomenon during those early pandemic days.\n\nEarly MGD Telegram messages about Genesis call\nSydney Lai then jumped in to craft the callâ€™s agenda. Her objectives were to align members on the groupâ€™s purpose and establish clear expectations that allowed each individual to make unique, meaningful contributions to MGD.\n\nEarly MGD Telegram message with anÂ agenda for Genesis call\nLaunching a DAO\nLaunching a DAO requires creating smart contracts that enable members to participate in democratic decision-making by creating and voting on proposals. Among the pioneering options available on the Ethereum network was (and still is) DAOHaus, a platform that provides a user-friendly interface and suite of tools to help DAOs manage funds, allocate grants, and conduct voting processes using a framework called Moloch.\nLaunching the Meta Gamma Delta DAO on DAOHaus was, in hindsight, almost predetermined. Since DAOHaus originated in the MetaCartel universe, a foundation of shared values already existed. Consequently, members of DAOHaus became ardent supporters of MGD and graciously donated their time and energy to assist launching the DAO.\nJuliana captured the essence of DAOHaus members support in a blog post:\nDAOHaus was of immense help to us. From late Sunday evening calls to quick Telegram channel responses. If it werenâ€™t for Dekan, Ven, James Waughn, Alex Masmej, Pet3r Pan, Yalor, James Dunkan, Burrata, to name a fewâ€¦we wouldnâ€™t have been where we are today.\nIn the midst of MGDâ€™s launch as an official DAO on DAOHaus, Sydney was spearheading another crucial endeavor. Recognizing the need to secure sustainable operational capital, she diligently embarked on raising a modest amount of funds by composing a compelling grant proposal on MetaCartel DAOâ€™s forum.\nMGD Today\nLetâ€™s now fast forward three and a half years to 2023 and take a look into how Meta Gamma Delta DAO has evolved.\nSince inception, MGD has seen its earliest members, the OGs, soar to new heights in their crypto careers. A prime example is Kseniya Lifanova, who founded Upstate Interactive while contributing to MGD. She is now the VP of Decentralized Strategy &amp; Engineering at Foundry.\nMany of these OGs have gracefully transitioned into advisory roles within the DAO. While they are available for support and guidance, they do not participate in day-to-day operational activities. A few exceptions exist, such as Nich Kesonpat, who is now a Researcher at 1kx but continues to contribute her technical skills to MGD.\nWhat remains unchanged within MGD is its unwavering mission and the foundational structure that the OG members established. Every day, diligent MGD members dedicate themselves to empowering and supporting women-led projects building on the Ethereum network. They rely on structures the founding team put in place, which encompass everything from DAOHaus-facilitated on-chain onboarding and governance mechanisms to crafted templates within Google Sheets and channel structures within Discord.\nActive members strive to evolve and enhance these structures as the crypto landscape changes. Embodying nimbleness, MGD members consistently seek innovative approaches to advance the DAOâ€™s mission.\nIn the following quote, Kseniya astutely highlights the inherent flexibility of a DAO:\nThe beauty of a DAO is that the structure can be evolved or changed at any time as long as the members agree.\nThe next section will build on this idea of flexibility through consensus, and dive into the new structures that have evolved within MGD.\nCommittees and Seasons\nAt first, MGD operated with a stagnant committee structure. The four committees: grants, fundraising, onboarding, and treasury â€“ were static and had the same Lead who served in the position for an indefinite amount of time.\nThis led to member burnout.\nIn the Fall of 2022, MGD started an initiative called MGD Revival to tackle the challenge of burnout, amongst other DAO challenges. Members hoped that the initiative would enable the initial core contributors to take a step back from day-to-day operations, while empowering the next generation of DAO leaders.\nAs part of MGD Revival, the DAO implemented a dynamic committee structure with cohorts and seasons. Committees ran for one quarter (season), with a Lead who rotated out every three months. Each cohort had a defined scope of work, with clear timelines, and KPIs (key performance indicators).\nSeveral OG contributors, including Nich, heyitsDB, and Zayi, joined the early cohorts to provide support. And new members, including Into the Woods and Quantum Alpha stepped up to the plate.\nFellowship Program\nMeta Gamma Delta strives to empower and enable women from diverse industries to reap economic, financial, and social benefits from Web3 - while contributing their invaluable skills to the DAO.\nDespite being highly skilled in their professions, talented women shared during community calls that they needed more guidance to transition to and navigate this new Web3 career path.\nIn response to membersâ€™ needs, a group of exceptional core contributors including Ann Willmott, Tess Willmott, Zayi Reyes, Dr. Kelly Page, and LeRae Bigelow, collaborated to address this challenge â€“ a pressing onboarding issue where new members lacked the Web3 knowledge and skills necessary to contribute to the DAO.\nRecognizing the urgency and importance of this matter, this exceptional group of women realized that an evolution of the DAOâ€™s onboarding structure was critical. The existing structure failed to account for the skill and knowledge gap that new members faced.\nAs a solution, MGD made the strategic decision to collaborate with ConsenSys, a prominent incubator for Ethereum projects and an early pioneer in the cryptocurrency industry. Together, they embarked on co-creating a Fellowship program specifically designed to equip new members with essential skills before they actively participated in the DAO within a cohort and Season.\nThe Fellowship Program, which started in September 2022 and spanned three months, offered MGD members the opportunity to undertake one of two educational tracks provided by ConsenSys entirely free of charge. The first track, ConsenSys Blockchain Essentials, emphasized practical applications over technical intricacies for individuals seeking a more foundational understanding. The second track, ConsenSys Developer Bootcamp, offered a more advanced curriculum, which delved into the technical aspects of blockchain development.\nThrough this partnership with ConsenSys , MGD helped new members prepare to make meaningful contributions to the DAO and to the wider cryptocurrency industry.\nGrants\n[My favorite memory of MGD] has been knowing that they took a chance on the company I work for, and me, by proxy, to help us progress the companyâ€™s mission and further me along in my professional journey with a much appreciated financial gift.\n-Kori Riddick, 2023 grant recipient\nBy 2022, Meta Gamma Delta had issued $76k+ of DAI in grants. The following are a few examples of the types of trailblazing projects that were funded:\n\n\nLYNX Technology â€” Founders: Alexandra McCarroll &amp; Sarah Hamburg â€” 14,520 DAI\n\nA backend data management system for real-time biometric user data collected through wearables and interfaces (including brain-computer interfaces [BCIs], fitness trackers and eye-tracking technologies)\n\n\n\nARTVX â€” Founders: Ava &amp; Tara â€” 10K DAI\n\nARTXV started out as the first NFT collective for neurodivergent artists and consequently the first Web3 community for the disabled. It has since become the #1 agency and community, providing neurodivergent artists with everything needed to sell their work on the blockchain.\n\n\n\nSHYRO â€” Founder: Kat Kuzmeskas â€” 10K DAI\n\nFitness tracker where anyone in the world can connect and earn for their health and wellness data. Shyro is a web3 application at its core. Shyro memberships, point structure, and profit sharing is managed on-chain automatically via an NFT and smart contract structure.\n\n\n\nThese women-led projects exemplify the pioneering spirit that MGD wholeheartedly supports. The impact of these grants resonates throughout the ecosystem, helping amplify the voices and achievements of these ladies and inspiring others to forge their own paths of success.\nConclusion\nMGD has left its mark on the Web3 ecosystem. Although DAO members have chosen to wind down operations, the community that the DAO created will continue to create ripple effects within the industry.\nAs this story concludes, letâ€™s celebrate the pioneering women of MGD and reminisce about the unforgettable moments and achievements throughout their journey.\nI hope you enjoy the below quotes, photos, and, of course, memes!\nQuotes\nFor me, MGD has always been about giving women funds to go and build our decentralized future.\n\nKseniya Lifanova, MGD â€œOGâ€ member, currently VP of Decentralized Strategy and Engineering at Foundry\n\nI love the irony of calling ourselves a sororityâ€“ the juxtaposition between this group of highly educated, motivated, leaders in their fields with a bikini-clad-car-wash crew or whatever you think of when you think of a college sorority.\n-Tess Willmott, Operations at MGD\nMemes and Photos\n\n\n\n\n\n\n\n\nMCON 2021\n\n\n\n\nAdditional Resources\nMGD Twitter\nMGD Medium\n\nAcknowledgments\nThank you to Kseniya Lifanova, Kori Riddick, and Tess Willmott for shaping this story with your insightful interview responses.\nThank you to Zayi for providing guidance and direction throughout my writing process. And for the final copy edits and polishing.\nThank you to Gabriel Tumlos and Sam Houghton for your thoughtful feedback and line edits.\nAnd, of course, thank you to Meta Gamma Delta for your generous grant to write this story."},"Newsletter/0-Ethereum-meets-Gizmodo-and-Consumer-Reports":{"slug":"Newsletter/0-Ethereum-meets-Gizmodo-and-Consumer-Reports","filePath":"Newsletter/0 Ethereum meets Gizmodo and Consumer Reports.md","title":"Ethereum meets Gizmodo and Consumer Reports","links":["Quality"],"tags":["published"],"content":"Read Full Newsletter Here\nOctober 20, 2023\n\nWelcome to my new newsletter! I know it has been a while since I last posted. Thanks so much for sticking around. Seriously, I mean it, I am very grateful to all 164 of you!\nIn this newsletter, I will do my best to demystify Ethereum protocols and products in a digestible format, much like how Gizmodo breaks down tech gadgets and Consumer Reports evaluates consumer products.\nBefore diving into the post, there are a few housekeeping items to get through (thanks for bearing with me!)\nFirst things first, I have migrated the newsletter from the Substack platform to Paragraph. If you subscribed to my Substack, you now automatically subscribe to my Paragraph. You will not experience any disruption to your reading experience. New posts will continue to come to your inbox, and all you need to do is continue to read and enjoy!\nWhy did I leave Substack? Itâ€™s nothing personal. The Paragraph platform is very similar to Substackâ€™s, but it also has additional features that make it more attractive for crypto newsletter writers, like myself. A few of these features:\n(1) posts are stored in Arweave, a decentralized storage system\n(2) posts can be minted and collected as NFTs\n(3) readers can earn referral rewards by sharing my posts\nEssentially, Paragraph offers more flexibility and customization than Substack in creating, distributing, and monetizing content, but the icing on the cake for me was that I really like and admire the Paragraph team. Their support on Discord is top-notch and the founders go out of their way to make writers feel like owners, not just users.\nLastly, you may have noticed that I kept the same newsletter name, Sharing is Caring. This is for brand continuity purposes. You can still find and read all original posts on Substack.\nThe â€œwhyâ€ for this newsletter\nThe original Sharing is Caring newsletter was born out of the COVID pandemic, in January 2021. At the time, I was taking a break from crypto and spending my time exploring and making friends in online communities such as Ness Labs and Interintellect.\nMany of my current subscribers discovered me through these non-crypto communities and have stuck around (thank you!!) as I have published both crypto and non-crypto content. No one has left, yet, so there must be some curiosity in my crypto writing.\nWith that said, writing a newsletter for two years has taught me many lessons - one is adaptability.\nThe time has now come for Sharing is Caring to adapt.\nAs far as I know, a newsletter that breaks down Ethereum protocols and products in a digestible format, does not exist. This newsletter will not be news-driven, there will be no paid product placements, and it will not be pay-walled.\nWhat you can expect from this newsletter\nThe Ethereum ecosystem is chock-full of [FOMO](www.ncbi.nlm.nih.gov/pmc/articles/PMC8283615/#:~:text=Fear%20of%20missing%20out%20(FoMO,to%20maintain%20these%20social%20connections.), where a sense of missing out on rewards â€”social or financial â€” makes people lose sight of critical thinking, falling for overhyped projects, sometimes with deceptive marketing, without understanding the true risks involved.\nIn my experience, most Ethereum products, particularly financial products, are intended for professionals. For highly trained experts, who have both traditional finance and software experience, and who also have the time and bandwidth to do proper diligence and assess risk.\nThis newsletter is not for the experts. It is for the crypto-curious. P.S. You can be an advanced Ethereum user AND be crypto-curious. I put myself in this category â€” there is always more that I can learn, and more foundational elements that I could refresh on.\nMy goal for this newsletter is to provide practical insights into using Ethereum protocols and products safely. You will surely fail, as one does when learning anything new, but you will, most importantly, fail safely.\nNewsletter Topics\nMy intention with this newsletter is to write about areas that I donâ€™t already cover for my day job. That means I will write very little about Decentralized Autonomous Organizations (DAOs) and Decentralized Finance (DeFi).\nYou can expect to read breakdowns of:\n\n\nStaking (including liquid staking)\n\n\nWallets\n\n\nSocial networks\n\n\nZero-knowledge proofs\n\n\nConclusion\nMy vision for this newsletter is to write digestible breakdowns of complex protocols and products in the Ethereum ecosystem. There will be no hype pieces, no shilling, and no paywall. Just Quality substantive content for the crypto-curious â€” people who are either newer to crypto or advanced users who value learning and refreshers on foundational elements.\nMigrating from Substack to Paragraph allows me to explore new avenues for distribution and monetization. I do have a day job so this newsletter will serve as a passion project, at least for now. Iâ€™m hoping that if I take the right steps, follow a process, and with a little luck on my side, I can grow this newsletter to become a sustainable income stream.\nFeel free to reach out to me with any questions, comments, or suggestions about the content; your feedback is invaluable in refining this newsletter and making it a valuable resource for everyone. You can reply directly to this email (if you received this post in your email inbox) or you can send me a message on Twitter.\nYou should expect the first newsletter, where I cover Ethereum staking, in the next few weeks. Until then, take good care!\n-Rika"},"Newsletter/Moral-Dilemmas-in-Greek-Tragedies,-a-Discussion-of-Aeschylusâ€™s-Agamemnon-and-Sophoklesâ€™s-Antigone":{"slug":"Newsletter/Moral-Dilemmas-in-Greek-Tragedies,-a-Discussion-of-Aeschylusâ€™s-Agamemnon-and-Sophoklesâ€™s-Antigone","filePath":"Newsletter/Moral Dilemmas in Greek Tragedies, a Discussion of Aeschylusâ€™s Agamemnon and Sophoklesâ€™s Antigone.md","title":"Moral Dilemmas in Greek Tragedies, a Discussion of Aeschylusâ€™s Agamemnon and Sophoklesâ€™s Antigone","links":[],"tags":["random"],"content":"Quotes\nI. Introduction\nIt is tempting to see Agamemnonâ€™s situation, for example, as the mere cruelty of capricious Gods or simply as bad luck; what he needs to do, we might think, is to grit his teeth, make the decision and then get on with his life and not dwell too much on a painful episode. What I would like to show is that the dilemma can reveal certain crucial information about the decision-maker (i) to us readers-spectators, (ii) to other characters in the play who witness, or are implicated by, the incident, (iii) as well as, and perhaps most importantly, to the protagonist himself or herself. Only through a dilemma is the character forced to acknowledge his own priorities, the â€˜priceâ€™ he puts on certain values relative to other values, and the consequences that his value-system will have on the relationships to other people and institutions and the responsibilities inherent in such relationships. Ideally, the protagonist will acquire wisdom from the dilemma and the way he handles it.==\nII. The nature of moral dilemmas\nOne important and trivial question to settle right away is whether a dilemma can actually beÂ solved, since, paradoxically, if a choice has to be made in a dilemmatic situation, this very choice would seem to dissolve the dilemma. There are two ways around this.\nThe second way around the paradox is to adopt a careful definition of â€˜dilemmaâ€™. Christopher Gowans (3), for example, prefers the term â€inescapable moral wrongdoing,&quot; to stress that even if the choice is clear, the dilemmatic aspect is the fact that even a good person is effectively forced to commit a wrong.\nA good way to start would be with MacIntyreâ€™s classification of dilemmas, featuring his distinction between the three types ofÂ genuineÂ and two types of merelyÂ apparentÂ dilemmas. In each case he describes how things appear from the standpoint of the agent involved.\n\nRole responsibility:\n\nSomeone â€” a morally serious person â€” who, having assumed or been assigned the responsibilities of more than one social roleâ€¦ discovers that to discharge the responsibilities of one will prevent him or her from discharging those of the other.\n\n\nGenerally-accepted norms\n\n\n[Such norms] involve inescapable failure by some morally serious person, not in doing what role-responsibilities require, but in doing what generally-accepted norms for human beings as such, independently of their roles, require.\n\n\nThis involves such things as the conventions of keeping promises, repaying debts, trust in friendship or business etc. Here the dilemma arises from the heterogeneity and apparent incommensurability of the relevant norms. Actions which preserve confidentiality might threaten those precepts which forbid bringing avoidable harm upon the innocent; actions which avoid such harm will violate the norms which enjoin trustworthiness. This could be seen as a narrower version of theÂ freely-enteredÂ â€˜stationâ€™ typical of the first category. Rather than commit oneself to a whole list of duties associated with a particular job, one commits oneself to a single duty in the form of a promise. As such one could speak of a dilemma as being a co-instantiation of incompatible responsibilities to two different entities, either a concrete person or institution (representing concrete persons, e.g. Agamemnonâ€™s army), each of whom has a legitimate claim corresponding to that responsibility; one such claim will have to be frustrated.\n\n\nAlternative ideals of character\n\n\nSomeone is compelled by his or her analysis of what is required for supreme excellence of some kindâ€¦ to conclude that at least for him or herself a ruthless single-mindedness is indispensable. But he or she also finds good reasons to conclude that such ruthlessness precludes the development of the qualities needed in a good friend or for compassion toward the needy\n\n\nFor each character the pursuit of their standard of excellence is partially constitutive of who they conceive themselves to be, and so such a pursuit cannot be simply abandoned when it seems to threaten relationships. This austere priority when dealing with this kind of dilemma, I will argue, results in a character that is defective in a very specific way.\n\n2.1. What moral dilemmas are not\n\n\nAn everyday conflict of duties: my plans to attend a friendâ€™s concert conflict with my duty to correct and return a studentâ€™s paper on time.\n\n\nOne popular example in the recent literature about dilemmas involves two people drowning while I, standing on the riverbank, can only save one.\n\nIf there are no relevant differences, then it does not matter which I decide to save first: my moral obligation is to saveÂ oneÂ of themÂ (by, say, first tossing a coin) and, if possible, to return to save the other. If there is a relevant difference between the two (for example, one of them is my wife), then there is no dilemma either.\n\n\n\nHowever, it would be quite inappropriate to toss a coin to resolve any of the first three types of dilemmas. For in each case the decision seems to concernÂ meÂ much more closely. My station, for example, may be an integral part of how I see myself, and my particular choice in the event of irreconcilable conflict may very well change the way I see myself and make decisions in the future. When contemplating whom to save first in the lake, the case is more detached from the contemplating agent.\n2.2. The importance of regret, remorse or guilt\n\nThe advocates of monist theories such as Kant (11)Â and Mill (12)Â simply denied that dilemmas could occur at all. The problem of the apparent dilemma was usually the result of an either culpable or mitigating deficiency in the agentâ€™s knowledge, since, by their definition of morality, there could never be inconsistent, unrankable requirements placed upon a rational agent at a single moment.\nWhat the above critics claim, however, is that moral dilemmas are not evenÂ conceptuallyÂ possible, for they would threaten the fabric of one or another moral theory, and could also threaten the underlying pre-supposition of moral realism. However â€” and hereâ€™s another purpose of this essay â€” ==I believe the intuitive existence of moral dilemmas canÂ legitimatelyÂ threaten unified moral theories by reminding us that the moral life is sometimes just too damn complicated to be captured in a tidy system.== The examples of Antigone and Agamemnon cannot be rejected as easily as the theorist would like.\n\n\nAGAMEMNON\n\n\n==The first choral ode of the play tells how a Greek naval expedition has been ordered by Zeus himself (55-62) (15)Â against the city of Troy to avenge the kidnapping of Helen by Paris (16). Agamemnon, son of Atreus, joint king of Argos, leads the expedition, and takes his daughter Iphigenia along with him. The goddess Artemis, however, is angry for unspecified reasons (17), and has becalmed the 1000-ship expedition at Aulis, out to sea. Not only will this prevent the fulfilment of Zeusâ€™s command (18), but there will eventually be problems with food and water (188-9) for the large marine army. The prophet Calchas (19), on Agamemnonâ€™s ship, divines that the only remedy for the situation is the sacrifice of Agamemnonâ€™s daughter to placate the goddess. The alternative is a slow death by starvation for everyone in the expedition (20). After deliberation, Agamemnon indeed has her sacrificed. Here is the crucial passage:\n\n\nThen the elder king [Agamemnon] spake and said: â€œHard is my fate to refuse obedience, and hard, if I must slay my child, the glory of my home, and at the altar-side stain with streams of a virginâ€™s blood a fatherâ€™s hand. Which of these courses is not fraught with ill? How can I become a deserter to my fleet and fail my allies in arms? For that they should with passionate eagerness crave a sacrifice to lull the winds â€” even a virginâ€™s blood â€” stands within their right. May it be for the best.â€\n\n\n\nBut when he had donned the yoke of Necessity, with veering of spirit, impious, unholy, unsanctified, from that hour his purpose shifted to resolve that deed of uttermost audacity. For mankind is emboldened by wretched delusion, counsellor of ill, primal source of woe. So then he hardened his heart to sacrifice his daughter that he might prosper a war waged to avenge a woman, and as an offering for the voyaging of a fleet! (205-226)\n_\n3.1. Assumptions and consequences\n_\nDiscussions of moral dilemmas make several important assumptions about the situation and its participants, which we can address by looking directly at Agamemnon. Edwards begins his article with the following questions:\n==â€œCan we think of him as having a free choice between viable alternatives? If so, is it a choice between alternatives both of which are disastrous? Or has he no free choice, and does Zeus, or Necessity, force him to choose one way, and then later punish him for so doing? Is heÂ guiltyÂ of anything, and if so, what? If he in fact makes a choice, and it leads to his death, is it because of his misjudgement, hisÂ hamartia, his personality, his folly (22), the guilt he inherited from his father? Is he a devout man, subordinating his feelings to undertake a mission ordered by his god? A patriot, sacrificing his daughter for the good of his country? Does Aeschylus even realise he is posing a problem? (23)â€\nSuch questions are important to understand the nature of Agamemnonâ€™s specific dilemma, and to what degree he can be said to be free and therefore responsible for the consequences of his choice (24). Our first reaction is that Agamemnon is simply unlucky to have found himself between the wishes of two competing gods; we might think that he should see himself as the unwilling instrument of their feud, but that the result is morally theÂ sameÂ as if Artemis herself had struck Iphigenia down without human involvement. ==The Chorus, however, while accepting her death as a â€œyoke of Necessity,â€ also proceeds toÂ blameÂ Agamemnon for the sacrifice (25). They even call Agamemnonâ€™s state of mind â€œimpious, impure, unholyâ€ (219) â€” because Greek emotive language exploited to the full the assumption that what is offensive to the speaker, or to man in general, is also offensive to the gods. And yet the crime was committedÂ forÂ the gods, for Artemis directly, and for Zeus indirectly (i.e. that the expedition might proceed) (www2.units.it/etica/2001_1/cowley.html#b26)).\nThis seems incompatible. But we have to look carefully at (i) the nature and the genesis of the â€œyokeâ€ (does the necessity govern the choice ofÂ oneÂ of the options, or the actualÂ choiceÂ to be made?) and also at (ii) what exactly the Chorus finds blameworthy in the conduct of their chief.\nOne thing is certain, that Agamemnon, as far as we know a hitherto blameless man and loving father, is not responsible for finding himself in the situation, and hence it cannot be reduced to MacIntyreâ€™s firstÂ non-dilemmatic situation. Secondly, we can see that the sacrifice of Iphigenia is indeed preferable with a view to Agamemnonâ€™s sense of self as primarily a military commander, to the reliably-anticipated consequences to the expedition and to the impiety of failing Zeus. Indeed, it is hard to imagine that Agamemnon could rationally have chosen any other way. But both courses involve him in inescapable moral wrongdoing (27).\nHowever, Agamemnon must not be seen as a mere puppet; he is allowed to deliberate and to choose, he knows what he is doing, he is aware of all relevant aspects of the situation (except perhaps of the reason for Artemisâ€™s anger), and he is not being physically compelled or personally threatened. But he is under necessity insofar as his alternatives include no very desirable options. As such there does not appear to be any incompatibility between choice and necessity here.\nAgamemnonâ€™s first reaction is anger and grief (203-4). His subsequent description (206-13) shows that he is fully aware of all the relevant consequences, but more importantly, already shows himÂ leaningÂ one way rather than the other (the rhetorical question â€œhow can I become a deserterâ€¦?â€).\n==Nussbaum compares this situation so far (28)Â to the plight of Abraham, divinely ordered to sacrifice his son Isaac. If we ignore the impression we get of the cruel, vainglorious gods in both Agamemnonâ€™s and the biblical stories, and the whole question of the reliability of the source of the order (how does one recognise a divine command?), the comparison is valid up to a point: a good man is ordered to kill his own innocent child or incur the heavier guilt of disobedience and impiety. But here the comparison ends, for Abraham clearly attempted to fulfil the order only with the greatest horror and reluctance. Whereas in theÂ Agamemnon, the Chorus describes the situation: â€œholding no seer at fault, bending to the adverse blasts of fortuneâ€ (186-8). Agamemnon does not blame either prophet or gods, but inwardly begins to co-operate with necessity,Â arranging his feelingsÂ with his fortune. It is a masterpiece of self-deception, typical of the toughest soldiers who must face the danger, carnage, and utter senselessness of war on a regular basis.\nInstead of speaking of his pain and revulsion to himself or others, he talks about the rights of his soldiers to her death: â€œFor that they should with passionate eagerness carve a sacrifice to lull the winds â€” even a virginâ€™s blood â€” stands within their rightâ€ (214-217). How far is this self-deception, and how far has natural fatherly feeling been smothered? Whatever the extent, his attitude toward the decision itself seems to have changedÂ with the making of it. Instead of thinking about the evil that he must commit, he hopes it turns out â€œfor the best,â€ as though he had genuinely resolved the conflict and justified the crime he is about to commit. And if it is right to obey the gods (both Zeus and Artemis), then it is right toÂ wantÂ to obey them, and even to yearn for it with â€œpassionate eagerness.â€ The Chorus blames Agamemnon no such much for committing the necessary deed, but for changing his thoughts and passions with â€œuttermost audacityâ€ (225). He had to see her as a sacrificial beast, commanding his officer to lift her up â€œas it were a kidâ€ (232) onto the altar and to stop her mouth with a â€œbitâ€ (239). ==He simply does not see what the Chorus sees. Never do we hear the king utter a word of regret or painful memory. Nussbaum clearly thinks this reflects badly on Agamemnonâ€™s character, and that we the audience are also invited by the Chorus to condemn him â€” not for his deed, but for his reactions.\n_\n3.2. The cultivation of responsiveness\n_\nNussbaum brings up another interesting point concerning theÂ memoryÂ of the good person who has been forced to commit wrong:\nâ€œEven if an agent comes to the dilemma with good general principles, the case does not present itself with labels written on it, indicating its salient features. To pick these out, he must interpret it; and since often the relevant features emerge distinctly only through memory and projection of a more complicated kind, he will have to use his imagination as well as perception. (29)â€\n==As Nussbaum goes on to stress, Agamemnon, to lessen the Chorusâ€™s blame, would have to realise, when faced with the choice, all the consequences of each different option in the dilemma: this will involve a deep understanding of his own pluralistic theology and the price of disobedience (assuming reliably intelligible divine instructions), and the possibility of mutually-contradictory instructions. At the same time, Agamemnon would have to allow himself to reallyÂ seeÂ his daughter as such, rather than the sacrificial goat that some querulous god has demanded. Most importantly, after the act, Agamemnon would have to remember the act itself as the murder of his daughter and not the destruction of an animal. If the Ancient Mariner was able to suspend the dead albatross on his neck, then Agamemnon should be able to buckle under the weight of his memories of what he has done, in the form of her face, her trailing yellow robes, the cries of â€˜Fatherâ€™, and the look of accusation in the silent eyes (228-247).\n==Above all, Agamemnon must allow himself to feel that he has committed wrong, and not be deceived by a choice well made (30). Though he must, to a certain extent,Â actÂ like a resolute person, he will feel the deepest remorse and make every effort through the rest of his life to make reparations.\n==In tragedy, as in life, the experience of conflict could be said to have twoÂ functions, two ways of being rendered intelligible: it reveals to others and to the agent himself aspects of what the agentâ€™s character has beenÂ all along. It can also mark the beginning of a period of self-discovery and change, both voluntary and involuntary. This has traditionally been one explanation for the caprice of the gods in bringing down misfortune on the undeserving. The condition, as described above, is that one really be allowed to experience them, that the shock will break through the interpretative curtain; Agamemnon of course knows that it is his daughter lying before him, in the sense that he can truthfully answer questions about her, but he does not seem to know that it is theÂ distinct personÂ who is Iphigenia, that it isÂ hisÂ daughter, that she is just as much alive and individual as he. An honest effort to do justice to all aspects of a hard case, seeing and feeling it in all its conflicting many-sidedness, could enrich future deliberative efforts. The Chorus invites us to believe that Agamemnon denies himself this opportunity for growth out of fear of the pain that it would involve; but with the ensuing self-knowledge, he could reach a new understanding of piety and of the love he owes to the rest of his family:\nâ€œBut even in trouble, bringing memory of pain, droppeth oâ€™er the mind in sleep, so to men in their despite cometh wisdom. With constraint, methinks, cometh the grace of the powers divine enthroned upon their awful seats.â€ (182-185) (31)\nHowever, if Agamemnon is deficient in this sensitivity, in this capacity for understanding, in imagination, surely that deficiency is itself a piece of bad luck. How can we share the Chorusâ€™s condemnation? The assumption is that emotional responses are not subject to any sort of control and cannot form a character that an agent deliberately forms. But this would be to deny that an agent cannot cultivate responsiveness by working through the memory of the event. Nussbaum writes:\n==â€œ[the Chorusâ€™s] patient work, even years later, on the storyâ€¦ reminds us that responsive attention to these complexities is a job that practical rationality can, and should, undertake to perform; and that this job of rationality claims more from the agent than the exercise of reason and intellect, narrowly conceivedâ€¦ We seeâ€¦ a two-way interchange of illumination and cultivation working between emotions and thoughts: we see feelings prepared by memory and deliberation, learning brought about throughÂ pathos. (At the same time, we ourselves, if we are good spectators, will find this complex interaction in our own responses).(32)â€\n==The Kantian assumption that only the intellect and the will are appropriate objects for ethical assessment now begins to impoverish and distort our deeper understanding of tragedy.\n_\n3.3. Agamemnon and moral dilemmas\n_\n==What light does the tragedy of Agamemnon throw on our understanding of moral dilemmas? It would be worthwhile considering Sartre at this point (33), for whom the moral of such hard cases is that it is useless for an agent to form an ordered system of ethical principles and to try and live by that system. Since principles clash, it is no good trying to live by principles at all, since to be bound in general to what cannot guide one in extreme cases is foolishÂ mauvaise foi. If Agamemnon were a Sartrean hero, he would, at the moment of perceiving the conflict and understanding it as unresolvable, dissociate himself altogether from both of the competing principles, and regard himself as entirely, radically free to make an unregretted choice. Although this approach is correct in regarding the choice as a key moment in Agamemnonâ€™s life, the solution seems arbitrary and strange, like the tossing of the coin advocated for the second type of MacIntyreâ€™sÂ non-dilemmas (the two people drowning).\nThe standard response to existentialist invention is that it attempts to deny continuity in character, and this is neither possible nor commendable. As Nussbaum puts it:\nâ€œAll our judgements about the appropriateness of certain kinds of emotional and imaginative activity in our two cases has presupposed a background of ongoing character and value commitments (the agentâ€™s own, or, where that proves deficient, the Chorusâ€™s) against which action and response can be assessed. The very possibility of moral assessment seems here to be bound up to the idea of on-going character. We do not know how we would talk about an agent who keeps improvising himself from moment to moment and was never willing to identify himself with any general commitments.(34)â€\nIt is not even clear, in Agamemnonâ€™s dilemmatic situation, that his duties as military commander and as father (and, as human being, the duty to respect innocent life) do offer him bad guidance. The guidance they offer is that he should feel bound to each of two contingently incompatible actions. He will be forced to go against his commitment, but â€œinsofar as such thoughts and feelings both express and further strengthen a virtuous and committed character, the guidance seems to be good (35).â€\n==Again, Nussbaumâ€™s main point is the educational aspect of moral dilemmas. Agamemnon ultimately does not need any help to decide what to do; but he does need help in deciding how to feel.\nI tend to sympathise with Nussbaumâ€™s analysis, but I think she simplifies things a little, and is too quick to blame, partly because there would be noÂ pointÂ to blame. In the context of a slightly different argument over Agamemnonâ€™sÂ rationality, Williams wrote that it would be â€œa glib moralist who said, as some sort of criticism, that he must be irrational to lie awake at night. (36)â€ Similarly, it would be a glib moralist who tried to enter the situation and admonish Agamemnon for his lack ofÂ outwardÂ feeling. In one sense, that is all we have to go by; in another, we have insufficientÂ warrantÂ to speculate about the inner feelings, especially those of a military commander. I would suggest that the text allows enough room for a skilled actor to flavour his apparently cold words with a hint of desperate irony, to show that he is acting out the part in an almost blind frenzy and rage, as if to throw the deed back in the faces of the playwright and the gods. Indeed, Nussbaum also seems to accept the possibility that when he suppresses his initially accurate judgements, â€his shift may be inspired by horror at the situation confronting him, which he can endure in no other way than to deny that it exists.(37)â€ But it is Bernard Williams again, who I think sums up a very plausible alternative judgement:\n\n==One way me might understand this is as a manâ€™s being driven mad with extremity. Equally (and indeed in no conflict with that) we might see the rage as something that was necessary to Agamemnon if he was to do this thing at all. This is not a text that invites us very far into psychological interpretation, but still less does it beckon us towards blame. The Chorus is laying before us what happened, and this horror, the fatherâ€™s fury, is part of it. A sense of the work requires a suspension of moral comment at this point, and so does a sense of the event that it describes.(38)â€\n\n**\n\nAntigone\n\n**\nIt is now time to consider the second of our dilemmatic situations from Greek drama, quite different from that in which Agamemnon found himself. The latter, through no fault of his own, was forced by feuding gods to choose a woeful alternative in order to save his fleet and fulfil his divine mission. Whatever his reaction to the choice and the murder of his daughter, the situation seems to us, the audience, to warrant revulsion, remorse, painful memory and a life-long desire to amend what will always remain, in the eyes of the agent himself, a crime.\nThat dilemma involves one person with two conflicting options, both of which are painful. ==The contrast with the situation of Antigone is clear, for in this case there are two people (Antigone and Creon) who represent two incompatibleÂ specificÂ commitments which form part of two larger, otherwise often compatibleÂ systemsÂ of values==. The other difference is the attitude that we the audience are invited to have toward the two titular heroes. Are the two characters to represent polar moral opposites, or is there a sense in which they are both wrong? Both can be accused of having too narrow a vision of moral duty, of elevating their perceived duty into a moral fetish. Agamemnonâ€™s situation offered no easy way out, since his decision concerned irreparable damage done to one person or to many. Antigoneâ€™s, on the other hand, is marked by what some of us would perceive as an irrational stubbornness that ultimately concerns nobodyâ€™s life except her own. We may admire her for a supererogatory gesture, but would not blame her for failing to perform it. I propose looking at the dramatic situation, then at Creonâ€™s dilemma, then at Antigoneâ€™s.\n4.1. The situation inÂ Antigone\nOedipusâ€™s two sons, Polynices and Eteocles, ended up on opposite sides of a near-civil war surrounding Thebes, which resulted in both their deaths. Creon, the new king of Thebes and uncle to the two brothers and to Antigone, orders a full state burial for Eteocles who was defending the city, and condemns Polynices to the fate of traitors (39): his body is to be left to rot, unburied, outside the city gates. Antigone and Ismene are both sisters to the two brothers, and therefore nieces to Creon. Antigone resolves to bury the corpse of Polynices symbolically, by sprinkling earth on it. She is caught by the guards and sentenced to death by Creon for breaking the law, a sentence that she was well aware of. At first glance, then, we have two incompatible desires: to bury a brother, in accordance with religious and family custom and fraternal sentiment, and to prevent the burial of a traitor, in accordance with prudential principles of government â€” a government which Antigone considers legitimate and whose laws she acknowledges, and a adroitly-preserved civic order from which she benefits.\nIn theÂ AntigoneÂ there are no gods directly relevant to the dilemmatic situation, although they are frequently invoked by both protagonists in partial justification of their priorities. It is a drama that could easily be imagined taking place today, between the people and the institutions they support and represent (40).\n==In addition,Â AntigoneÂ portrays a more protracted conflict than inÂ Agamemnon; there is plenty of room for softening and relenting before Creon is forced to make good his threat by Antigoneâ€™s firmness of purpose.\n==We shall see two different attempts to close off the prospect of conflict -and tension byÂ simplifyingÂ the structure of the agentâ€™s commitments; we shall examine what motivates such attempts, and what becomes of them within the context of the tragic crisis.\n==Finally, as withÂ Agamemnon, we shall ask whether practical wisdom is to be gained, if nothing else, from such a conflict.\n==Just as the situation in theÂ AgamemnonÂ did not appear like a classic dilemma, since the hero knew what he had to do, so in theÂ Antigone, the two protagonists are so clear in their minds, have their priorities so carefully ordered, that they do notÂ experienceÂ their dilemmas with the same urgency as we the audience.\nAntigone and Creon can approach problems of choice with unusual confidence and stability, and seem unusually safe from the ravages of luck. As such, it is again difficult, at first, to speak of choice. Both Creon and Antigone have freedom to do what they want, of course, but they only want one thing, and the alternatives (not attempting to bury her brother, or, making an exception to a city edict) are seen as too much of a sacrifice to the values with which they firmly identify. \n==And yet each, we are invited to see, is somehow defective in vision. Each has omitted recognitions, denied claims, called situations by names that are not their most relevant or truest names.\n_\n4.2. Creonâ€™s dilemma\n_\n==Creon believes that the most important thing a man can have is practical wisdom (1050-1), and that the healthy mind is devoted to civic safety and civic well-being (41); he is either the consummate unimaginative bureaucrat, or, less charitably, the Machiavellian tyrant, seeking to justify his maintenance of power with moral labels.\n==As such he is able to forestall confusion and inconsistency by a â€˜healthyâ€™ rearrangement of evaluations, so that positive ethical terms apply uniquely to those who promote, by effort or opinion, the good of the city, which Creon has established as the single intrinsic good. Antigoneâ€™s badness becomes civic disloyalty, and Eteoclesâ€™s goodness is his honourable defence of his native town (42).\n==To give burial to the cityâ€™s enemy would be, he argues, to give equal share to the good and the bad (520). As Santirocco points out in a discussion of the concept of justice:\nâ€œAt different times and in different contexts the word can signify custom or usage, law-enforcing authority, penalty and of course â€˜justiceâ€™ as a higher standard. Its precise semantic range is wide and fluctuating. Thus tragedy becomes, in a sense, a matter of vocabulary. In theÂ Antigone, the characters appeal to justice, but each defines it differently, so that the conflict is not so much between justice and injustice as between one sort of justice and anotherâ€¦ . Sophoklesâ€™s visionâ€¦ is austere. Although he acknowledges the existence of an ideal of justice, he exposes the tensions and ambiguities inherent in it and thereby questions whether that ideal can ever be realised in the lives of men. (43)â€\nCivic order and prospering is the highest good, to which, Creon believes, even the gods would aspire. As such he feels justified in defying religious custom to promote this good, in â€œspurning the due of Heavenâ€ (743). â€œWhy would the gods honour someone who came to destroy their temples and their laws?â€ (287) â€œDo you see the gods honouring bad people? It cannot beâ€ (289-90).\n==In addition to words like â€˜justiceâ€™, â€˜respectâ€™ and the â€˜goodâ€™, Creon also shifts the meanings of â€˜loveâ€™ (44)Â and â€˜pietyâ€™ (Nussbaum 57). We would expect him to have numerous obligations to members of his family, for example to his son Haemon, to his nephewâ€™s body lying outside the city gates, and to his niece Antigone herself. And yet he is determined,Â for the sake of consistency, to conceal from deliberative view the claims of both familial and affective ties, at least insofar as they clash with civic interest.\nSo â€œan enemy is never aÂ philos, not even when he diesâ€ (522). So when Creon is presented with the claims of piety and philos, he cannot recognise them and sees not a dilemma but merely insurrection. Any other description would be misguided. Like Millâ€™s utilitarian, every object or concept of value can be coined in a single currency and then easily measured against each other. It does not contain conflicts within itself, and can recognise no rival source of value and commitment.\nThe play is partly about Creonâ€™s discovery of a more complicated deliberative world; his supreme end, once properly conceived, is not so simple as he thought it, and it fails to do justice, finally, to all his concerns. The clearest rupture is Haemonâ€™s presumably trustworthy statement that the people support Antigone (733), even though it is still possible that her actions threaten the city unbeknownst to its inhabitants. As Nussbaum puts it:\n==â€œA city is a complex whole, composed of individuals and families, with all its disparate, messy, often conflicting concerns that individuals and families have, including their religious practises, their concern for the burial of kin. A plan that makes the city the supreme good cannot so easily deny the intrinsic value of the religious goods that are valued by the people who compose itâ€(45).\nIn the end, it is his own recalcitrant humanity that Creon fails to subdue. He is forced to acknowledge his love for his son and to see its separate value:\nOh errors of my ill-reasoning reasonâ€¦ Oh, how impoverished my deliberations wereâ€¦ You have died, [my son], you have gone away, through my bad deliberations, not your ownâ€ (1261-9) (46).\n_\n4.3. Antigoneâ€™s dilemma\n_\nWhile most commentators agree that Creon is morally defective and superficial, the situation with Antigone and her dilemma is more controversial. There has been a lamentable tendency to see her in saintly terms, dying for truth, resisting tyranny (47).\n==However, it seems more plausible to suggest that, like Creon, AntigoneÂ alsoÂ engages in a ruthless simplification of the world of value in order to effectively eliminate conflicting obligations. And like Creon, she can be blamed for narrowness of vision, even though she still remains morally superior to Creon. (48)\nAntigoneâ€™s prime concern is for her family and the duties she sees as incumbent upon her, whether she likes it or not; and she is Ismeneâ€™s sister, Antigone reminds her, whether she [Ismene] likes it or not (45). Although the â€˜familyâ€™ as a value-concept is not so all-encompassing as the â€˜cityâ€™ (fewer value words can be realigned), Antigoneâ€™s effort can easily be seen as a direct parallel to Creonâ€™s. For her, there is no â€˜enemyâ€™, â€˜traitor to the stateâ€™ or â€˜friend to the stateâ€™ among her brothers, there are merelyÂ philoi, to whom she is related and therefore bound.\nIf one listened only to Antigone, one would not know that a war had nearly taken place, or that Thebes,Â herÂ city and the location of all she claims to hold dear, had been directly attacked by the brother she is now trying to sanctify through burial.\n==What is important, however, is that this duty doesÂ notÂ seem to be backed by natural sentiment; she loves her duties more than she does her brothers: â€œI shall lie with him as a loved one with a loved one,â€ (73) she proclaims, without any sense of closeness, personal memory or particularity animating her speech (49).\nIsmene, the one person to whom she might be drawn after the deaths of their two siblings, is treated from the beginning with remote coldness, and is even called â€œenemyâ€ (93) when she takes the â€˜wrongâ€™ stand on matters of pious obligation. Whereas it is Ismene whom we see weeping â€œsister-loving tearsâ€, and who asks, with an intensity of feeling that never animates her sisterâ€™s piety: â€œwhat life is worth living for me, bereft of you?â€ (548) (50).\nDuty to the family dead is therefore the supreme law, passion and value, and Antigone structures her entire life and her vision of the world in accordance with this simple, self-contained system of duties. Indeed, she is just as obsessed about what she conceives as justice as is Creon about whatÂ heÂ conceives of justice, only she claims to equate it with the gods and their desires as manifest in religious customs. It reflects the central question of Platoâ€™sÂ Euthyphro: is an act good because it is pious, or is it pious because it is good?\nFor Creon, civic justice governs the gods themselves; for Antigone, the customs sponsored by the gods define goodness and justice, to which the sublunary world must succumb. Even within her system, Antigone is ready to handle any conflicts with her fixed priority ordering to dictate her choice without regret. So all-consuming is her interest that one wonders what she has been doing to entertain herself before her brothers went to war.\nI am not so sure about Antigoneâ€™s attempts to justify her act by appeal to religious custom. Like Creon, she claims allegiance to Zeus when convenient (e.g. 950) while considering her general commitments to be themselves above the gods. The very expression of her devotion is suspect: â€œZeus did not decree this, as far as I am concernedâ€ (450). Antigone is a â€˜maker of her own lawâ€™ (autonomos, 821) and her defiance is a â€™self-invented passionâ€™ (autognotos orga, 875). If we ask of Antigone the same question she asked of herself: â€œWhat divine justice have I disobeyed?â€ (921), we must answer: â€œnoneâ€. But as Santirocco explains:\nâ€œin a very real sense this is the wrong question. Although Antigoneâ€™s actions coincide with the requirements ofÂ dikÃ©Â (i.e. that the dead should not go unburied) they are not the result of any conscious concern forÂ dikÃ©. Antigoneâ€™s motive was personal, and this, in some way, qualifies her response since it leads her to ignore the claims of society just as dramatically as Creon ignores the claims of the gods.â€ (51)\nLike Creon, she comes to recognise the complexity of life as her own demise grows imminent. She comes to see that the service of the dead requires theÂ polis, that her own religious aims cannot be fulfilled without civic institutions. In her last speeches, she laments not her imminent death, but rather, her isolation from her community of offspring, from friends and mourners. How is it, therefore, that we can admire Antigone over Creon, if they are so similar? Nussbaum gives three reasons: first, in the world of the play, it seems clear that Antigoneâ€™s choice is preferable to Creonâ€™s.\nâ€œThe dishonour to civic values and the inherent prudential risk is far less radical than the violation of religious custom involved in Creonâ€™s act. Antigone shows a deeper understanding of the community and its values when she argues that the obligation to bury the dead is an unwritten law, which cannot be set aside by the decree of a particular ruler.â€ (52)\nThis view will be shared by the audience and emerge even despite the criticism of Antigoneâ€™s single-mindedness. Second, Antigoneâ€™s pursuit of virtue is her own, and involves nobody else and commits her to abusing no other person (although Ismene might justifiably expect better treatment). Third, and perhaps most importantly, Antigone is ready to risk and sacrifice her ends in a way that is not possible for Creon. There is room in Antigoneâ€™s system for a genuine sacrificeÂ withinÂ the defence of piety. She dies recanting nothing.\n4.4. The importance of theÂ Antigone\nThe main dramatic dilemma is the conflict between the two of them. Interestingly, the conflict is highly personal. Creonâ€™s â€˜victoryâ€™ in destroying Antigone does not represent a victory for civic duty, and Antigoneâ€™s relative â€˜victoryâ€™ inÂ ourÂ eyes doesÂ notÂ represent the defeat of the city by the family. A==nd yet it is hard to speak of a real conflict, since the two speak such different languages (with similar terminology, to be sure) that they never reallyÂ engage,Â and never really listen. As Blundell points out, Sophokles could have achieved far more interaction and dramatic excitement in two ways: Creonâ€™s case could certainly have been much stronger, since Classical Greek sympathies would definitely be with him and his devotion to the city. On the other hand, Antigone could have tried to persuade him on his own terms that, for example, both brothers had been responsible for the war. Rather, the two remain narrow and self-absorbed ==(53).\nThe simplistic hagiography of modern versions of the play does detract from an important dramatic question. We, the spectators, can imagine ==ourselves in Antigoneâ€™s predicament, and ask: â€œare there any values I personally would be willing to die for in conditions of sufficient adversity?â€ In modern western democratic society, such adversity has been scarce since the system allows dissent to be voiced and indeed, if voiced by sufficient numbers, heeded.\n==But the question of adversity remains relevant in two contexts: first, in questions of integrity and compromise in the face of any form of authority making specific rules perceived as unjust: a teacher, boss or local politician.\nSecond, in more extreme political regimes as many will remember in Europe this century. Annouilh was not particularly original in seeing the parallels with defiance to the Nazi occupation of France, but in portraying his heroine as a guiding ideal he lost not only much of the subtlety of Sophoklesâ€™s dramatic portrayal, he also failed to capture fully the individual experience during those terrible years in France. While it is true that many emerged from the occupation with a definite feeling of moral stigma for what they themselves perceived as craven collaboration with an unambiguous enemy, the choice that French individuals faced on a daily basis was mostly a moral and not a moral-prudential dilemma.\n==A moral-prudential dilemma involves one moral horn and one prudential horn. In such dilemmas, one knows what one morally ought to do, but one is afraid or one does not consider the risks to be worth taking. This need not be cowardice: it does not seem blameworthy for me to refrain from jumping in to save somebody when I cannot swim; although I will feel awful if I therefore have to watch them drown. No doubt I will feel a similar stigma as the self-described collaborator for not having fulfilled what I myself considered a moral requirement: to resist the enemy by all means at my disposal. Antigoneâ€™s conflict with Creon is not really a moral-prudential dilemma, and it would not be interesting if it were.\nRather, the two horns of her dilemma are both moral requirements, and I as an audience member have to decide â€” regardless of the way Antigone resolves it â€” what I would do in her situation. Similarly, Sartreâ€™s student faces a moral dilemma in that he cannot decide between two moral requirements he himself acknowledges: filial duty versus patriotic duty. This is far more characteristic of the dilemmas typical of occupation.\nThe important point is that Antigone is not a revolutionary. She does not attempt to incite or persuade others to lobby the government, she does not write passionate letters to the media about her grievances, she does not even bother to really engage her own sister in rational argument about the point of dissent. She is utterly alone, and well recognises theÂ futilityÂ of her gesture in terms of long-term change, and Ismene is careful to explain this to her â€” in the same way resistance to a military occupier is also likely to be futile. Were it not for Creonâ€™s wifeâ€™s and sonâ€™s support for her desperate act with a likewise desperate protest, it is unlikely that Creon would have been moved to reconsider his policy, or his way of viewing Antigoneâ€™s transgression.\nAgain, though, it is one thing to be provoked into thoughts of integrity and resistance, and quite another to see theÂ AntigoneÂ purely in such terms. We have no strong reason to assume that Creonâ€™s rule is otherwise unjust, and that Antigone suffers unduly. If anything, her special position as relative to the king might give her privileges. We never hear her complain of other constraints on her desires, beyond the widespread and unquestioned patriarchal thinking of a womanâ€™s place and role in society. ==In one sense, Antigone is not a very effective role model when portrayed as an unswerving saint because her behaviour is too demanding for the rest of us, who have ambitions and hobbies that we take delight in, who have relationships with people whom we care about and who depend on us, and who, ultimately, only have one life to lead. Antigone did not have to live with her choice after she had made it in the way Agamemnon did, she did not have toÂ becomeÂ a person capable of killing his own daughter. As such it may be said that although Antigone loses her life at the end, she did not have muchÂ elseÂ to lose.="},"Newsletter/Template":{"slug":"Newsletter/Template","filePath":"Newsletter/Template.md","title":"Template","links":["tags/"],"tags":[""],"content":"Greetings, readers! (or Gm, as we commonly greet others in the crypto community). The purpose of this newsletter is to provide digestible breakdowns of complex protocols and products in the Ethereum ecosystem. You can expect quality substantive content (no hype pieces, shilling, or paywall) written for crypto-curious readers who are either newer to crypto or seasoned users who value refreshers on the fundamentals. You can learn more about this newsletter in the introductory post.\nÎTH Market Capitalization = X\nÎTH Price = Y\nAs always, feel free to reach out to me with questions, suggestions, or feedback, by replying directly to this email (if you are a subscriber), commenting on this post, or sending me a message on Twitter. My DMs are open.\n-Rika\n\n\n\n\n\n\n Placeholder Image\n[Placeholder for Catchy Intro Title]\nUseful Definitions"},"Articles--and--Papers/Cryptoeconomic-Research/Flash-Boys-2.0---Frontrunning,-Transaction-Reordering,-andConsensus-Instability-in-Decentralized-Exchanges":{"slug":"Articles--and--Papers/Cryptoeconomic-Research/Flash-Boys-2.0---Frontrunning,-Transaction-Reordering,-andConsensus-Instability-in-Decentralized-Exchanges","filePath":"Articles & Papers/Cryptoeconomic Research/Flash Boys 2.0 - Frontrunning, Transaction Reordering, andConsensus Instability in Decentralized Exchanges.md","title":"Flash Boys 2.0 - Frontrunning, Transaction Reordering, andConsensus Instability in Decentralized Exchanges","links":["Bitcoin"],"tags":[],"content":"arxiv.org/pdf/1904.05234.pdf\nQuotes\nWe show that MEV creates systemic consensus-layer vulnerabilities\nOur results are surprising for two key reasons. First, they identify a concrete difference between the consensus-layer security model required for blockchain protocols securing simple payments and those securing smart contracts. In a payment system such asBitcoin, all independent transactions in a block can be seen as executing atomically, making ordering generally unprofitable to manipulate.\nSmart contract security is often studied purely at the application layer, abstracting away low-level details like miner selection and P2P relayersâ€™ behavior in order to make analysis tractable\nLow-level protocol behaviors pose funda- mental challenges to developing robust smart contracts that protect users against exploitation by profit-maximizing miners and P2P relayers that may game contracts to subsidize attacks\nBecause pure revenue opportunities offer unconditional revenue, arbitrage bots often compete against each other by bidding up transaction fees (gas) in what we call PGAs. We formally model bot PGA behavior and observe a cooperative equilibrium. We show that empirical measurements of the evolution of bot PGA strategies validate key features of our model.\n"},"Articles--and--Papers/Cryptoeconomic-Research/MEV-Auction-Auctioning-transaction-ordering-rights-as-a-solution-to-Miner-Extractable-Value":{"slug":"Articles--and--Papers/Cryptoeconomic-Research/MEV-Auction-Auctioning-transaction-ordering-rights-as-a-solution-to-Miner-Extractable-Value","filePath":"Articles & Papers/Cryptoeconomic Research/MEV Auction Auctioning transaction ordering rights as a solution to Miner Extractable Value.md","title":"MEV Auction Auctioning transaction ordering rights as a solution to Miner Extractable Value","links":[],"tags":[],"content":"ethresear.ch/t/mev-auction-auctioning-transaction-ordering-rights-as-a-solution-to-miner-extractable-value/6788\nSpecial thanks to Vitalik for much of this, Phil Daian as well (&amp; his amazing research on MEV), Barry Whitehat for alsoÂ coming up with this ideaÂ 283, andÂ Ben JonesÂ for the rest!\nBlockchain miners (also known as validators, block producers, or aggregators) are nominally rewarded for their services by some combination of block rewards and transaction fees. However, being a block producer tasked with producing a particular block gives you a lot of power within the span of that block, letting you arbitrarily reorder transactions, insert your own transactions before or after other transactions, and delay transactions outright until the next block, and it turns out that there are a lot of ways that one can earn money from this. For example, one can front-run decentralized exchanges (both Uniswap-style and the order book variety), be the first to claim whistleblower rewards, have a favorable position in ICOs, as well as many other forms of mild manipulation of applications. Recent research shows that the revenue that can be extracted from this (called â€œminer-extractable valueÂ 338â€ or MEV) is potentially significantly higher than transaction fee revenue.\nFrequent batch auctionsÂ 199Â are one traditional response to market manipulation by reordering. In an FBA, instead of processing transactions â€œas they comeâ€, a market gathers all transactions submitted within the same time span (could be short eg. 100 ms, or a minute or longer), reorders them according to a standard algorithm that does not depend on order of submission, and then processes them in that new order. This makes micro-scale timing manipulation nearly irrelevant.\nWe propose a technique in a similar spirit to how FBAs remove micro-scale timing manipulation, with one major difference. In an FBA, there is only one application, and so there is one natural â€œoptimalâ€ order for transactions (orders): process them in order of price. In a general-purpose blockchain, there are many applications with arbitrary properties, and so coming up with a â€œcorrectâ€ order is virtually impossible for a fixed algorithm. Instead,Â we simply auction off the right to reorder transactions within an N-block window to the highest bidder. That is, we create a MEV Auction (MEVA), in which the winner of the auction has the right to reorder submitted transactions and insert their own, as long as they do not delay any specific transaction by more than N blocks.\nThis creates a form of â€œmanaged centralizationâ€: a single sophisticated party wins the auction and can captureÂ allÂ of the MEV. We call this party a â€œsequencer.â€ Having a single sequencer reduces the benefit to other block proposers of using â€œcleverâ€ algorithms to near-zero, thereby increasing the chance that â€œdumbâ€ block proposers will be long-term viable and hence promoting decentralization at the block proposal layer. This technique can theoretically be used at layer 1, though we also show how it is a perfect fit for layer 2 systems, particularly systems such as Optimistic Rollup, zkRollup, or Plasma.\n\nThis mechanism is designed to extract MEV for the sole purpose of supporting our (inclusive) blockchain community. In fact, this mechanism could be the revenue stream for opt-in self governance built to fund the internetâ€™s public goods. We mustnâ€™t participate in an MEVA which funds things we donâ€™t like!\n\nMEV Auction on top of Gas Price Auction\nControl over transaction ordering has become extremely profitable especially as smart contracts like Uniswap have gained popularity. There have been multiple occasions where trades on Uniswap with high slippage caused tens of thousands of dollars in free arbitrage profits.\nThese arbitrage opportunities are taken advantage of by arbitrage bots that watch the blockchain and participate in the gas price auction. These bots outbid each other at high frequency as long as the price they pay for the transaction is not excess of the amount of money they stand to make.Â Frontrun.meÂ 379Â has great information collected on these auctions happening in the background of Ethereum every day.\nCounter-intuitively, the real winner of these auctions isÂ Ethereum miners, as bots which outbid each other raise the gas price. This increased gas price increases miner fees and revenue. By introducing an MEV AuctionÂ in additionÂ to this gas price auction we can employ the same market mechanism that extracts frontrunning fees to be directed at miners, and redirect that profit back to the community.\n[\n1482Ã—462 73.8 KB\n](ethresear.ch/uploads/default/original/2X/2/29eefa9820ab10319cf522474a17798c420748a5.png)\nImplementing the Auction\nThe auction is able to extract MEV from miners by separating two functions which are often conflated: 1) Transaction inclusion; and 2) transaction ordering. In order to implement our MEVA we can define a role for each function.Â Block producersÂ which determine transaction inclusion, andÂ sequencersÂ which determine transaction ordering.\nBlock producers // Transaction Inclusion\nBlock proposers are most analogous to traditional blockchain miners. It is critical that they preserve the censorship resistance that we see in blockchains today. However, instead of proposing blocks with an ordering, they simply propose a set of transactions to eventually be included before N blocks.\nSequencers // Transaction Ordering\nSequencers are elected by a smart contract managed auction run by the block producers called the MEVA contract. This auction assigns the right to sequence the last N transactions. If, within a timeout the sequencer has not submitted an ordering which is included by block proposers, a new sequencer is elected.\nSequencers and Instant Transaction Inclusion\nIn addition to extracting MEV, the MEVA provides the current sequencer the ability to provide instant cryptoeconomic guarantees on transaction inclusion. They do this by signing off on an ordering immediately after receiving a transaction from a user â€“ even before it is sent to a block producer. If the sequencer equivocates and does not include the transaction at the index which they promised, the user may submit a fraud proof to the MEVA contract to slash the sequencer. As long as the sequencer stands to lose more than it can gain from an equivocation, we can expect the sequencer to provide realtime feed of blockchain state which can be monitored, providing, for instance, realtime price updates on Uniswap.\nImplementation on Layer 2\nIt is possible to enshrine this MEVA contract directly on layer 1 (L1) blockchain consensus protocols. However, it is also possible to non-invasively add this mechanism in layer 2 (L2) and use it to manage Optimistic Rollup transaction ordering.\nIn layer 2, we simply repurpose L1 miners and utilize them as block proposers. We then implement the MEVA contract and designate a single sequencer at a time. (Note: Interestingly the single sequencer can also be run by a sub-consensus protocol if desired.)\nIn fact, using MEVA for layer 2 is a perfect fit as it allows us to permissionlessly experiment with different parameters for the auction while simultaneously realigning Ethereum incentives to direct revenue back into the ecosystem. This may serve as the primary revenue stream for blockchain self-sustenance.\nConsiderations\nMEV Auction Collusion\nOne concern isÂ auction collusionÂ 34. Bidders colluding to reduce competition and keep the auction price artificially low breaks the ability to accurately discover and tax the MEV.\nA mitigation is to simply increase the ease of entering the aggregation market by releasing open source sequencer software. This can help to establish a price floor because with low barriers of entry we can expect enough competition that there will be at least one honest sequencer bid.\nLong term incentive alignment\nThe most naive way to implement MEVA is by holding a first-price auction once a day, giving the winner of the auction a monopoly on block production for that day. All proceeds raised by the auction are then sent into a public goods fund. Unfortunately, this approach has a serious problem: an attacker need only outbid the aggregation costs for a single time-slot in order to become the selected sequencer and degrade network quality.\nAdding the equivalent of a security deposit for the sequencer goes a long way to help mitigating this problem. If the sequencer degrades network quality at any point during their slot, they should be penalized in proportion to the amount of harm they cause to the network. This can be implemented as a simple bond which can be slashed by a subjective judgement of misbehavior, or by locking up an asset which has a price correlated with the health of the network. Note that sequencer misbehavior can often come as a non-uniquely attributable fault and so unfortunately require subjective judgements to enforce.\nThe Parasitic L2 Problem\nLayer 2 mining has gotten bad press for diverting revenue away from L1 miners who secure the network. Diverting revenue from L1 implicitly decreases the security budget, and thereby makes it less costly to perform 51% attacks.\nWhile I wish there was a clear mitigation, in reality the parasitic L2 problem deserves much more research &amp; risk analysis. It could be the case that L2 chains drive up demand for L1 enough to keep the price of ETH high, or ETH remains valuable because it is seen as money, or we simply use out-of-protocol means to protect our most critical blockchains. This remains to be seen and is a great area of research.\nPath Forward\nDesigns like these are critical for framing the coming wave of Ethereum upgrades as not only innovations in scalability, but also as an opportunity to realign incentives to be pro-community, pro-commons, and pro-public goods. Without serious thought around how we will sustain blockchain technology we risk creating resilient decentralized architectures which eventually crumble due to massive economic centralization. This is not a future anyone wants to live in.\nThankfully, these designs show the possibility of encapsulating and reinvesting MEV back into the community. Further research and economic models will be key as we bring these systems into production. Letâ€™s do it!"},"Articles--and--Papers/Decentralization/Notes,-The-Value-of-Decentralization-Using-The-Blockchain-by-Marco-Reuters":{"slug":"Articles--and--Papers/Decentralization/Notes,-The-Value-of-Decentralization-Using-The-Blockchain-by-Marco-Reuters","filePath":"Articles & Papers/Decentralization/Notes, The Value of Decentralization Using The Blockchain by Marco Reuters.md","title":"Notes, The Value of Decentralization Using The Blockchain by Marco Reuters","links":["tags/processed","Articles--and--Papers/Decentralization/PAPER-The-Value-of-Decentralization-Using-The-Blockchain-by-Marco-Reuters","Assuming-that-users-are-smart,-a-rational-entrepreneur-will-decentralize-a-new-network-that-she-is-building-when-the-locked-in-effects-for-her-users-are-high"],"tags":["processed"],"content":"processed\nSource: PAPER The Value of Decentralization Using The Blockchain by Marco Reuters\nSummary\nIn this paper, the researcher proves mathematically that it makes sense for an entrepreneur to decentralize her network, ceding control to users via governance, when the locked-in effects are high. A prime example of a locked-in effect is switching costs.\nIn a centralized network, as the network effects grow, and users get locked-in, the entrepreneur rationally wants to exploit users by charging them fees or showing more advertisements. For established centralized networks like GAFA, their network effects are already very strong so they wonâ€™t decentralize. But for new networks, decentralization makes sense when locked-in effects are high.\nIf a network has high locked-in effects, making it hard for users to switch to another network, the entrepreneur should make a credible commitment to users by allowing them to make monetization decisions. That way, users are assured the entrepreneur will not exploit them.\nNotes\nAssuming that users are smart, a rational entrepreneur will decentralize a new network that she is building when the locked-in effects for her users are high\nIntroduction\nVitalik Buterin, co-founder of the Ethereum blockchain, argues that ==decentralization is, among other things, useful for Collusion resistance â€” it is much harder for participants in decentralized systems to collude to act in ways that benefit them at the expense of other participants, whereas the leaderships of corporations and governments collude in ways that benefit themselves but harm less well-coordinated citizens, customers, employees, and the general public all the time.\nWith that, I provide an answer to a question that is frequently raised when it comes to the topic of blockchain and cryptocurrencies: Why would anybody use it? As the core friction at play, I assume that ==users of the network are subject to a locked-in effect, for example due to switching costs.3f the frictions that arise due to the potential of exploiting this locked-in effect by the entrepreneur are sufficiently large, I show that an entrepreneur prefers decentralizing her network. As a result, she effectively gives up control of the network and thus generates commitment to not abuse the locked-in effect of the users.\nHowever, decentralization also comes at a cost for the entrepreneur: she surrenders the control of the network to the users and, to align incentives, engages in revenue sharing. \nTherefore, there is a trade-off between the costs of centralization and decentralization. I show that if the locked-in effect is small, an entrepreneur should implement her network in a centralized manner. On the other hand, ==if the locked-in effect is sufficiently large, an entrepreneur should implement her network in a decentralized\nmanner.=\nGiven this result, the list of companies with decentralized counterparts is not surprising. Arguably, users of AWS, Facebook, and other tech companies are subject to\nparticularly large locked-in effects.\n==The entrepreneur is purely interested in generating revenue through monetization, while the usersâ€™ utility consists of three parts: First, they derive utility from using the network. Second, they dislike monetization such as advertisements, and third, they benefit from any revenue that is shared with them. I use sub-game perfect equilibria to analyze the game.\n==Therefore, an entrepreneur using a centralized implementation of the network is unable to credibly commit to future levels of monetization and revenue sharing. Instead, her choice of monetization and revenue sharing has to be sequentially optimal for every history of the game given the strategy of the users.\n==I divide the analysis of the model into three subsections. First, the sub-game of centralized governance. Second, the sub-game of decentralized governance and third,\ndetermining the optimal governance structure for the network.\nModel\n==If the entrepreneur chooses decentralized governance, she commits, without loss of generality, to a fixed percentage Î± of revenue sharing in t = 0 through the tokenomics of the network. She achieves this through the appropriate distribution of the networkâ€™s token between herself and the users.\n==In every period t = 1, 2, â€¦ the users of the network determine the amount of monetization Ï€t through on-chain governance. Regardless of the mode of governance, each period, users have a binary choice. Newly arriving users can join or not join the network. Existing users can stay in the network or leave the network. Users that decide to leave the network or newly arriving users who decide not to join the network exit the game and realize the value of their outside option.\nGrowth\nEvery period, new potential users become aware of the network. Let Î¼tâˆ’1 be the mass of users in the network in period t âˆ’ 1. Then, in period t there will be a mass\nof g(Î¼tâˆ’1) âˆ’ Î¼tâˆ’1 â‰¥ 0 new users who become aware of the network. Each potential new user can join or not join the network. For example, if all new users join, the new measure of users in the network is equal to g(Î¼tâˆ’1). If no new user joins, the network remains at Î¼tâˆ’1 users. If only some users join, the network will have a size in between these two.\nThe growth function g is continuously differentiable and the mass of users in period 0 is\nset to Î¼0 = 0. I assume that if the network loses all its users within a period, no new\nusers will arrive at any point in the future. This assumption rules out cyclical equilibria\nin which the entrepreneur continuously â€starts overâ€. There is complete information and\nboth the entrepreneur and the users observe the full history of the game.\nPreferences\nThe entrepreneur is strictly interested in revenue: her utility in a particular period t is equal to her revenue share Î±t multiplied by the revenue raised by monetization Ï€tÏ•(Î¼t): uEt = Î±tÏ€tÏ•(Î¼t). The utility a user receives from participating\nin the network has three components: First, a user derives utility V (Î¼t) from using the network. I assume that V is increasing, i.e. there are network effects, it is continuously differentiable and that V (0) = 0. Second, as a result of the monetization of the network, Ï€t, the userâ€™s utility decreases by kÏ€2t , where k &gt; 0 describes the userâ€™s aversion to monetization. This represents the decrease in utility a user suffers when being forced to watch advertisements, through the sale of his data, or other detrimental effects of monetization. As a third component, a user may potentially receive a share of the revenues that the network generates.\nThe utility function of a user equals the sum of these three components: ut = V (Î¼t)âˆ’kÏ€2t + (1âˆ’Î±t)Î¼t Ï€tÏ•(Î¼t).\nLocked-in effects\nA user who newly arrives in the network can decide to join\nthe network and realize the utility as described above. If the user decides not to join the\nnetwork, he realizes an outside option that is normalized to 0. A user who has already\ntaken part in the network for at least one period can decide to stay in the network, re-\nalizing the utility of participating, or leave the network. However, the outside option for\nthese users is equal to âˆ’u &lt; 0. Thus, users that already take part in the network suffer\nfrom a locked-in effect. This assumption represents the idea that users have spent time\ninteracting with the network, such that its algorithm has adapted to their needs.14 An\nequivalent interpretation is that the value of the outside option has remained constant,\nbut users encounter a switching cost equal to u when leaving the network in favor of the outside option.\nBoth the entrepreneur and the users maximize the sum of their discounted utilities.\nFuture utilities are discounted by a common discount factor Î´ âˆˆ (0, 1). I divide the analysis into subsections dedicated to the sub-games of centralized and decentralized\ngovernance. Within those sections, I provide a detailed description of the structure of the sub-games of centralized and decentralized governance. Then I derive the sub-game perfect Nash equilibria and discuss their properties. Finally, I determine the optimal decision of the entrepreneur at the start of the game: to implement her network with centralized or decentralized governance.\nGrowth vs. exploitation.\nTo derive the equilibrium of the centralized governance sub-game, it is instructive to consider the entrepreneurâ€™s incentives to grow her network. Every period, new users arrive to potentially join the network. For the network to grow, joining the network has to be weakly beneficial for a newly arriving user. That is, joining the network has to yield at least utility equal to 0. Instead of growing the network, the entrepreneur can exploit the existing users. Given that existing users are locked into the network and have an outside option that is valued at âˆ’u &lt; 0, the entrepreneur can potentially achieve a higher level of revenue when focusing on extracting additional revenue from existing users. To quantify the revenue that an entrepreneur generates when she decides to exploit the users in her network, consider some period t. The amount of existing users at the start of the period is equal to Î¼tâˆ’1. If she exploits the existing users forever, the present value of the stream of her discounted future revenue equals the point at which the entrepreneur is indifferent between growing the network one last\ntime and exploiting the existing users in her network will be crucial for the analysis of\nthe equilibrium. I denote this point of indifference by Â¯Î¼. It is defined as the solution to the following equation:\n1 âˆ’ Î´ Ïˆ(Â¯Î¼, âˆ’(1 âˆ’ Î´)u) = Ïˆ(g(Â¯Î¼), Î´u) + Î´\n1 âˆ’ Î´ Ïˆ(g(Â¯Î¼), âˆ’(1 âˆ’ Î´)u)\nIt is exactly at the network size Â¯Î¼ where the entrepreneur is indifferent between growing the network one last time and then exploiting the users in the future, and exploiting the users right away. It highlights the trade-off between exploiting the locked-in effect of a smaller mass Î¼tâˆ’1 of users starting today, or, growing the network at the cost of providing utility Î´u to the users to then exploit a larger network with g(Î¼tâˆ’1) users starting tomorrow.\nThe key feature is the idea, that user growth will slow down over time. For example, if the overall pool of potential users is limited and a large amount of users has already\njoined the network, user growth necessarily slows down mechanically over time.\nStrategies\nDefinition 1 (Grow-then-exploit strategy)\nThe entrepreneurâ€™s strategy has three distinct parts. If g(Î¼tâˆ’1) &lt; Â¯Î¼, the entrepreneur will\ngrow the network again in the next period, as g(Î¼tâˆ’1) = Î¼t &lt; Â¯Î¼. Thus, the entrepreneur sets user utility equal to Ë†ut = 0 and the users are willing to join the network. Note that in\nthese growth periods, the entrepreneur has basically regained commitment to not abuse\nthe locked-in effect of the users. The entrepreneur refrains from exploiting the locked-in\neffect of the existing users in the network with the aim to grow the network larger.\nDefinition 2 (Join-if-compensated strategy)\n==The usersâ€™ strategies obey the following rationale: when they newly arrive at the network, they do not suffer from a locked-in effect. They observe the network size and if\ng(Î¼tâˆ’1) &lt; Â¯Î¼, anticipate that the entrepreneur will grow the network further in the future, such that it is optimal for them to join the network if Ë†ut â‰¥ 0. If Î¼tâˆ’1 &lt; Â¯Î¼ and Â¯Î¼ â‰¤ g(Î¼tâˆ’1),\nthey know that the entrepreneur will grow the network just one last time. As such, they require a level of utility Ë†ut â‰¥ Î´u to join the network. If they are already locked into the\nnetwork, they will remain in the network if Ë†ut â‰¥ âˆ’(1 âˆ’ Î´)u, as this implies that the discounted value of their futu e utility is at least equal to the value of their outside option âˆ’u\nNaturally, as a next step, I formally establish that these strategies constitute a sub-\ngame perfect Nash equilibrium:\nProposition 1 Suppose that the network is sufficiently profitable at size Â¯Î¼ to ensure utility level Î´u to its users, i.e. inequality II.4 is satisfied. ==Then, there is a sub-game\nperfect Nash equilibrium in which the entrepreneur plays according to the grow-then-exploit strategy and the users play the join-if-compensated strategy.\n==The entrepreneurâ€™s main issue in the network with centralized governance is her lack of commitment to not abusing the locked-in effect of the user.\nII.B Decentralized Governance\nThe equilibrium highlights that decentralized governance is an effective commitment tool\nfor the entrepreneur. ==In contrast to centralized governance, the users can be certain that\ntheir locked-in effect will not be exploited by the entrepreneur.\n==Thus, new users will continue to join the network every period. However, for the entrepreneur, this commitment comes at a substantial cost: she shares half the revenues of the network with her users.\nNonetheless, it is necessary for her to share revenue with her users. If she would not share\nany revenue, the users would subsequently vote to stop the monetization of the network.\nAs a result, the entrepreneur would not receive any revenue. Therefore, sharing revenue\nin a decentralized implementation of the network is necessary, as it aligns the incentives\nof the entrepreneur and the incentives of the networkâ€™s users.\n==One potential point of contention in decentralized governance could be conflicts of\ninterest between existing and newly arriving users. The usersâ€™ utility function equals V (Î¼t) âˆ’ kÏ€2t + 1âˆ’Î± Î¼t Ï€tÏ•(Î¼t). The share of revenue that each user gets in the network is 1âˆ’Î±Î¼t .\nAs such, newly arriving users dilute the revenue shares of existing users in the network.\nHowever, note that the usersâ€™ per period utility in the equilibrium equals V (Î¼t) + Ï•(Î¼t)2\n8kÎ¼2t.\n==Since Ï•(Î¼t)Î¼t is non-decreasing by assumption, the equilibrium utility is increasing in Î¼t. Intuitively speaking, the network effects that accompany the entry of new users sufficiently compensate the dilution of the revenue share of existing users. Thus, there is no incentive for existing users to try to prevent entry from newly arriving users to avoid dilution of their revenue shares.\nOptimal Governance\nThe two preceding sections have solved the sub-games of centralized and decentralized\ngovernance. But the main question remains: which form of governance the entrepreneur\nshould choose when she creates her network?\n==However, a complete comparison between the entrepreneurâ€™s revenue in centralized and decentralized governance remains. That is, what is the optimal mode of governance for any arbitrary size of the locked-in effect? To answer this question, I start by considering the opposite extreme, namely when the locked-in effect is very small. Then, I move to locked-in effects of arbitrary size.\nII.D Welfare\n==Finally, I want to address the welfare implications of the governance decision. In particular: When does decentralization improve welfare?\nPareto efficiency. It turns out that the analysis that has been conducted so far\nis sufficient to compare the modes of governance in terms of Pareto efficiency.\n==First, note that users in the centralized implementation of the network are always indifferent between joining the network and their outside option ex-ante.  Thus, their equilibrium utility is 0.\n==In contrast, users receive strictly positive utility in the decentralized implementation of the network. Ergo, users always prefer decentralized governance. For the entrepreneur, proposition 3 has established that she prefers decentralization if and only if the size of\nthe locked in effect u is larger than the threshold uâˆ—âˆ—. Therefore, the following corollary\ncan be established:\n==Corollary 2 Decentralized governance of the network is a Pareto improvement over centralized governance if and only if the size of the locked-in effect u is larger than u**\nDiscussion\nIII.A Airdrops: Decentralizing at a Later Time\nThe main concern is once again commitment, that is, the entrepreneur is unable to commit that she will\ndecentralize the network in the future. Instead, it has to be sequentially optimal for her to decentralize the network. Intuitively, there is a tension between delaying decentralization for a while and delaying it for too long, when staying in control and exploiting the users becomes too tempting.\nIV Conclusion\nBefore concluding, I want to briefly discuss some further points of interest. First, one might wonder if this model implies that an established network such as Google\nor Facebook should decentralize their business through a blockchain. Such a conclusion cannot be drawn from this model, as these networks have already established a large\namount of users (e.g. Facebook already has around 3 billion users20). ==As such, the value of extracting additional revenues from existing users that are already locked-in may outweigh the value of commitment that is offered by a decentralized implementation. In contrast, the model provides insights on the optimal governance of newly founded networks.\n==To summarize, this paper provides an answer to a question that is frequently raised when it comes to the topic of blockchain and cryptocurrencies: Why would anybody use\nit? As the main result, I showed that (i) an entrepreneur prefers to decentralize her network and (ii) decentralization is a Pareto improvement, if and only if the locked-in effect is sufficiently large. To broaden our understanding of further implications of decentralization, I believe that further research is needed, especially regarding the economics\nof decentralized governance and competition between centralized and decentralized networks."},"Articles--and--Papers/Decentralization/PAPER-The-Value-of-Decentralization-Using-The-Blockchain-by-Marco-Reuters":{"slug":"Articles--and--Papers/Decentralization/PAPER-The-Value-of-Decentralization-Using-The-Blockchain-by-Marco-Reuters","filePath":"Articles & Papers/Decentralization/PAPER The Value of Decentralization Using The Blockchain by Marco Reuters.md","title":"PAPER The Value of Decentralization Using The Blockchain by Marco Reuters","links":[],"tags":[],"content":"Source\n\nQuotes\nNotes"},"Articles--and--Papers/Decentralization/Progressive-Decentralization,-a16z-crypto":{"slug":"Articles--and--Papers/Decentralization/Progressive-Decentralization,-a16z-crypto","filePath":"Articles & Papers/Decentralization/Progressive Decentralization, a16z crypto.md","title":"Progressive Decentralization, a16z crypto","links":["tags/processed","Decentralization-minimizes-platform-risk"],"tags":["processed"],"content":"processed\nSource:\na16zcrypto.com/posts/article/progressive-decentralization-crypto-product-management/\nSummary\nThe three components of cryptoâ€™s success are: 1) product/market fit ; 2) community participation ; 3) sufficient decentralization.\nThe founding team must over time relenquish control because that is better long term for the health of the network. Because decentralization minimizes platform risk, the possibility that the rules will change on developers. Platforms need committed developers and committed users.\nSufficient decentralization is also important for regulatory reasons. SEC deems decentralized companies not as securities (?? why??)\nNotes\nDecentralization minimizes platform risk\nQuotes\nCrypto founders have a unique challenge in front of them. In addition to building a product that people want, ==they also need to consider how that product can successfully run in a decentralized manner â€” that is, as a protocol owned and operated by a community of users.\nThis is a difficult challenge because much of what it takes to build a successful product at the outset â€” product leadership, rapid iteration, a managed go-to-market â€” ==complicates the path to community ownership and regulatory compliance, which guarantee long-term health.\n==Iâ€™ve talked to a number of crypto founders working to resolve this tension. Here Iâ€™ll propose a three-step process that may serve as a guide for how to do it, by way of progressive decentralization â€” a process in which founding teams relinquish control by degrees, over time. Doing so step-by-step allows teams to focus and creates a path toward regulatory compliance, including issuing tokens that hopefully will not run afoul of securities regulations.\n==Keep in mind that this process is intended for certain crypto startups buildingÂ applicationsÂ on smart contract platforms.** Itâ€™s less useful for blockchain computing platforms themselves, which require sufficient decentralization from inception in order to be useful.**\nThe answer is thatÂ community participation and controlÂ results in limited platform risk â€” the risk that the rules of a platform will change against the will of its users\nThe Three Components of Crypto Success\n==1. Product/market fit\n=2. Community participation\n=3. Sufficient decentralization (community ownership)\nThe need forÂ product/market fitÂ is obvious. Without a product people want, there are no users, no business, and it will be difficult to sustain a community for long. ==Community participation and decentralized control are less applicable to traditional startups, but are crucial for crypto startups. Why are they so important?\n==The answer is thatÂ community participation and controlÂ results in limited platform risk â€” the risk that the rules of a platform will change against the will of its users. Web 2.0 platforms have demonstrated the potential for this kind of misalignment, for example by killing innovative app ecosystems built on their APIs, or by profiting at the expense of usersâ€™ privacy or wellbeing. In contrast, user-owned networks can benefit from aÂ cooperative economic modelÂ that helps ensure crypto services remain better aligned with their users, even as they scale.\nAnother important reason for achieving decentralized community control is regulatory compliance**.**Â ==Crypto tokens that facilitate economic alignment can be deemed securities under theÂ Howey Test, a regulatory framework used by the SEC. Managing a distribution of securities to a large community of users can be challenging and expensive for a startup to manage â€” even Airbnb and UberÂ havenâ€™t figured out how to do it.\n==But analysis of recent SEC commentary and enforcement actions suggests that true decentralization may enable a startupâ€™s token to transmute from a security to a non-security if the team is able to sufficiently decentralize operations, eliminating information asymmetry or dependency on the efforts of the founding team to create value.\nThe idea of a core team controlling all aspects of a project may ruffle the feathers of some early users, but founders shouldnâ€™t be wary of this.\nThat said, itâ€™s important to communicate clearly about where control exists. Faking autonomy is a quick way to undermine trust, whereas transparency is a way to build it.\nObjective 2: Community Participation\nAt early signs of product traction â€” a growing user base, developer ecosystem and network effects â€” itâ€™s time to start devoting more cycles to fostering harmony between passive users, more-active contributors and the core team.\n==To start, founders might invest more heavily in best practices for running the product like an open source project: invest in good documentation; develop openly; offer bounties, grants or other incentives for third-party development; hire community leaders to help steward open development; and introduceÂ rough consensusÂ on decision makingâ€™\n==Going further, it may make sense to start eliminating platform risk through imposed technical constraints. For example, in Compound v2.2,Â upgrades take effect 48 hours after they are pushed, allowing time for users to exit the protocol, or review and voice dissent. Urbit practices â€œKelvin versioning,â€ in which version numbers countÂ downwardsÂ to 0, at which point no more updates are to be made.\nIncentives (Fees)\nAn economic incentive is one way to engender community contribution. But where do the economics come from? A pragmatic and familiar business model for crypto services is a fee-per-call, similar to an API micro-service like Twilio or Stripe. Distributing this fee stream to active contributors can align the community around the projectâ€™s success.\nDistribution (Tokens)\n==To start, teams might test a distribution with a managed and permissioned group of community members. A number of teams have elected to do this by allocating a slice of future tokens to early â€œpowerâ€ contributors, for example through testnet programs where independent community members can register to participate in operating a node. A promissory and managed token distribution to users that contribute valuable work can help eliminate community dependency on the effort of founding teams.\n==Next, teams need to plan how remaining tokens will be distributed to participants, both fairly for past contributions, and effectively as a future incentive for ongoing participation**.**Â The distribution design needs to consider the core team that built the product, as well as the users that make it useful. Getting this right is hard, and will always be specific to the application in question, but some common questions to think through are:\n\nWhat percentage of tokens should be allocated to the initial team and cap table?\nHow will you reward different types of contributors to the product or service, historically and in the future?\nHow will technology leadership be rewarded going forward?\n\nObjective 3: Sufficient Decentralization\nIn practice, I imagine teams will â€œexit to the communityâ€ by airdropping tokens to users and contributors based on the plan mapped out in the prior objective. This would happen the moment a smart contract is triggered to mint and distribute tokens. Optimally, once this function is triggered a number of things will have happened:\n\nThe core team will have ceded majority ownership of the application (fees and control) and mitigated platform risk by ensuring the product is community-owned and operated.\nThe token may have transmuted to a non-security, given that the service is now sufficiently decentralized â€” that is, independent of the efforts of a single entity that might have asymmetric information.\nThe company is sustainable, having retained enough tokens to benefit from fees and growth.\nUser-owners realize increasing returns to scale, as the cooperative economics of the service allow for better alignment and growing value (as defined by users rather than shareholders.)\n\nHow to Avoid Getting Stuck\n==For instance, app teams that pursue community ownership first (starting with a wide token distribution) risk engendering a community of speculators, rather than real users. Without a working product, ownership is worthless, and the community wonâ€™t stick. Many teams that have done this are unable to back into product/market fit, and as a result have a hard time kickstarting meaningful community participation.\n==Another sequencing risk is jumping straight from early signs of product/market fit to decentralized community ownership (skipping objective 2, community participation.) Failing to formalizeÂ realÂ community participation can land projects in an uncanny valley of decentralization theater. A symptom of being caught here is an apathetic community with low participation rates, and a heavy dependency on founding teams. In this situation, formalizing control (e.g. through delegation) may be a better path to building trust, whereas hiding under the pretense of decentralization is a quick way to undermine it."},"Articles--and--Papers/Decentralization/The-Value-of-Decentralization-Using-The-Blockchain":{"slug":"Articles--and--Papers/Decentralization/The-Value-of-Decentralization-Using-The-Blockchain","filePath":"Articles & Papers/Decentralization/The Value of Decentralization Using The Blockchain.md","title":"The Value of Decentralization Using The Blockchain","links":["Articles--and--Papers/Decentralization/PAPER-The-Value-of-Decentralization-Using-The-Blockchain-by-Marco-Reuters","Assuming-that-users-are-smart,-a-rational-entrepreneur-will-decentralize-a-new-network-that-she-is-building-when-the-locked-in-effects-for-her-users-are-high"],"tags":["decentralization"],"content":"Source: PAPER The Value of Decentralization Using The Blockchain by Marco Reuters\nSummary\nIn this paper, the researcher proves mathematically that it makes sense for an entrepreneur to decentralize her network, ceding control to users via governance, when the locked-in effects are high. A prime example of a locked-in effect is switching costs.\nIn a centralized network, as the network effects grow, and users get locked-in, the entrepreneur rationally wants to exploit users by charging them fees or showing more advertisements. For established centralized networks like GAFA, their network effects are already very strong so they wonâ€™t decentralize. But for new networks, decentralization makes sense when locked-in effects are high.\nIf a network has high locked-in effects, making it hard for users to switch to another network, the entrepreneur should make a credible commitment to users by allowing them to make monetization decisions. That way, users are assured the entrepreneur will not exploit them.\nNotes\nAssuming that users are smart, a rational entrepreneur will decentralize a new network that she is building when the locked-in effects for her users are high\nIntroduction\nVitalik Buterin, co-founder of the Ethereum blockchain, argues that ==decentralization is, among other things, useful for Collusion resistance â€” it is much harder for participants in decentralized systems to collude to act in ways that benefit them at the expense of other participants, whereas the leaderships of corporations and governments collude in ways that benefit themselves but harm less well-coordinated citizens, customers, employees, and the general public all the time.\nWith that, I provide an answer to a question that is frequently raised when it comes to the topic of blockchain and cryptocurrencies: Why would anybody use it? As the core friction at play, I assume that ==users of the network are subject to a locked-in effect, for example due to switching costs.3f the frictions that arise due to the potential of exploiting this locked-in effect by the entrepreneur are sufficiently large, I show that an entrepreneur prefers decentralizing her network. As a result, she effectively gives up control of the network and thus generates commitment to not abuse the locked-in effect of the users.\nHowever, decentralization also comes at a cost for the entrepreneur: she surrenders the control of the network to the users and, to align incentives, engages in revenue sharing. \nTherefore, there is a trade-off between the costs of centralization and decentralization. I show that if the locked-in effect is small, an entrepreneur should implement her network in a centralized manner. On the other hand, ==if the locked-in effect is sufficiently large, an entrepreneur should implement her network in a decentralized\nmanner.=\nGiven this result, the list of companies with decentralized counterparts is not surprising. Arguably, users of AWS, Facebook, and other tech companies are subject to\nparticularly large locked-in effects.\n==The entrepreneur is purely interested in generating revenue through monetization, while the usersâ€™ utility consists of three parts: First, they derive utility from using the network. Second, they dislike monetization such as advertisements, and third, they benefit from any revenue that is shared with them. I use sub-game perfect equilibria to analyze the game.\n==Therefore, an entrepreneur using a centralized implementation of the network is unable to credibly commit to future levels of monetization and revenue sharing. Instead, her choice of monetization and revenue sharing has to be sequentially optimal for every history of the game given the strategy of the users.\n==I divide the analysis of the model into three subsections. First, the sub-game of centralized governance. Second, the sub-game of decentralized governance and third,\ndetermining the optimal governance structure for the network.\nModel\n==If the entrepreneur chooses decentralized governance, she commits, without loss of generality, to a fixed percentage Î± of revenue sharing in t = 0 through the tokenomics of the network. She achieves this through the appropriate distribution of the networkâ€™s token between herself and the users.\n==In every period t = 1, 2, â€¦ the users of the network determine the amount of monetization Ï€t through on-chain governance. Regardless of the mode of governance, each period, users have a binary choice. Newly arriving users can join or not join the network. Existing users can stay in the network or leave the network. Users that decide to leave the network or newly arriving users who decide not to join the network exit the game and realize the value of their outside option.\nGrowth\nEvery period, new potential users become aware of the network. Let Î¼tâˆ’1 be the mass of users in the network in period t âˆ’ 1. Then, in period t there will be a mass\nof g(Î¼tâˆ’1) âˆ’ Î¼tâˆ’1 â‰¥ 0 new users who become aware of the network. Each potential new user can join or not join the network. For example, if all new users join, the new measure of users in the network is equal to g(Î¼tâˆ’1). If no new user joins, the network remains at Î¼tâˆ’1 users. If only some users join, the network will have a size in between these two.\nThe growth function g is continuously differentiable and the mass of users in period 0 is\nset to Î¼0 = 0. I assume that if the network loses all its users within a period, no new\nusers will arrive at any point in the future. This assumption rules out cyclical equilibria\nin which the entrepreneur continuously â€starts overâ€. There is complete information and\nboth the entrepreneur and the users observe the full history of the game.\nPreferences\nThe entrepreneur is strictly interested in revenue: her utility in a particular period t is equal to her revenue share Î±t multiplied by the revenue raised by monetization Ï€tÏ•(Î¼t): uEt = Î±tÏ€tÏ•(Î¼t). The utility a user receives from participating\nin the network has three components: First, a user derives utility V (Î¼t) from using the network. I assume that V is increasing, i.e. there are network effects, it is continuously differentiable and that V (0) = 0. Second, as a result of the monetization of the network, Ï€t, the userâ€™s utility decreases by kÏ€2t , where k &gt; 0 describes the userâ€™s aversion to monetization. This represents the decrease in utility a user suffers when being forced to watch advertisements, through the sale of his data, or other detrimental effects of monetization. As a third component, a user may potentially receive a share of the revenues that the network generates.\nThe utility function of a user equals the sum of these three components: ut = V (Î¼t)âˆ’kÏ€2t + (1âˆ’Î±t)Î¼t Ï€tÏ•(Î¼t).\nLocked-in effects\nA user who newly arrives in the network can decide to join\nthe network and realize the utility as described above. If the user decides not to join the\nnetwork, he realizes an outside option that is normalized to 0. A user who has already\ntaken part in the network for at least one period can decide to stay in the network, re-\nalizing the utility of participating, or leave the network. However, the outside option for\nthese users is equal to âˆ’u &lt; 0. Thus, users that already take part in the network suffer\nfrom a locked-in effect. This assumption represents the idea that users have spent time\ninteracting with the network, such that its algorithm has adapted to their needs.14 An\nequivalent interpretation is that the value of the outside option has remained constant,\nbut users encounter a switching cost equal to u when leaving the network in favor of the outside option.\nBoth the entrepreneur and the users maximize the sum of their discounted utilities.\nFuture utilities are discounted by a common discount factor Î´ âˆˆ (0, 1). I divide the analysis into subsections dedicated to the sub-games of centralized and decentralized\ngovernance. Within those sections, I provide a detailed description of the structure of the sub-games of centralized and decentralized governance. Then I derive the sub-game perfect Nash equilibria and discuss their properties. Finally, I determine the optimal decision of the entrepreneur at the start of the game: to implement her network with centralized or decentralized governance.\nGrowth vs. exploitation\nTo derive the equilibrium of the centralized governance sub-game, it is instructive to consider the entrepreneurâ€™s incentives to grow her network. Every period, new users arrive to potentially join the network. For the network to grow, joining the network has to be weakly beneficial for a newly arriving user. That is, joining the network has to yield at least utility equal to 0. Instead of growing the network, the entrepreneur can exploit the existing users. Given that existing users are locked into the network and have an outside option that is valued at âˆ’u &lt; 0, the entrepreneur can potentially achieve a higher level of revenue when focusing on extracting additional revenue from existing users. To quantify the revenue that an entrepreneur generates when she decides to exploit the users in her network, consider some period t. The amount of existing users at the start of the period is equal to Î¼tâˆ’1. If she exploits the existing users forever, the present value of the stream of her discounted future revenue equals the point at which the entrepreneur is indifferent between growing the network one last\ntime and exploiting the existing users in her network will be crucial for the analysis of\nthe equilibrium. I denote this point of indifference by Â¯Î¼. It is defined as the solution to the following equation:\n1 âˆ’ Î´ Ïˆ(Â¯Î¼, âˆ’(1 âˆ’ Î´)u) = Ïˆ(g(Â¯Î¼), Î´u) + Î´\n1 âˆ’ Î´ Ïˆ(g(Â¯Î¼), âˆ’(1 âˆ’ Î´)u)\nIt is exactly at the network size Â¯Î¼ where the entrepreneur is indifferent between growing the network one last time and then exploiting the users in the future, and exploiting the users right away. It highlights the trade-off between exploiting the locked-in effect of a smaller mass Î¼tâˆ’1 of users starting today, or, growing the network at the cost of providing utility Î´u to the users to then exploit a larger network with g(Î¼tâˆ’1) users starting tomorrow.\nThe key feature is the idea, that user growth will slow down over time. For example, if the overall pool of potential users is limited and a large amount of users has already\njoined the network, user growth necessarily slows down mechanically over time.\nStrategies\nDefinition 1 (Grow-then-exploit strategy)\nThe entrepreneurâ€™s strategy has three distinct parts. If g(Î¼tâˆ’1) &lt; Â¯Î¼, the entrepreneur will\ngrow the network again in the next period, as g(Î¼tâˆ’1) = Î¼t &lt; Â¯Î¼. Thus, the entrepreneur sets user utility equal to Ë†ut = 0 and the users are willing to join the network. Note that in\nthese growth periods, the entrepreneur has basically regained commitment to not abuse\nthe locked-in effect of the users. The entrepreneur refrains from exploiting the locked-in\neffect of the existing users in the network with the aim to grow the network larger.\nDefinition 2 (Join-if-compensated strategy)\n==The usersâ€™ strategies obey the following rationale: when they newly arrive at the network, they do not suffer from a locked-in effect. They observe the network size and if\ng(Î¼tâˆ’1) &lt; Â¯Î¼, anticipate that the entrepreneur will grow the network further in the future, such that it is optimal for them to join the network if Ë†ut â‰¥ 0. If Î¼tâˆ’1 &lt; Â¯Î¼ and Â¯Î¼ â‰¤ g(Î¼tâˆ’1),\nthey know that the entrepreneur will grow the network just one last time. As such, they require a level of utility Ë†ut â‰¥ Î´u to join the network. If they are already locked into the\nnetwork, they will remain in the network if Ë†ut â‰¥ âˆ’(1 âˆ’ Î´)u, as this implies that the discounted value of their futu e utility is at least equal to the value of their outside option âˆ’u\nNaturally, as a next step, I formally establish that these strategies constitute a sub-\ngame perfect Nash equilibrium:\nProposition 1 Suppose that the network is sufficiently profitable at size Â¯Î¼ to ensure utility level Î´u to its users, i.e. inequality II.4 is satisfied. ==Then, there is a sub-game\nperfect Nash equilibrium in which the entrepreneur plays according to the grow-then-exploit strategy and the users play the join-if-compensated strategy.\n==The entrepreneurâ€™s main issue in the network with centralized governance is her lack of commitment to not abusing the locked-in effect of the user.\nII.B Decentralized Governance\nThe equilibrium highlights that decentralized governance is an effective commitment tool\nfor the entrepreneur. ==In contrast to centralized governance, the users can be certain that\ntheir locked-in effect will not be exploited by the entrepreneur.\n==Thus, new users will continue to join the network every period. However, for the entrepreneur, this commitment comes at a substantial cost: she shares half the revenues of the network with her users.\nNonetheless, it is necessary for her to share revenue with her users. If she would not share\nany revenue, the users would subsequently vote to stop the monetization of the network.\nAs a result, the entrepreneur would not receive any revenue. Therefore, sharing revenue\nin a decentralized implementation of the network is necessary, as it aligns the incentives\nof the entrepreneur and the incentives of the networkâ€™s users.\n==One potential point of contention in decentralized governance could be conflicts of\ninterest between existing and newly arriving users. The usersâ€™ utility function equals V (Î¼t) âˆ’ kÏ€2t + 1âˆ’Î± Î¼t Ï€tÏ•(Î¼t). The share of revenue that each user gets in the network is 1âˆ’Î±Î¼t .\nAs such, newly arriving users dilute the revenue shares of existing users in the network.\nHowever, note that the usersâ€™ per period utility in the equilibrium equals V (Î¼t) + Ï•(Î¼t)2\n8kÎ¼2t.\n==Since Ï•(Î¼t)Î¼t is non-decreasing by assumption, the equilibrium utility is increasing in Î¼t. Intuitively speaking, the network effects that accompany the entry of new users sufficiently compensate the dilution of the revenue share of existing users. Thus, there is no incentive for existing users to try to prevent entry from newly arriving users to avoid dilution of their revenue shares.\nOptimal Governance\nThe two preceding sections have solved the sub-games of centralized and decentralized\ngovernance. But the main question remains: which form of governance the entrepreneur\nshould choose when she creates her network?\n==However, a complete comparison between the entrepreneurâ€™s revenue in centralized and decentralized governance remains. That is, what is the optimal mode of governance for any arbitrary size of the locked-in effect? To answer this question, I start by considering the opposite extreme, namely when the locked-in effect is very small. Then, I move to locked-in effects of arbitrary size.\nII.D Welfare\n==Finally, I want to address the welfare implications of the governance decision. In particular: When does decentralization improve welfare?\nPareto efficiency. It turns out that the analysis that has been conducted so far\nis sufficient to compare the modes of governance in terms of Pareto efficiency.\n==First, note that users in the centralized implementation of the network are always indifferent between joining the network and their outside option ex-ante.  Thus, their equilibrium utility is 0.\n==In contrast, users receive strictly positive utility in the decentralized implementation of the network. Ergo, users always prefer decentralized governance. For the entrepreneur, proposition 3 has established that she prefers decentralization if and only if the size of\nthe locked in effect u is larger than the threshold uâˆ—âˆ—. Therefore, the following corollary\ncan be established:\n==Corollary 2 Decentralized governance of the network is a Pareto improvement over centralized governance if and only if the size of the locked-in effect u is larger than u**\nDiscussion\nIII.A Airdrops: Decentralizing at a Later Time\nThe main concern is once again commitment, that is, the entrepreneur is unable to commit that she will\ndecentralize the network in the future. Instead, it has to be sequentially optimal for her to decentralize the network. Intuitively, there is a tension between delaying decentralization for a while and delaying it for too long, when staying in control and exploiting the users becomes too tempting.\nIV Conclusion\nBefore concluding, I want to briefly discuss some further points of interest. First, one might wonder if this model implies that an established network such as Google\nor Facebook should decentralize their business through a blockchain. Such a conclusion cannot be drawn from this model, as these networks have already established a large\namount of users (e.g. Facebook already has around 3 billion users20). ==As such, the value of extracting additional revenues from existing users that are already locked-in may outweigh the value of commitment that is offered by a decentralized implementation. In contrast, the model provides insights on the optimal governance of newly founded networks.\n==To summarize, this paper provides an answer to a question that is frequently raised when it comes to the topic of blockchain and cryptocurrencies: Why would anybody use\nit? As the main result, I showed that (i) an entrepreneur prefers to decentralize her network and (ii) decentralization is a Pareto improvement, if and only if the locked-in effect is sufficiently large. To broaden our understanding of further implications of decentralization, I believe that further research is needed, especially regarding the economics\nof decentralized governance and competition between centralized and decentralized networks."},"Articles--and--Papers/Decentralization/The-hidden-dangers-of-the-decentralized-web":{"slug":"Articles--and--Papers/Decentralization/The-hidden-dangers-of-the-decentralized-web","filePath":"Articles & Papers/Decentralization/The hidden dangers of the decentralized web.md","title":"The hidden dangers of the decentralized web","links":[],"tags":[],"content":"Source:\nwww.wired.com/story/the-hidden-dangers-of-the-decentralized-web/"},"Articles--and--Papers/Decentralization/When-is-decentralizing-on-a-blockchain-valuable-by-Marco-Reuter":{"slug":"Articles--and--Papers/Decentralization/When-is-decentralizing-on-a-blockchain-valuable-by-Marco-Reuter","filePath":"Articles & Papers/Decentralization/When is decentralizing on a blockchain valuable by Marco Reuter.md","title":"When is decentralizing on a blockchain valuable by Marco Reuter","links":["tags/"],"tags":[""],"content":"Source: When is decentralizing on a blockchain valuable\nNotes\nAssume users are smart.\nSmart users expect Internet platforms â€” Facebook, Twitter, Airbnb, Amazon â€” to take advantage of them. To exploit them.\nx\nSmart users want compensation, monetary or a perk, to get them to use the protocol or app. Smart users know they are being locked in â€” the switching costs are high, the network effects are great. So they&#039;re fine with being exploited as long as they get something for it. \nTwitter is a good example. Smart users hate Twitter yet there is a high switching cost. So users stay on this platform that exploits them.\n==The future of applications though should be decentralized because decentralization helps to prevent user exploitation. ==\nIn the a16z article, he argues that decentralization is valuable when the lock-in effect is strong. Users know they will be locked in so they need a carrot to entice them to stay. That carrot can be governance. \nAn entrepreneur is enticed to monetize when the time is right. Monetization however can make users leave or have new users not join. You donâ€™t want to monetize too soon. An entrepreneur with strong lock-in effects will be tempted to exploit their users. Users will not have a choice but to stay.\nOne big responsibility of an entreprenuer is to monetize their platform. When to do it though? Itâ€™s easy to exploit users like when market research shows that you can start to sell ads or charge fees. Users donâ€™t want this. So with a decentralized platform you can offload the monetization decisions to users. This is credible commitment.\nNow users decide when to bring in ads or when to charge fees. Ofc users won&#039;t exploit themselves. They&#039;ll be in charge of monetization. Even if they are locked in, they know the rules won&#039;t change up on them later or they won&#039;t start to get fees or rugged. \n\n\n                  \n                  NOTE\n                  \n                \n\n\nMy metaphor: Decentralized governance is the carrot for a business with strong lock-in effects.\n\n\n\nMonetization is linked to growth. When the network is growing a lot, you donâ€™t want to monetize because you will lock out new users. But when growth slows down, you want to take advantage of locked in effects with existing users.\nUsers have become so used to being subject to the whims of Web2 platforms, they expect to be exploited. So they want to be compensated beforehand, monetary or with little ads. But this is costly. So in a centralized system you have to pay users upfront. \nIn a decentralized system, users donâ€™t need to be compensated beforehand. Because they control monetization decisions and know you wonâ€™t exploit them.\nUpfront compensation is the carrot to not exploiting users later. You need to share revenues with users.\nDecentralized governance with airdropped tokens, revenue sharing, governance tokens, is making a commitment to users that they will not exploited. \nBut only delegates have sufficient voting power. So users will pick delegates who are like them, who are watching out for their interests. What are the interests of most token holders? What are interests of liquidity providers? Of all the stakeholders?\nQuotes\n\nIf you want to create a â€œnew Facebookâ€ or â€œnew Google,â€ should you use a regular company or leverage a decentralized implementation through a blockchain? The answer may seem straightforward: crypto enthusiasts would answer with a resounding â€œyes,â€ while skeptics shake their heads. But the decision has less to do with faith than with practical market design considerations.\n\n\nThe fundamental question is how, precisely, decentralization through a blockchain can bring value to your business. In this article, I will guide you through an analysis of this question thatâ€™s rooted in economic theory and provide some insights to inform your decision.\n\n\nLike all models in economics, mine is built on several simplifying assumptions, which may not be applicable in all contexts. But the simplified model nevertheless helps uncover key sources of value for blockchains, and also helps characterize the context in which when decentralization may or may not be valuable.\n\n\nAt the center of this analysis is the â€œlocked-in effectâ€. Users may incur switching costs â€“ the cost of the annoyance of setting up an account in another network\n\n\nAlternatively, users may find leaving less attractive after they have spent time and effort training the algorithm of the network to adapt to their needs â€“ think how Google learns from your past searches and personalizes search results to match your interests. Additionally, locked-in effects can be exacerbated by network effects that can give large networks significant advantages over competitors. Locked-in effects are inherent to many businesses, but their size varies case-by-case.\n\n&gt; For the business owner, locked-in effects come with a temptation to exploit locked-in users to increase profits. Suppose you own a company that has millions or potentially even billions of users and market research indicates that you can increase monetization â€“ perhaps through advertising or charging higher platform fees â€“ without losing customers. What would you do? A game theoretic analysis (and, quite frankly, common sense) predicts that you should increase monetization.\nUsers are smart and know that you will exploit them later by charging high fees or ads or something else.\n\nThe obvious danger, though, is that users may know that they can become locked-in and donâ€™t want to be exploited. If you canâ€™t credibly commit to not exploiting them (and you often canâ€™t), then rational users, in my model, would demand â€œcompensationâ€ upfront. Such compensation might be monetary, but it can also take the form of no or very little advertisement during the growth phase of the network. Alternatively, users may refuse to join the network at all for the fear of being locked-in.\n\n\nThe key insight when considering using a blockchain, though, is that it allows you to generateÂ credible commitmentÂ through the design of the network. That is, you surrender control over monetization decisions to the users, enabling them to decide it through decentralized governance. This means that users can safely join the network because they arenâ€™t worried about it being exploited later, even if they do get locked in.\nhey user, weâ€™ll give you free tokens and perks at the beginning but by also giving you governance rights, you donâ€™t have to worry about being exploited. As long as the governance system is sufficiently capture resistant, you can make decisions. So we may sell ads later of charge fees but you can make those decisions?\nThis leads to the main result of my analysis:Â It makes sense to decentralize your business using a blockchain when the locked-in effect is sufficiently strong.\n\nThe model: game-theoretic analysis\n\nIf you decide to implement the network through a regular company, you can change the intensity of monetization daily as you deem fit. If you decentralize the network through a blockchain, users will decide on the intensity of monetization through on-chain voting.\n\n\nNow we can solve the model through backward induction. That is, we look at the game-theoretic predictions for centralized and decentralized governance, which will show which mode of governance you should choose at the inception of your network to maximize profits.\n\nChoosing centralized governance\n\nCentralized governance allows you, the entrepreneur, to decide the level of monetization in every period. Two levels of monetization seem reasonable intuitively: first, a low level of monetization such that new users are willing to join, or a higher level of monetization that, while off-putting to new users, is not so high that it makes the the existing, locked-in users leave.\nThe monetization strategy that is more profitable depends crucially on the networkâ€™s growth prospects. When future growth is sufficiently strong, you are incentivized not to exploit the locked-in effect because you want to maintain network growth. But when growth slows down sufficiently, it makes more sense to forego network growth in favor of exploiting the locked-in effect of existing users by increasing monetization.\n\n\nHowever, in equilibrium, users â€“ having been subject to the whims of Web2 platforms for so many years â€“ have gotten smart and anticipate future exploitation. They therefore insist on being â€œcompensatedâ€ beforehand (in my model, compensation might be monetary, but it can also take the form of little or no advertisement during the growth phase of the network, for example), which is costly to you. Thus, the control over monetization that you retain in centralized governance serves as both the advantage and the disadvantage of centralization. You can freely increase monetization to increase profits. However, you canâ€™t commit to future monetization choices but will instead do what is optimal at each particular moment.\n\n Decentralizing using a blockchain\n\nThe tradeoffs are clear. If users have control over monetization, then you cannot exploit the usersâ€™ locked-in effect, and they will not exploit their own locked-in effect either. As such, users do not need to be wary of future exploitation and need not be â€œcompensatedâ€ beforehand. Thus, the network will be able to grow continuously rather than experience a growth phase followed by an exploitation phase.\n\n\nYet surrendering control and giving away governance tokens imposes serious costs. First, you cannot choose monetization of the network. Second, you have to share revenues with the users through the governance tokens. This is necessary to align the incentives between you and the users. If you did not share any revenues, users would not wantÂ anyÂ monetization of the network.\n\nShould you decentralize at the start?\n\nWithout the locked-in effect, though, there is also no lack of commitment. This eliminates the disadvantage from centralization, and only the advantages remain. As a result, centralization will generally be preferred if there are no locked-in effects or if they are very small.\n\n\nIf locked-in effects are very large, it may not even be possible to attract users to the network. In particular, the threat of exploitation in the future may be too substantial to overcome, even if you did offer monetary compensation or to not monetize the network during the growth phase. In this case, decentralization is clearly preferable, as only then users can be attracted to the network.\n"},"Articles--and--Papers/Decentralization/Why-Decentralization-Matters,-Chris-Dixon":{"slug":"Articles--and--Papers/Decentralization/Why-Decentralization-Matters,-Chris-Dixon","filePath":"Articles & Papers/Decentralization/Why Decentralization Matters, Chris Dixon.md","title":"Why Decentralization Matters, Chris Dixon","links":["tags/processed","Decentralized-platforms-win-because-unlike-their-centralized-counterparts-they-don't-exploit-users-and-they-don't-bait-and-switch-builders-and-creators","Decentralized-platforms-tend-to-come-half-baked-unlike-their-polished-and-bundled-centralized-counterparts","Typical-lifecycle-for-centralized-platforms-is-to-extract-from-users-and-market-participants-(businesses,-creators,-developers)-as-they-go-up-the-S-curve-of-adoption","Regulation-is-effective-for-centralized-platform-monopolies-that-create-hardware-(telecom,-phone,-radio,-tv)-but-less-necessary-for-the-Internet-(software-stack)-because-it-can-be-rearchitected","Decentralized-protocols-use-two-mechanisms-to-prevent-bait--and--switch-of-their-centralized-counterparts:-(1)-open-source-code-and-(2)-checks-and-balances-with-voice-and-exit","Graphics/Dangers-of-building-and-using-centralized-platforms","Bitcoin"],"tags":["processed"],"content":"processed\nSource: cdixon.org/2018/02/18/why-decentralization-matters\nSummary\nDecentralization matters for builders, creators, and users because centralized platforms have proven to eventually exploit as they seek profit. Centralized platforms change up the rules on 3rd parties. Crypto networks are better because they create incentives via crypto economics that make it better for people to build and stick around for the long term. \nCentralized platforms bait and switch builders and creators. And create social tensions like privacy issues, fake news, de-platforming, for users. They have a predictable lifecycle as they go up the S-curve and start to extract users and compete with developers, creators, and businesses. \nDecentralized platforms tend to come half-baked, unlike their polished and bundled counterparts, which creates skepticism amongst the experienced. But decentralized platforms get ahead as they attract more developers. \nNotes\nDecentralized platforms win because unlike their centralized counterparts they donâ€™t exploit users and they donâ€™t bait and switch builders and creators\nDecentralized platforms tend to come half-baked unlike their polished and bundled centralized counterparts\nTypical lifecycle for centralized platforms is to extract from users and market participants (businesses, creators, developers) as they go up the S-curve of adoption\nRegulation is effective for centralized platform monopolies that create hardware (telecom, phone, radio, tv) but less necessary for the Internet (software stack) because it can be rearchitected\nDecentralized protocols use two mechanisms to prevent bait &amp; switch of their centralized counterparts: (1) open source code and (2) checks and balances with voice and exit\nQuotes\nThe first two eras of the internet\nDuring the first era of the internet â€” from the 1980s through the early 2000s â€” internet services were built on open protocols that were controlled by the internet community. ==This meant that people or organizations could grow their internet presence knowing the rules of the game wouldnâ€™t change later on. Huge web properties were started during this era including Yahoo, Google, Amazon, Facebook, LinkedIn, and YouTube. In the process, the importance of centralized platforms like AOL greatly diminished.\nDuring the second era of the internet, from the mid 2000s to the present, for-profit tech companies â€” most notably Google, Apple, Facebook, and Amazon (GAFA) â€” built software and services that rapidly outpaced the capabilities of open protocols. ==The explosive growth of smartphones accelerated this trend as mobile apps became the majority of internet use. Eventually users migrated from open services to these more sophisticated, centralized services. Even when users still accessed open protocols like the web, they would typically do so mediated by GAFA software and services\nThe good news is that billions of people got access to amazing technologies, many of which were free to use. ==The bad news is that it became much harder for startups, creators, and other groups to grow their internet presence without worrying about centralized platforms changing the rules on them, taking away their audiences and profits. This in turn stifled innovation, making the internet less interesting and dynamic. Centralization has also created broader societal tensions, which we see in the debates over subjects like fake news, state sponsored bots, â€œno platformingâ€ of users, EU privacy laws, and algorithmic biases. These debates will only intensify in the coming years.\nâ€œWeb 3â€: the third era of the internet\nOne response to this centralization is to impose government regulation on large internet companies. This response assumes that the internet is similar to past communication networks like the phone, radio, and TV networks. But the hardware-based networks of the past are fundamentally different than the internet, a software-based network. Once hardware-based networks are built, they are nearly impossible to rearchitect. ==Software-based networks can be rearchitected through entrepreneurial innovation and market forces.\n==The internet is still early in its evolution: the core internet services will likely be almost entirely rearchitected in the coming decades. This will be enabled by crypto-economic networks, a generalization of the ideas first introduced inÂ BitcoinÂ and further developed inÂ Ethereum. Cryptonetworks combine the best features of the first two internet eras: community-governed, decentralized networks with capabilities that will eventually exceed those of the most advanced centralized services.\nWhy decentralization?\n==Centralized platforms follow a predictable life cycle. When they start out, they do everything they can to recruit users and 3rd-party complements like developers, businesses, and media organizations. They do this to make their services more valuable, as platforms (by definition) are systems with multi-sided network effects. As platforms move up the adoption S-curve, their power over users and 3rd parties steadily grows.\nDangers of building and using centralized platforms\n](cdixon.org/static/6acb0932610c3553e96e9b2e7766cc29/e1c95/07lrwGIDbAYk6q7zG.png)\n==When they hit the top of the S-curve, their relationships with network participants change from positive-sum to zero-sum. The easiest way to continue growing lies in extracting data from users and competing with complements over audiences and profits. Historical examples of this are Microsoft vs. Netscape, Google vs. Yelp, Facebook vs. Zynga, and Twitter vs. its 3rd-party clients. Operating systems like iOS and Android have behaved better, although still take a healthy 30% tax, reject apps for seemingly arbitrary reasons, and subsume the functionality of 3rd-party apps at will.\n==For 3rd parties, this transition from cooperation to competition feels like a bait-and-switch. Over time, the best entrepreneurs, developers, and investors have become wary of building on top of centralized platforms. We now have decades of evidence that doing so will end in disappointment. In addition, users give up privacy, control of their data, and become vulnerable to security breaches. These problems with centralized platforms will likely become even more pronounced in the future.\nEnter cryptonetworks\n==Cryptonetworks are networks built on top of the internet that 1) use consensus mechanisms such as blockchains to maintain and update state, 2) use cryptocurrencies (coins/tokens) to incentivize consensus participants (miners/validators) and other network participants. Some cryptonetworks, such as Ethereum, are general programming platforms that can be used for almost any purpose. Other cryptonetworks are special purpose, for example Bitcoin is intended primarily for storing value,Â GolemÂ for performing computations, andÂ FilecoinÂ for decentralized file storage.\nEarly internet protocols were technical specifications created by working groups or non-profit organizations that relied on the alignment of interests in the internet community to gain adoption. This method worked well during the very early stages of the internet but since the early 1990s very few new protocols have gained widespread adoption.Â ==Cryptonetworks fixÂ these problems by providing economics incentives to developers, maintainers, and other network participants in the form of tokens. They are also much more technically robust. ==For example, they are able to keep state and do arbitrary transformations on that state, something past protocols could never do.\n==Cryptonetworks use multiple mechanisms to ensure that they stay neutral as they grow, preventing the bait-and-switch of centralized platforms. First, the contract between cryptonetworks and their participants is enforced in open source code. Second, they are kept in check through mechanisms forÂ â€œvoiceâ€ and â€œexit.â€Â Participants are given voice through community governance, both â€œon chainâ€ (via the protocol) and â€œoff chainâ€ (via the social structures around the protocol). Participants can exit either by leaving the network and selling their coins, or in the extreme case by forking the protocol.\n==In short, cryptonetworks align network participants to work together toward a common goal â€” the growth of the network and the appreciation of the token. This alignment is one of the main reasons Bitcoin continues to defy skeptics and flourish, even while new cryptonetworks like Ethereum have grown alongside it.\n==Todayâ€™s cryptonetworks suffer from limitations that keep them from seriously challenging centralized incumbents. The most severe limitations are around performance and scalability. The next few years will be about fixing these limitations and building networks that form the infrastructure layer of the crypto stack. After that, most of the energy will turn to building applications on top of that infrastructure.\nHow decentralization wins\nSoftware and web services are built by developers. There are millions of highly skilled developers in the world. Only a small fraction work at large technology companies, and only a small fraction of those work on new product development. Many of the most important software projects in history were created by startups or by communities of independent developers.\nAn illustrative analogy is the rivalry in the 2000s between Wikipedia and its centralized competitors like Encarta. If you compared the two products in the early 2000s, Encarta was a far better product, with better topic coverage and higher accuracy. ==But Wikipedia improved at a much faster rate, because it had an active community of volunteer contributors who were attracted to its decentralized, community-governed ethos. By 2005, Wikipedia was the mostÂ popularÂ reference site on the internet. Encarta was shut down in 2009.\nThe lesson is that when you compare centralized and decentralized systems you need to consider them dynamically, as processes, instead of statically, as rigid products. Centralized systems often start out fully baked, but only get better at the rate at which employees at the sponsoring company improve them. Decentralized systems start out half-baked but, under the right conditions, grow exponentially as they attract new contributors.\nIn the case of cryptonetworks, there are multiple, compounding feedback loops involving developers of the core protocol, developers of complementary cryptonetworks, developers of 3rd party applications, and service providers who operate the network. ==These feedback loops are further amplified by the incentives of the associated token, which â€” as weâ€™ve seen with Bitcoin and Ethereum â€”== can supercharge the rate at which crypto communities develop (and sometimes lead to negative outcomes, as with the excessive electricity consumed by Bitcoin mining)\nThe question of whether decentralized or centralized systems will win the next era of the internet reduces to who will build the most compelling products, which in turn reduces to who will get more high quality developers and entrepreneurs on their side. ==GAFA has many advantages, including cash reserves, large user bases, and operational infrastructure. Cryptonetworks have a significantly more attractive value proposition to developers and entrepreneurs. If they can win their hearts and minds, they can mobilize far more resources than GAFA, and rapidly outpace their product development.\nCentralized platforms often come bundled at launch with compelling apps: Facebook had its core socializing features and the iPhone had a number of key apps. ==Decentralized platforms, by contrast, often launch half-baked and without clear use cases. As a result, they need to go through two phases of product-market fit: 1) product-market fit between the platform and the developers/entrepreneurs who will finish the platform and build out the ecosystem, and 2) product-market fit between the platform/ecosystem and end users. This two-stage process is what causes many people â€” including sophisticated technologists â€” to consistently underestimate the potential of decentralized platforms.\nThe next era of the internet\nCompare the problem of Twitter spam to the problem of email spam. Since TwitterÂ closedÂ their network to 3rd-party developers, the only company working on Twitter spam has been Twitter itself. By contrast, there were hundreds of companies that tried to fight email spam, financed by billions of dollars in venture capital and corporate funding. Email spam isnâ€™t solved, but itâ€™s a lot better now, because 3rd parties knew that theÂ email protocolÂ was decentralized, so they could build businesses on top of it without worrying about the rules of the game changing later on.\nOr consider the problem of network governance. Today, unaccountable groups of employees at large platforms decide how information gets ranked and filtered, which users get promoted and which get banned, and other important governance decisions. In cryptonetworks, these decisions are made by the community, using open and transparent mechanisms. As we know from the offline world, democratic systems arenâ€™t perfect, but they are a lot better than the alternatives.\n==Centralized platforms have been dominant for so long that many people have forgotten there is a better way to build internet services. Cryptonetworks are a powerful way to develop community-owned networks and provide a level playing field for 3rd-party developers, creators, and businesses. We saw the value of decentralized systems in the first era of the internet. Hopefully weâ€™ll get to see it again in the next"},"Articles--and--Papers/Ethereum-Staking/A-rollup-centric-ethereum-roadmap-(Oct.-2020)":{"slug":"Articles--and--Papers/Ethereum-Staking/A-rollup-centric-ethereum-roadmap-(Oct.-2020)","filePath":"Articles & Papers/Ethereum Staking/A rollup centric ethereum roadmap (Oct. 2020).md","title":"a rollup centric ethereum roadmap","links":[],"tags":["staking"],"content":"Source: ethereum-magicians.org/t/a-rollup-centric-ethereum-roadmap/4698\nLast week the Optimism teamÂ announcedÂ the launch of the first stage of their testnet, and the roadmap to mainnet. They are not the only ones;Â FuelÂ is moving toward a testnet andÂ ArbitrumÂ has one. In the land of ZK rollups,Â Loopring,Â ZksyncÂ 348Â and the Starkware-tech-basedÂ DeversifiÂ are already live and have users on mainnet. WithÂ OMG networkâ€™s mainnet beta, plasma is moving forward too. Meanwhile, gas prices on eth1 are climbing to new highs, to the point whereÂ some non-financial dapps are being forced to shut downÂ 983Â andÂ othersÂ 294Â are running on testnets.\nThe eth2 roadmap offers scalability, and the earlier phases of eth2 are approaching quickly, but base-layer scalability for applications is only coming as the last major phase of eth2, which is still years away. In a further twist of irony, eth2â€™s usability as a data availability layer for rollups comes in phase 1, long before eth2 becomes usable for â€œtraditionalâ€ layer-1 applications. These facts taken together lead to a particular conclusion:Â the Ethereum ecosystem is likely to be all-in on rollups (plus some plasma and channels) as a scaling strategy for the near and mid-term future.\nIf we start from this premise, we can see that it leads to some particular conclusions about what the priorities of Ethereum core development and ecosystem development should be, conclusions that are in some cases different from the current path. But what are some of these conclusions?\nThe Short Term: Advancing Eth1 for Rollups\nIn the short term, one major outcome of this is thatÂ Ethereum base-layer scaling would primarily be focused on scaling how much data blocks can hold, and not efficiency of on-chain computation or IO operations. The only determinant of the scalability of a rollup is how much data the chain can hold, and any increase beyond the current ~60 kB/sec will help increase rollupsâ€™ scalability further.\nThere are some things that would continue to matter at the base layer:\n\nEIP 2929Â 536, to ensure that the chain is safe against DoS attacks at current gas levels\nEIP 1559Â 369, both for the ETH burn and for the benefit of making it easy to send transactions that almost certainly get into the next block (which rollups still depend on for confirmations)\nNew elliptic curve precompiles, to fully support what people want to do with ZK rollups\nThe hex â†’ binary tree change and other changes to advance support for stateless clients (as stateless clients are valuable regardless of how the chain is being used)\n\nAccount abstraction is somewhat less important, because it can be implemented on L2 regardless of whether or not L1 supports it. Other â€œclever base layer featuresâ€ also become relatively less important.\nEth1 clients could be repurposed as optimistic rollup clients. Optimistic rollups still need to have full nodes, and if the rollupâ€™s internal state transition rules are essentially ethereum-like with a few modifications (as is the goal of eg. Optimism), then existing code could be repurposed to run these full nodes. The work of separating out the consensus engine from the state transition engine is already being doneÂ in the context of the eth1+eth2 mergeÂ 202, which can also help with this goal. Note in particular that this implies thatÂ projects like TurboGeth are still very important, except it would be high-throughput rollup clients, rather than base-layer eth1 clients, that would benefit the most from them.\nThe Short Term: Adapting Infrastructure for Rollups\nCurrently, users have accounts on L1, ENS names on L1, applications live entirely on L1, etc. All of this is going to have to change. We would need to adapt to a world where users have their primary accounts, balances, assets, etc entirely inside an L2. There are a few things that follow from this:\n\nENS needs to support names being registered and transferred on L2; seeÂ hereÂ 381Â for one possible proposal of how to do this.\nLayer 2 protocols should be built into the wallet, not webpage-like dapps. Currently, L2 integration into dapps/quasidapps (eg. Gitcoinâ€™s zksync integration) requires the user to fully trust the dapp, which is a great decrease in security from the status quo. We ideally want to make L2s part of the wallet itself (metamask, status, etc) so that we can keep the current trust model. This support should be standardized, so that an application that supports zksync payments would immediately support zksync-inside-Metamask, zksync-inside-Status, etc.\nWe need more work on cross-L2 transfers, making the experience of moving assets between different L2s as close to instant and seamless as possible.\nMore explicitly standardize on Yul or something similar as an intermediate compiling language. Ethereumâ€™s base-layer EVM and the OVM used in the Optimism rollup are slightly different compiling targets, but both can be compiled to from Solidity. To allow an ecosystem with different compiling targets, but at the same time avoid a Solidity monoculture and admit multiple languages, it may make sense to more explicitly standardize on something like Yul as an intermediate language that all HLLs would compile to, and which can be compiled into EVM or OVM. We could also consider a more explicitly formal-verification-friendly intermediate language that deals with concepts like variables and ensures basic invariants, making formal verification easier for any HLLs that compile to it.\n\nEconomic Sustainability Benefits of Rollup-Centrism\nItâ€™s an inescapable fact that a crypto project must be financially sustainable, and in 2020 this means millions or even tens of millions of dollars of funding. Some of this can be covered by common public-good-funding entities such as Gitcoin Grants or the Ethereum Foundation, but the scale of these mechanisms is just not sufficient to cover this level of funding. However, layer 2 projects launching their own tokenÂ isÂ sufficient - provided, of course, that the token is backed by genuine economic value (ie. prediction of future fees captured by the L2).\nAn important secondary benefit of a rollup-centric roadmap is that it leaves open space for L2 protocols, and these L2 protocols have the ability to collect fees/MEVÂ 218Â that can fund development, either directly or indirectly (by backing a token that funds development). The Ethereum base layer has an important need to be credibly neutral, making in-protocol public goods funding difficult (imagine ACD calls trying to agree on who deserves how much money), but L2s having their own public goods funding mechanisms (and/or contributing to Gitcoin Grants) is much less contentious. Leaving open this space can thus be a good strategic move for the long-term economic sustainability of Ethereum as a whole.\nIn addition to the funding issues, the most creative researchers and developers oftenÂ wantÂ to be in a position of great influence on their own little island, and not in a position of little influence arguing with everyone else on the future of the Ethereum protocol as a whole. Furthermore, there are manyÂ already existing projectsÂ trying to create platforms of various kinds. A rollup-centric roadmap offers a clear opportunity for all of these projects to become part of the Ethereum ecosystem while still maintaining a high degree of local economic and technical autonomy.\nThe Long Term\nIn addition to these short-term concerns, a rollup-centric roadmap could also imply a re-envisioning ofÂ eth2â€™s long-term future: as a single high-security execution shard that everyone processes, plus a scalable data availability layer.\nTo see why this is the case, consider the following:\n\nToday, Ethereum has ~15 TPS.\nIf everyone moves to rollups, we will soon have ~3000 TPS.\nOnce phase 1 comes along and rollups move to eth2 sharded chains for their data storage, we go up to a theoretical max of ~100000 TPS.\nEventually, phase 2 will come along, bringing eth2 sharded chains with native computations, which give usâ€¦ ~1000-5000 TPS.\n\nIt seems very plausible to me that when phase 2 finally comes, essentially no one will care about it. Everyone will have already adapted to a rollup-centric world whether we like it or not, and by that point it will be easier to continue down that path than to try to bring everyone back to the base chain for no clear benefit and a 20-100x reduction in scalability.\nThis implies a â€œphase 1.5 and doneÂ 497â€ approach to eth2, where the base layer retrenches and focuses on doing a few things well - namely, consensus and data availability.\nThis may actually be a better position for eth2 to be in, becauseÂ sharding data availability is much safer than sharding EVM computation. While dishonest-majority-proof verification of sharded EVM computation requires fraud proofs, which require a strict and potentially risky two-epoch synchrony assumption, data availability sampling (if done with ZKPs or polynomial commitments) is safe under asynchrony.\nThis will help Ethereum distinguish itself as having a stronger security model than other sharded L2 chains, which are all going in the direction of having sharded execution of some form; eth2 would be theÂ base layer thatâ€™s just powerful enough to have functionality escape velocityÂ 310, and no more powerful.\nWhat could eth2 focus on in the long run?\n\nStaggering block times on different shards, so that at any time there will always be some shard scheduled to propose a block within a few hundred milliseconds. This allows rollups that operate across multiple shards to have ultra-low latency, without the risks of the chain itself having ultra-low latency\nImproving and solidifying its consensus algorithm\nAdjusting the EVM to be more friendly to fraud proof verifications (eg. this could imply some kind of â€œframeâ€ feature that prevents code from breaking out of a sandbox or allows SLOAD/SSTORE to be remapped to using something other than account storage as their data source)\nZK-SNARKing everything\n\nCompromise Proposals\nIf you are not convinced to go â€œall the wayâ€ on the â€œphase 1.5 and doneâ€ direction, there is a natural compromise path to take: having a small number of execution shards (eg. 4-8) and many more data shards. The goal would be that the number of execution shards would still be low enough that in exceptional situations, regular computers would be able to fully validate all of them, but there would still be considerably more base-layer space than there is today.\nBase-layer space cannot be minimizedÂ tooÂ much, as users and applications still need it to eg. move between rollups, submit fraud proofs, submit ZK proofs in ZK rollups, publish root ERC20 token contracts (sure, most users will live in rollups, but the base contract has to liveÂ somewhereâ€¦), etc. And it would still be a large UX loss if those things cost $140 per transaction. Hence, if necessary, having 4-8 execution shards instead of 1 could provide significant relief. And it would still be possible for one computer to verify all shards; today, verifying eth1 blocks on average takes ~200-500 ms every 13 seconds, so verifying eight threads of such execution for short periods of time is completely feasible. One can imagine clients have policies like â€œif network latency appears low or committees are &gt;80% full, rely on fraud proofs and committees, under exceptional conditions verify all shards directlyâ€."},"Articles--and--Papers/Ethereum-Staking/Comparing-staking-options.-Native,-Pooled,-and-Liquid.-Finding-the-right-approach-for-you":{"slug":"Articles--and--Papers/Ethereum-Staking/Comparing-staking-options.-Native,-Pooled,-and-Liquid.-Finding-the-right-approach-for-you","filePath":"Articles & Papers/Ethereum Staking/Comparing staking options. Native, Pooled, and Liquid. Finding the right approach for you.md","title":"Comparing staking options. Native, Pooled, and Liquid. Finding the right approach for you","links":[],"tags":[],"content":"Source: www.kiln.fi/post/comparing-staking-options-native-pooled-and-liquid-finding-the-right-approach-for-you\nQuotes\nNative staking (solo staking)\nYou own the individual validator which will earn rewards that are solely for you, rewards are not shared with any other user in this case. Your 32 ETH is not mixed with other users and is deposited against your validator directly.\nâ€Rewards are not earned instantly after your initial staking transaction as there is an activation process enforced by the protocol. You may need to wait days, weeks (or months in extreme cases) before your validator is active. Similar to activation, there is a deactivation, and exit queue processes that may take days or weeks.\nNative staking is viewed as the least risky option when it comes to the staking landscape.\nValidator-as-a-Service\nOn the other hand, validator-as-a-service providers, like Kiln, offer the convenience of managing the validator on your behalf. They handle the technical aspects, maintenance, and ensure its smooth operation. In exchange for their services, they typically charge a commission on earned rewards.\nWhile different validator-as-a-service providers may have variations in their offerings and billing processes, their core purpose remains the same: to alleviate the burden of managing a validator and provide you with a hassle-free staking experience for a reasonable fee.\nBalancing rewards and accessibility: Locking ETH, bonding and unbonding periods\nAdditionally, itâ€™s important to be aware of the bonding and unbonding periods (known as validator entry, exit, and withdrawal queues). This refers to the time it takes for validators to enter and exit the system, as well as the withdrawal queue that processes the return of your 32 ETH. For most of this period your validator will not be earning any rewards while your 32 ETH remains inaccessible.\nAnother consideration is that ownership of the validator, as well as the withdrawal credentials, are permanently tied to the wallet from which you initiated the stake. You cannot transfer ownership, exit your validator, or withdraw your 32 ETH to any other wallet. With this in mind, it is imperative that you never lose access to your wallet or private keys.\nPooled staking\nBecause this is not supported natively on the protocol, pooled staking can be viewed as more risky than native staking because of the additional counterparty risk.\nWhile Ethereumâ€™s protocol does not natively support staking pools, third-party solutions offer pooled staking services to fill this gap.\nâ€This collaborative approach allows individuals to benefit from staking rewards while mitigating the need for owning and operating entire, individual validators. Users effectively own a percentage of the pool based on their contributions.\nIn contrast to native staking, staking pools offer immediate rewards without a bonding period. This does mean, however, that new entrants to the pool are diluting rewards for those who have already staked tokens.\nâ€Full or partial withdrawals of your original stake can be requested at any time, subject to processing times.\nYour staked ETH is locked and not readily available for immediate use or trading, just like in native staking. As the pool earns rewards, the value of your initial stake grows over time. Therefore, when you decide to withdraw either partially or in full, the pool will return your ETH to you, including the additional amount gained from the accumulated rewards.\nLiquid Staking\nLiquid staking is pooled staking with a twist.\nYou stake any amount of ETH into a pool, with the pool operator managing the validator infrastructure. Pools earn rewards via validators securing the network, proposing and validating blocks, and maintaining consensus. Rewards are pooled and distributed to users based on each participantâ€™s percentage ownership.\nThe primary difference is that you will receive a transferrable receipt token (liquid staking token) in exchange for your stake. The token represents your stake in the pool, acts as proof of ownership, and allows withdrawal rights. It can be transferred to other wallets, and may be accepted by other services as collateral for further reward generating activities all while you continue to earn staking rewards.\nLiquid staking is often viewed as the riskiest option compared to pooled or native staking, as it introduces further counterparty risk as the receipt tokens are transferable.\nAccessibility. Your staked ETH is still locked and not readily available for immediate use or trading, however your transferrable receipt tokens are accessible, liquid, and give you more flexibility.\nDepending on the pool operator or the application built on top of the pool, there are various types of receipt token models available, such as aTokens (AAVE) and cTokens (Compound). These token models have distinct characteristics.\nâ€With aTokens, the amount you hold will remain constant while their value grows over time. This means that the number of aTokens you own will not change, but their value will increase as the pool generates more rewards.\ncTokens maintain a fixed exchange rate with the underlying asset. As rewards are earned in the pool, the number of cTokens you hold increases. This allows you to accumulate a greater quantity of tokens representing your share of the poolâ€™s rewards.\nâ€aTokens are highly composable, relative to cTokens, and can be easily integrated and utilized across diverse DeFi protocols, applications, and platforms.\n==Ultimately, the choice of staking approach depends on your risk appetite, technical capabilities, and desired level of control and flexibility"},"Articles--and--Papers/Ethereum-Staking/Pooled-Staking":{"slug":"Articles--and--Papers/Ethereum-Staking/Pooled-Staking","filePath":"Articles & Papers/Ethereum Staking/Pooled Staking.md","title":"Pooled Staking","links":[],"tags":[],"content":"Source: ethereum.org/en/staking/pools/\nQuotes\nWhy stake with a pool?\n\nLow barrier to entry\nStake today\nStaking tokens\n\nComparison with other options\nSolo staking: Stakers never have to hand over their keys, and they earn full rewards without any middlemen taking a cut.\nSaaS: Rewards accumulate to the staker, and usually involve a monthly fee or other stake to use the service. If youâ€™d prefer your own validator keys and are looking to stake at least 32Â ETH, using a SaaS provider may be a good option for you.\nWhat to consider\nEach pool and the tools or smart contracts they use have been built out by different teams, and each comes with benefits and risks. Pools enable users to swap their ETH for a token representing staked ETH. The token is useful because it allows users to swap any amount of ETH to an equivalent amount of a yield-bearing token that generates a return from the staking rewards applied to the underlying staked ETH (and vice versa) on decentralized exchanges even though the actual ETH stays staked on the consensus layer. This means swaps back and forth from a yield-bearing staked-ETH product and â€œraw ETHâ€ is quick, easy and not only available in multiples of 32 ETH.\nHowever, these staked-ETH tokens tend to create cartel-like behaviors where a large amount of staked ETH ends up under the control of a few centralized organizations rather than spread across many independent individuals. This creates conditions for censorship or value extraction. The gold standard for staking should always be individuals running validators on their own hardware whenever possible."},"Articles--and--Papers/Ethereum-Staking/Proof-of-stake-is-a-superior-consensus-mechanism-(1)":{"slug":"Articles--and--Papers/Ethereum-Staking/Proof-of-stake-is-a-superior-consensus-mechanism-(1)","filePath":"Articles & Papers/Ethereum Staking/Proof-of-stake is a superior consensus mechanism (1).md","title":"Proof-of-stake is a superior consensus mechanism (1)","links":["tags/saplings"],"tags":["saplings"],"content":"saplings\nVitalik explains in his essay Why proof of stake that proof-of-stake is more secure and more decentralized than proof of work.\n(1) Proof-of-stake systems are more expensive to attack. In summary, pow systems are mostly hardware costs whereas pos systems are mostly capital costs.\n\nVitalik theorizes a small calculation to show that itâ€™s more expensive to be a malicious actor on a proof-of-stake network than on a proof-of-work network.\n\nThe total cost of attack on a GPU-based proof of work system is .26 and on an ASIC pow system it&#039;s 486.75\n\nFrom Ethereum.org, Ethereum was mostly mined using GPUs rather than ASICs, which kept the cost down (although had Ethereum stayed on proof-of-work, ASIC mining may have become more popular)\nPer Vitalik, GPUs are relatively inexpensive to rent\n\n\n\n\nAttacks in a proof-of-stake system are much easier to recover from than in a proof-of-work system.\n\nIn a pow system, an attacker can make a chain permanently useless with a spawn camping attack. Honest miners will drop out. If community implements a hard fork, miners on the attacked fork would be â€œbrickedâ€ making them useless.\nOn the other hand, a proof-of-work system has a built in lashing mechanism where only the bad actor, and no one else on the network, has their stake destroyed. And for or harder-to-detect attacks such as a 51% coalition censoring nodes on the network, the community can coordinate a minority user-activated soft that destroys the attackerâ€™s stake\n(2) Proof-of-stake systems are more decentralized iffy\n\n\nPoW is a hardware arms race that tends to price out individuals and small entities. If Ethereum stayed on proof of stake, it would have probably started to use ASIC mining\nInteresting because proof-of-stake algo I believe favors those with more locked capital?\n\nOther benefits:\nElectricity consumption issue was definitely big in the news and a big deal."},"Articles--and--Papers/Ethereum-Staking/Proof-of-stake-is-a-superior-consensus-mechanism":{"slug":"Articles--and--Papers/Ethereum-Staking/Proof-of-stake-is-a-superior-consensus-mechanism","filePath":"Articles & Papers/Ethereum Staking/Proof-of-stake is a superior consensus mechanism.md","title":"Proof-of-stake is a superior consensus mechanism","links":["Newsletter/1-Ethereum-Staking/Staking-ETH,-A-lay-of-the-land"],"tags":["Resource"],"content":"See: Staking ETH, A lay of the land\nVitalik explains in his essay Why proof of stake that proof-of-stake is more secure and more decentralized than proof of work.\n(1) Proof-of-stake systems are more expensive to attack. In summary, pow systems are mostly hardware costs whereas pos systems are mostly capital costs.\n\nVitalik theorizes a small calculation to show that itâ€™s more expensive to be a malicious actor on a proof-of-stake network than on a proof-of-work network.\n\nThe total cost of attack on a GPU-based proof of work system is .26 and on an ASIC pow system it&#039;s 486.75\n\nFrom Ethereum.org, Ethereum was mostly mined using GPUs rather than ASICs, which kept the cost down (although had Ethereum stayed on proof-of-work, ASIC mining may have become more popular)\nPer Vitalik, GPUs are relatively inexpensive to rent\n\n\n\n\nAttacks in a proof-of-stake system are much easier to recover from than in a proof-of-work system.\n\nIn a pow system, an attacker can make a chain permanently useless with a spawn camping attack. Honest miners will drop out. If community implements a hard fork, miners on the attacked fork would be â€œbrickedâ€ making them useless.\nOn the other hand, a proof-of-work system has a built in lashing mechanism where only the bad actor, and no one else on the network, has their stake destroyed. And for or harder-to-detect attacks such as a 51% coalition censoring nodes on the network, the community can coordinate a minority user-activated soft that destroys the attackerâ€™s stake\n(2) Proof-of-stake systems are more decentralized iffy\n\n\nPoW is a hardware arms race that tends to price out individuals and small entities. If Ethereum stayed on proof of stake, it would have probably started to use ASIC mining\nInteresting because proof-of-stake algo I believe favors those with more locked capital?\n\nOther benefits:\nElectricity consumption issue was definitely big in the news and a big deal."},"Articles--and--Papers/Ethereum-Staking/Relevant-definitions":{"slug":"Articles--and--Papers/Ethereum-Staking/Relevant-definitions","filePath":"Articles & Papers/Ethereum Staking/Relevant definitions.md","title":"Relevant definitions","links":["tags/saplings"],"tags":["saplings"],"content":"saplings\nPer Chainlink:\nMost broadly,Â stakingÂ is a cryptoeconomic model that incentivizes the correct behavior of network participants using penalties and rewards in order to strengthen its underlying security\nPer Ethereum.org\nThe term consensus mechanism refers to the entire stack of protocols, incentives and ideas that allow a network of nodes to agree on the state of a blockchain\nPer Ethereum.org:\nStaking is a type of consensus mechanism that derives its crypto-economic security from a set of rewards and penalties applied to capital locked by stakers. This incentive structure encourages individual stakers to operate honest validators, punishes those who donâ€™t, and creates an extremely high cost to attack the network.\nPer Ethereum.org:\nNode operators can add a validator to their consensus clients by depositing 32 ETH in the deposit contract. The validator client comes bundled with the consensus client and can be added to a node at any time. The validator handles attestations and block proposals. They enable a node to accrue rewards or lose ETH via penalties or slashing. Running the validator software also makes a node eligible to be selected to propose a new block"},"Articles--and--Papers/Ethereum-Staking/Rocket-Pool---Staking-Protocol-Part-1":{"slug":"Articles--and--Papers/Ethereum-Staking/Rocket-Pool---Staking-Protocol-Part-1","filePath":"Articles & Papers/Ethereum Staking/Rocket Pool - Staking Protocol Part 1.md","title":"Rocket Pool - Staking Protocol Part 1","links":[],"tags":[],"content":"Source: medium.com/rocket-pool/rocket-pool-staking-protocol-part-1-8be4859e5fbd\nWelcome to the Rocket Pool Staking Protocol Explainer series! This is part of a four-part guide that covers all aspects of Rocket Pool, a decentralised, trustless and community owned staking protocol designed for Ethereum.\nOur goal is to help all Ethereum users gain a better understanding of Rocket Pool. If youâ€™re brand new to Ethereum staking, an experienced staker or even a high level staking as a service (SaaS) provider; this series will provide valuable insights into how you can use Rocket Pool.\nRocket Pool has received multiple audits from the industryâ€™s best,Â Sigma PrimeÂ andÂ ConsenSys Diligence. Part 4 of this series will go over the audit results and details of Rocket Poolâ€™s ongoing development.\nRocket Pool Liquid Staking Protocol Series\n\nPart 1 â€” Overview and Users of the protocol\nPart 2 â€” The Protocol and Oracle Node DAOâ€™s\nPart 3 â€” RPL &amp; Tokenomics\nPart 4 â€” Launch Details, oDAO Members and more\n\nFor this introduction, weâ€™ll give a high level overview of Rocket Pool and how to stake.\nBeing a community owned staking protocol, we cater to all aspects of collective ownership. This includes ETH bulls using our simpleÂ staking token rETH,Â to smart contract dApps, wallet providers, DEXs or you amazing staking node operators, be it hobbyist or professional. Thereâ€™s room for everyone!\nProtocol Overview\nRocket Pool is the base layer protocol for decentralised and trustless Ethereum staking.\nDesigned to support stakers of all shapes and sizes, Rocket Pool was built with the intent to allow anyone to trustlessly stake ETH to a network of decentralised node operators with full autonomy underpinned by RPL token collateral.\n\nThe core premise behind a protocol is to ensure the network is not beholden to any one party. This is a principle directly linked to Ethereum itself, and a mindset used at every stage of the process as we continue to upgrade the protocol.\n\nRocket Pool strives to embody the core ethos of Ethereum and DeFi, specifically the non-custodial, trustless nature that allows self-sovereignty to truly thrive.\nThis is why creating the protocol layer for Ethereum staking is so important, especially with the vast majority of players either not having the technical skills to run a node, or the financial capacity to own 32 ETH.\n\nA 10,000 foot view of the components which make up the Rocket Pool Staking Protocol â€” Click for full size\nProtocol vs Staking as a Service\nProtocols support a wide array of actors, including service providers.\nWeb3 is full of highly knowledgeable Staking as a Service providers (SaaS), helping the world better access the proof of stake (PoS) landscape with projects like Ethereum. They support everything from institutional capital, to hedge funds, family offices and everything in between.\nRocket Pool was designed to support those providers, meaning ETH staked through SaaS solutions can be put to use through Rocket Pool, rather than having to spin up bespoke staking solutions to deal with each client.\nETH holders can choose between paying a service provider or being paid to be an operator. With Rocket Pool, service providers maximize their return by being paid to run a node, both inÂ ETH and RPL. The protocol allows teams to run their own infrastructure, and use Rocket Pool to trustlessly stake ETH in batches of 16 ETH â€” allowing them to put their capital to work further and earn a larger share of returns.\nThis design means Coinbase or any other large entity could use Rocket Pool the same as a DeFi power user. Simply show up with 16 ETH and youâ€™re treated the same as any other node operator. Rocket Poolâ€™s democratized staking systemÂ doesnâ€™t favor any one partyÂ as ETH staked through Rocket Pool always directly supports the network.\n\nRocket Poolâ€™s staked ETH wrapper, rETH, is the purest in DeFi. We foresee a vibrant ecosystem of integrations ranging from lending markets to run validators more efficiently to composability for productivity.\n\nIn short, rETH is a natural building block for Etherum, and the most trust-minimised form of staked ETH.\nProtocol Users\nRocket Pool is designed to cater to two main user groups; those that wish to participate in tokenised liquid staking using rETH and those that wish to stake ETH and run a node.\nrETH Tokenised Liquid Staking\nIn exchange for depositing ETH to Rocket Pool, users receive rETH in return. rETH is fully composable in the wider DeFi landscape, while accruing value from ETH earned through staking.\n\nVisual description of ETH &lt;&gt; rETH swaps\nDepositing ETH and receiving rETH can be done in a single transaction by a variety of different user groups, be it individuals, dApps, exchanges, wallets or just about anyone looking to use the protocol or build on top of it. It is an easy and permissionless way to engage in staking without needing to run any staking infrastructure or even haveÂ 32 ETH, with Rocket Pool you can stake as little asÂ 0.01 ETHÂ this way.\n[\nRocket Pool 2.5 â€” Tokenised Liquid Staking\nHello Rocket Poolers! Weâ€™re excited today to reveal some big improvements to Rocket Pool, a decentralised stakingâ€¦\nmedium.com\n](medium.com/rocket-pool/rocket-pool-2-5-tokenised-staking-48601d52d924)\nWhen you stake ETH and receive rETH, it will automatically begin accruing staking rewards based on performance of the entire decentralised network of node operators operating in Rocket Pool. This means rETH grows in value over time, while holders can utilise that collateral to leverage the wider DeFi landscape while helping to secure the Ethereum network.\nrETHâ€™s value is protected against node slashing and downtime by several built in insurance mechanisms, with node operators staking RPL on nodes as collateral for any penalties they incur. More details on these mechanics will be included in Part 3 of this series, RPL &amp; Tokenomics.\nIf you have rETH, youâ€™ll also be able to trade this back to Rocket Pool for ETH plus rewards at any time if liquidity in the deposit pool will cover the amount. Or swap on any supported decentralised provider such as 1inch at the prevailing market price. No need to wait a few years for Ethereum withdrawals to have liquidity or get your staking rewards. Awesome!\nNode Staking\nFrom hobbyist node operators to full on SaaS professionals, Rocket Pool allows you to earn a greater ROI staking inside the protocol vs outside of it.\n\nOverview of Rocket Pool node staking process\nIf you want to run a node in Rocket Pool, you are not charged any fees as you are providing a valuable service for the protocol. What service is that you ask?\n\nWith Rocket Pool, running a node only requires a minimum of 16 ETH per validator vs 32 ETH outside of the protocol.\n\nOnce you deposit 16 ETH, the protocol will assign you 16 ETH from users who are depositing ETH and receiving rETH.Â So as a node operator you are staking your own 16 ETH and 16 ETH on behalf of the protocol.\nRocket Pool has a flat commission rate ofÂ 15%Â which allows the node operator to earn a percentage of the rewards earned on that 16 ETH assigned by the protocol. This means that node operators earn rewards on their own 16 ETH deposit plus a commission from the network for staking its ETH.\n\nRocket Pool is designed to reward node operators for providing valuable insurance in the case they are heavily penalised or slashed.\n\nWhen depositing ETH, node operators must also deposit a minimum amount of RPL to act as collateral in the case they incur any of these penalties. Should a penalty occur and the user finishes staking with &lt; 16 ETH, the collateral is sold for ETH at auction and the proceeds from this sale are given back to the protocol to compensate for the missing ETH.\nWhen a node operator provides an amount of RPL as collateral as an insurance promise, they are rewarded with RPL rewards respective to the amount of collateral they provide. The minimum collateral required is currently 10% of the node operators ETH value and capped at a maximum of 150%.\n\nThis means a good node operator can earn rewards on their own ETH, a commission in ETH and RPL rewards. Not a bad pay day if you know your way around a node or two!\n\nTrustless Staking\nWith all this talk about token staking and node staking, I bet youâ€™re wondering who holds the keys to all these deposits by these different users.\nWith smart contract support integrated into Ethereumâ€™s PoS system, Rocket Pool is able to provide the only fully noncustodial, trustless, and permissionless staking protocol.\nAbout Rocket Pool\nRocket PoolÂ is Ethereumâ€™s most decentralised liquid staking protocol. Its 2,000+ worldwide node operators have staked over 295,000 ETH representing over 2% of all Ethereum staked.\nLiquid stakers can participate by depositing as little as 0.01 ETH to receive the rETH liquid staking token. Rocket Pool is a fully non-custodial solution, and its node operators are economically-aligned to perform well for stakers.\nJoining as a node operator is fully permissionless and requires just 16 ETH (instead 32). A boosted ROI is provided from both operator commission plus RPL rewards. For more information check out ourÂ node operator guide.\nThe Rocket Pool team have been in the staking space since its inception in 2016, which gives them a pedigree and track record without peer."},"Articles--and--Papers/Ethereum-Staking/Staking-as-a-service":{"slug":"Articles--and--Papers/Ethereum-Staking/Staking-as-a-service","filePath":"Articles & Papers/Ethereum Staking/Staking as a service.md","title":"Staking as a service","links":[],"tags":[],"content":"Source: ethereum.org/en/staking/saas/\nQuotes\nConsiderations\nAll SaaS options require additional trust assumptions compared to home-staking. Saas options may have additional code wrapping the Ethereum clients that is not open or auditable. SaaS also has a detrimental effect on network decentralization. Depending on the setup, you may not control your validator - the operator could act dishonestly using your ETH.\n\nOpen Source\nAudited\nBug Bounty\nBattle tested\nPermissionless\nExecution diversity\nConsensus diversity\nSelf custody\n"},"Articles--and--Papers/Ethereum-Staking/The-Risks-of-LSD":{"slug":"Articles--and--Papers/Ethereum-Staking/The-Risks-of-LSD","filePath":"Articles & Papers/Ethereum Staking/The Risks of LSD.md","title":"The Risks of LSD","links":[],"tags":[],"content":"Source: notes.ethereum.org/@djrtwo/risks-of-lsd\nLiquid Staking Derivatives cannot safely exceed consensus thresholds\nLiquid staking derivatives (LSD) such as Lido and similar protocols are a stratum for cartelization and induce significant risks to the Ethereum protocol and to the associated pooled capital when exceeding critical consensus thresholds. Capital allocators should be aware of the risks on their capital and allocate to alternative protocols. LSD protocols should self-limit to avoid centralization and protocol risk that can ultimately destroy their product.\nNote, although current LSD protocols such as Lido have a lot of room for improvement, this article does not target short-comings in currently implemented designs. Instead, the aim is to **show that LSD protocols haveÂ inherentÂ issues when they exceed consensus thresholds.**\nStratum for cartelization\nIn the extreme, if an LSD protocol exceeds critical consensus thresholds such as 1/3, 1/2, and 2/3, the staking derivative can achieve outsized profits compared to non-pooled capital due to coordinated MEV extraction, block-timing manipulation, and/or censorship â€“ the cartelization of block space. And in this scenario, staked capital becomes discouraged from staking elsewhere due to outsized cartel rewards, self reinforcing the cartelâ€™s hold on staking.\nLSD protocols can minimize governance, upgradability, and other risks over time, but the question of â€œwhoâ€ gets to be a part of the Node Operator (NO) set remains. This lever is the primary cause of cartelization.\nDeciding â€œwhoâ€ gets to be a NO is a matter of two questions â€“ who is added to the set and who is removed the set. This can be designed in one of two ways in the long run â€“ either via governance (a coin vote or other similar mechanism) or via an automated mechanism around reputation and profitability.\nOption 1: Governance of Node Operators\nIn the former â€“ governance deciding NOs â€“ the governance token (e.g. LDO) becomes a major risk to Ethereum. If the token can decide who can be a node operator in this theoretical majority-LSD, then the token holders can force cartel activities of censorship, multi-block MEV, etc, or else the NO is removed from the set.\nIn fact, the enforcement of such economically monopolistic activies only strengthens the tokenâ€™s control over the NOs. In the event that the token exercises its monopoly to gain outsized profits through destructive mechanisms, then, in the extreme, NOs would not be nearly as profitable operating independently. Thus the governance token deciding NOs can become a self-reinforcing cartelization and abuse of the Ethereum protocol.\nGovernance deciding NOs has another distinct risk which is regulatory censorship and control. If pooled stake under one LSD protocol exceeds 50%, this pooled staked gains the ability to censor blocks (and worse-so at 2/3 due to being able to finalize such blocks). In a regulatory censorship attack, we now have a distinct entity â€“ the governance token holders â€“ that a regulator can make requests of censorship. Depending on the token distribution, this is likely a much simpler regulatory target than the Ethereum network as a whole. And, in fact, DAO token distributions are generally pretty terrible with just a few entities deciding most votes.\nIn any sort of token governance control over a majority-LSD, we thus rely on the benevolence of the DAO or however control is structured. Relying on such an entityâ€™s benevolence, anonymity, or geographic distribution to prevent attacks is not safe, and we must assume not sufficient in the long run.\nOption 2: Economic selection of Node Operators\nIn the alternative design â€“ economic and reputation based NOs â€“ we actually end up in a similar, albeit automated cartelization. Firstly, entering the set would require time and capital (i.e. put some ETH on the line, akin to rocketpool design, and slowly show profitability and get more pooled ETH allocation). Although the entering of the set requiring time and money could make it hard for new entrants, it is not the true cartelization vector here. Instead itâ€™s the requisite automated removal of NOs in the event that they do not perform to some profitability standard.\nKicking from the NO set on profitability is likely the only trustless (non-governance) method to ensure that NOs are good for the pool. Defining profitability is problematic â€“ either you define some absolute number (e.g. getting good baseline issuance rewards) or you need to define some relative number (e.g. within 10% of average/normal profitability). Given the unpredictability of MEV/TX rewards in some time window but also given the importance of MEV rewards to profits in the long term, this needs to be dynamic and a comparison over some time period to other operators/validators. That is, the system cannot be designed to just have some absolute metric â€“ must make X in TX fees â€“ due to the high variance in economic activity of the system over time.\nThis profitability comparison metric works well when all operators are using â€œhonestâ€ techniques, but if any amount of the NOs defect to utilizing destructive techniques such as multi-block MEV or adjusting block release times to capture more MEV, then they skew the profitability target such that honest NOs will eventually be automatically ejected if they do not join in on the destructive techniques.\nThis means that in either method â€“ governance of NOs or economic selection/ejection â€“ such a pool exceeding consensus thresholds becomes a stratum for cartelization. Itâ€™s either a direct cartel by governance or itâ€™s a destructive, profitability cartel through smart contract design.\nStaked ETH governance fallback\nAn aside â€“ some suggest that LSD ETH holders could have a say in governance of their underlying LSD protocol, and thus become a safety backstop on what might be a poorly distributed, plutocratic token.\nIt is important to note here that ETH holders are not by definition Ethereum users, and in the long run, we expect that there are massively more EthereumÂ usersÂ than ETHÂ holdersÂ (people with ETH held beyond the amount needed to facilitate TXs). This is a critical and important fact that informs Ethereum governance â€“ there is no on-chain governance granted to ETH holders or stakers. Ethereum is the protocol thatÂ usersÂ choose to run.\nETH holders in the long run are just a subset of users, so staked ETH holders are even a subset from there. In the extreme of all ETH becoming staked ETH under one LSD, governance vote weights or aborts by staked ETH do not protect the Ethereum platform forÂ users.\nThus even if the LSD protocol and the LSD holders are aligned on subtle attacks and capture, users are not and can/will react.\nInsidious nature of governance\nEven with time-delays in LSD governance such that pooled capital can exit the system before a change occurs, LSD protocols suffer from frog-boil governance attacks. Small, slow changes are unlikely to get staked capital to exit the system, but the system can still drastically change over time.\nAdditionally, as mentioned above, LSD holders are not the same as Ethereum users. LSD holders might be fine with some sort of censorship-requisite governance vote, but this is still an attack on the Ethereum protocol and one that users and developers will mitigate through the means at their disposal â€“ social intervention.\nNote: â€œStaked ETH can always exit in the event of malicious governanceâ€ is not actually technically true today and is not certain to be true in the future. The validatorâ€™s active key is the only key allowed to exit from staking in the current Ethereum PoS design. Although there are a number of proposals to add the feature for BLS and smart contract withdrawal credentials to initiate exits, these are not yet agreed upon in either intent or design.\nRisks-on-Capital vs Risks-to-Protocol\nMuch of the above discussion focuses on risks an LSD pool, such as Lido, pose to the Ethereum protocol and not actually the risk to those holding capital in the pooled system. Thus this appears to suffer from the tragedy of the commons â€“ each individual making a rational decision to stake with the LSD protocol is making a good decision for the user but an increasingly bad decision for the protocol. But, in fact, risk to the Ethereum protocol and risk to capital allocated to the LSD protocol when exceeding consensus thresholds areÂ tied together.\nCartelization, abusive MEV extraction, censorship, etc are all threats to the Ethereum protocol and ones that users and devs will respond to in the same methods available for traditional centralization attacks - leak or burn through social intervention. Thus pooling of capital into this stratum for cartelization puts not only the Ethereum protocol at risk, but, in turn, the pooled capital.\nThese may seem like â€œtail risksâ€ that are hard to take seriously or that might never happen, but if weâ€™ve learned anything in crypto itâ€™s â€“ if it can be exploited or has some unlikely â€œcritical edge caseâ€, then it will be exploited or collapse much sooner than you think. Time and time again in this open and dynamic setting brittle systems collapse and vulnerable systems are exploited for both fun and profit.\nThe Ethereum protocol and users can recover from an LSD centralization and governance attack, but it wonâ€™t be pretty. I recommend that Lido and similar LSD products self-limit for their own sake, and I recommend capital allocators to acknowledge the pooling risks inherent to LSD protocol designs. Capital allocators should not allocate to LSD protocols exceeding 25% of total staked Ether due to the inherent and extreme risks associated.\n\n"},"Articles--and--Papers/Ethereum-Staking/Ways-to-stake-ETH":{"slug":"Articles--and--Papers/Ethereum-Staking/Ways-to-stake-ETH","filePath":"Articles & Papers/Ethereum Staking/Ways to stake ETH.md","title":"Ways to stake ETH","links":["tags/saplings"],"tags":["saplings"],"content":"saplings\n\nSolo Staking\n\n\nGold standard - run a full node\n\nTactics here: ethstaker.cc/resources\n\n\nRequires 32 ETH\nNeed basic hardware &amp; understand minimal specs\nOn software side, need to run 1 node on Ethereum and 1 node on Ethereum 2, validator software, and key manager software\nNeed to do maintenance on your node\nThere are common mistakes  folks make\n\n\nStaking as a service\n\n\nHassle-free staking experience for a reasonable fee\nCompanies who provide this service:\n\nKiln - â€œenterprise-grade stakingâ€\n\n\nâ€œWhile different validator-as-a-service providers may have variations in their offerings and billing processes, their core purpose remains the same: to alleviate the burden of managing a validator and provide you with a hassle-free staking experience for a reasonable fee.â€ www.kiln.fi/post/comparing-staking-options-native-pooled-and-liquid-finding-the-right-approach-for-you\n\n\nAttestant - for institutional clients\n\nâ€œit is possible, and indeed is part of Ethereum 2â€™s design, to ensure that validators can run on low-end hardware and anyone can run a validator at home. That said, being possible does not mean it is desirable: there are significant costsÂ involved with running a validator and, as such, many people will look to a third party to operate some or all of the validator functions.â€ - Jim McDonald, co-founder of Attestant\n\n\n\n\n\n\nPooled staking\n\nAgain Kiln\n\n\n"},"Articles--and--Papers/Ethereum-Staking/Where-we-are-and-what's-to-come":{"slug":"Articles--and--Papers/Ethereum-Staking/Where-we-are-and-what's-to-come","filePath":"Articles & Papers/Ethereum Staking/Where we are and what's to come.md","title":"Where we are and what's to come","links":[],"tags":["staking"],"content":"Source: medium.com/rocket-pool/where-we-are-and-whats-to-come-7f5f932e9035\nHello Rocket Poolers! With our mainnet launch on theÂ 9th November 2021, the decentralised protocol has rocketed to become the second largest Ethereum staking provider in just a matter of weeks.\nWith todayâ€™s article, weâ€™ll be outlining the current state of Rocket Pool, a new beta program weâ€™re launching that includes a new staking UI and weâ€™ll also be highlighting some amazing community projects that have sprung up around our mainnet release + more!\nThis is a pretty decently sized article, so grab a seat + beverage of your choice and weâ€™ll get started.\nState of Rocket Pool\nThe popularity of a first ever decentralised trustless staking protocol has surprised even us. Since Rocket Pool was designed to be trustless, we had to wait until the beacon chain spec allowed trustless withdrawals via smart contracts, this happened several months after ETH2 staking launched. We then had to undergo months of audits and testing once that feature was locked in.\nThis meant we launched a good deal later than the majority of current staking services. However the wait was indeed worth it, with the decentralised staking protocol overtaking all other Ethereum staking providers bar one in just a matter of weeksâ€¦\n\nNumber 2 baby!Â defillama.com/protocols/staking/Ethereum\nWith that amazing growth, there are also amazing numbers, some of which weâ€™ll throw at you right now.\nAt the time of writing, the protocolâ€™s Total Value Locked (TVL) has grown to a whoppingÂ 118,219Â ETH. This includesÂ 82,336Â staked ETH andÂ 3,058,145Â RPL.\nThe Network\nRocket Pool hasÂ 744Â individual node operators spread acrossÂ 70Â decentralised geographic regions. Thatâ€™s tremendously more node operators than any other Ethereum staking provider to date.\n\nView the current network map here @Â stake.rocketpool.net/network\nRocket Pool has deployedÂ 2,584Â beacon chain validators (minipools) and is still growing rapidly. In just 2 months Rocket Pool, is almost atÂ 1%Â of the Ethereum validator share (0.89%).\nRocket Pool is already contributing to client diversity. Due to the way we have designed our smart node software, running a staking node can be done simply and easily with just about any beacon chain client.\n\nCurrent ETH2 Client Distributions across minipool validators and node operators, determined by proposals\nrETH Liquid Staking\nWith our liquid staking token rETH, users can enjoy the benefits of staking without needing to run a node.\nrETH has accrued value against ETH (from our decentralised network of node operators staking) and is now worthÂ 1.01299 ETHÂ at the time of writing.\n\nrETH is available on many cost-effective L2s as well\nrETH has shown to be in very high demand. Many node operators have been able to lock in the maximumÂ commission of 20%Â on their validators, and continue to do so today. By staking their RPL collateral node operators have also earned almostÂ 1,593 ETH in RPL rewards.\nRoadmap\nAs seen above, Rocket Pool has had a great start! But what comes next?\nWorking with our community, we are co-developing a roadmap for the next 12 months. This is a living document that will provide clear direction for the core team and community initiatives.\nKey themes include:\n\nrETH integration with DeFi protocols, wallets, and DeFi trackers\nNode operator reach and onboarding\nThe Merge and MEV (big one)\nLeveraging layer 2\nNode operator RPL claim optimisation\nGovernance and funding of community initiatives\n\nAs a community-driven decentralised protocol, Rocket Pool values its communityâ€™s contributions immensely and believes they are a significant advantage. Our community has proven it can deliver content/products/features (based on Rocket Pool) that fulfils community needs.\nThese include:\n\nVGRâ€™s staking/node operator dashboard\nThe Rocketeers NFT\nInvisible Symbolâ€™s Discord bots\nRocket Pool Tool\nRocketScan\n\nPartners are also seeing the value of integrating Rocket Pool into their products.\nTo remain agile, Rocket Pool will leverage support from the community and partners. The Rocket Pool core team will still be core contributors for important elements of Rocket Pool but we will stimulate community contributions through a new grants and bounty program. Rocket Pool has always worked closely with its community of Rocketeers but we hope this will further develop a sense of shared success.\n\nBelow is the draft roadmap detailing coming protocol changes and potential grant / bounty opportunities. As we flesh out the grant / bounty program we will provide ways to be involved.\n\nBeta Program\nAs we design new changes to the protocol, weâ€™d love people to help us test them out and provide feedback long before they hit a mainnet release. Rocket Pool has high standards and we need your help to keep us that way. With the introduction of our beta program, we hope we can accomplish that.\nIf you participate, youâ€™ll get to try out the new features across virtually all aspects of Rocket Pool, from the staking UI to smart node stack releases.\nWe will provide more information about how you can get involved in ourÂ Discord.\nNew Staking UI\nTo kickstart the beta program, weâ€™ll be launching a new staking UI which participants will get to test out. Incorporating feedback from our passionate community, we decided to rework the staking UI from the ground up.\nThe new interface should be familiar to most DeFi users but retains Rocket Poolâ€™s unique character. The rETH exchange rate is predominantly displayed, is shown more intuitively, and includes help text. Transaction cost is now included on the page.\n\nA wallet menu shows all associated balances, including the rETH value denominated in ETH â€” so that holders can see their balance increasing.\n\nWeâ€™ll have this new UI launched with our beta program shortly, all details will be released in ourÂ DiscordÂ for those who want to give it a go first.\nQuestions or just say hello!\nWell 16 points to you for making it this far, that was a whopper! If you have mainnet questions, feedback, bug reports or want to know a bit more about us, why not swing by for a chat and say Gâ€™day! You can view ourÂ websiteÂ or have a chat with us in our Discord chat room thatÂ anyone can join. If chat rooms arenâ€™t your thing, weâ€™re also onÂ Twitter!\n\n"},"Articles--and--Papers/Ethereum-Staking/mauve-paper":{"slug":"Articles--and--Papers/Ethereum-Staking/mauve-paper","filePath":"Articles & Papers/Ethereum Staking/mauve paper.md","title":"Ethereum 2.0 Mauve Paper","links":[],"tags":[],"content":"Source: cdn.hackaday.io/files/10879465447136/Mauve%20Paper%20Vitalik.pdf"},"Newsletter/1-Ethereum-Staking/Outline":{"slug":"Newsletter/1-Ethereum-Staking/Outline","filePath":"Newsletter/1 Ethereum Staking/Outline.md","title":"Reviewing Ethereum Staking","links":[],"tags":[],"content":"Fixed intro for each post\nI. Each post should align on the definition of Ethereum and ETH\nII. Identify which stakeholder(s) the post is addressing\nStats\nIII. Market cap of ETH\nIV. Price of ETH\nI. Introduction\nA. The Merge was executed\nB. What is proof-of-stake\nA. [Most broadly,Â stakingÂ is a cryptoeconomic model that incentivizes the correct behavior of network participants using penalties and rewards in order to strengthen its underlying security](blog.chain.link/liquid-staking/\nB. Benefits of proof-of-stake\ni. Vitalik article (very theoretical, not necessarily grounded in practice?)\nA. See Paragraph post\nii. Visa Article usa.visa.com/solutions/crypto/the-merge-ethereum.html\na. The claim is that staking ETH is essential for sustainability, security, and scalability\na. Sustainability - less electricity usage\nb. Security - more decentralized, in theory, because less capital requirements (stake 32 ETH &amp; donâ€™t need expensive hardware) so more people can run propose blocks/run nodes\nc. Scalability - Staking doesn&#039;t actually bring scalability. Rollups are what scale Ethereum. L1 serves as the settlement layer, which is why it&#039;s important for it to be decentralized.\nc1. Ethereum Mainnet provides a hub for optimistic rollups to verify fraud proofs and resolve disputes. Moreover, transactions conducted on the rollup are only finalÂ afterÂ the rollup block is accepted on Ethereum. Once a rollup transaction is committed to Ethereumâ€™s base layer, it cannot be rolled back (except in the highly unlikely case of a chain reorganization)\nc2. Danksharding is what will make Ethereum reach more TPS (again, on the rollup level)\nd. Capital efficiency? Instead of HODLING ETH, use it for passive income. Is there anything like this for traditional investing? Maybe like an ETF? Weâ€™re so used to banks &amp; regulation providing our money, but then there was the bank run on Silicon Valley Bank, and thereâ€™s inflationâ€¦(idk!)\nII. Ways to stake ETH\nA. Run a full node (solo staking).\n&gt; Great resources here\ni. requires 32 ETH\nii. you are a node operator, running your own node i.e, running hardware\na. requires basic hardware setup and understanding of minimal specs. Using a CLI is no longer required..but the medium article makes it sound lil more complicatedâ€¦I think setting up an OS and getting it properly configured would be hard\niii. requires software setup - run an Ethereum 1 node, an Ethereum 2 node, validator software, and key manager software. www.attestant.io/posts/evaluating-staking-services/\niv. you need to do maintenance on your node - network upgrades or other critical client upgrades\nv. you need reliable uptime. rewards are proportional to the time your validator is online and properly attesting. 10 mb/s upload and download time is recommended. you get penalized without this.\nvi. you can get slashed even if youâ€™re not a malicious actor, by doing common mistakes. Lots of them here medium.com/prysmatic-labs/eth2-slashing-prevention-tips-f6faa5025f50\nB. Staking as a service\n&gt;  [[It is possible, and indeed is part of Ethereum 2â€™s design, to ensure that validators can run on low-end hardware and anyone can run a validator at home. That said, being possible does not mean it is desirable: there are significant costs1Â involved with running a validator and, as such, many people will look to a third party to operate some or all of the validator functions](www.attestant.io/posts/evaluating-staking-services/) - Jim McDonald]\ni. requires 32 ETH\nii. donâ€™t need to run your own node, so donâ€™t need to upgrade/maintain hardware\niii. But more trust assumptions &amp; detrimental to network decentralization\nC. Pooled Staking (aka Delegated Staking)\na. Description\ni. Pooled or delegated staking is not natively supported by the Ethereum protocol, which creates counterparty risk, but many users want to stake &lt;32 ETH so this service was built out for the demand\nii. Staking pools are managed by a pool operator with the participation of multiple stakers; typically less than 32 ETH as is a requirement for native staking. Rather than owning your validator, your stake is combined with other users to meet the required 32 ETH deposit. The operator is responsible for activating and deactivating validators in line with deposit and withdrawal activity, and managing the validator infrastructure supporting the pool\niii. This collaborative approach allows individuals to benefit from staking rewards while mitigating the need for owning and operating entire, individual validators. Users effectively own a percentage of the pool based on their contributions.\niv. [However, these staked-ETH tokens tend to create cartel-like behaviors where a large amount of staked ETH ends up under the control of a few centralized organizations rather than spread across many independent individuals. This creates conditions for censorship or value extraction. The gold standard for staking should always be individuals running validators on their own hardware whenever possible](ethereum.org/en/staking/pools/\nb. Pool Operators\ni.  Rocket Pool\nii.  Kiln\nD. Liquid Staking\ni. Pooled staking with a twist! While not all pooled staking platforms offer liquid staking tokens to users, others do\nA. Benefits\na. unlocks liquidity for staked tokens with composability (a new token is minted e.g. stETH that represents a claim to your staked eth)\nb.  composability (use on defi protocols for lending and such\nc. no minimum eth requirement so extremely accessible to anyone\nSaid differently:\nii. The primary difference is that you will receive a transferrable receipt token (liquid staking token) in exchange for your stake. The token represents your stake in the pool, acts as proof of ownership, and allows withdrawal rights. It can be transferred to other wallets, and may be accepted by other services as collateral for further reward generating activities all while you continue to earn staking rewards\niii. â€Liquid staking is often viewed as the riskiest option compared to pooled or native staking, as it introduces further counterparty risk as the receipt tokens are transferable\n. iv.  Liquid Staking Metrics\na2. Staking Metrics - Dune Dashboard\nwow, solo staking is only ~1%??\nii. Pool providers\nIII. Rewards\nA. Solo Staking\ni. A common misconception is that the gross rewards rate is a given in native staking, whilst the reality is that there is variability in this rate when running an individual validator\nB. Pooled Staking\ni. Gross rewards rates of a pool are not guaranteed. The risks and luck associated with different reward types, and the impact of short-term fluctuations that is present with dedicated validators, is somewhat mitigated as rewards are shared out amongst many validators\nIV. Risks of staking (macro &amp; micro risks)\nA. Macro Risks\n\nMuch of the above discussion focuses on risks an LSD pool, such as Lido, pose to the Ethereum protocol and not actually the risk to those holding capital in the pooled system. Thus this appears to suffer from the tragedy of the commons â€“ each individual making a rational decision to stake with the LSD protocol is making a good decision for the user but an increasingly bad decision for the protocol. But, in fact, risk to the Ethereum protocol and risk to capital allocated to the LSD protocol when exceeding consensus thresholds areÂ tied together\ni. market conditions and behavior has created centralization of nodes, which opens up attack vectors e.g, governance, self-dealing (is this similar to centralization of mining pools - is this relevant for this post?!)\na. While PoS removes the computational complexity of PoW and makes it possible for more people to take part in securing the network, a significant chunk of the ETH that goes into staking can still concentrate on the hands of very few validators. This is especially relevant with the case of staking pools, where a few smart contracts or off-chain entities can become concentration points for a large proportion of staked ETH. Therefore, we should not take the transition to PoS as a simple guarantee for more decentralization. Rather, we should observe the network metrics to help make sure security and decentralization donâ€™t regress in the long run\nii. staked-ETH tokens tend to create cartel-like behaviors where a large amount of staked ETH ends up under the control of a few centralized organizations rather than spread across many independent individuals. This creates conditions for censorship or value extraction. The gold standard for staking should always be individuals running validators on their own hardware whenever possible\na. In the extreme, if an LSD protocol exceeds critical consensus thresholds such as 1/3, 1/2, and 2/3, the staking derivative can achieve outsized profits compared to non-pooled capital due to coordinated MEV extraction, block-timing manipulation, and/or censorship â€“ the cartelization of block space. And in this scenario, staked capital becomes discouraged from staking elsewhere due to outsized cartel rewards, self reinforcing the cartelâ€™s hold on staking\nB. Micro Risks\na. Running a node &amp; pooled staking - Hardware risk / smart contract risk / penalties for not knowing what youâ€™re doing\nb. DeFi risk (staking with Lido)\ni. impermanent loss?\nii. smart contract risk\n\nV. Conclusions\nA. Learn more about proof-of-stake, for visual Learners: www.youtube.com/watch\nB. Recc. for solo stakers is to get started by using the staking launchpad on Ethereum.orgâ€™s website  ethereum.org/en/staking/solo/#get-started-on-the-staking-launchpad. Remember to practice on a testnet!\nIV. Things I enjoyed reading this week\nA. Check Substack saved\nReasons for staking\n\nHelp to secure the Ethereum network\nEarn passive income (deploy capital and have it make you money - capital efficiency)\n\nLiquid staking solves problem of financial exclusivity\n\nAlso solves problem of having technical expertise to run your own node, keep it live, and not lose your money.\nI think any computer would do to run a node but it always has to be on. You get penalized for it going offline. So would probably want another computer.\nWith lido staking, Lido runs nodes and you just get passive income. They take a cut. But it comes at the expense of decentralization\n\nLido creates centralization problems\n\nLido owns many nodes on Ethereum network, which opens up opportunities for 51percent attacks. LIDO DAO is very powerful??\n\nThis newsletter is for crypto curious, not for experts. To give them practical ways they can participate (and me!) in Ethereum. So I need to get to the chase of hereâ€™s how you can â€¦ run your own node? Maybe with a raspberry pi? Maybe buy buying staked eth?\nThis newsletter can review Ethereum protocols and products. So review them!\nWhich products are available for staking your ETH?\n\nLido\nRocket Pool\nEthereum itself\n"},"Newsletter/1-Ethereum-Staking/Staking-ETH,-A-lay-of-the-land":{"slug":"Newsletter/1-Ethereum-Staking/Staking-ETH,-A-lay-of-the-land","filePath":"Newsletter/1 Ethereum Staking/Staking ETH, A lay of the land.md","title":"Staking ETH: A lay of the land","links":["Newsletter/1-Ethereum-Staking/Outline"],"tags":["staking"],"content":"Final published: paragraph.xyz/@sharingiscaring/staking-eth-a-lay-of-the-land\nOutline\nStaking ETH: A lay of the land\nAn exploration of why and how to stake ÎTH, along with considerations and risks\n\n\n\nRika\nNovember 5, 2023\nGreetings, readers! (or Gm, as we say in crypto). The purpose of this newsletter is to provide digestible breakdowns of complex protocols and products in the Ethereum ecosystem. You can expect quality substantive content (no hype pieces, shilling, or paywall) written for crypto-curious readers who are either newer to crypto or seasoned users who value refreshers on the fundamentals. You can learn more about this newsletter in the introductory post.\nÎTH Market Capitalization = 226,848,377,160 (approximately 227B)\nÎTH Price = 1,886 (approximately 2k)\nIntroduction\nMost likely because staking ETH is a cornerstone, and potentially lucrative, component of the Ethereum network, you can find a Godzilla amount of information about it online.\nOne problem however with information overload is misinformation. The crypto space is plagued with self-serving marketing campaigns that embellish or distort the truth, making it challenging for people to suss out whatâ€™s real and whatâ€™s not.\nI wrote this post for two reasons:\n\n\nAs a (gentle and fun) forcing mechanism for me to think more clearly and deeply about Ethereum staking.\n\n\nTo share what I learned with my newsletter readers.\n\n\nThe post is structured as follows:\n\n\nthe first part will get us aligned on important definitions\n\n\nthen Iâ€™ll introduce some theory and a background on staking.\n\n\nthen weâ€™ll dive into practical ways for how to stake ETH, including risks and considerations.\n\n\nfinally, the recap and conclusion.\n\n\nI hope you have fun reading this post. As always, feel free to reach out to me by replying directly to this email (if you are a subscriber), commenting on this post, or sending me a message on Twitter. My DMs are open.\n\nUseful definitions\nLetâ€™s align on six important definitions. You may find some of these rudimentary, so feel free to skip to the next section if youâ€™re already comfortable with these concepts.\n*Note: all of these definitions are from Ethereum.org, a leading educational resource.\n\n\nWhat is Ethereum?\n\nEthereum is a public network, a blockchain, and an open-source protocol â€” operated, governed, managed, and owned by a global community of tens of thousands of developers, node operators, ETH holders, and users.\n\n\n\nWhat is Ether (a.k.a. ETH)?\n\nEther (also known by its ticker symbol ETH) is the native currency transacted on Ethereum. ETH is needed to pay for usage of the Ethereum network (in the form of transaction fees). ETH is also used to secure the network with staking.\n\n\n\nWhat is a consensus mechanism?\n\nThe term consensus mechanism refers to the entire stack of protocols, incentives, and ideas that allow a network of nodes to agree on the state of a blockchain.\n\n\n\nWhat is proof-of-stake?\n\nA type of consensus mechanism that derives its crypto-economic security from a set of rewards and penalties applied to capital locked by stakers. This incentive structure encourages individual stakers to operate honest validators, punishes those who donâ€™t, and creates an extremely high cost to attack the network.\n\n\n\nWhat is a validator?\n\nNode operators can add a validator to their consensus clients by depositing 32 ETH in the deposit contract. The validator client comes bundled with the consensus client and can be added to a node at any time. The validator handles attestations and block proposals. They enable a node to accrue rewards or lose ETH via penalties or slashing. Running the validator software also makes a node eligible to be selected to propose a new block.\n\n\n\nWhat is proof-of-work?\n\nProof-of-work is a type of consensus mechanism that derives its crypto-economic security from â€œminingâ€, the act of nodes running GPUs or ASICs hardware to solve cryptographic puzzles, validating transactions, and adding blocks to the chain. Ethereum has deprecated proof-of-work and now uses proof-of-stake consensus instead.\n\n\n\nTheory and background on staking ÎTH\nStaking is a native feature of the Ethereum blockchain, and it is one of the most important contributions that an Ethereum user can make to the network. Because Ethereum is a decentralized and community-driven network, owned and managed by its users, anyone who owns ETH can actively contribute to the networkâ€™s security.\nThe Merge\nThe ability to stake ETH was added as a native feature to the Ethereum blockchain on September 15, 2022, during a technical upgrade known as The Merge. It was a momentous event that celebrated one of Ethereumâ€™s most profound technical advancements, the merging of Ethereumâ€™s original execution layer (Mainnet) with its new proof-of-stake consensus layer, the Beacon Chain.\nProof-of-stakeâ€™s predecessor, proof-of-work, was used since Ethereumâ€™s genesis in 2015. For years, however, Ethereum developers were developing and testing proof-of-stake, to ensure the highest level of security and efficiency before it was finally integrated into the Ethereum network in The Merge upgrade.\nProof-of-stake is a superior consensus mechanism to proof-of-stake, for the following reasons:\n\n\nProof-of-work burns an insanely large amount of electricity.\n\n\nProof-of-work is much cheaper for a malicious actor to attack than proof-of-stake.\n\n\nIn a proof-of-work system, the primary financial hurdle for individuals is the acquisition of hardware for mining. Most miners on Ethereum use GPUs, which are significantly less expensive than ASICs and can be rented cheaply.\n\n\nOn the other hand, the primary cost to participate as a validator in a proof-of-stake system is capital. Validators must deposit 32 ETH.\n\nVitalik (the founder of Ethereum) explains this in greater detail with a small theoretical calculation. If youâ€™re interested, you can see how he crunches the numbers, along with the full rationale, in his essay Why Proof-of-Stake.\n\n\n\n\n\nAttacks on a proof-of-work network are very difficult to recover from. Attacks on a proof-of-stake network are much easier to recover from.\n\n\nIn a proof-of-work network, a 51% miner cartel can keep attacking the chain, with a type of attack called spawn camping, making the chain permanently useless, and causing honest miners to drop out. To recover, the community can choose to implement a hard fork, but miners on the attacked chain will be â€œbrickedâ€, rendering them useless.\n\n\nOn the other hand, a proof-of-stake system has a built-in slashing mechanism where only the bad actor, and no one else on the network, has their stake destroyed. And for harder-to-detect attacks such as a 51% coalition censoring nodes on the network, the community can coordinate a minority user-activated soft that destroys the attackerâ€™s stake.\n\n\n\n\nThe different ways to stake ÎTH\nThere are four ways to stake ETH. Each method requires a different level of technical expertise and carries its own set of risks.\nThese four methods are:\n\n\n1) Solo staking, where you deposit a minimum of 32 ETH and run a validator node on a home computer\n\n\n2) Staking-as-a-service, where you deposit a minimum of 32 ETH and a 3rd party runs a validator node for you\n\n\n3) Pooled staking, where you deposit any amount of ETH, a 3rd party runs a validator node for you, and you receive a receipt token\n\n\n4) Liquid staking, where you deposit any amount of ETH, a 3rd party runs a validator node for you, and you receive a receipt token, which can be used across DeFi (decentralized finance) protocols.\n\n\n1. Solo staking\nSolo staking is the gold standard because it yields maximal decentralization for the Ethereum network. And decentralization is a core pillar of Ethereum, not just a nice-to-have feature.\nIn an ideal world, every node on the Ethereum network would be a solo staker, but the reality is that only approximately 1% of nodes on Ethereum are solo stakers (the green section in the visual below represents the share of solo stakers compared to other types of staking).\n\nEth staked by category. Dune dashboard by @hildobby.\nOnly ~1% of stakers solo stake because compared to the other methods, it is the most technically challenging, requiring a user to set up and manage a validator node.\nSolo staking requirements:\n\n\nBasic hardware setup and an understanding of minimal specs\n\n\nBasic software setup: run a node on Ethereum 1, another node on Ethereum 2, validator software, and key manager software\n\n\nNode maintenance: network upgrades or other critical client upgrades\n\n\nReliable uptime: &gt;10 mb/s upload and download time. (Rewards are proportional to the time your validator node is online and properly attesting)\n\n\n32 ETH deposit\n\n\nSolo staking risks:\n\n\nYour ETH is at stake\n\n\nThere are financial penalties for your node going offline\n\n\nBehavior that is deemed harmful to the network, even if not intentionally malicious, results in financial penalties\n\n\nSolo stakers are prone to making common mistakes that will get their validator node slashed, resulting in financial penalties.\n2. Staking-as-a-service\n\nIt is possible, and indeed is part of Ethereum 2â€™s design, to ensure that validators can run on low-end hardware and anyone can run a validator at home. That said, being possible does not mean it is desirable: there are significant costsÂ involved with running a validator and, as such, many people will look to a third party to operate some or all of the validator functions.\n\nJim McDonald, co-founder of Attestant, a staking-as-a-service provider\n\n\nStaking-as-a-Service exists to alleviate the hassle of setting up and maintaining a validator node. In exchange for a fee, individuals or organizations can rely on a third party to handle the complexities of being a validator.\nAlthough using a Staking-as-a-Service provider is convenient, there are inevitable trust assumptions, therefore itâ€™s crucial to choose a reputable service provider. In addition to reputation, other important considerations need to be thought through, as outlined below.\nStaking-as-a-service considerations:\n\n\nIs essential code 100% open source?\n\n\nWas essential code audited and the results made available to the public?\n\n\nWas a public bug bounty performed on essential code?\n\n\nHas the code been available and used by the public for &gt;1 year?\n\n\nIs the service permissionless for users to sign up?\n\n\nIs there diversity in execution clients used?\n\n\nIs there diversity in consensus clients used?\n\n\nDo users have self-custody of validator credentials, signing, and withdrawal keys?\n\n\nA sample of Staking-as-a-service Providers: Kiln, Attestant, Stakefish. More can be found on Ethereum.orgâ€™s website here.\nStaking-as-a-service risks:\n\n\nCounterparty risk of using a service provider\n\n\nUse of your signing keys is entrusted to someone else who could behave maliciously\n\n\n3. Pooled staking\nUnlike solo staking and staking-as-a-service, pooled staking doesnâ€™t require a user to have a minimum of 32 ETH to stake. Rather, pooled staking uses a collaborative approach where usersâ€™ funds are combined in the pool to meet the 32 ETH minimum deposit.\nThe pool operator manages the validator node infrastructure. They are responsible for activating and deactivating validators according to deposit and withdrawal activity in the relevant pool.\nUsers benefit by using a staking pool because they earn staking rewards without having to own or operate a validator node. Individuals effectively own a percentage of the pool based on their contributions, which, again, can be any amount of ETH, not necessarily a minimum of 32 ETH.\nPooled staking considerations:\n\n\nIs essential code 100% open source?\n\n\nWas essential code audited and the results made available to the public?\n\n\nWas a public bug bounty performed on essential code?\n\n\nHas the code been available and used by the public for &gt;1 year?\n\n\nIs the service trustless in that no one holds custody of usersâ€™ keys or reward distributions?\n\n\nIs the service permissionless for anyone to sign up as a node operator?\n\n\nIs there diversity in execution clients used?\n\n\nIs there diversity in consensus clients used?\n\n\nA sample of Staking pool operators: Rocket Pool, Stakewise, Bedrock. More can be found on Ethereum.orgâ€™s website here.\nPooled Staking is not natively supported by Ethereum, which adds a new layer of risk, as outlined below.\nPooled staking Risks:\n\n\nCounterparty risk of using a pool operator\n\n\nSmart contract risk of pool contract\n\n\nExecution risk of using a pool operator\n\n\n4. Liquid staking\nLiquid staking is staking with a DeFi (decentralized finance) twist.\nThe purpose of liquid staking is to unlock liquidity in staked ETH by creating a financial product: a derivative. Similar to derivatives traded on traditional financial exchanges, a liquid staking derivative represents some value of the underlying staked ETH.\nMany staking pool operators offer liquid staking derivatives. This means when a user deposits some amount of ETH into the pool, they receive a transferable receipt token (i.e., liquid staking token) that represents their share in the pool. This token allows withdrawal rights and, unlike other types of staking, it can be transferred to other wallets.\nFurthermore, a liquid staking token can be used across DeFi protocols and applications, for swapping, borrowing, and lending. It can act as collateral, generating further income, while earning staking rewards.\nHowever, as with all DeFi products, liquid staking tokens carry significant risks.\nLiquid staking is considered the riskiest type of staking, compared to solo staking, staking-as-a-service, and pooled staking, because it introduces further counterparty risk as the liquid staking tokens are transferable.\nLiquid staking tokens tend to create cartel-like behaviors where a large amount of staked ETH ends up in the control of a few centralized organizations, creating conditions for censorship or value extraction.\nA sample of liquid staking providers: Rocket Pool, Stakewise, Lido. More can be found on Ethereum.orgâ€™s website here.\n\nVitalik wrote a post titled The Risks of LSD, heeding capital allocators about the significant risks associated with pooled capital when it exceeds critical consensus thresholds. He notes that these risks are inherent, therefore the community needs to keep a close eye on the numbers. He writes that capital allocators should not allocate to LSD protocols exceeding 25% of total staked Ether due to the inherent and extreme risks associated.\nA worrying statistic, and one that the Ethereum community is rightfully enraged about, is liquid-staking-provider, LIDO, whose current market share is at ~31%, as seen in this Dune dashboard.\n\nLido Staking Market share by @hildobby\nRecap and conclusion\nTo recap, there are four methods to stake ETH:\n\n\nSolo staking, where you set up and maintain a validator node. Requires a deposit of 32 ETH. Although this is the most technically challenging method, it is the gold standard because it is maximally decentralized for the Ethereum network. If you find it fun to tinker and be technical, then learning how to solo stake may be the best method for you. Plus, there are no middlemen so you keep 100% of the rewards that your node earns.\n\n\nStaking-as-a-service, where you use a third party to set up and maintain a validator node. Requires a deposit of 32 ETH. In exchange for alleviating the hassle of running infrastructure, you pay the service provider a fee, and sometimes a portion of the rewards your node earns. This method, although convenient, introduces trust assumptions and is potentially detrimental to network decentralization.\n\n\nPooled staking, where you use a pool operator and participate with multiple stakers to pool funds. A deposit of 32 ETH is not required. You can deposit any amount of ETH. Rewards are proportional to your ownership share in the pool. The operator is responsible for activating and deactivating validators in line with deposit and withdrawal activity, and managing the validator infrastructure supporting the pool. Pooled staking, although convenient, is not natively supported by the Ethereum protocol, and it introduces counterparty risk.\n\n\nLiquid staking, where, similar to pooled staking, you receive a transferable receipt token that represents your share in the pool, acts as proof of ownership, and allows withdrawal rights. The additional functionality of this token, which differs from pooled staking, is that you can use this token across DeFi protocols as collateral for borrowing and lending. Liquid staking, although convenient, and potentially lucrative, introduces counterparty risk, and is considered the riskiest type of staking. It is also the biggest threat to Ethereumâ€™s decentralization.\n\n\nIdeally, every node on Ethereumâ€™s network is a solo staker, running on a home computer. However, the reality is much different, likely due to market forces, human psychology, and behavioral economics. Only approximately 1% of nodes on the Ethereum network are solo stakers, with most individuals and organizations choosing to participate in staking through liquid staking, the riskiest type of staking, and also the biggest threat to Ethereumâ€™s decentralization.\nIf you are curious about solo staking, Ethereum.org built a great comprehensive portal to help you get your hands dirty in a safe way. Remember to always practice on Testnet, with fake ETH, before depositing real money into Mainnet.\n\nAs always, feel free to reach out to me with questions, suggestions, or feedback, by replying directly to this email (if you are a subscriber), commenting on this post, or sending me a message on Twitter. My DMs are open.\n-Rika"},"Newsletter/1.5-Midweek-Roll/Midweek-Roll-November-8-2023":{"slug":"Newsletter/1.5-Midweek-Roll/Midweek-Roll-November-8-2023","filePath":"Newsletter/1.5 Midweek Roll/Midweek Roll November 8 2023.md","title":"Midweek Roll","links":[],"tags":[],"content":"Read Newsletter Here\nSeveral pieces of (non-crypto) content for your reading pleasure\nGm readers,\nHappy Wednesday. Itâ€™s the middle of the week, which means itâ€™s time for the Midweek Roll. In this post, youâ€™ll find three curated pieces of content. These are articles that Iâ€™ve read during the week about culture and geopolitics. They are exceptionally thoughtful and I canâ€™t stop thinking about them.\nEnjoy.\n\nWould you sell them out?\n\nSource: Timothy Snyderâ€™s Substack\nAbout the Author:\nTimothy Snyder is a Professor of History at Yale University, specializing in the history of Central and Eastern Europe, the Soviet Union, and the Holocaust.\nArticle Summary:\nThe article underscores Ukraineâ€™s pivotal role in deterring Russian aggression, ensuring global stability, and protecting American interests. It emphasizes Ukraineâ€™s value as a democratic ally and its contributions to broader global war prevention. The piece rejects â€œfatigueâ€ as a reason to abandon Ukraineâ€™s calls for help, and urges American lawmakers to maintain their support for Ukraine.\nRead the article here.\n\nThe Extremistâ€™s Gambit Helps Explain Why Hamas Attacked Now\n\nTerrorists from the Al-Qassam Brigades, a military wing of Hamas, marching in Gaza on May 28, 2021. Sameh Rahmi/NurPhoto via Getty Images.\nAbout the Author:\nTanner Greer is an essayist, journalist, and independent researcher. He is also the director of the Center for Strategic Translation.\nArticle Summary:\nThe article discusses the concept of the â€œextremistâ€™s gambit,â€ a strategy employed by radical groups or individuals when they believe time is not on their side and they want to force a fearful or apathetic majority to see things their way. The strategy involves taking actions to provoke a crisis, making it a binary choice for people to pick a side, effectively eliminating middle ground in a political dispute. While not specific to any one group, the article suggests that this strategy may explain the actions of organizations like Hamas in certain circumstances.\nRead the article here. Special thanks to Anna Gatâ€™s post for helping me with discovery.\n\nBritney Spearsâ€™ American horror story\n\nIllustration by Jordan Carter\nAbout the Author:\nAnna Leszkiewicz is the editor and writer for the New Statesman, the New York Times, and the Guardian.\nArticle Summary:\nThe article discusses Britney Spearsâ€™s memoir, â€œThe Woman in Me,â€ which recounts her life as a child star and her subsequent loss of autonomy under a conservatorship. It highlights how Spears was preyed upon by the entertainment industry, with her fame spiraling out of her control. It discusses the abuse she endured by her family during her conservatorship, where her every move was controlled, and she was subjected to overbearing surveillance.\nRead the article here. Special thanks to Anna Gatâ€™s post for helping me with discovery.\n\nAs always, feel free to reach out to me with questions, suggestions, or feedback, by replying directly to this email (if you are a subscriber), commenting on this post, or sending me a message on Twitter. My DMs are open.\n-Rika"},"Newsletter/2-Midweek-Roll-Nov-16-2023/Being-nice-vs.-being-kind-(1)":{"slug":"Newsletter/2-Midweek-Roll-Nov-16-2023/Being-nice-vs.-being-kind-(1)","filePath":"Newsletter/2 Midweek Roll Nov 16 2023/Being nice vs. being kind (1).md","title":"Being nice vs. being kind (1)","links":[],"tags":["ethics"],"content":"Source: www.scu.edu/the-big-q/being-nice-vs-being-kind/\nSummary\nâ€œNiceâ€ and â€œkindâ€ are commonly used interchangeably, but they carry distinct meanings. Unlike â€œnice,â€ which lacks ethical significance and can describe inanimate objects (e.g., a nice dress), â€œkindâ€ specifically conveys benevolence. The key difference between a â€œkindâ€ and a â€œniceâ€ person lies in their motivation. While a nice person seeks to please others, often with expectations of reciprocity, a kind person may act in ways that are not necessarily pleasing but align with benevolence, such as delivering difficult news.\nAre they the same?\nKelly Shi\nWhat is the difference between being nice and being kind? At first glance, it is hard to tell.Â  We seem to use â€œniceâ€ and â€œkindâ€ interchangeably when describing people. A â€œnice personâ€ holds the door for others, and so does a â€œkind personâ€; both behave in ways that demonstrate consideration for others. So are â€œniceâ€ and â€œkindâ€ just synonyms for each other?\nNot exactly, according toÂ dictionary.com. ==â€œNiceâ€ is defined as â€œpleasing; agreeable; delightfulâ€, while â€œkindâ€ is defined as â€œhaving, showing, or proceeding from benevolence.â€ This difference seem to explain why we use â€œniceâ€ but not â€œkindâ€ to describe things besides people and the way they treat each other. For example, â€œnice shirtâ€ is understood as a compliment (albeit a vague one), but â€œkind shirtâ€ is a nonsensical phrase. It seems that while â€œniceâ€ and â€œkindâ€ carry positive connotations, only the latter indicates an ethical significance.Â \nDoes that mean that â€œkindâ€ is merely a subset of â€œniceâ€ that applies to ethical matters? Since â€œniceâ€ describes moral things that are pleasing, as well as nonmoral things that are pleasing, perhaps â€œkindâ€ simply refers to the first group of nice things. ==While this interpretation is appealing in its simplicity, it might be that things can be nice without being kind, and vice versa. The distinguishing factor seems to lie in the motivation of a person or act.Â \nFor example, consider again how holding the door for others can be described as either â€œniceâ€ or â€œkindâ€.Â  If the underlying motivation is to create a favorable impression for the purpose of asking for a favor later, then the action can be considered nice due to its pleasing effect, but not kind without a sense of benevolence. Conversely, if the motivation is to spare the other person from extra effort or inconvenience, then the action can be considered kind, as well as nice if it pleases the other person. ==After all, pleasing others and benevolence do not have to be mutually exclusive.Â \nIt seems that they do not have to be mutually inclusive, either. Perhaps not every action coming from a place of benevolence has a pleasing effect. For example, imagine that you have to break some bad news to a good friend of yours. While the news is almost guaranteed to displease your friend, you know that the information will help them in the long run. In such a situation, breaking the news to your friend can be considered a kind action, but not necessarily a nice one.Â \nWhat do you think? What marks the difference being nice and being kind? Can the two overlap? Share your thoughts with us below!\nKelly Shi is the Hackworth Fellow and the Markkula Center for Applied Ethics.Â \nApr 26, 2016"},"Newsletter/2-Midweek-Roll-Nov-16-2023/Being-nice-vs.-being-kind":{"slug":"Newsletter/2-Midweek-Roll-Nov-16-2023/Being-nice-vs.-being-kind","filePath":"Newsletter/2 Midweek Roll Nov 16 2023/Being nice vs. being kind.md","title":"Being nice vs. being kind","links":[],"tags":["ethics"],"content":"Summary\nâ€œNiceâ€ and â€œkindâ€ are commonly used interchangeably, but they carry distinct meanings. Unlike â€œnice,â€ which lacks ethical significance and can describe inanimate objects (e.g., a nice dress), â€œkindâ€ specifically conveys benevolence. The key difference between a â€œkindâ€ and a â€œniceâ€ person lies in their motivation. While a nice person seeks to please others, often with expectations of reciprocity, a kind person may act in ways that are not necessarily pleasing but align with benevolence, such as delivering difficult news.\nAre they the same?\nKelly Shi\nWhat is the difference between being nice and being kind? At first glance, it is hard to tell.Â  We seem to use â€œniceâ€ and â€œkindâ€ interchangeably when describing people. A â€œnice personâ€ holds the door for others, and so does a â€œkind personâ€; both behave in ways that demonstrate consideration for others. So are â€œniceâ€ and â€œkindâ€ just synonyms for each other?\nNot exactly, according toÂ dictionary.com. ==â€œNiceâ€ is defined as â€œpleasing; agreeable; delightfulâ€, while â€œkindâ€ is defined as â€œhaving, showing, or proceeding from benevolence.â€ This difference seem to explain why we use â€œniceâ€ but not â€œkindâ€ to describe things besides people and the way they treat each other. For example, â€œnice shirtâ€ is understood as a compliment (albeit a vague one), but â€œkind shirtâ€ is a nonsensical phrase. It seems that while â€œniceâ€ and â€œkindâ€ carry positive connotations, only the latter indicates an ethical significance.Â \nDoes that mean that â€œkindâ€ is merely a subset of â€œniceâ€ that applies to ethical matters? Since â€œniceâ€ describes moral things that are pleasing, as well as nonmoral things that are pleasing, perhaps â€œkindâ€ simply refers to the first group of nice things. ==While this interpretation is appealing in its simplicity, it might be that things can be nice without being kind, and vice versa. The distinguishing factor seems to lie in the motivation of a person or act.Â \nFor example, consider again how holding the door for others can be described as either â€œniceâ€ or â€œkindâ€.Â  If the underlying motivation is to create a favorable impression for the purpose of asking for a favor later, then the action can be considered nice due to its pleasing effect, but not kind without a sense of benevolence. Conversely, if the motivation is to spare the other person from extra effort or inconvenience, then the action can be considered kind, as well as nice if it pleases the other person. ==After all, pleasing others and benevolence do not have to be mutually exclusive.Â \nIt seems that they do not have to be mutually inclusive, either. Perhaps not every action coming from a place of benevolence has a pleasing effect. For example, imagine that you have to break some bad news to a good friend of yours. While the news is almost guaranteed to displease your friend, you know that the information will help them in the long run. In such a situation, breaking the news to your friend can be considered a kind action, but not necessarily a nice one.Â \nWhat do you think? What marks the difference being nice and being kind? Can the two overlap? Share your thoughts with us below!\nKelly Shi is the Hackworth Fellow and the Markkula Center for Applied Ethics.Â \nApr 26, 2016"},"Newsletter/2-Midweek-Roll-Nov-16-2023/College-Presidents-Debate-When-to-Speak-Out-â€”-and-When-to-Keep-Quiet":{"slug":"Newsletter/2-Midweek-Roll-Nov-16-2023/College-Presidents-Debate-When-to-Speak-Out-â€”-and-When-to-Keep-Quiet","filePath":"Newsletter/2 Midweek Roll Nov 16 2023/College Presidents Debate When to Speak Out â€” and When to Keep Quiet.md","title":"College Presidents Debate When to Speak Out â€” and When to Keep Quiet","links":[],"tags":["ethics"],"content":"Source: www.chronicle.com/article/college-presidents-debate-when-to-speak-out-and-when-to-keep-quiet%40gmail.com&amp;success=true&amp;code=success&amp;bc_nonce=80ykpbkqidmogincp45cpk\nByÂ Â Charlotte Matherly\nSummary\nThe article explores the challenges faced by college presidents in responding to global events, particularly the Israel-Hamas conflict, where leaders have been criticized for either taking a stance or not taking a stance. College presidents, including Jonathan R. Alger, President of James Madison University, and Lori S. White, President of DePauw University, discussed the delicate balance of making public statements. They often exercise caution and institutional neutrality, aiming in part to preserve the influence of their voice. The University of Chicagoâ€™s Kalven Report, promoting institutional neutrality, is referenced, and a distinction is drawn between large public colleges and small private colleges in navigating these challenges.\n\nLori S. White, president of DePauw U.\nCollege presidents were inundated with demands last month that theyÂ make a statementÂ after Hamas attacked Israel and killed 1,200 people â€” and then Israel retaliated. But there seemed to beÂ no right wayÂ to do it.\nSince then, the leaders have been simultaneously criticized for being too supportive of Israel or not supportive enough; for ignoring the estimated 10,000 Palestinian people who have died in Israelâ€™s military response; for taking any stance on the Israel-Hamas war; and for saying nothing at all.\n==With pressures on all sides, how do college presidents decideÂ when to commentÂ on world events? And when they do make a statement, what should they say?==\nâ€œWe know we canâ€™t make everybody happy in these circumstances,â€ said Jonathan R. Alger, president of James Madison University, â€œand that canâ€™t be the goal.â€\nAlger and three other college presidents â€” Lori S. White of DePauw University, Jonathan J. Sanford of the University of Dallas, and Ana Mari Cauce of the University of Washington â€” convened on Thursday at aÂ virtual panelÂ hosted by the Bipartisan Policy Center, a nonprofit advocacy group, to discuss how college presidents shouldÂ walk the tightropeÂ of responding publicly, or not, to political and world events.\n\nThe more that you put out statements, the more it waters the others down. You really do want to be very cognizant of when youâ€™re going to say something.\n\nWhen Cauce draftsÂ a public statement, she said, itâ€™s usually for one of four reasons: The matter at hand affects a large part of the campus community, influences college operations, deals with the death or serious injury of a campus-community member, or is creating high stress on campus. But, she said, â€œitâ€™s still a bit of an art.â€\nUnless the situation directly affects their college, panelists said, they often err on the side of caution and, as Sanford put it, â€œresist the temptationâ€ to comment on current events. Part of that approach, Cauce said, is to preserve the influence of a presidentâ€™s voice.\nâ€œThe more that you put out statements, the more it waters the others down,â€ Cauce said. â€œYou really do want to be very cognizant of when youâ€™re going to say something.â€\nADVERTISEMENT\nAt DePauw, a liberal-arts college in Indiana, White posted anÂ online messageÂ outlining her criteria for making a statement. She shares Cauceâ€™s guiding principles but broadens the scope, including comments on matters related to DePauwâ€™s â€œcore mission of teaching and scholarshipâ€ as well as â€œsignificantâ€ national and world events like the September 11 attacks and the death of George Floyd.\nWhen commenting on national and world events, especially in the political realm, things can get messy fast. The college presidents said they tend to stay neutral in such cases. For example, Cauce said, when the U.S. Supreme Court struck down affirmative action in admissions, she released a statement talking not about the issue but about how itâ€™d affect the university.\nâ€œI made a very clear statement that we were still very much focused on our values of inclusivity and access, et cetera, but never actually taking a position one way or another,â€ Cauce said.\n==Several panelists said they follow guidance from the University of Chicagoâ€™sÂ Kalven Report, which promotesÂ institutional neutralityÂ in order to maintain campus free speech and expression. But there are moments of historical significance, like the September 11 attacks, that they said call for more nuance.==\nThe panelists also drew a distinction between large public colleges, like Washington and James Madison, which Alger emphasized must remain nonpartisan to protect individual rights to free expression, and small private colleges like DePauw and Dallas. Although they do have more leeway on what they can say, White and Sanford said they also try to avoid getting swept up in politics in favor of promoting civil discourse."},"Newsletter/2-Midweek-Roll-Nov-16-2023/Gaza-Israelâ€™s-â€˜Open-Air-Prisonâ€™-at-15":{"slug":"Newsletter/2-Midweek-Roll-Nov-16-2023/Gaza-Israelâ€™s-â€˜Open-Air-Prisonâ€™-at-15","filePath":"Newsletter/2 Midweek Roll Nov 16 2023/Gaza Israelâ€™s â€˜Open-Air Prisonâ€™ at 15.md","title":"Gaza Israelâ€™s â€˜Open-Air Prisonâ€™ at 15","links":[],"tags":["Geopolitics"],"content":"Source: www.hrw.org/news/2022/06/14/gaza-israels-open-air-prison-15\nSummary\nsensitive topic so I have just quoted a paragraph\nBetween February 2021 and March 2022, Human Rights Watch interviewed 20 Palestinians who sought to travel out of Gaza via either the Israeli-run Erez crossing or the Egyptian-administered Rafah crossing. Human Rights Watch wrote toÂ IsraeliÂ andÂ EgyptianÂ authorities to solicit their perspectives on its findings, and separately to seek information about an Egyptian travel company that operates at the Rafah crossing but had received no responses at this writing.\nArticle\n(Gaza) â€“ ==Israelâ€™s sweeping restrictions on leaving Gaza deprive its more than two million residents of opportunities to better their lives, Human Rights Watch said today on the fifteenth anniversary of the 2007 closure. The closure has devastated the economy in Gaza, contributed to fragmentation of the Palestinian people, andÂ forms partÂ of Israeli authoritiesâ€™ crimes against humanity ofÂ apartheid and persecutionÂ against millions of Palestinians.==\nIsraelâ€™s closure policy blocks most Gaza residents from going to the West Bank, preventing professionals, artists, athletes, students, and others from pursuing opportunities within Palestine and from traveling abroad via Israel, restricting their rights to work and an education. Restrictive Egyptian policies at its Rafah crossing with Gaza, including unnecessary delays and mistreatment of travelers, have exacerbated the closureâ€™s harm to human rights.\n==â€œIsrael, with Egyptâ€™s help, has turned Gaza into an open-air prison,â€ saidÂ Omar Shakir, Israel and Palestine director at Human Rights Watch. â€œAs many people around the world are once again traveling two years after the start of the Covid-19 pandemic, Gazaâ€™s more than two million Palestinians remain under what amounts to a 15-year-old lockdown.â€==\nIsrael should end its generalized ban on travel for Gaza residents and permit free movement of people to and from Gaza, subject to, at most, individual screening and physical searches for security purposes.\nJune 14, 2022\nInterview: For Palestinians in Gaza, Freedom is Priceless\nHow Israelâ€™s Travel Ban Crushes the Dreams of the Palestinians of Gaza\n\n\nBetween February 2021 and March 2022, Human Rights Watch interviewed 20 Palestinians who sought to travel out of Gaza via either the Israeli-run Erez crossing or the Egyptian-administered Rafah crossing. ==Human Rights Watch wrote toÂ IsraeliÂ andÂ EgyptianÂ authorities to solicit their perspectives on its findings, and separately to seek information about an Egyptian travel company that operates at the Rafah crossing but had received no responses at this writing.==\nSince 2007, Israeli authorities have, with narrow exceptions, banned Palestinians from leaving through Erez, the passenger crossing from Gaza into Israel, through which they can reach the West Bank and travel abroad via Jordan. Israel also prevents Palestinian authorities from operating an airport or seaport in Gaza. Israeli authorities also sharply restrict the entry and exit of goods.\n==They often justify the closure, which came after Hamas seized political control over Gaza from the Fatah-led Palestinian Authority in June 2007, on security grounds. Israeli authorities have said they want to minimize travel between Gaza and the West Bank to prevent the export of â€œa human terrorist networkâ€ from Gaza to the West Bank, which has a porous border with Israel and where hundreds of thousands of Israeli settlers live.==\nThis policy has reduced travel to a fraction of what it was two decades ago, Human Rights Watch said. Israeli authorities have instituted aÂ formalÂ â€œpolicy of separationâ€ between Gaza and the West Bank, despite international consensus that these two parts of the Occupied Palestinian Territory form a â€œsingle territorial unit.â€ Israel accepted that principle in the 1995 Oslo Accords, signed with the Palestine Liberation Organization. Israeli authorities restrict all travel between Gaza and the West Bank, even when the travel takes place via the circuitous route through Egypt and Jordan rather than through Israeli territory.\nDue to these policies, Palestinian professionals, students, artists, and athletes living in Gaza have missed vital opportunities for advancement not available in Gaza. Human Rights Watch interviewed seven people who said that Israeli authorities did not respond to their requests for travel through Erez, and three others who said Israel rejected their permits, apparently for not fitting within Israeliâ€™s narrow criteria.\nWalaa Sada, 31, a filmmaker, said that she applied for permits to take part in film training in the West Bank in 2014 and 2018, after spending years convincing her family to allow her to travel alone, but Israeli authorities never responded to her applications. The hands-on nature of the training, requiring filming live scenes and working in studios, made remote participation impracticable and Sada ended up missing the sessions.\nThe â€œworld narrowedâ€ when she received these rejections, Sada said, making her feel â€œstuck in a small box.â€¦ For us in Gaza, the hands of the clock stopped. People all over the world can easily and quickly book flight and travel, while we â€¦ die waiting for our turn.â€\nThe Egyptian authorities have exacerbated the closureâ€™s impact by restricting movement out of Gaza and at times fully sealing its Rafah border crossing, Gazaâ€™s only outlet aside from Erez to the outside world. Since May 2018, Egyptian authorities have been keeping Rafah open more regularly, making it, amid the sweeping Israeli restrictions, the primary outlet to the outside world for Gaza residents.\nPalestinians, however, still face onerous obstacles traveling through Egypt, including having to wait weeks for permission to travel, unless they are willing to pay hundreds of dollars to travel companies with significant ties to Egyptian authorities to expedite their travel, denials of entry, and abuse by Egyptian authorities.\nSada said she also received an opportunity to participate in a workshop on screenwriting in Tunisia in 2019, but that she could not afford the US$2000 it would cost her to pay for the service that would ensure that she could travel on time. Her turn to travel came up six weeks later, after the workshop had already been held.\n==As an occupying power that maintainsÂ significant control overÂ many aspects of life in Gaza, Israel has obligations underÂ international humanitarian lawÂ to ensure the welfare of the population there. Palestinians also have the right under international human rights law to freedom of movement, in particular within the occupied territory, a right that Israel can restrict under international law only in response to specific security threats.==\nIsraelâ€™s policy, though, presumptively denies free movement to people in Gaza, with narrow exceptions, irrespective of any individualized assessment of the security risk a person may pose. These restrictions on the right to freedom of movement do not meet the requirement of being strictly necessary and proportionate to achieve a lawful objective. Israel has had years and many opportunities to develop more narrowly tailored responses to security threats that minimize restrictions on rights.\nEgyptâ€™s legal obligations toward Gaza residents are more limited, as it is not an occupying power. However, as a state party to the Fourth Geneva Convention, it should ensure respect for the convention â€œin all circumstances,â€ including protections for civilians living under military occupation who are unable to travel due to unlawful restrictions imposed by the occupying power. The Egyptian authorities should also consider the impact of their border closure on the rights of Palestinians living in Gaza who are unable to travel in and out of Gaza through another route, including the right to leave a country.\nEgyptian authorities should lift unreasonable obstacles that restrict Palestiniansâ€™ rights and allow transit via its territory, subject to security considerations, and ensure that their decisions are transparent and not arbitrary and take into consideration the human rights of those affected.\nâ€œThe Gaza closure blocks talented, professional people, with much to give their society, from pursuing opportunities that people elsewhere take for granted,â€ Shakir said. â€œBarring Palestinians in Gaza from moving freely within their homeland stunts lives and underscores the cruel reality of apartheid and persecution for millions of Palestinians.â€\nIsraelâ€™s Obligations to Gaza under International Law\nIsraeli authoritiesÂ claimÂ â€œbroad powers and discretion to decide who may enter its territoryâ€ and that â€œa foreigner has no legal right to enter the Stateâ€™s sovereign territory, including for the purposes of transit into the [West Bank] or aboard.â€ While international human rights law gives wide latitude to governments with regard to entry of foreigners, Israel has heightened obligations toward Gaza residents. Because of the continuing controls Israel exercises over the lives and welfare of Gazaâ€™s inhabitants, Israel remains an occupying power under international humanitarian law, despite withdrawing its military forces and settlements from the territory in 2005. Both the UN and theÂ International Committee of the Red Cross, the guardians of international humanitarian law, have reached this determination. As the occupying power, Israel remains bound to provide residents of Gaza the rights and protections afforded to them by the law of occupation. Israeli authorities continue to control Gazaâ€™s territorial waters and airspace, and the movement of people and goods, except at Gazaâ€™s border with Egypt. Israel also controls the PalestinianÂ population registryÂ and theÂ infrastructureÂ upon which Gaza relies.\nIsrael has an obligation to respect the human rights of Palestinians living in Gaza, including their right to freedom of movement throughout the Occupied Palestinian Territory and abroad, which affects both the right to leave a country and the right to enter their own country. Israel is also obligated to respect Palestiniansâ€™ rights for which freedom of movement is a precondition, for example the rights to education, work, and health. The UNÂ Human Rights CommitteeÂ has saidÂ that while states can restrict freedom of movement for security reasons or to protect public health, public order, and the rights of others, any such restrictions must be proportional and â€œthe restrictions must not impair the essence of the right; the relation between the right and restriction, between norm and exception, must not be reversed.â€\nWhile the law of occupation permits occupying powers to impose security restrictions on civilians, it also requires them to restore public life for the occupied population. ThatÂ obligation increasesÂ in a prolonged occupation, in which the occupier has more time and opportunity to develop more narrowly tailored responses to security threats that minimize restrictions on rights. In addition, the needs of the occupied population increase over time. Suspending virtually all freedom of movement for a short period interrupts temporarily normal public life, but long-term, indefinite suspension in Gaza has had a much more debilitating impact, fragmentating populations, fraying familial and social ties,Â compoundingÂ discriminationÂ against women, and blocking people from pursuing opportunities to improve their lives.\nThe impact is particularly damaging given the denial of freedom of movement to people who are confined to a sliver of the occupied territory, unable to interact in person with the majority of the occupied population that lives in the West Bank, including East Jerusalem, and its rich assortment of educational, cultural, religious, and commercial institutions.\nAfter 55 years of occupation and 15 years of closure in Gaza with no end in sight, Israel should fully respect the human rights of Palestinians, using as a benchmark the rights it grants Israeli citizens. Israel should abandon an approach that bars movement absent exceptional individual humanitarian circumstances it defines, in favor of an approach that permits free movement absent exceptional individual security circumstances.\nIsraelâ€™s Closure\n==Most Palestinians who grew up in Gaza under this closure have never left the 40-by-11 kilometer (25-by-7 mile) Gaza Strip. For the last 25 years, Israel hasÂ increasingly restrictedÂ the movement of Gaza residents. Since June 2007, when Hamas seized control over Gaza from the Fatah-led Palestinian Authority (PA), Gaza has been mostly closed.==\nIsraeli authorities justify this closure on security grounds, in light of â€œHamasâ€™ rise to power in the Gaza Strip,â€ as they lay out in aÂ December 2019 court filing. ==AuthoritiesÂ highlight in particularÂ the risk that Hamas and armed Palestinian groups will recruit or coerce Gaza residents who have permits to travel via Erez â€œfor the commission of terrorist acts and the transfer of operatives, knowledge, intelligence, funds or equipment for terrorist activists.â€ Their policy, though, amounts to a blanket denial with rare exceptions, rather than a generalized respect for the right of Palestinians to freedom of movement, to be denied only on the basis of individualized security reasons. Â ==\nThe Israeli army has since 2007 limited travel through the Erez crossing except in what it deems â€œexceptional humanitarian circumstances,â€ mainly encompassing those needing vital medical treatment outside Gaza and their companions, although the authorities also make exceptions for hundreds of businesspeople and laborers and some others. Israel has restricted movement even for thoseÂ seeking to travelÂ underÂ these narrowÂ exceptions, affecting their rights toÂ health and life, amongÂ others, as Human Rights Watch and other groups have documented. Most Gaza residents do not fit within these exemptions to travel through Erez, even if it is to reach the West Bank.\nBetween January 2015 and December 2019, before the onset of Covid-19 restrictions, an average of about 373 Palestinians left Gaza via Erez each day, less than 1.5 percent of the daily average of 26,000 in September 2000, before the closure, according to the Israeli rights group Gisha.Â Israeli authorities tightened the closure further during the Covid-19 pandemic â€“ between March 2020 and December 2021, an average of about 143 Palestinians left Gaza via Erez each day, according to Gisha.\nIsraeli authoritiesÂ announcedÂ in March 2022 that they would authorize 20,000 permits for Palestinians in Gaza to work in Israel in construction and agriculture, though Gisha reports that the actual number of valid permits in this category stood at 9,424, as of May 22.\nIsraeli authorities have also for more than two decadesÂ sharply restrictedÂ the use by Palestinians of Gazaâ€™s airspace and territorial waters. TheyÂ blockedÂ the reopening of the airport that Israeli forces made inoperable in January 2002, and prevented the Palestinian authorities from building a seaport, leaving Palestinians dependent on leaving Gaza by land to travel abroad. The few Palestinians permitted to cross at Erez are generally barred from traveling abroad via Israelâ€™s international airport andÂ must instead travel abroad viaÂ Jordan. Palestinians wishing to leave Gaza via Erez, either to the West Bank or abroad, submit requests through the Palestinian Civil Affairs Committee in Gaza, which forwards applications to Israeli authorities who decide on whether to grant a permit.\nSeparation Between Gaza and the West Bank\nAs part of the closure, Israeli authorities have sought to â€œdifferentiateâ€ between their policy approaches to Gaza and the West Bank, such as imposingÂ more sweeping restrictionsÂ on the movement of people and goods from Gaza to the West Bank, and promote separation between these two parts of the Occupied Palestinian Territory. The armyâ€™s â€œProcedure for Settlement in the Gaza Strip by Residents of Judea and Samaria,â€ published in 2018,Â statesÂ that â€œin 2006, a decision was made to introduce a policy of separation between the Judea and Samaria Area [the West Bank] and the Gaza Strip in light of Hamasâ€™ rise to power in the Gaza Strip. The policy currently in effect is explicitly aimed at reducing travel between the areas.â€\nIn each of the 11 cases Human Rights Watch reviewed of people seeking to reach the West Bank, including East Jerusalem, for professional and educational opportunities not available in Gaza, Israeli authorities did not respond to requests for permits or denied them, either for security reasons or because they did not conform to the closure policy. Human Rights Watch also reviewed permit applications on the website of the Palestinian Civil Affairs Committee, or screenshots of it, including the status of the permit applications, when they were sent on to the Israeli authorities and the response received, if any.\nRaed Issa, a 42-year-old artist, said that the Israeli authorities did not respond to his application for a permit in early December 2015, to attend an exhibit of his art at a Ramallah art gallery between December 27 and January 16, 2016.\nThe â€œBeyond the Dreamâ€ exhibitÂ sought to highlight the situation in Gaza after the 2014 war. Issa said that the Palestinian Civil Affairs committee continued to identify the status of his application as â€œsent and waiting for responseâ€ and he ended up having to attend the opening of the exhibit virtually. Issa felt that not being physically present hampered his ability to engage with audiences, and to network and promote his work, which he believes limited his reach and hurt sales of his artwork. He described feeling pained â€œthat I am doing my own art exhibit in my homeland and not able to attend it, not able to move freely.â€\nAshraf Sahweel, 47, chairman of the Board of Directors of the Gaza Center for Art and Culture, said that Gaza-based artists routinely do not hear back after applying for Israeli permits, forcing them to miss opportunities to attend exhibitions and other cultural events. A painter himself, he applied for seven permits between 2013 and 2022, but Israeli authorities either did not respond or denied each application, he said. Sahweel said that he has â€œgiven up hope on the possibility to travel via Erez.â€\nPalestinian athletes in Gaza face similar restrictions when seeking to compete with their counterparts in the West Bank, even though the Israeli armyÂ guidelinesÂ specifically identify â€œentry of sportspeopleâ€ as among the permissible exemptions to the closure. The guidelines, updated in February 2022, set out that â€œall Gaza Strip residents who are members of the national and local sports teams may enter Israel in transit to the Judea and Samaria area [West Bank] or abroad for official activities of the teams.â€\nHilal al-Ghawash, 25, told Human Rights Watch that his football team, Khadamat Rafah, had a match in July 2019 with a rival West Bank team, the Balata Youth Center, in the finals of Palestine Club, with the winner entitled to represent Palestine in the Asian Cup. The Palestinian Football Federation applied for permits for the entire 22-person team and 13-person staff, but Israeli authorities, without explanation, granted permits to only 4 people, only one of whom was a player. The game was postponed as a result.\nAfterÂ Gisha appealedÂ the decision in the Jerusalem District Court, Israeli authorities granted 11 people permits, including six players, saying the other 24 were denied on security grounds that were not specified. Al-Ghawash was among the players who did not receive a permit. The Jerusalem district court upheld the denials. With Khadamat Rafah prevented from reaching the West Bank, the Palestine Football Federation canceled the Palestine Cup finals match.\nAl-Ghawash said that West Bank matches hold particular importance for Gaza football players, since they offer the opportunity to showcase their talents for West Bank clubs, which are widely considered superior to those in Gaza and pay better. Despite the cancellation, al-Ghawash said, the Balata Youth Center later that year offered him a contract to play for them. The Palestinian Football Federation again applied for a permit on al-Ghawashâ€™s behalf, but he said he did not receive a response and was unable to join the team.\nIn 2021, al-Ghawash signed a contract with a different West Bank team, the Hilal al-Quds club. The Palestinian Football Federation again applied, but this time, the Israeli army denied the permit on unspecified security grounds. Al-Ghawash said he does not belong to any armed group or political movement and has no idea on what basis Israeli authorities denied him a permit.\nMissing these opportunities has forced al-Ghawash to forgo not only higher pay, but also the chance to play for more competitive West Bank teams, which could have brought him closer to his goal of joining the Palestinian national team. â€œThereâ€™s a future in the West Bank, but, here in Gaza, thereâ€™s only a death sentence,â€ he said. â€œThe closure devastates playersâ€™ future. Gaza is full of talented people, but itâ€™s so difficult to leave.â€\nPalestinian students and professionals are frequently unable to obtain permits to study or train in the West Bank. In 2016, Augusta Victoria Hospital in East Jerusalem agreed to have 10 physics students from Al-Azhar University in Gaza come to the hospital for a six-month training program. Israeli authorities denied five students permits without providing a rationale, two of the students said.\nThe five other students initially received permits valid for only 14 days, and then encountered difficulties receiving subsequent permits. None were able to complete the full program, the two students said. One, Mahmoud Dabour, 28, said that when he applied for a second permit, he received no response. Two months later, he applied again and managed to get a permit valid for one week. He received one other permit, valid for 10 days, but then, when he returned and applied for the fifth time, Israeli authorities rejected his permit request without providing a reason. As a result, he could not finish the training program, and, without the certification participants receive upon completion, he said, he cannot apply for jobs or attend conferences or workshops abroad in the field.\nDabour said that the training cannot be offered in Gaza, since the necessary radiation material required expires too quickly for it to be functional after passing through the time-consuming Israeli inspections of materials entering the Gaza Strip. There are no functioning devices of the kind that students need for the training in Gaza, Dabour said.\nOne of the students whose permit was denied said, â€œI feel I studied for five years for nothing, that my life has stopped.â€ The student asked that his name be withheld for his security.\nTwo employees of Zimam, a Ramallah-based organization focused on youth empowerment and conflict resolution, said that the Israeli authorities repeatedly denied them permits to attend organizational training and strategy meetings. Atta al-Masri, the 31-year-old Gaza regional director, said he has applied four times for permits, but never received one. Israeli authorities did not respond the first three times and, the last time in 2021, denied him a permit on the grounds that it was â€œnot in conformityâ€ with the permissible exemptions to the closure. He has worked for Zimam since 2009, but only met his colleagues in person for the first time in Egypt in March 2022.\nAhed Abdullah, 29, Zimamâ€™s youth programs coordinator in Gaza, said she applied twice for permits in 2021, but Israeli authorities denied both applications on grounds of â€œnonconformity:â€\nThis is supposed to be my right. My simplest right. Why did they reject me? My colleagues who are outside Palestine managed to make it, while I am inside Palestine, I wasnâ€™t able to go to the other part of Palestine â€¦ itâ€™s only 2-3 hours from Gaza to Ramallah, why should I get the training online? Why am I deprived of being with my colleagues and doing activities with them instead of doing them in dull breakout rooms on Zoom?\nHuman Rights Watch has previously documented that the closure has prevented specialists in the use of assistive devices forÂ people with disabilitiesÂ from opportunities for hands-on training on the latest methods of evaluation, device maintenance, and rehabilitation. Human Rights Watch also documented restrictions on theÂ movement of human rights workers. Gisha, the Israeli human rights group, has reported that Israel hasÂ blocked health workersÂ in Gaza from attending training in the West Bank on how to operate new equipment and hampered the work ofÂ civil societyÂ organizations operating in Gaza.\nIsraeli authorities have also made it effectively impossible for Palestinians from Gaza to relocate to the West Bank. Because of Israeli restrictions, thousands of Gaza residents who arrived on temporary permits and now live in the West Bank are unable to gain legal residency. Although Israel claims that these restrictions are related to maintaining security, evidence Human Rights Watch collected suggests the main motivation is toÂ control Palestinian demographyÂ across the West Bank, whose land Israel seeks to retain, in contrast to the Gaza Strip.\nEgypt\n==With most Gaza residents unable to travel via Erez, the Egyptian-administered Rafah crossing has become Gazaâ€™s primary outlet to the outside world, particularly in recent years. Egyptian authorities kept Rafah mostly closed for nearly five years following the July 2013 military coup in Egypt that toppled President Mohamed Morsy, whom the military accused of receiving support from Hamas. Egypt, though, eased restrictions in May 2018, amid theÂ Great March of Return, the recurring Palestinian protests at the time near the fences separating Gaza and Israel.==\nDespite keeping Rafah open more regularly since May 2018, movement via Rafah is a fraction of what it was before the 2013 coup in Egypt. Whereas an average of 40,000 crossed monthly in both directions before the coup, the monthly average was 12,172 in 2019 and 15,077 in 2021, according to Gisha.\nHuman Rights Watch spoke with 16 Gaza residents who sought to travel via Rafah. Almost all said they opted for this route because of the near impossibility of receiving an Israeli permit to travel via Erez.\nGaza residents hoping to leave via Rafah are required to register in advance via a process the UN Office for the Coordination of Humanitarian Affairs (OCHA) hasÂ deemed â€œconfusingâ€ and â€œobscure.â€ Gaza residents can either register via the formal registration process administered by Gazaâ€™s Interior Ministry or informally via what is known asÂ tanseeq,Â or travel coordination with Egyptian authorities, paying travel companies or mediators for a place on a separate list coordinated by Egyptian authorities. HavingÂ two distinct listsÂ of permitted travelers coordinated by different authorities has fueled â€œallegations of the payment of bribes in Gaza and in Egypt to ensure travel and a faster response,â€ according to OCHA.\nThe formal process often takes two to three months, except for those traveling for medical reasons, whose requests are processed faster, said Gaza residents who sought to leave Gaza via Rafah. Egyptian authorities have at times rejected those seeking to cross Rafah into Egypt on the grounds that they did not meet specific criteria for travel. The criteria lack transparency, butÂ Gisha reportedÂ that they include having a referral for a medical appointment in Egypt or valid documents to enter a third country.\nTo avoid the wait and risk of denial, many choose instead the tanseeqÂ route. Several interviewees said that they paid large sums of money to Palestinian brokers or Gaza-based travel companies that work directly with Egyptian authorities to expedite peopleâ€™s movement via Rafah. On social media, some of theseÂ companies advertiseÂ that they can assure travel within days to those who provide payment and a copy of their passport. The cost of tanseeq has fluctuated from several hundred US dollars to several thousand dollars over the last decade, based in part on how frequently Rafah is open.\nIn recent years, travel companies have offered an additional â€œVIPâ€ tanseeq, which expedites travel without delays in transit between Rafah and Cairo, offers flexibility on travel date, and ensures better treatment by authorities. The cost was $700, as of January 2022.\nThe Cairo-based company offering the VIP tanseeq services,Â HalaÂ Consulting and Tourism Services, has strong links with Egyptâ€™s security establishment and is staffed largely by former Egyptian military officers, a human rights activist and a journalist who have investigated these issues told Human Rights Watch. This allows the company to reduce processing times and delays at checkpoints during the journey between Rafah and Cairo. The activist and journalist both asked that their names be withheld for security reasons. Â \nThe company isÂ linkedÂ to prominent Egyptian businessman Ibrahim El-Argani, who hasÂ closeÂ ties with Egyptâ€™s president, Abdel-Fattah al-Sisi. ErganyÂ headsÂ the Union of Sinai Tribes, which worksÂ hand-in-handÂ with the Egyptian military and intelligence agencies against militants operating in North Sinai. Ergany, one of Egyptâ€™s few businessmen able to export products to Gaza from Egypt,Â ownsÂ the Sinai Sons company, which has anÂ exclusiveÂ contract to handle all contracts related to Gaza reconstruction efforts. Human Rights WatchÂ wrote to El-ArganiÂ to solicit his perspectives on these issues, but had received no response at this writing.\nA 34-year-old computer engineer and entrepreneur said that he sought to travel in 2019 to Saudi Arabia to meet an investor to discuss a potential project to sell car parts online. He chose not to apply to travel via Erez, as he had applied for permits eight times between 2016 and 2018 and had either been rejected or not heard back.\nHe initially registered via the formal Ministry of Interior process and received approval to travel after three months. However, on the day assigned for his exit via Rafah, an Egyptian officer there said he found his reason for travel not sufficiently â€œconvincingâ€ and denied him passage. A few months later, he tried to travel again for the same purpose, this time opting for tanseeq and paying $400, and, this time, he successfully reached Saudi Arabia within a week of seeking to travel.\nHe said that he would like to go on vacation with his wife, but worries that Egyptian authorities will not consider vacation a sufficiently compelling reason for travel and that his only option will be to pay hundreds or thousands of dollars to do tanseeq.\nA 73-year-old man sought to travel via Rafah in February 2021, with his 46-year-old daughter, to get knee replacement surgery in al-Sheikh Zayed hospital in Cairo. He said Gaza lacks the capacity to provide such an operation. The man and his daughter are relatives of a Human Rights Watch staff member. They applied via the Interior Ministry process and received approval in a little over a week.\nAfter they waited for several hours in the Egyptian hall in Rafah on the day of travel, though, Egyptian authorities included the daughterâ€™s name among the 70 names of people who were not allowed to cross that day, the daughter said. The father showed the border officials a doctorâ€™s note indicating that he needed someone to travel with him given his medical situation, but the officer told him, â€œYou either travel alone or go back with her to Gaza.â€ She said she returned to Gaza, alongside 70 other people, and her father later traveled on his own.\nFive people who did manage to travel via Rafah said that they experienced poor conditions and poor treatment, including intrusive searches, by the Egyptian authorities, with several saying that they felt Egyptian authorities treated them like â€œcriminals.â€ Several people said that Egyptian officers confiscated items from them during the journey, including an expensive camera and a mobile phone, without apparent reason.\nUpon leaving Rafah, Palestinians are transported by bus to Cairoâ€™s airport. The trip takes about seven hours, but several people said that the journey took up to three days between long periods of waiting on the bus, at checkpoints and amid other delays, often in extreme weather. Many of those who traveled via Rafah said that, during this journey, Egyptian authorities prevented passengers from using their phones.\nThe parents of a 7-year-old boy with autism and a rare brain disease said they sought to travel for medical treatment for him in August 2021, but Egyptian authorities only allowed the boy and his mother to enter. The mother said their journey back to Gaza took four days, mostly as a result of Rafah being closed. During this time, she said, they spent hours waiting at checkpoints, in extreme heat, with her son crying nonstop. She said she felt â€œhumiliatedâ€ and treated like â€œan animal,â€ observing that she â€œwould rather die than travel again through Rafah.â€\nA 33-year-old filmmaker, who traveled via Rafah to Morocco in late 2019 to attend a film screening, said the return from Cairo to Rafah took three days, much of it spent at checkpoints amid the cold winter in the Sinai desert.\nA 34-year-old man said that he planned to travel in August 2019 via Rafah to the United Arab Emirates for a job interview as an Arabic teacher. He said, on his travel date, Egyptian authorities turned him back, saying they had met their quota of travelers. He crossed the next day, but said that, as it was a Thursday and with Rafah closed on Friday, Egyptian authorities made travelers spend two nights sleeping at Rafah, without providing food or access to a clean bathroom.\nThe journey to Cairo airport then took two days, during which he described going through checkpoints where officers made passengers â€œput their hands behind their backs while they searched their suitcases.â€ As a result of these delays totaling four days since his assigned travel date, he missed his job interview and found out that someone else was hired. He is currently unemployed in Gaza.\nGiven the uncertainty of crossing at Rafah, Gaza residents said that they often wait to book their flight out of Cairo until they arrive. Booking so late often means, beyond other obstacles, having to wait until they can find a reasonably priced and suitable flight, planning extra days for travel and spending extra money on changeable or last-minute tickets. Similar dynamics prevail with regard to travel abroad via Erez to Amman.\nHuman Rights Watch interviewed four men under the age of 40 with visas to third countries, whom Egyptian authorities allowed entry only for the purpose of transit. The authorities transported these men to Cairo airport and made them wait in what is referred to as the â€œdeportation roomâ€ until their flight time. The men likened the room to a â€œprison cell,â€ with limited facilities and unsanitary conditions. All described a system in which bribes are required to be able to leave the room to book a plane ticket, get food, drinks, or a cigarette, and avoid abuse. One of the men described an officer taking him outside the room, asking him, â€œWonâ€™t you give anything to Egypt?â€ and said that others in the room told him that he then proceeded to do the same with them."},"Newsletter/2-Midweek-Roll-Nov-16-2023/Midweek-Roll-November-16-2023":{"slug":"Newsletter/2-Midweek-Roll-Nov-16-2023/Midweek-Roll-November-16-2023","filePath":"Newsletter/2 Midweek Roll Nov 16 2023/Midweek Roll November 16 2023.md","title":"End-of-week Roll","links":["Newsletter/2-Midweek-Roll-Nov-16-2023/Being-nice-vs.-being-kind","Newsletter/2-Midweek-Roll-Nov-16-2023/Gaza-Israelâ€™s-â€˜Open-Air-Prisonâ€™-at-15","Newsletter/2-Midweek-Roll-Nov-16-2023/College-Presidents-Debate-When-to-Speak-Out-â€”-and-When-to-Keep-Quiet"],"tags":[],"content":"www.hrw.org/news/2022/06/14/gaza-israels-open-air-prison-15\nThis is linked under above article, hyperlinked as â€œEgyptianâ€\nwww.hrw.org/sites/default/files/media_2022/06/gl.2022.05.23.Palestine%20Letter%20to%20Egyptian%20PM%20on%20Gaza%20Residents%20Travel%20Restrictions_Redacted.pdf\nlistingcenter.nasdaq.com/assets/rulebook/nasdaq/filings/SR-NASDAQ-2023-045.pdf\nI. Articles that I have enjoyed reading this week.\nA. Being nice vs. being kind\na. About the Author:\nb. Article Summary:\nâ€œNiceâ€ and â€œkindâ€ are commonly used interchangeably, but they carry distinct meanings. Unlike â€œnice,â€ which lacks ethical significance and can describe inanimate objects (e.g, nice dress), â€œkindâ€ specifically conveys benevolence. The key difference between a â€œkindâ€ and a â€œniceâ€ person lies in their motivation. While a nice person seeks to please others, often with expectations of reciprocity, a kind person may act in ways that are not necessarily pleasing but align with benevolence, such as delivering difficult news.\nc. Tweet: x.com/RikaGoldberg/status/1689001545919086592\nB. Gaza Israelâ€™s â€˜Open-Air Prisonâ€™ at 15\na. About the Author:\nb.  Article Summary:\nC. College Presidents Debate When to Speak Out â€” and When to Keep Quiet\na. About the Author:\nb. Article Summary"},"Newsletter/3-Wallets/3-Wallets---Outline":{"slug":"Newsletter/3-Wallets/3-Wallets---Outline","filePath":"Newsletter/3 Wallets/3 Wallets - Outline.md","title":"3 Wallets - Outline","links":[],"tags":[],"content":"Beginner level explanation of wallets. Overview of the different wallets out there.\n==My goal for this newsletter is to provide practical insights into using Ethereum protocols and products safely. You will surely fail, as one does when learning anything new, but you will, most importantly, fail safely.==\nTitle Ideas: What is an Ethereum wallet? An overview of Ethereum wallets.\n[insert quote]\n[insert personal story about the first time I used crypto wallets e.g. exodus]\nIntroduction\nI. What is an Ethereum wallet?\nItâ€™s a user interface for accessing your cryptocurrency so you can send and receive money and access application. Itâ€™s a different frame/paradigm thatâ€™s unlike a physical wallet or a bank account. A physical wallet has credit cards. A crypto wallet also has accounts that you can create. That first account creation is the public/private key with your seed phrase. Then you can create more accounts but theyâ€™re all linked to the top account (probably can exclude this, itâ€™s a little too technical)\nII. Basic Mechanics of an Ethereum Wallet\n\nPublic Key Cryptography\n\npublic &amp; private key\n\n\nEOA\nSeed phrases\n\nMnemonic\nBip39, Bip32, Bip44\nIII. Wallet Recommendations\n\n\nYou probably want some recs (and want to not get rekt!) My guess is that youâ€™ve heard of at least one of the four wallets that I will recommend!\nII. Wallet evaluation framework\nOpen source\nSelf custody\nPermissionless (anyone can sign up)\nAudited, code available for anyone to review\n\nPublic bug bounty\n\n\nBattle Tested\nII. The different wallets available?\nMetamask\nRabby Wallet\nCoinbase Wallet\nBrume Wallet (cupoJoseph) - low fidelity-ish iâ€™m not sure if appropriate for this audience\nB. There are browser extension wallets\nMetamask - OG. First one. Has portfolio.\nBrave - Iâ€™ve tried it to try a new browser extension wallet. I use brave so I tried their wallet.\nC. Hardware wallet\nFor long term storage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetamaskRabbyCoinbaseBrumeOpen SourceYesYesNoYesSelf custodyYesYesYesYesPermissionless (no account required) note: an argument can be made that social login/email helps onboard new users by providing a familiar flowYesYesYesYesAudited / public bug bountyYes (Mobile &amp; Snaps &amp; have a HackerOne public bug bounty) metamask.io/files/LeastAuthority-MetaMask-Audit-Report.pdfhttps://metamask.io/files/least-authority-metamask-snaps-audit-extension.pdfYes, slowmistNot publicly availableNoBattle TestedYes. 2016. 30M monthly active users as of January2021NoKey Differentiator1. Ease of multi-chain experience (DeFi era)2. Human readable details around the contracts users are signingBuilt-in Tor so your IP address is not tracked. Tradâ€™l wallets send IP address to 3rd parties (Coingecko, Etherscan) which can track you and put your multiple identities togetherGrassroots project funded by community. juicebox.money/v2/p/594"},"Newsletter/3-Wallets/Appendix":{"slug":"Newsletter/3-Wallets/Appendix","filePath":"Newsletter/3 Wallets/Appendix.md","title":"Appendix","links":[],"tags":["seeds"],"content":"x.com/rainbowdotme/status/1903095966913143185\nrainbow.me/support/app/rainbow-token-launcher\nRainbow Token Launcher\nAn Overview:\nRainbow Token Launcher is the easiest way to create and launch your own token on Ethereum and its Layer 2 networks. Whether you want to make a fun memecoin for your friends or launch a social token for your community, weâ€™ve got you covered with a simple mobile-first experience.\n\nGetting Started:\nTo launch a token, you simply need:\n\n\nA Rainbow wallet\n\n\nSome ETH on your chosen network for launch costs\n\n\nA creative idea for your token!\n\n\nFor now, youâ€™ll need to pay network fees to deploy your token, though we are working to make this free for everyone soon. These fees vary by network. Weâ€™ll always show you the exact cost before you launch. In the future, we plan to make this free.\nYou can launch on the below networks that Rainbow supports! And those networks are able to create incentives for deploying tokens on their network through Rainbow. Go wild ğŸŒˆ\n\n\nMainnet\n\n\nArbitrum\n\n\nBase\n\n\nOP\n\n\nPolygon\n\n\nBSC\n\n\nAVAX\n\n\nBlast\n\n\nInk\n\n\nBerachain\n\n\nUnichain\n\n\nZora\n\n\n\nToken Distribution:\nAbout 94% goes into liquidity (so people can trade it), while you get 0.5%-1% as the creator (depending on whether you enable airdrop). If you enable airdrops, 0.5% is reserved for your community. If you donâ€™t enable airdrops, you get 1% as the creator (0.5% base + 0.5% from unused airdrop allocation). You can also pre-buy tokens at launch to boost the initial price. Lastly, 5% is allocated Over The Rainbow.\nWhen you launch your token, 5% of the total supply goes â€œOver the Rainbowâ€ which is our way of saying itâ€™s held on chain (for now) and will one day be used for Future Rainbow Community Distributions. This gets your token into more hands and gives the Rainbow community a stake in projects launched on the platform while keeping most of your tokenâ€™s supply (94%) in the liquidity pool for trading. As the creator, you still receive your share (0.5-1%) of the total supply, with an optional portion for airdrops to your community.\nLiquidity Pool:\nWhen people trade your token, a 1% fee is charged on each transaction. This fee is split between you (the creator) and the Rainbow Token Launcher protocol. You get 50% of these trading fees and the protocol gets 50%. These fees come from the liquidity pool thatâ€™s created when you launch your token. The more trading volume your token generates, the more fees you earn! You can collect these fees anytime through the Rainbow app, with no minimum threshold required. Itâ€™s a great way to earn passive income from your creation, even if youâ€™re not actively trading it yourself.\n\nTrading &amp; Prices:\nToken prices are initially determined by supply and demand through Uniswap liquidity pools. This is in place of a bonding curve. If more people are buying than selling, the price goes up. If more are selling than buying, it goes down. Think of it like a digital trading card - the value depends on how much people want it!\nYou can trade any token that exists on supported networks through Rainbowâ€™s swap feature. Rainbow Token Launcher tokens can also be traded on other platforms that support ERC20 tokens.\n\nCreating Your Token:\nWhen creating your token, youâ€™ll be able to customize the token and create an initial total supply amount.\nYour tokenâ€™s â€œtotal supplyâ€ is the total number of tokens that get created when you launch your token. Rainbow uses â€œ1 billionâ€ as the default value, but you can customize your tokenâ€™s Total Supply with any value between 0 and 1 trillion for added fun!\nYou can be creative with names and symbols, but we donâ€™t allow impersonation of existing projects. Also, â€œRainbowâ€ and â€œRNBWâ€ are reserved (sorry! ğŸ˜‰).\nWhen you launch, you can optionally buy some of your token right away. This raises the initial price, and makes sure you can get enough of your own token before anyone else does!\nHow it Works:\n\n\nLaunch the token launcher under the discover screen: ğŸ”Â â†’ Launch your Coin\n\n\nHere, you can begin editing your token details along with additional fields to customize. When youâ€™re all set, you can tap continue to finalize those token details.\n\n\n\nAirdrops &amp; Community:\nBefore we get into specifics, an airdrop is when you give away some of your tokens to specific people like your friends or community members. Itâ€™s a great way to get people excited about your token!\nWith the token launcher, you can easily select friends to airdrop to using their Farcaster username, ENS name, or wallet address. We also have preset groups like â€œYour Farcaster Followersâ€ to make it super simple.\n\nSafety &amp; Security:\nWhile launching tokens is fun, remember that crypto trading involves risk. Never invest more than you can afford to lose, and be especially careful with new tokens which can be highly volatile.\nLearn more about protecting your wallet here.\nWhile we canâ€™t prevent all copycats, we do have measures to prevent impersonation. Report suspicious tokens to support@rainbow.me and weâ€™ll investigate.\n\nCommon Questions:\n\n\nWhatâ€™s â€œgasâ€ and why do I need it?\nGas is like a transaction fee you pay to the network. You need some ETH (or whatever the networkâ€™s native token is) to pay for gas when you launch a token or make trades.\nLearn more about gas here.\n\n\n_Help! My transaction is stuck!\n_Donâ€™t worry! Transactions can sometimes take a moment depending on network conditions. Check your transaction status in Rainbow, and if you need help, our support team is just a message away.\nLearn more about fixing stuck transactions here.\n\n\nWhatâ€™s the difference between swapping and bridging?\n\n\nSwapping is trading one token for a different token on the same network\n\n\nBridging is moving your tokens from one network to another (like from Base to Arbitrum)\n\n\nLearn more about swapping and bridging here.\n\n\n\nNeed more help? Reach out to support via email at support@rainbow.me, or, visit our Support Center to learn more. Weâ€™re here to make your token launch as smooth as possible! ğŸŒˆ\nCanâ€™t find what youâ€™re looking for? Send us a message, tweet at us @rainbowdotme, or email support@rainbow.me for further assistance."},"Newsletter/3-Wallets/Binance-Enters-Wallet-Wars":{"slug":"Newsletter/3-Wallets/Binance-Enters-Wallet-Wars","filePath":"Newsletter/3 Wallets/Binance Enters Wallet Wars.md","title":"Binance Enters Wallet Wars","links":["tags/newsletter"],"tags":["newsletter"],"content":"newsletter\nBlockworks Daily Newsletter\nAfter a brief dip and recovery, majors continued to oscillate overnight within tight 2-3% ranges. Notable movers of the day include Cowswap (COW) and Illuvium (ILV). COW has been up-only this week thanks to a proposal in governance to select and test different fee models for the protocol. Cowswap is easily one of the best aggregators on the market, and the protocol offers value through MEV protection. When the protocol airdropped COW tokens in March 2022, there was no clear utility besides â€œgovernance,â€ and as a result the token only went lower as time passed.\nIlluvium came out with a big announcement that the Web3 gaming studioâ€™s PVP Beta is set for release on Epic Gamesâ€™ marketplace on November 28. The teams behind this have been building and fundraising for years, and it finally looks like crypto gamingâ€™s big moment is quickly approaching. Epic Gamesâ€™ marketplace offers exposure to 180M+ users and gained most of its fame from Fortnite, which significantly impacted gaming culture over the past few years.\nIn other news, Binance finally dropped their â€œmass onboard the next billion usersâ€ news. The exchange took a page from Coinbaseâ€™s book and launched Binance Web3 Wallet, which allows users to self-custody crypto and utilize dApps within the Binance app. ==The wallet utilizes Multi-Party Computation (MPC) to create three different key files, which are split between different locations for added security.==\nThis wallet move makes a ton of sense for Binance. In the peak of the last bull run, BSC saw tons of volume and users, and one of the biggest fumbles of that time period was the fact that BSC users had to turn to third party wallets, such as Trust Wallet or MetaMask, to access the chain. Now, users will have an enhanced experience, and Binance gets to silo these users within its ecosystem. As the UX improves, we can only get more and more bullish on crypto."},"Newsletter/3-Wallets/Navigating-Ethereum-Wallets":{"slug":"Newsletter/3-Wallets/Navigating-Ethereum-Wallets","filePath":"Newsletter/3 Wallets/Navigating Ethereum Wallets.md","title":"Navigating Ethereum Wallets","links":[],"tags":["newsletter"],"content":"Final Published: paragraph.xyz/@sharingiscaring/navigating-ethereum-wallets\nGreetings, readers! (or Gm, as we say in crypto). This newsletter provides digestible breakdowns of complex protocols and products in the Ethereum ecosystem. You can expect quality substantive content (no hype pieces, shilling, or paywall) written for crypto-curious readers who are either newer to crypto or seasoned users who value refreshers on the fundamentals. You can learn more about this newsletter in the introductory post.\nEthereum Wallets\nA non-custodial Ethereum wallet is a portal to the Ethereum blockchain. It gives you a window to access your digital assets and sign in to decentralized applications.\nAlthough the focus of this post is on non-custodial wallets, itâ€™s important to understand that some wallets are custodial, such as an exchangeâ€™s wallet. Custodial wallets have their purpose, such as providing an off-ramp to local currency, but they lack in many features of non-custodial wallets.\nIn contrast to custodial wallets, non-custodial wallets allow you to meaningfully engage with crypto and use decentralized applications (dApps) for activities such as staking (see the last post), borrowing, lending, gaming, social networks, and more.\nVery importantly: non-custodial wallets give you full control over your digital assets. Custodial wallets do not.\nIn this post, I will explain the basic mechanics of non-custodial wallets before sharing a handful of reputable wallet providers, along with a simple wallet evaluation framework to help you make informed decisions when selecting a wallet.\nHopefully you will come back to this guide throughout the bull market to help you get grounded when the energy may start to feel frenetic.\nAs always, letâ€™s start with a few useful definitions before diving into the meat of the post.\n\nUseful Definitions\nLetâ€™s align on six important definitions. You may find some of these rudimentary, so feel free to skip to the next section if youâ€™re already comfortable with these concepts.\n*Note: all of these definitions are from Ethereum.org, a leading educational resource.\n\n\n\nWhat is Ethereum\nEthereum is a public network, a blockchain, and an open-source protocol â€” operated, governed, managed, and owned by a global community of tens of thousands of developers, node operators, ETH holders, and users.\n\n\nWhat is Ether (a.k.a. ETH)?\nEther (also known by its ticker symbol ETH) is the native currency transacted on Ethereum. ETH is needed to pay for usage of the Ethereum network (in the form of transaction fees). ETH is also used to secure the network with staking.\n\n\nWhat is an Ethereum Account?\nAn Ethereum account is an entity with an ether (ETH) balance that can send transactions on Ethereum. Accounts can be user-controlled or deployed as smart contracts.\n\n\nWhat is an Externally-owned account (EOA)?\nOne of the two types of accounts on Ethereum. An externally-owned account is controlled by anyone with the private keys.\n\n\nWhat is a Contract Account?\nOne of the two types of accounts on Ethereum. A smart contract account is deployed to the Ethereum network, controlled by code.\n\n\nWhat is a Non-custodial Wallet?\nA non-custodial wallet gives you full control over your accounts. This means that the wallet provider does not have access to the private keys.\n\n\n\nBasic Mechanics of an Ethereum Wallet\nAn Ethereum wallet is software that allows you to interact with your Ethereum account. Wallets use public key cryptography, a method of encrypting or signing data with two different keys: a public and a private key so you can sign in to Ethereum applications, read balances, send transactions, and verify your identity. Public key cryptography is an important technology to Internet security broadly, not only to crypto.\nWhen you download a wallet (usually a browser extension) from the Google Play or App Store, the wallet software creates an account first by creating a private key. This is a 64-character string (e.g., 233EE78O5â€¦) that should be kept secret. Then, a public key is generated from the private key. Finally, a hash of the private and the public key creates an address.\n\nSource: Github â€” Ethereum EVM\nMany wallet providers allow you to create and manage multiple addresses. Creating a new account is simple, as long as you have your private key.\nSeed Phrases\nTaking a step back, before generating a private key, the wallet software creates a seed phrase, a string of 12 or 24 words. A private key is also called a mnemonic.\nThe string of words in a seed phrase consists of common terms, e.g., tree, table, chair. The wallet software converts this string of words into binary numbers (ones and zeros) and uses it to produce a private key. When you change wallet providers, all you have to do is enter your seed phrase into the new wallet to pull up your accounts and have control of them.\nBelow is an example of a 12-word mnemonic phrase.\n\nSource: Github â€” Bips Wordlist\nSeed Phrase Standards\nBIP39 (Bitcoin Improvement Proposal 39) is the standard for seed phrases. It has become popular across many cryptocurrencies, including Bitcoin and Ethereum.\nWorking in conjunction with BIP39, are two other standards: BIP32 and BIP44. BIP32 allows one seed phrase to control multiple accounts in Bitcoin, and BIP44 does the same for Ethereum (and other cryptocurrencies).\nBIP32 and BIP44 specify a tree structure for organizing addresses. A tree structure is important because it adds a layer of privacy and security protection by enabling different addresses to be used for every transaction.\nImportant Features of Wallets\nIf youâ€™ve ever researched wallets, then youâ€™ve encountered a wide array of options.\nThe next section will introduce you to four reputable wallet providers, each with unique characteristics while sharing a common core of features. Additionally, youâ€™ll find a simple evaluation framework that highlights key features of wallets and will help you to make well-informed decisions when selecting a new wallet.\nMetamask\n\nFounded by Dan Finley and Aaron Davis, who first met online while contributing to the project VoxelJS, a Minecraft clone, Metamask was incubated in ConsenSys. ConsenSys is a software technology company founded by Joseph Lubin, the co-founder of Ethereum. Similar to many crypto founders, Finley and Davis have a unique origin story, the details of which are outside of the scope of this post, but if youâ€™re curious I suggest reading their origin story here.\nMetamask is one of the earliest players in the Ethereum wallet space, preceded only by Mist Wallet which went live in 2015 and was the first desktop crypto wallet with a GUI (user interface). Mist was taken out of circulation in 2019, with Metamask overtaking Mist, capitalizing on its second-mover advantage, and growing to lead the Ethereum wallet space with 30 million monthly active users.\nDespite Metamaskâ€™s market leadership, its biggest flaw, that many users, including myself, complain about is that itâ€™s â€œbuggy.â€ For example, transactions randomly fail, which can be frustrating and annoying.\nMetamaskâ€™s Key Differentiator: In my opinion, not much at this point, but it continues to be the market leader because of its wide distribution and appeal to crypto natives who face high switching costs if they were to use another wallet.\nRabby Wallet\n\nRabby Wallet (@Rabby_io) / X\nA few months ago, when I became increasingly frustrated by Metamaskâ€™s random transaction errors, I discovered Rabby by happenstance while reading this essay by Vitalik Buterin about crypto and AI.\nWhen I started to research Rabby, I was surprised that unlike other wallets it doesnâ€™t have much marketing or hype around it. After spending some time digging into the wallet, the reason why started to unfold.\nIn the wallet space, distribution reigns supreme. Wallets with extensive distribution, i.e., a large network of followers and users, tend to succeed, while those lacking distribution, tend to flail. One effective strategy to attain distribution when launching a new product like a wallet is to leverage an already widely distributed product.\nRabbyâ€™s parent company, DeBank used this strategy in 2021 when it rolled out Rabby Wallet. DeBank, a renowned provider of on-chain activity data, leveraged its existing brand and user base to give Rabby a seat at the wallet table without overt marketing tactics.\nRabby Walletâ€™s Key Differentiators\n\n\nEase of multi-chain experience â€” This is a must in the decentralized finance (DeFi) era where users constantly switch between Ethereum chains (e.g., Arbitrum, Optimism, Base, etc.) The Rabby Wallet can automatically detect which chain users are on and switch to that chain so that users donâ€™t need to take any manual actions.\n\n\nPre-transaction risk scanning â€” human-readable information for users about the transaction they are signing and alerting them to potentially malicious contracts (previously, astute users would use tools like Scope Scan to detect malicious contracts).\n\n\nCoinbase Wallet\n\nIf you have ever bought any cryptocurrency, you may have used Coinbase. Coinbase is the largest cryptocurrency exchange in the United States and was founded by Brian Armstrong in 2012.\nCoinbase is a custodial exchange and wallet, which means that the company controls your private keys, however in 2021, the same year that Coinbase went public with an IPO, they released a new product: a non-custodial wallet. Similar to Metamask and Rabby, Coinbase Wallet gives users full control over their private keys as they explore decentralized applications (dApps).\nThe Coinbase Wallet was an interesting strategic move by Coinbase. Similar to Rabbyâ€™s story, Coinbase was able to leverage its wide distribution and trusted brand to secure a leading position in the wallet space.\nKey Differentiator: Trusted brand and reputation, particularly with mainstream crypto users.\nBrume Wallet\n\nBrume Wallet\nBrume is a new grassroots wallet. In October of 2023, it raised 1.46 ETH on Juicebox, a fundraising platform for Ethereum. Founded by two co-founders, HazAE41 and Bryce Gabari, Juicebox is a privacy-centric wallet built with Tor, a free and open source software for anonymous communication.\nIâ€™m not expecting that most readers will try Brume, but if you are a crypto nerd, like me, then you may enjoy digging into Brume, or at least keeping it on your radar. It will be interesting to keep tabs on the trajectory of this wallet.\nKey Differentiator: Built-in Tor so usersâ€™ IP address is not tracked (Traditional wallets send usersâ€™ IP addresses to 3rd parties e.g., Coingecko and Etherscan).\n\nWallet Evaluation Framework\nIn this final section, I want to provide you with a wallet evaluation framework that can help you make informed decisions when choosing a wallet provider.\nImportant factors to consider include whether the wallet is open-source, non-custodial, and permissionless (i.e., no account creation is required), as well as its security track record and public availability of audits or bug bounties. For instance, MetaMask and Rabby are both open-source, non-custodial, and permissionless wallets with publicly available audits and a proven track record, making them reliable choices.\nCoinbase Wallet, while also non-custodial, isnâ€™t open-source and doesnâ€™t have a publicly available audit. Lastly, Brume, though a promising newcomer with privacy-centric features, hasnâ€™t been battle-tested yet. Always remember, do your homework before using any new crypto product.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetaMaskRabby WalletCoinbase WalletBrumeOpen SourceYesYesNoYesNon-custodialYesYesYesYesPermissionless (no account required)YesYesYesYesPublicly Available Audit / Public Bug BountyYes* (Mobile &amp; Snaps product, but not browser extension)YesNoNoBattle Tested (live for &gt;1 year)YesYesYesNo\nConclusion\nAs we enter the next bull market cycle, many new crypto products, wallets included, will start to captivate peopleâ€™s attention on the Internet. It will become increasingly more important to be an informed user and understand the basics inner workings of the products that you use.\nA wallet is table stakes for accessing the Ethereum ecosystem of decentralized applications. Wallets have come a long way in user experience and design, but as with any nascent industry, there is still a long way to go to make the experience of using crypto as seamless as it is to say use Venmo or Apple Pay.\nBeing an early adopter will reap benefits down the road, so as I tell my friends and family, itâ€™s definitely not too late to start using Ethereum and building your skillset.\nLastly, stay tuned for the topic of the next newsletter: Ethereum social networks.\n\nFeel free to reach out to me directly with questions, suggestions, or feedback. You can also drop me a message on Twitter. My DMs are open.\n-Rika"},"Newsletter/3-Wallets/Research":{"slug":"Newsletter/3-Wallets/Research","filePath":"Newsletter/3 Wallets/Research.md","title":"Research","links":["Bitcoin"],"tags":[],"content":"www.youtube.com/watch\n\nDefinition of wallet: The place where you store digital goods and access digital applications â€” itâ€™s an access point.\n- &quot;Metamask&#039;s path to success is more of an exception than a rule.&quot; - Qiao Wang\n\nethereum.org/wallets\n\nWallets help you access your digital assets and sign in to applications.\nEthereum wallets are applications that give you control over your account.\nJust like your physical wallet, it contains everything you need to prove your identity and handle your assets. Your wallet allows you to sign in to applications, read your balance, send transactions and verify your identity.\nYour wallet is a tool for interacting with your Ethereum account. That means you can swap wallet providers at any time. Many wallets also let you manage several Ethereum accounts from one application.\nWallet providers donâ€™t have custody of your funds. They just provide you a window to see your assets on Ethereum and tools to easily manage them\nAn Ethereum account is a pair of keys. One key is used to create the address you can share freely, and the other key you need to keep secret because itâ€™s used to sign things. Together, these keys let you hold assets and make transactions.\nA wallet is a tool that lets you interact with your account, using your keys. It allows you to view your account balance, send transactions, and more.\n\n==Good graphic to have handy for later: ethereum.org/en/developers/docs/accounts/\nRobinhood self-custody wallet!\nwww.coindesk.com/video/how-robinhood-and-arbitrum-hope-to-bring-more-people-on-chain/\nâ€œOne thing that AJ, the Offchain Labs CSO, said that particularly resonated is that we shouldnâ€™t build out a system that replicates, under the hood and on top of the hood, TradFi.  It would be easy to create a login system with forget your password but itâ€™s important to stay true to the ethos of the industry (self custody &amp; sovereignty) and create a hybrid solution.â€\nHe also said that yes, crypto is harder to use but itâ€™s pretty hard to open a bank account too. Perhaps the bigger issue is that in crypto the stakes are just higher because you have to self-custody funds.\nen.wikipedia.org/wiki/Cryptocurrency_wallet\n\nA crypto wallet offers the functionality of encrypting and/or signing information\nA number of technologies known as wallets exist that store the key value pair of private and public key known as wallets\n\nSeed Phrases\nblockworks.co/news/what-are-seed-phrases\nA seed phrase is different from a private key. A seed phrase is generated before a private key. First, a mnemonic is generated. The software then converts the string of words into a binary seed (ones and zeros) and uses it to produce a private key &amp; then a public key. â‡â€”This is the BIP39 standard (originally proposed for Bitcoin but has become a popular standard across the board).\nThere are 3 widely-used standards for seed phrases: BIP39, BIP44, and BIP32.\nâ€œThey can also use BIP44 and BIP32. These standards work together with BIP39 and specify a tree structure for organizing addresses derived from a seed phrase. This method is often called a hierarchical deterministic structure and allows for the creation of multiple private/public key pairings and child pairings. This structure is important because it adds a layer of privacy and security protection by using a different address for every transaction.\nOnce users set up their wallet address and child public and private pairings, they donâ€™t need to use the recovery seed phrase for access. Instead, they login to their hardware wallet (cold) or software wallet (hot) with a passcode or pin to automatically sign transactions. This keeps the private keys out of view from the public.â€\nWallet History\nwww.investopedia.com/terms/m/mist-browser.asp#toc-what-was-the-mist-browser\nMist browser was the first GUI for the Ethereum blockchain. Before, users needed to used command line to access the blockchain. Mist browser was legit like a browser, think Internet Explorer, Safari, Chrome. It allowed users to access dApps. Mist also created the first desktop crypto wallet with a GUI.  Went live in 2015. Taken out of circulation in 2019.\n\nMist browser was essentially a wallet, so it was replaced by many other wallets that allow you to access cryptocurrency, blockchains, dApps, and even trade on a cryptocurrency exchange.\n\nMPC Wallets\nblockworks.co/news/mpc-wallets-security\nMPC wallets are a more recent attempt to secure peopleâ€™s crypto. Multi-party computation, or MPC,Â walletsÂ do away with the traditional concept of user-facing private keys entirely, replacing them with a process that involves breaking up a holderâ€™s key into different pieces, called shards. While this purportedly â€œseedlessâ€ approach is a significant departure from traditional key security, some implementations of MPC wallets may still utilize seed phrases as an additional backup or recovery option for added security.\nRohan Agarwal is the CEO and co-founder of Cypherock, a hardware MPC solution. He told Blockworks that certain MPC wallets, especially those relying on software or web apps, trade a high level of security for increased ease of use."},"Newsletter/3-Wallets/Words-that-I-cut":{"slug":"Newsletter/3-Wallets/Words-that-I-cut","filePath":"Newsletter/3 Wallets/Words that I cut.md","title":"Words that I cut","links":[],"tags":[],"content":"first guide you through the basic mechanics of how non-custodial wallets work under the hood.\nSome wallets are custodial, meaning that the wallet provider has final control over your assets (for example, if you use an exchangeâ€™s wallet, the exchange has custody of your assets); others are non-custodial, meaning that you, and only you, have control over your digital assets.\nAlthough empowering, non-custodial wallets can also feel daunting. Therefore, itâ€™s important to understand how they work. Furthermore, we will probably see new wallets enter the space during this current bull market, so you will find it helpful to have a simple framework to reference to assess the quality of the wallet. Ultimately, being equipped with knowledge will help you to make informed decisions.\nIn this post, I seek to do exactly this: give you a small education about wallets and equip you with a framework, empowering you to make informed decisions when you encounter a new wallet.\nas new wallets enter the market (which they most likely will in this bull market cycle, itâ€™s important to have a framework to rely on to assess good wallets from not so good ones.\nin the rapidly changing space of cryptocurrencies, where itâ€™s important to understand the fundamentals of non-custodial wallets to be an educated user\nNon-custodial wallets are empowering but, at times, can be daunting. Therefore, understanding thow non-custodial Ethereum wallets work and h win the world of cryptocurrencies. â€œIn this rapidly evolving space, itâ€™s crucial to comprehend the different types of Ethereum wallets available and their respective features, to ensure secure and efficient interactions with the Ethereum blockchain.â€\nPersonally, like many people in crypto, I value self-sovereignty, the ability to have full control over oneâ€™s assets, therefore I will focus exclusively on non-custodial wallets in this post. Fortunately, many developers build with self-sovereignty top of mind, which means that non-custodial wallets are easily accessible.\nFull\n. There is no company or customer service number to call to recover funds.\nFor the sake of when I use the term wallet, I am referring to non-custodial wallet.\nThe reason is that na fundamental principle of crypto is self-sovereignty. For the sake of brevity, I w\nnon-custodial wallets embody a fundamental crypto principle: self-sovereignty.\nUnlike a traditional wallet where you store bank cards that are ultimately controlled by centralized financial institutions, Ethereum wallets are non-custodial which means you are fully in control over your digital assets.\nSelf-sovereignty, the power to fully control your digital assets is both empowering and at times daunting. Therefore, understanding how Ethereum wallets work and why we need them becomes crucial in the world of cryptocurrencies.\nFor the sake of brevity, from here on out,\nThis is exactly what DeBank did when they launched Rabby Wallet in 2021.\nDeBank, a popular and reputable data provider for on-chain activity launched Rabby Wallet with a â€œkiller featureâ€ that makes Rabby superior to Metamask. This killer feature is its native multichain experience, which means that the wallet automatically switches between different chains. It knows which chain a user is on and will automatically switch. This makes the user experiences really great because Ethereum has a plethora of chains (e.g, Arbitrum, Optimism, Base, Manta, etc.) and the reality is that when you are interacting with dApps, you are constantly switching between chains. Other wallets, like Metamask, require that users manually change networks â€” this is annoying. Additionally, Rabby has another very useful feature which is alerts around the contracts that you are signing. Rabby will tell you if it believes that a contract is malicious (previously, astute users would check websites such as Scope Scan to ensure they are not interacting with a malcious contract). Rabby has this built in natively. It will also tell you if your wallet has previously interacted with a malicious contract.\nIn a sign of the DeFiâ€™s increased complexity, Rabby also promises to display more details regarding the contracts users are signing. â€œDeFi users are blindly signing transactions they donâ€™t really understand,â€ the post states.\nRabby has a pre-transaction risk-scanning feature, which will alert users if it finds potential vulnerabilities in the contracts the user is interacting with. For instance, if a contract has previously been hacked, users will get a notification.\nRabby was created in 2021 by DeBank, a popular and reputable data provider for on-chain activity."},"Newsletter/4-Decentralized-Social-Media/Breaking-Down-Decentralized-Social-Media-â€”-Outline":{"slug":"Newsletter/4-Decentralized-Social-Media/Breaking-Down-Decentralized-Social-Media-â€”-Outline","filePath":"Newsletter/4 Decentralized Social Media/Breaking Down Decentralized Social Media â€” Outline.md","title":"Breaking Down Decentralized Social Media â€” Outline","links":["ActivityPump-(circa-2014)-predated-ActivityPub","Newsletter/Template","A-social-network-is-a-series-of-messages-passed-between-users-through-a-centralized-server","Public-message-boards-were-the-first-example-of-online-public-messaging","Decentralized-social-networks-are-blockchain-based-platforms-that-allow-users-to-exchange-information-as-well-as-publish-and-distribute-content-to-audiences","/","Bulletin-Board-System","Newsletter/4-Decentralized-Social-Media/Breaking-Down-Decentralized-Social-Media---Master","Social-Media-Fun-Inspiration","Decentralized-social-networks-are-censorship-resistant-and-open-to-everyone.This-means-users-cannot-be-banned,-deplatformed,-or-restricted-arbitrarily","Decentralized-social-networks-are-built-on-open-source-ideals-and-make-source-code-for-applications-available-for-public-inspection","Decentralized-social-networks-eliminate-the-\"middle-man\"","Decentralized-social-platforms-offer-an-improved-monetization-framework-for-content-creators-via-non-fungible-tokens-(NFTs),-in-app-crypto-payments,-and-more","Decentralized-social-networks-afford-users-a-high-level-of-privacy-and-anonymity","Decentralized-social-networks-rely-on-decentralized-storage,-not-centralized-databases,-which-are-considerably-better-for-safeguarding-user-data.","Twitter-exodus","social-media","Articles--and--Papers/Love-vs.-Fame","Status-as-a-Service","Fediverse-platforms-are-developed-by-a-community-of-people-from-all-over-the-world,-independent-from-any-company-or-official-institution.","Fediverse-platforms-unlike-mainstream-platforms-(Facebook,-Twitter,-Tik-Tok,-Pinterest,-Goodreads)-DO-NOT-control-all-of-the-decision-making,-enforce-censorship,-or-hoard-users-data-for-profit-or-surveillance","Fediverse-is-a-new-word-made-of-two-words-â€œfederationâ€-+-â€œuniverseâ€","Fediverse-is-a-federated-social-network-running-on-free-open-software-on-a-myriad-of-computers-across-the-globe","With-Fediverse,-you-choose-a-server-to-register.-This-ensures-some-decentralization-and-sovereignty-of-data.","ActivityPub","ActivityPub-is-a-protocol-that-produces-a-client-to-server-API-for-creating,-updating,-and-deleting-content,-as-well-as-a-federated-server-to-server-API-for-delivering-notifications-and-subscribing-to-content.","ActivityPub-doesnâ€™t-provide-a-way-to-use-a-managed-host-without-compromising-decentralization","Threads-integrated-ActivityPub-so-you-can-post-from-Threads-to-Mastodon,-but-not-from-Mastodon-to-Threads","activity","Can-ActivityPub-save-the-internet","Distributed-Social-Networks-and-Public-History","A-history-of-online-public-messaging","Can-Mastodon-seize-the-moment-from-Twitter","Threads-is-officially-starting-to-test-ActivityPub-integration","Sufficient-Decentsralization-for-Social-Networks","Decentralized-protocols-use-two-mechanisms-to-prevent-bait--and--switch-of-their-centralized-counterparts-(1)-open-source-code-and-(2)-checks-and-balances-with-voice-and-exit"],"tags":[],"content":"\nDo not be ideological and pick sides with my writing. Just present the landscape. Readers should be smart enough to decide for themselves.\n\n\nBe friendly and welcoming to people of all crypto knowledge levels.\n\nThereâ€™s a ton of software that runs on ActivityPub, wow! Wikipedia:\n\n\nSocial media is a vastly complex landscape that extends beyond the commonly known legacy platforms of Facebook, Instagram, and Twitter.\nThere are new players in the space too, like Farcaster and Blue Sky. And there are old players like Mastodon, based on the ActivityPub protocol which goes back many many years, even before Facebook and ActivityPump (circa 2014) predated ActivityPub\n\n==What one provocative point that I want to make?\n\nWeâ€™re at the tipping point of the social media age. Weâ€™re at the stage when the incumbents know it and start to innovate. Just like when FB created the Libra coin, Cash app is accepting cryptocurrencies, and now FB is getting into Threads / Activity Pub because they know this is how they stay relevant.\nIf engagement drives legacy social media, what drives ownership social media?\n\nOwnership social media? No, need a better term. Legacy social media vs. crypto social media? no yucky. decentralized? no b/c activitypub is decentralized but its not on the blockchain.\n(sufficiently) decentralized social media. come build with us, farcaster says to devs.\nwhy does activitypub ecosystem not have the same explosion of apps that farcaster has?\n\nwhy are more devs building on farcaster protocol on ethereum blockchain than on activitypub on pub (?) protocol?\n\n\n\n\n\n\nIâ€™m addressing my reader as a provider of information\nPronoun is first person, participant (iâ€™m using protocols like farcaster)\nTense is present\n==Style is casual, informative, inspirational, and forward-thinking. It is not ideological or persuasive. I am providing perspective of someone who works in the industry and who sees the crypto movement taking place in front of my eyes.\nAttitude is informative\nHow much do I want to cover?\n\nActivityPub â‡’ Fediverse ecosystem â‡’ Mastodon (1 app)\nEthereum blo\nFocus on Farcaster ecosystem of apps vs. Fediverse ecosystem of apps\nActivityPub is to Ethereum blockchain as Fediverse is to Farcaster ecosystem Threads is to Mastodon\n\n\n\nI. Template\n\nUseful Definitions\nSocial Network\nA social network is a series of messages passed between users through a centralized server Decentralized social media is a series of messages passed between users through servers that are spread out / self-hosted.\nSocial Media\nA broader term that includes media like Hollywood and is more about creating a brand and entertainment.\nPublic Messaging\nAlso known as forums, public messaging predated social networks and enabled people to communicate with one another by posting messages to a public bulletin board, replying to threads, receiving notifications, and sending private messages. Public message boards were the first example of online public messaging\nDecentralized social network\nDecentralized social networks are blockchain-based platforms that allow users to exchange information as well as publish and distribute content to audiences\nServer\nA server is a computer that provides information to other computers called â€œclientsâ€ on computer network.\n\nBulletin Board System\n\nII. Resources\nBreaking Down Decentralized Social Mediaâ€” Master\nSocial Media Fun Inspiration\nIntroduction\n\nâ€¦weâ€™ve reached what feels like a saturation point as we are now squarely at the end of the social media age before we embark on whatever this new internet is going to be\n\nwww.linkedin.com/pulse/future-creation-curation-gavin-guidry-jatte/\nOption 2\nPeople can mint a NFT on paragraph with this article. I capture 100% of that value as a creator. If people know my work, they follow me, they like the ideas that I have then they pay for it as a NFT. I am creating quality stuff. \nKey here is probably distribution. How do you get seen? Does the platform help you to get visibility?\n- *Could be a good segway into â€œfameâ€ *fame platforms help you with visibility. Twitter with a premium account boosts you up. Paragraph will automatically RT you on Farcaster.\nOption 3\nWhy decentralized social media on crypto? \n\nCould be killer use case. Good UI, good content, people go to it because they enjoy spending time on there.  Warpcast could be the rising tide that lifts all boats. maybe?\nGood for creators. Good for brand recognition. Able to put out content and quickly get rewarded with more quality followers.\nYouâ€™re part of the Fediverse. With Yup for example, you can see all of the platforms aggregated into one.\n\nBody\nBody 1\nA. What are social networks?\na. centralized vs. decentralized social networks\n\nDecentralized social networks areÂ blockchain-basedÂ platforms that allow users to exchange information as well as publish and distribute content to audiences\nDecentralized social networks are censorship-resistant and open to everyone.This meansÂ users cannot be banned, deplatformed, or restricted arbitrarily\nDecentralized social networks areÂ built on open-source idealsÂ and make source code for applications available for public inspection\nDecentralized social networks eliminate the â€œmiddle-manâ€\nDecentralized social platforms offer anÂ improved monetizationÂ framework for content creators viaÂ non-fungible tokens (NFTs), in-app crypto payments, and more\nDecentralized social networks afford usersÂ a high level of privacy and anonymity\nDecentralized social networks rely on decentralized storage, not centralized databases, which are considerably better for safeguarding user data.\nc. Why decentralized social networks now?\ni. Trend with Twitter exodus\nB. ==What is social media?==\na. centralized vs. decentralized social media\nC. What do users want?\na. Love vs. Fame\nb. Status as a Service\nB. A history of decentralized social networks\na. What is Fediverse?\nFediverse platforms are developed by a community of people from all over the world, independent from any company or official institution.\nFediverse platforms unlike mainstream platforms (Facebook, Twitter, Tik Tok, Pinterest, Goodreads) DO NOT control all of the decision-making, enforce censorship, or hoard users data for profit or surveillance\nFediverse is a new word made of two words â€œfederationâ€ + â€œuniverseâ€\nFediverse is a federated social network running on free open software on a myriad of computers across the globe\nWith Fediverse, you choose a server to register. This ensures some decentralization and sovereignty of data.\nb. What is ActivityPub?\nActivityPub is a protocol that produces a client to server API for creating, updating, and deleting content, as well as a federated server to server API for delivering notifications and subscribing to content.\nActivityPub doesnâ€™t provide a way to use a managed host without compromising decentralization\nThreads integrated ActivityPub so you can post from Threads to Mastodon, but not from Mastodon to Threads\nactivity\nii. Can ActivityPub save the internet?\n\nC. Distributed Social Networks and Public History\ni. A history of online public messaging\nii. Can Mastodon seize the moment from Twitter?\nii. Threads is officially starting to test ActivityPub integration\nA. What crypto social media networks can do really well.\n- Sufficient Decentsralization for Social Networks\n- users own a direct relationship with their audience\n- developers can always build apps (API will not be cut off, revenue terms will not be changed up on them, etc.)\n- This thing about decentralized protocols is a common, very common thing in crypto that Iâ€™ve read about.\n- Decentralized protocols use two mechanisms to prevent bait &amp; switch of their centralized counterparts (1) open source code and (2) checks and balances with voice and exit\nB. Decentralized Social Media Business Models\nnot ads, but what? Unlock says â€œevolves the web from a business model built on attention toward one based on membership.â€"},"Newsletter/4-Decentralized-Social-Media/Breaking-Down-Decentralized-Social-Media---Master":{"slug":"Newsletter/4-Decentralized-Social-Media/Breaking-Down-Decentralized-Social-Media---Master","filePath":"Newsletter/4 Decentralized Social Media/Breaking Down Decentralized Social Media-- Master.md","title":"Breaking Down Decentralized Social Media-- Master","links":["Newsletter/4-Decentralized-Social-Media/Breaking-Down-Decentralized-Social-Media-â€”-Outline","Breaking-Down-Decentralized-Social-Media-â€”-Drafts-Archive","Newsletter/4-Decentralized-Social-Media/Web3-social-media","Articles--and--Papers/Love-vs.-Fame","Farcaster-Docs","Sufficient-Decentralization-for-Social-Networks","Status-as-a-Service","Decentralizing-social-media-a-guide-to-the-web3-social-stack","The-Future-of-Decentralized-Social-Media-with-Balaji-Srinivasan,-Vitalik-Buterin,-Juan-Benet","Benjamin-Goering-on-\"ActivityPub-W3C-Recommendation\"","Fediverse","About-ActivityPub","Distributed-Social-Networks-and-Public-History","Threads-is-officially-starting-to-test-ActivityPub-integration","A-history-of-online-public-messaging"],"tags":[],"content":"Breaking Down Decentralized Social Media â€” Outline\nBreaking Down Decentralized Social Media â€” Drafts Archive\nResources\nWeb3\n\n\nWeb3 social media\n\n\nLove vs. Fame\n\n\nFarcaster Docs\n\n\ndocs.farcaster.xyz/learn/what-is-farcaster/frames\n\nFrames are fun. Lots of NFT art. Also a cool game for Build for example where you can nominate best builders. You get a daily allocation of Build tokens that you can use to nominate peeps.\n\n\n\nSufficient Decentralization for Social Networks\n\n\nFarcaster is Now Open to Everyone\n\n\nStatus as a Service\n\n\nDecentralizing social media a guide to the web3 social stack\n\ncrappy article\n\n\n\nThe Future of Decentralized Social Media with Balaji Srinivasan, Vitalik Buterin, Juan Benet\n\n\nBenjamin Goering on â€œActivityPub W3C Recommendationâ€\n\n\nDecentralized Social Network\nFediverse\nAbout ActivityPub\nDistributed Social Networks and Public History\nThreads is officially starting to test ActivityPub integration\nA history of online public messaging"},"Newsletter/4-Decentralized-Social-Media/Exploring-Social-Media's-Evolution":{"slug":"Newsletter/4-Decentralized-Social-Media/Exploring-Social-Media's-Evolution","filePath":"Newsletter/4 Decentralized Social Media/Exploring Social Media's Evolution.md","title":"Exploring Social Media's Evolution","links":[],"tags":[],"content":"Read Full Newsletter\n\nA guide to understanding social mediaâ€™s evolution from centralized platforms to onchain networks\nGreetings, readers! (or Gm, as we say in crypto). This newsletter provides digestible breakdowns of complex protocols and products in the Ethereum ecosystem. You can expect quality substantive content (no hype pieces, shilling, or paywall) written for crypto-curious readers who are either newer to crypto or seasoned users who value refreshers on the fundamentals. You can learn more about this newsletter in the introductory post.\n\n\nThe potential of cryptocurrency is transformative: many of the online services we rely on todayâ€”such as banking, ride-sharing, and music streamingâ€”are poised to shift to the blockchain, or â€œonchain.â€ Unlike traditional databases, blockchain operates on a decentralized network, eliminating control by any single entity. While blockchains donâ€™t store files, they maintain an immutable record of transactions, offering unprecedented levels of transparency, authentication, and ownership.\nThe widespread adoption of crypto hinges on several factors, including market dynamics, regulatory considerations, and technological advancements. The good news? Early indicators suggest weâ€™re on the cusp of a major shift.\n2025 could very well be the year we see the first mainstream crypto consumer application and the breakout app may be a social media application.\n\nIn this post..a lay of the land\nIn this post, Iâ€™ll explore the rise of onchain social media, tracing the evolution of social networks from early centralized platforms like Myspace and Friendster to todayâ€™s decentralized, non-crypto networks like Mastodon, to onchain networks like Farcaster and Lens, which represent the latest shift toward user control, data sovereignty, and creator monetization.\nThis is a lay of the land, breaking down how social platforms have innovated, scaled, and, in many cases, failed. By analyzing their strategiesâ€”what worked, what didnâ€™t, and whyâ€”we can better understand the challenges and opportunities facing the next generation of social networks.\nTo wrap up, Iâ€™ve included a framework to help you evaluate decentralized social media platforms.\n\nUseful definitions\nBefore diving in to the meat of the post, letâ€™s align on three important definitions. You may find some of these rudimentary, so feel free to skip to the next section if youâ€™re already comfortable with these concepts.\n*Note: These definitions are not absolute and are an amalgamation of my research. References and further reading are provided at the end of this post.\n\n\n\nWhat is a Social Network?\nA social network is a system for exchanging messages and information between users. Traditionally, this exchange has been facilitated by centralized servers. However, with the rise of decentralized social media, social networks now operate across distributed networks of servers.\n\n\nWhat is Social Media?\nWhile often used interchangeably with â€œsocial network,â€ social media has a broader meaning. It refers to platforms that enable users to create, share, and distribute contentâ€”whether for entertainment, personal expression, or building a brand.\n\n\nWhat is Onchain Social Media?\nOnchain social media refers to protocols, applications, and platforms that use blockchain as their backend for storing and verifying data. This approach grants users greater control and ownership over their digital identity, content, and followers. Developers also benefit from the freedom to build applications on top of existing protocols without the risk of centralized platforms altering the rules.\n\n\n\nSocial media pioneers: Friendster and Myspace\nFriendster and Myspace were the first social networks to set the standard for online communication, connection, and self expression â€” ultimately paving the way for the future of social networking.\nFriendster\n\nLaunched in 2002 by Jonathan Abrams, Friendster gained widespread popularity, capturing the attention of both developers and users, with its structured approach to online connections and relationships.\nFriendster pioneered early social media features that have since become the gold standard:\n\n\nProfiles &amp; Connections â€“ Users could create personal profiles, connect with friends, and explore extended networks through mutual connections.\n\n\nSocial Graph â€“ A visual map of connections, where users are â€œnodesâ€ and relationships are â€œedges.â€ This concept enabled features like friend recommendations and optimized content delivery.\n\n\nBetween 2003 and 2004, Friendsterâ€™s user base exploded to millions. However, this rapid growth came with challenges. The platformâ€™s infrastructure struggled to scale, leading to slow performance and user frustration. Meanwhile, competitors emerged with faster, more reliable experiences, enhanced functionality, and stronger cultural appeal.\nOne such competitor was Myspace.\n\nMyspace\n\nLaunched in 2003, Myspace was developed by Chris DeWolfe and Tom Anderson, along with a team of developers, at eUniverse, a digital marketing and entertainment company.\nBy 2005, leveraging eUniverseâ€™s marketing expertise and existing user base to accelerate its growth, Myspace became a household name and earned a reputation as a hub for musicians with bands like Arctic Monkeys using the platform to gain exposure and build fan bases.\nMyspace innovated with the following features:\n\n\nProfile Customization â€“ Users could personalize their profiles with custom backgrounds, graphics, and music using HTML/CSS.\n\n\nTop 8 Friends â€“ A unique feature allowing users to showcase their closest friends on their profile.\n\n\nAt the height of its success, Myspace was acquired by News Corporation for $580 millionâ€”a massive deal at the time. However, mismanagement under News Corp, slow load times caused by cluttered profiles, and the rise of Facebook ultimately led to Myspaceâ€™s decline.\nSocial media giants: Facebook and Twitter\nAs social networks evolved, staying culturally relevant and providing monetization opportunities for creators has become increasingly more important. Todayâ€™s social networks prioritize not just connection but also status, recognition, and influence.\nFacebook\nLaunched in 2004 by Mark Zuckerberg, Facebook initially catered exclusively to Harvard students but opened to the public in 2006. By 2008, it had surpassed Myspace in monthly active users, marking the beginning of its dominance in social media.\nFacebook innovated with the following features:\n\n\nExclusivity â€“ Originally limited to Harvard students, Facebook created a sense of desirability before expanding to the public in 2006.\n\n\nNews Feed â€“ A real-time, scrolling feed that aggregated updates from friends. This shift from profile-based browsing to a centralized stream of content fundamentally changed how users interacted with social networks.\n\n\nLike Button â€“ Revolutionized social engagement, becoming the primary metric for measuring content popularity.\n\n\nTagging â€“ Users could tag friends in photos, posts, and comments, increasing engagement and encouraging users to return to the platform.\n\n\nFacebook outcompeted Myspace for several key reasons:\n\n\nBetter User Design â€“ Facebookâ€™s clean, unified design offered a smoother user experience compared to Myspaceâ€™s cluttered interface.\n\n\nTargeted Advertising â€“ Initially offering fewer, less intrusive ads, Facebook perfected targeted advertising, capitalizing on its vast user data.\n\n\nReal-Name Culture â€“ Encouraging users to adopt real-name identities created a platform that appealed to a more mature audience, in contrast to Myspace, which remained largely associated with teen culture and music. As users grew older, they outgrew Myspace, while Facebook evolved to cater to their shifting needs.\n\n\nTwitter\nOne year after Facebookâ€™s launch, Twitter was introduced in 2006 by Jack Dorsey, Biz Stone, and Evan Williams. It revolutionized social media by becoming an online public town squareâ€”the go-to platform for news, trends, and public discourse.\nTwitter innovated with the following features:\n\n\nCharacter Limit â€“ Originally set at 140 characters, this limitation was later expanded to 280 characters, encouraging concise and impactful communication.\n\n\nHashtags â€“ Initially a user-driven concept, hashtags were later embraced by Twitter, turning the platform into a powerful tool for activism\n\n\nReal-Time News â€“ The news feed provided live updates on breaking news, sports, and cultural events, making Twitter the go-to place for immediate information.\n\n\nRetweet Feature â€“ Amplified content virality and allowed usersâ€”ranging from public officials and journalists to brandsâ€”to engage massive audiences.\n\n\nTwitter reshaped how we consume news, entertainment, politics, and digital marketing, influencing how the modern world interacts in the digital age.\nDecentralized Competitors\nSo far, weâ€™ve focused on centralized social media companies, but thereâ€™s also a growing presence of decentralized platforms, primarily within the Fediverse. The Fediverse is a federated network of independent servers that communicate with each other, running on the ActivityPub protocolâ€”a decentralized framework that allows different platforms to interact.\nOne prominent application within the Fediverse is Mastodon, which gained significant traction after Elon Muskâ€™s acquisition of Twitter. Following the acquisition, many journalists, political figures, and brands migrated to Mastodon, attracted by its decentralized nature, which frees users from the control of any single individual or corporation.\nSeeing this shift, Meta also seized the opportunity and launched Threads, which directly competes with X (formerly Twitter).\nMastodon\n\nMastodon was created in 2016 by Eugene Rochko, a German developer who, disillusioned with Twitter, sought to build a decentralized, open-source alternative. His vision was to create a platform that prioritized user freedom, privacy, and community governance, positioning Mastodon as a space free from corporate control.\nInitially launched as a non-profit, open-source project, Mastodon gained early traction among tech-savvy and privacy-conscious users.\nMastodon innovated with the following features:\n\n\nDecentralization â€“ No single company controls the platform. Users can choose from different instances, each with its own content and moderation rules. If one instance shuts down, the network remains functional, and users can migrate to another instance, taking their followers with them.\n\n\nNo Algorithms, Ads, or Tracking â€“ Posts appear chronologically, with no algorithmic feeds, ads, or data tracking.\n\n\nOpen-Source Community â€“ Anyone can create their own instance, fostering transparency and trust, unlike corporate-owned social media platforms.\n\n\nUnified Feeds â€“ Users can see feeds from all Mastodon instances, creating a larger interconnected network.\n\n\nIn 2022, when Elon Musk took over Twitter, many users migrated to Mastodon. However, the platform faced growing pains. The decentralized structure, with its multiple â€œinstancesâ€ (independent servers running their own websites), proved challenging for new users. Each instance operates with its own domain, rules, administrators, and community, meaning users must create a separate account for each instance they join. While users can migrate instances and take their followers with them, old posts do not transfer, and profile details must be updated for each new instance.\nThreads\n\nMeta saw an opportunity after Elon Muskâ€™s acquisition of X, and Threads has since positioned itself as a more approachable, less contentious competitor to X. Unlike X, Threads lacks a real-time trending section or hashtags, which reduces the focus on political debates, viral content, and news-driven engagement.\nOfficially launched on July 5, 2023, just days after Twitter implemented rate limits and restricted access for non-logged-in users, Threads quickly gained traction. Within just five days, the platform reached 100 million users, making it the fastest-growing app in history at the time.\nWhile Threads shares many features with X/Twitter, it also introduces several unique elements:\n\n\nInstagram Integration â€“ Threads is built on top of Instagram, allowing users to log in with their Instagram account. This creates an instant social graph, leveraging existing followers, profile pictures, and usernames. This approach helps avoid the â€œempty networkâ€ problem faced by new social platforms.\n\n\nNo Ads (For Now) â€“ Threads offers a cleaner, ad-free experience compared to X and Facebook, which enhances user experience.\n\n\n500 Character Limit â€“ Threads allows up to 500 characters per post, surpassing Twitterâ€™s 280-character limit for free users. Currently, there are no premium plans or subscriptions, so all users have the same features.\n\n\nThreads, like Mastodon, is powered by ActivityPub, a decentralized protocol that allows data sharing across platforms built on the same protocol. This raises an intriguing question: why would a centralized company like Meta embrace decentralization?\nThe answer lies in strategy. By adopting ActivityPub, Meta can present Threads as a more open platform, distancing itself from the â€œwalled gardenâ€ model of its other platforms (e.g., Facebook and Instagram). This move helps alleviate antitrust concerns and makes Threads more appealing to users who are drawn to decentralized networks.\nAdditionally, embracing decentralization allows Meta to tap into an existing ecosystem of applications, the â€œFediverseâ€, positioning itself as a supporter of open social networking. However, despite this decentralized front, Meta still controls key elements like discovery, account linking, and notifications. While ActivityPub allows posts to be visible across platforms, Meta is likely to impose restrictionsâ€”for example, only allowing interoperability with select Mastodon instances and prioritizing Threads posts over Mastodon posts.\nOnchain social media\nFarcaster\n\nFarcaster was founded by former Coinbase executives Dan Romero and Varun Srinivasan with the vision of creating an open social network on Ethereum, free from control by any single entity.\nThe platform prioritizes user sovereignty, enabling individuals to own their identities and content while maintaining a familiar social experience. It shares similarities with Reddit by allowing users to join interest-based channels. Unlike ActivityPub, which is not built on a blockchain, Farcaster operates on Ethereum, leveraging its decentralized infrastructure.\nFarcaster innovated with the following features:\n\n\nSovereign Identity â€“ User identities are tied to Ethereum Name Service (ENS) names, granting full ownership and control, similar to a website domain but entirely user-owned.\n\n\nPermissionless Social Graph â€“ An open social graph allows developers to build diverse applications on top of Farcaster without restrictions.\n\n\nHybrid Architecture â€“ Combines on-chain and off-chain elements: identity and authentication are on-chain, while posts, likes, and interactions remain off-chain for efficiency.\n\n\nBuilt-in Monetization â€“ Encourages new monetization models, providing opportunities beyond traditional ad-driven revenue.\n\n\nDeveloper-Driven Evolution â€“ A strong developer community contributes to protocol changes through Farcaster Improvement Proposals (FIPs).\n\n\nWhile Farcaster focuses on sovereign identities, an open social graph, and sufficient decentralization, another notable player in the decentralized social space, Lens Protocol, takes a different approach to redefining online interactions.\nLens\n\nLens Protocol, developed by Avaraâ€”the company behind Aave, Lens, and Familyâ€”was launched in 2022 under the leadership of founder Stani Kulechov.\nKulechov describes Lens as a decentralized social network that flips the traditional model, empowering users over platforms. This shift opens the door for transparent revenue-sharing models and better rewards for creators.\nLens innovated with the following features**:**\n\n\nBuilt-in Monetization â€“ Provides multiple ways for creators to earn, fostering a more sustainable ecosystem.\n\n\nCollect, Mirror, Subscription &amp; Tipping â€“ Users can collect posts as NFTs, mirror (akin to sharing), and engage in direct monetization through subscriptions and tipping.\n\n\nFully On-Chain â€“ Unlike hybrid models, Lens ensures all social interactionsâ€”including posts, comments, follows, and likesâ€”are recorded on-chain for full transparency and ownership.\n\n\nWith its strong focus on decentralization, monetization, and user empowerment, Lens offers an alternative vision for social networking, further expanding the possibilities of Web3-powered online communities.\nEvaluation Framework\nIn this final section, I want to provide you with a social media evaluation framework that can help you make informed decisions that align with your values, needs, and goals.\nImportant factors to consider include whether the application is open source, on-chain, has built-in monetization, data sovereignty (e.g., identity), is interoperable with other applications, and has on-chain governance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMastodonThreadsFarcasterLensOpen Source Yes No Yes YesOn-chain No NoHybrid Yes (fully)Built-in monetization No No Yes YesData SovereigntyPartial (instance based) NoPartial YesInteroperability Yes (ActivityPub protocol)Partial (limited ActivityPub) Yes (Ethereum) Yes (Ethereum)On-chain Governance No No No No\nConclusion\nAs we stand on the brink of cryptocurrencyâ€™s mainstream adoption, the rise of onchain social media presents an opportunity to reshape how we connect, communicate, and create online. The evolution from centralized platforms like Myspace and Facebook to decentralized alternatives such as Mastodon, Farcaster, and Lens highlights a growing demand for user sovereignty, transparency, and new monetization models.\nWhile challenges remainâ€”ranging from adoption hurdles to regulatory uncertaintyâ€”the potential for on-chain social media to redefine digital interactions is immense. By understanding past successes and failures, we can better navigate this transition and make informed decisions about which social media platforms we use.\nAdditional Reading\n\nFeel free to reach out to me directly with questions, suggestions, or feedback. You can also drop me a message on Twitter. My DMs are open."},"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---1st-Draft":{"slug":"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---1st-Draft","filePath":"Newsletter/5 Decentralized Finance/5 Decentralized Finance - 1st Draft.md","title":"5 Decentralized Finance - 1st Draft","links":["tags/"],"tags":[""],"content":"Greetings, readers! (or Gm, as we commonly greet others in the crypto community). The purpose of this newsletter is to provide digestible breakdowns of complex protocols and products in the Ethereum ecosystem. You can expect quality substantive content (no hype pieces, shilling, or paywall) written for crypto-curious readers who are either newer to crypto or seasoned users who value refreshers on the fundamentals. You can learn more about this newsletter in the introductory post.\nÎTH Market Capitalization = X\nÎTH Price = Y\nAs always, feel free to reach out to me with questions, suggestions, or feedback, by replying directly to this email (if you are a subscriber), commenting on this post, or sending me a message on Twitter. My DMs are open.\n-Rika\n\n\n\n\n\n\n Placeholder Image\nIntro: Decentralized Finance (DeFi) is more than speculation\nDeFi has plenty of tropes: crypto bros timing the market, chasing jackpots, flexing wins (and downplaying losses). But trading to make a quick buck is hollow.\nTo be fair, some of these tropes are true.\nMost peopleâ€™s first touchpoint with crypto is speculation â€” buying a token on an exchange like Coinbase, driven by FOMO and the hope of making quick money. Personally, I think thatâ€™s problematic. Trading is short-term and risky; investing is long-term and purposeful.\nMy own experience with DeFi looks different. I work in Decentralized Autonomous Organizations (DAOs), a new type of organization.\n*Quick refresher on DAOs for those who may not be familiar: working in a DAO is akin to being a shareholder in a technology company and an active participant in decision making: from voting on treasury management to strategy to protocol upgrades.\nI am paid on-chain in a combination of stablecoins (e.g, USDC) and/or protocol native tokens (e.g, UNI, ARB), also known as governance tokens. From there, I move assets between wallets the way others move dollars between checking and savings. My DeFi experience is grounded in real-life financial flows, not speculation.\nDeFi isnâ€™t just a casino. Itâ€™s the rails of a new financial economy â€” open to traders, investors, builders, business folks, and really anyone curious enough to explore.\nUseful Definitions\nDecentralized Finance (DeFi)\nDeFi is a new type of finance that removes the intermediaries we rely on in traditional, centralized systems. Transactions are peer-to-peer, fast, and markets are open 24/7.\nTraditional Finance (TradFi)\nTradFi refers to the legacy financial system built around banks, brokers, and other intermediaries. In TradFi, access to money and markets depends on these middlemen â€” whether itâ€™s opening a checking account, applying for a loan, or trading stocks.\nTrading\nTrading is the buying and selling of assets with a short-term focus, aiming to profit from price swings. In crypto, this often means moving quickly between tokens â€” trying to â€œtime the marketâ€ or capture volatility.\nInvesting\nInvesting is the act of allocating money or assets with the expectation of long-term growth or income. In crypto, this usually means holding tokens, participating in governance, or providing liquidity with the belief that the protocol or ecosystem will increase in value over time.\nPermissionlessness\nGovernance Token\nA governance token gives its holders the right to participate in the decision-making of a protocol. Instead of control resting with a company or board of directors, governance tokens distribute voting power to the community.\nPump and Dump\nBody 1: The origins of DeFi\nAt the core of DeFi is permissionlessness, which means that anyone anywhere has access to the system  There is no need to ask for permission from an authority and anyone anywhere\nOne of the first breakthrough DeFi protocols started with MakerDAO in 2017, when it launched the stablecoin DAI. Â Instead of relying on a central issuer like a bank, DAI was backed by collateral locked in Ethereum smart contracts. It showed that a community could mint a stable, dollar-pegged asset without a centralized authority in control.\nThen in 2018 came Uniswap, which introduced the automated market market (AMM) to swap one token for another. Rather than order books and market makers, used by centralized exchanges, anyone could deposit tokens into a liquidity pool, with an algorithm setting the price.\nAround the same time emerged Compound, a protocol for decentralized borrowing and lending. Instead of a bank deciding who qualifies for a loan, Compound allows anyone with collateral to borrow from a shared liquidity pool, with interest rates determined algorithmically.\nBody 2: DeFi Summer\nThe summer of 2020 marked an explosion of DeFi experimentation on Ethereum.\nAt the center of it was a new mechanic: yield farming. Protocols began distributing their governance tokens to users who supplied liquidity. Suddenly, providing capital to DeFi platforms didnâ€™t just earn interest â€” it came with bonus tokens that could increase in value.\nCompound kicked it off by distributing COMP tokens to its lenders and borrowers. Soon after, protocols like Curve, Yearn, and the infamous SushiSwap piled in, each offering outsized rewards to attract liquidity. Billions of dollars in assets flooded into DeFi protocols within weeks.\nThe gold rush however had downsides. Many token incentives were unsustainable, leading to â€œpump-and-dumpâ€ cycles. Meme-inspired projects went from launch to collapse in days. Hacks and rug pulls became common as unaudited contracts rushed to market.\nDespite the chaos, DeFi Summer cemented that DeFi was not just a passing fad. Core protocols like Uniswap, Compound, MakerDAO, and Aave, emerged stronger, battle-tested by the flood of users and capital.\nBody 3: Core DeFi Protocols\nIâ€™ve already mentioned some of the core DeFi protocols â€” Uniswap, Compound, MakerDAO, and Aave. But theyâ€™re far from the only ones. In the five years since DeFi Summer, the ecosystem has expanded dramatically, with new protocols tackling everything from derivatives to perpetuals to cross-chain liquidity.\nWith that experimentation comes added risk. For beginners, only a handful of protocols are reliable starting points. That said, I donâ€™t want to suppress curiosity â€”as I noted in the introduction, DeFi ultimately rewards the curious.\nBody 4: Beginner Friendly DeFi Building Blocks\nFor those just getting started, here are a few DeFi protocols and applications that are widely used, battle-tested, and relatively beginner-friendly:\n\n\nUniswap (Trading): The go-to decentralized exchange for swapping tokens.\n\n\nAave (Lending/Borrowing): A leading platform for earning interest or borrowing against crypto.\n\n\nMakerDAO (Stablecoins): Creator of DAI, the most established decentralized stablecoin.\n\n\nCurve (Stablecoin Trading): Specialized in efficient swaps between stablecoins like USDC, DAI, and USDT.\n\n\nUSDC (Stablecoin): A centralized but highly liquid dollar-backed stablecoin, often the on-ramp into DeFi.\n\n\nArbitrum (Layer 2): A scaling network for Ethereum that makes transactions faster and cheaper, making DeFi more accessible to everyday users.\n\n\nâš ï¸ Note: Even with these tools, risks remain â€” from smart contract bugs to market volatility. Start small, do your research, and never invest more than you can afford to lose.\nEvaluation Framework\nAs in my previous posts, Iâ€™ve put together a simple framework to help you think about how to evaluate DeFi protocols and applications.\n\n\nSecurity &amp; Audits\n\n\nHas the protocol undergone third-party audits?\n\n\nHow long has it been live without major exploits?\n\n\nIs the code open-source and battle-tested?\n\n\n\n\nDecentralization\n\n\nWho controls upgrades and governance?\n\n\nIs voting distributed among many token holders, or concentrated in a few wallets?\n\n\nDoes the team have a track record of respecting community decisions?\n\n\n\n\nTransparency\n\n\nAre reserves, collateral, or liquidity visible onchain?\n\n\nCan you easily verify where yield is coming from?\n\n\n\n\nComposability\n\n\nDoes the protocol integrate with others (e.g., can you use assets from one platform on another)?\n\n\nIs it part of the broader DeFi â€œmoney Legoâ€ stack, or isolated?\n\n\n\n\nSustainability of Incentives\n\nAre yields coming from actual economic activity (fees, borrowing demand), or just inflationary token rewards?\nWill the model work without constant subsidies?\n\n\n\nUser Experience\n\n\nIs the app intuitive?\n\n\nAre transaction costs reasonable (especially on Layer 2s like Arbitrum)?\n\n\nIs there good documentation and community support?\n\n\n\n\nConclusion\nSome of DeFiâ€™s tropes â€” crypto bros chasing huge returns, flexing wins, and quietly downplaying losses â€” will probably always be true. Surprising as it sounds, speculation can play an important role in keeping financial markets healthy.\nThey key however for most normal folks who donâ€™t want to take on excessive risk is that you donâ€™t need to be a risk chasing crypto bro to build wealth in this new financial economy. You just need to have an appetite for curiosity and thoughtfulness, patience, and no rash decisions. Prioritize education ad prudence above all else.\nAnd itâ€™s true â€” speculation will probably always be part of the story. But to stop there misses the bigger picture.\nThe key for most people (myself included) who are not equipped to take excessive risk is this: you donâ€™t need to be a risk-chasing crypto bro to build wealth in this new financial economy. What you do need is curiosity, thoughtfulness, and a steady hand. Prioritize education and prudence â€” thatâ€™s how youâ€™ll be best positioned to benefit as DeFi continues to mature\nPractically, this might mean starting small with a swap on Uniswap, experimenting with a stablecoin like USDC or DAI, or lending on Aave. For others, it might mean contributing to a DAO or exploring new protocols.\nWherever you begin, the key is curiosity and a willingness to learn."},"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---Outline":{"slug":"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---Outline","filePath":"Newsletter/5 Decentralized Finance/5 Decentralized Finance - Outline.md","title":"5 Decentralized Finance - Outline","links":[],"tags":[],"content":"Possible Outline\n\n\nIntro\n\n\nGround the reader in todayâ€™s financial landscape: banks, fintech apps, and the trust model they rely on.\n\n\nBriefly highlight the promise of DeFi: open, programmable, permissionless finance.\n\n\nPosition DeFi as the â€œonchain evolutionâ€ of traditional finance, much like your last post framed onchain social as the evolution of social media.\n\n\n\n\nUseful Definitions\n\n\nWhat is Finance (TradFi)?\n\n\nWhat is DeFi?\n\n\nKey terms: smart contracts, liquidity pools, yield farming, governance tokens.\n\n\n\n\nHistorical Evolution\n\n\nEarly DeFi experiments: MakerDAO (DAI), Uniswap, Compound.\n\n\n2020â€™s â€œDeFi Summerâ€ boom â€” experimentation and excess.\n\n\nInstitutional interest and regulatory pushback.\n\n\n\n\nKey Protocols &amp; Models\n\n\nUniswap: automated market maker innovation.\n\n\nMakerDAO: stablecoin collateral and governance.\n\n\nAave/Compound: lending and borrowing.\n\n\nL2 ecosystems: how scaling (Arbitrum, Optimism) is shaping DeFi.\n\n\n\n\nChallenges &amp; Risks\n\n\nSmart contract risk, hacks, and exploits.\n\n\nRegulatory uncertainty.\n\n\nUser experience (still too complex for mainstream).\n\n\n\n\nFramework for Evaluation\nSimilar to your â€œevaluation frameworkâ€ in the last post. Possible criteria:\n\n\nDecentralization (governance, control, custody).\n\n\nTransparency (audits, on-chain data).\n\n\nComposability (how easily it plugs into the DeFi ecosystem).\n\n\nSustainability (tokenomics, incentives).\n\n\nRegulatory resilience.\n\n\n\n\nConclusion\n\n\nDeFi is still early â€” like social media before Facebook, itâ€™s fragmented and experimental.\n\n\nBut it has the potential to reshape finance in the same way onchain social is reshaping communication.\n\n\n\n"},"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---Tweet":{"slug":"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---Tweet","filePath":"Newsletter/5 Decentralized Finance/5 Decentralized Finance - Tweet.md","title":"5 Decentralized Finance - Tweet","links":[],"tags":[],"content":"From the outside, crypto looks like a speculative casino. Whatâ€™s often missed is that itâ€™s the foundation of a new financial system â€” one anyone can join with a little curiosity. My latest post breaks down DeFi and shares a few starting points for beginners. Share it ğŸ‘‡"},"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---final":{"slug":"Newsletter/5-Decentralized-Finance/5-Decentralized-Finance---final","filePath":"Newsletter/5 Decentralized Finance/5 Decentralized Finance - final.md","title":"5 Decentralized Finance - final","links":[],"tags":[],"content":"Greetings, readers! (or Gm, as we commonly greet others in the crypto community). The purpose of this newsletter is to provide digestible breakdowns of complex protocols and products in the Ethereum ecosystem. You can expect quality substantive content (no hype pieces, shilling, or paywall) written for crypto-curious readers who are either newer to crypto or seasoned users who value refreshers on the fundamentals. You can learn more about this newsletter in the introductory post.\nAs always, feel free to reach out to me with questions, suggestions, or feedback, by replying directly to this email (if you are a subscriber), commenting on this post, or sending me a message on Twitter. My DMs are open.\n-Rika\nDeFi is More than Speculation\nDeFi has plenty of tropes: crypto bros timing the market, chasing jackpots, flexing wins (and downplaying losses). But trading to make a quick buck is hollow.\nTo be fair, some of these tropes are true.\nMost peopleâ€™s first touchpoint with crypto is speculation â€” buying a token on an exchange like Coinbase, driven by FOMO and the hope of making quick money. Personally, I think thatâ€™s problematic. Trading is short-term and risky; investing is long-term and purposeful.\nMy own experience with DeFi looks different. I work in Decentralized Autonomous Organizations (DAOs), a new type of organization.\nI am paid on-chain in a combination of stablecoins (e.g, USDC) and protocol native tokens (e.g, UNI, ARB), also known as governance tokens. From there, I move assets between wallets the way others move dollars between checking and savings. My DeFi experience is grounded in real-life financial flows, not speculation.\nDeFi isnâ€™t just a casino. Itâ€™s the rails of a new financial economy â€” open to traders, investors, builders, business folks, and really anyone curious enough to explore.\n\nUseful Definitions\nWhat is Decentralized Finance (DeFi)?\n\nDeFi is a new type of finance that removes the intermediaries we rely on in traditional, centralized systems. Transactions are peer-to-peer, fast, and markets are open 24/7.\n\nWhat is Traditional Finance (TradFi)?\n\nTradFi refers to the legacy financial system built around banks, brokers, and other intermediaries. In TradFi, access to money and markets depends on these middlemen â€” whether itâ€™s opening a checking account, applying for a loan, or trading stocks.\n\nWhat is Trading?\n\nTrading is the buying and selling of assets with a short-term focus, aiming to profit from price swings. In crypto, this often means moving quickly between tokens â€” trying to â€œtime the marketâ€ or capture volatility.\n\nWhat is Investing?\n\nInvesting is the act of allocating money or assets with the expectation of long-term growth or income. In crypto, this usually means holding tokens, participating in governance, or providing liquidity with the belief that the protocol or ecosystem will increase in value over time.\n\nWhat is Permissionlessness?\n\nPermissionlessness means anyone can access and use a system without needing approval from a central authority. In DeFi, this is one of the defining features: you donâ€™t need a bank, broker, or government agency to grant you access. All you need is an internet connection and a crypto wallet.\n\nWhat is a Governance Token?\n\nA governance token gives its holders the right to participate in the decision-making of a protocol. Instead of control resting with a company or board of directors, governance tokens distribute voting power to the community.\n\nWhat is a Pump-and-Dump?\n\nA pump-and-dump is a market manipulation scheme where the price of a token is artificially inflated (â€œpumpedâ€) through hype, misinformation, or coordinated buying. Once the price spikes, early movers sell off their holdings (â€œdumpâ€), leaving latecomers holding the bag as the price crashes.\n\n\nThe Origins of DeFi\nAt the core of DeFi is permissionlessness, which means that anyone anywhere has access to the system There is no need to ask for permission from an authority.\nOne of the first breakthrough DeFi protocols started with MakerDAO (now known as Sky) in 2017, when it launched the stablecoin DAI. Â Instead of relying on a central issuer like a bank, DAI was backed by collateral locked in Ethereum smart contracts. It showed that a community could mint a stable, dollar-pegged asset without a centralized authority in control.\nThen in 2018 came Uniswap, which introduced the automated market market (AMM) to swap one token for another. Rather than order books and market makers, used by centralized exchanges, anyone could deposit tokens into a liquidity pool, with an algorithm setting the price.\nAround the same time emerged Compound, a protocol for decentralized borrowing and lending. Instead of a bank deciding who qualifies for a loan, Compound allows anyone with collateral to borrow from a shared liquidity pool, with interest rates determined algorithmically.\nDeFi Summer\nThe summer of 2020 marked an explosion of DeFi experimentation on Ethereum.\nAt the center of it was a new mechanic: yield farming. Protocols began distributing their governance tokens to users who supplied liquidity. Suddenly, providing capital to DeFi platforms didnâ€™t just earn interest â€” it came with bonus tokens that could increase in value.\nCompound kicked it off by distributing COMP tokens to its lenders and borrowers. Soon after, protocols like Curve, Yearn, and the infamous SushiSwap piled in, each offering outsized rewards to attract liquidity. Billions of dollars in assets flooded into DeFi protocols within weeks.\nThe gold rush however had downsides. Many token incentives were unsustainable, leading to â€œpump-and-dumpâ€ cycles. Meme-inspired projects went from launch to collapse in days. Hacks and rug pulls became common as unaudited contracts rushed to market.\nDespite the chaos, DeFi Summer cemented that DeFi was not just a passing fad. Core protocols like Uniswap, Compound, MakerDAO (now known as Sky), and Aave, emerged stronger, battle-tested by the flood of users and capital.\nCore DeFi Protocols\nIâ€™ve already mentioned some of the core DeFi protocols: Uniswap, Compound, MakerDAO, and Aave. But theyâ€™re far from the only ones. In the five years since DeFi Summer, the ecosystem has expanded dramatically, with new protocols tackling everything from derivatives to perpetuals to cross-chain liquidity.\nWith that experimentation comes added risk. For beginners, only a handful of protocols are reliable starting points. That said, I donâ€™t want to suppress curiosity â€”as I noted in the introduction, DeFi ultimately rewards the curious.\n\nBeginner Friendly DeFi Building Blocks\nFor those just getting started, here are a few DeFi protocols that are widely used, battle-tested, and relatively beginner-friendly:\n\n\nUniswap: The go-to decentralized exchange for swapping tokens.\n\n\nAave: A leading platform for earning interest or borrowing against crypto.\n\n\nSky (formerly MakerDAO): Creator of DAI, a leading decentralized stablecoin.\n\n\nCompound: A foundational protocol for earning interest or borrowing against crypto, with a strong track record.\n\n\nUSDC: A centralized but highly liquid dollar-backed stablecoin, often the on-ramp into DeFi.\n\n\nArbitrum: A scaling network for Ethereum that makes transactions faster and cheaper, making DeFi more accessible to everyday users.\n\n\n\nEvaluation Framework\nAs in my previous posts, Iâ€™ve put together a simple framework to help you think about how to evaluate DeFi protocols and applications.\n\n\nSecurity &amp; Audits\n\n\nHas the protocol undergone third-party audits?\n\n\nHow long has it been live without major exploits?\n\n\nIs the code open-source and battle-tested?\n\n\n\n\nDecentralization\n\n\nWho controls upgrades and governance?\n\n\nIs voting distributed among many token holders, or concentrated in a few wallets?\n\n\nDoes the team have a track record of respecting community decisions?\n\n\n\n\nTransparency\n\n\nAre reserves, collateral, or liquidity visible onchain?\n\n\nCan you easily verify where yield is coming from?\n\n\n\n\nComposability\n\n\nDoes the protocol integrate with others (e.g., can you use assets from one platform on another)?\n\n\nIs it part of the broader DeFi â€œmoney Legoâ€ stack, or isolated?\n\n\n\n\nSustainability of Incentives\n\n\nAre yields coming from actual economic activity (fees, borrowing demand), or just inflationary token rewards?\n\n\nWill the model work without constant subsidies?\n\n\n\n\nUser Experience\n\n\nIs the app intuitive?\n\n\nAre transaction costs reasonable?\n\n\nIs there good documentation and community support?\n\n\n\n\n\nConclusion\nSome of DeFiâ€™s tropes â€” crypto bros chasing huge returns, flexing wins, and quietly downplaying losses â€” will probably always be true. Surprising as it sounds, speculation can play an important role in keeping financial markets healthy.\nThey key however for most normal folks who donâ€™t want to take on excessive risk is that you donâ€™t need to be a risk chasing crypto bro to build wealth in this new financial economy. You just need to have an appetite for curiosity, thoughtfulness, and patience. Prioritize education and prudence above all else.\nPractically, this might mean starting small with a swap on Uniswap, experimenting with a stablecoin like USDC or DAI, or lending on Aave. For others, it might mean contributing to a DAO or exploring new protocols.\nWherever you begin, the key is curiosity and a willingness to learn.\n\nFeel free to reach out to me directly with questions, suggestions, or feedback. You can also drop me a message on Twitter. My DMs are open.\n-Rika"},"Newsletter/5-Decentralized-Finance/Brain-Dump-PRIVATE":{"slug":"Newsletter/5-Decentralized-Finance/Brain-Dump-PRIVATE","filePath":"Newsletter/5 Decentralized Finance/Brain Dump PRIVATE.md","title":"Brain Dump PRIVATE","links":["Newsletter/5-Decentralized-Finance/How-does-it-make-sense-to-invest-in-stETH-Lets-look-at-my-personal-experience."],"tags":[],"content":"Hi reading friends, or I mean the void because I donâ€™t know who many of you actually are but I write for myself to help me with the learning journey. And I write to help new people explore the world of DeFi. It also gives me something interesting and fun to do on Saturday. I set this goal for myself and I wasnâ€™t doing much of it previously but now I am on Saturday morning. Around the winter holidays and for months I didnâ€™t write on Saturday but now Iâ€™m getting back into the habit and I love it. I love writing. Click clacks on the keyboard feels satisfying. I also feel rested today, unlike yesterday. I was tired from the work week. Fucking Arbitrum taking up too much space. We have commitments there but they donâ€™t treat us well. So we can treat them like distant relatives. Bye bye Arb. Pay me and I go.\nWith that said, Iâ€™m thinking about the War book where Bob Woodward shared that Trump and Putin cannot put their personal interests below the greater interests. Meaning, in politics, you must put the nationâ€™s interests above your own personal interests and grudges, etc. Unfortunately these people cannot do that. Which is sad. No one teaches you these things. They are simply what you learn through experience and personal values, etc. Everyone makes their own choices. Iâ€™m not here to judge but the â€¦\nOkay, now round 2 phase 2 despite me being tired. It should pass I think. If I just keep writing through it.\nOk so whatâ€™s going on here lets see lets see lets see. Get some food.\nLook at dashboards.\nHow does it make sense to invest in stETH? Lets look at my personal experience."},"Newsletter/5-Decentralized-Finance/How-does-it-make-sense-to-invest-in-stETH-Lets-look-at-my-personal-experience.":{"slug":"Newsletter/5-Decentralized-Finance/How-does-it-make-sense-to-invest-in-stETH-Lets-look-at-my-personal-experience.","filePath":"Newsletter/5 Decentralized Finance/How does it make sense to invest in stETH? Lets look at my personal experience..md","title":"How does it make sense to invest in stETH? Lets look at my personal experience.","links":[],"tags":[],"content":"About one year ago, I decided to experiment with staking ETH. I wrote a newsletter post about it and I wanted to try out liquid staking. I read about it a ton online so finally I went for it. It took me a long time. A long time to trust what I was doing. Mostly to take the risk.\nBut all I did was risk 300. It&#039;s little money. I&#039;m privileged so its no big deal. But some people say they risk 3,000 and its no big deal. So whatever, doesn&#039;t mater. The important thing is that you risk something. You could risk 100 and still learn whatâ€™s going on. Enough to where it makes a difference.\nThe goal here is to learn. Itâ€™s not necessarily to make money. I promise you the money will come later. I donâ€™t have children, but thatâ€™s what I would teach my future kids. Try small risks, learn, and the money will come. Trust me. Clearly, this is nuanced too.\nTestnet is the best way to learn with no money. You are at risk of losing NOTHING. But youâ€™re learning. A few hundred dollars is okay too to gamble with.\nI gambled with X ETH for Y StETH.\nMy aspiration is to help people make money."},"Newsletter/5-Decentralized-Finance/Possible-Resources":{"slug":"Newsletter/5-Decentralized-Finance/Possible-Resources","filePath":"Newsletter/5 Decentralized Finance/Possible Resources.md","title":"Possible Resources","links":[],"tags":[],"content":"dune.com/fergmolina/world-liberty-financial\nwww.staderlabs.com/ (liquid restaking - read about it in Kpkâ€™s investment policy for ENS. They use Rocketpool &amp; Stader)"},"Books/DeFi-Investing/Introduction-to-On-Chain-Analysis-by-Patrick-Scott-aka-Dynamo-DeFi":{"slug":"Books/DeFi-Investing/Introduction-to-On-Chain-Analysis-by-Patrick-Scott-aka-Dynamo-DeFi","filePath":"Books/DeFi Investing/Introduction to On-Chain Analysis by Patrick Scott aka Dynamo DeFi.md","title":"Introduction to On-Chain Analysis by Patrick Scott aka Dynamo DeFi","links":[],"tags":["books"],"content":"\nNotes\n\n\nOn-chain analysis separates the pros from the amateurs in crypto\n\n\nDeBankâ€™s â€œWeb3 Social Rankingâ€ is used to find wallets with large portfolios (whale wallets) eg. $57 million portfolio\n\n\nWatcherâ€™s Pro is helpful for finding VC wallets. More digging in can be done on Arkham where you see exchanges &amp; counterparties VCs use. Helpful to understand 2nd order effects of a crash\n\n\nSteps to track whale wallets:\n\nGo to debank &amp; type wallet address or name\nClick â€œfollowâ€ to start following the address\n\n\n\nI briefly played around with DeBank &amp; Zapper. Unfortunately to see the change in a walletâ€™s address on DeBank requires a premium account.\n\n\nZapper seems to be better with wallet identification, meaning users add their ENS names and a description to their bio. eg. I was able to see thru Zapper that a whale account belongs to Robinhood. And that another whale account is an â€œOG crypto trader since 2015â€. I could not tell this on DeBank.\n\n\nArkham allows you to see the change in balance and profit/loss of an account. Although I am confused about how profit/loss is calculated.\n\n\nArkham visualizer is cool but I donâ€™t know how to make meaning out of it\n\n\nArkham emailed me guides which I think would be useful to go through\n\n\nTools\ndebank.com/\nwww.scopescan.ai/home\nplatform.arkhamintelligence.com/\nbubblemaps.io/\n**Finding new tokens(note: many are scams)\ndexscreener.com/\nde.fi/ - token scanner tool"},"Newsletter/4-Decentralized-Social-Media/Social-Media/Social-(Research)":{"slug":"Newsletter/4-Decentralized-Social-Media/Social-Media/Social-(Research)","filePath":"Newsletter/4 Decentralized Social Media/Social Media/Social (Research).md","title":"Social (Research)","links":[],"tags":[],"content":"docs.farcaster.xyz/learn/what-is-farcaster/frames\ndocs.farcaster.xyz/reference/frames/spec"},"DeFi/A-primer-on-NFVs-and-how-Non-Fungible-Vaults-improve-CDPs":{"slug":"DeFi/A-primer-on-NFVs-and-how-Non-Fungible-Vaults-improve-CDPs","filePath":"DeFi/A primer on NFVs and how Non-Fungible Vaults improve CDPs.md","title":"A primer on NFVs and how Non-Fungible Vaults improve CDPs","links":["tags/published"],"tags":["published"],"content":"published\nRead Full Article\nDespite going through the coldest of crypto winters, DeFi continues to gain leverage over inefficient Tradfi products. Lending, in particular, has found a strong product-market fit, as it enables users to borrow tokens by locking their assets inÂ Collateralized Debt PositionsÂ (CDPs).\nWhile CDPs create new opportunities to leverage and monetize oneâ€™s assets, theyâ€™re often inflexible due to infrastructure limitations. Open Dollar resolves these issues by introducing a new way to access and manage collateral. Instead of using their protocolâ€™s account, users can now do it via NFTs.\nThis article offers a primer on Non-Fungible Vaults (NFVs), describing their benefits over traditional, account-tied CDPs, and the new use cases they unlock for DeFi natives.\nTLDR;\n\n\nOpen Dollar enables users to create CDPs via Non-Fungible Vaults (NFVs).\n\n\nNFVs tie CDP ownership to transferable NFTs instead of protocol accounts.\n\n\nNFVs improve upon account-tied CDPs while creating new use cases.\n\n\nAccount-tied CDPs are inefficient\nCollateralized Debt Positions (CDPs) are becoming increasingly popular. The concept wasÂ first introduced by MakerDAOÂ in 2018 in order to mint its stablecoin, DAI. From a practical standpoint, interaction with CDPs looks as follows:\n\nUsing a traditional DeFi CDP\nLetâ€™s assume that youâ€™re using Lending protocol X to deposit Y collateral. If you want to borrow against Y or deposit more to avoid liquidating Y, you will always need to use an account tied to your wallet. If you want to withdraw Y, you will first need to pay back the debt in full (including fees that may incur). This, too, happens through your account.\nThe above example reveals two inefficiencies:\n\n\nCDP ownership is tied to a single account and is non-transferable.Â This makes CDPs illiquid and unusable until withdrawn. To illustrate, thatâ€™s like taking out a mortgage on a property that you cannot sell until you pay the debt back in full.\n\n\nAccess to CDPs occurs from the protocolâ€™s front end instead of the userâ€™s wallet.Â If the front end is buggy or doesnâ€™t work, you cannot retrieve your assets without much more technical knowledge of smart contracts.\n\n\nOpen Dollar and the introduction of NFVs\nUnlike traditional CDPs, where ownership is tied to an account, Open Dollar uses NFVs, which associate ownership of the collateral to NFTs. By doing so, the debt is locked in the protocol, but its ownership is not.\n\nThe NFT acts as a â€œreceiptâ€. Not only does it prove ownership of the collateral and gives access to it, but it is also backed by its value.Â In short, it is a derivative of the collateral.\nNFVs act as a building block that expands existing markets and creates opportunities for users. For example, they can sell vaults on NFT marketplaces, transfer them to other wallets, or display them in their portfolio trackers.\nNFVs resolve the problems of account-tied CDPs:\n\n\nOwnership of CDPs becomes transferable and therefore no longer tied to a single account.Â The NFT makes the collateral liquid, which improves cost-effectiveness and flexibility.\n\n\nUsers no longer need to access the protocol to manage or track their CDP.Â They can do so directly from their wallet. It is only when one wishes to interact with the CDP that they need to access the protocol (e.g. borrow against the collateral, deposit more, or withdraw any amount).\n\n\nWhy NFVs are superior to Account-tied CDPs\nNFVs are not only solving inefficiencies of account-tied CDPs. They also unlock new opportunities:\nAccessibility\nNFVs are more capital-efficient for users, who can now easily sell their vaults instead of interacting with them. Automations can also sell vaults to arbitrageurs without incurring liquidation penalties.\nExample:\n\n\nUser deposits X wstETH on Open Dollar and receives an NFT.\n\n\nNext, the user borrows $OD and decides to trade with leverage.\n\n\nThe trade goes poorly and incurs a loss.\n\n\nAt this point, the user can choose to sell the ownership of the vault (the NFT) instead of buying more $OD to unlock the wstETH collateral.\n\n\nUsers could also bridge NFTs from one blockchain to another. Cross-chain compatibility of NFTs is not only possible but is also more efficient in certain situations than bridging collateral directly.\nComposability\nIt is easier to batch-transfer NFTs and more straightforward for individuals to transfer ownership of their assets directly from their wallet. As described above, this may come in use if a protocolâ€™s front end fails, as it allows users to trade vaults without having to interact with a protocolâ€™s smart contracts on the back end.\nExample: User A wants to transfer his assets to user B. In traditional CDPs, user A would need to access the protocol, pay the required fees to withdraw, and send the funds from his wallet once unlocked.\nWith NFVs, user A can simply change the owner of his locked collateral by sending the NFT to user B.\nManagement\nThe infrastructure for transferring and owning NFTs as a DAO or DeFi protocol is already well-established for other use cases. This new primitive expands it further by improving treasury management, risk management, and performance tracking.\nVisibility\nWallet aggregators and portfolio trackers can display usersâ€™ NFVs along with their assets directly, instead of trying to calculate their position. Since the NFT is backed by the collateral, its price is dynamic and reprices accordingly. Open Dollar NFVs also take advantage of the display image of NFTs by giving users updated and interactive insights into their vaults.\n\nThe Open Dollar Non-Fungible Vault (NFV)\nSecurity\nNFVs can be used as a protection lever to avoid bad actors. NFTs could be locked into compliance services, escrow services, or others.\nSumming Up\nAccount-tied CDPs suffer from two main inefficiencies that make them problematic. First, they are tied to a single user account and are therefore not transferable. Second, they have a single point of failure, since access is only possible from the protocolâ€™s front end.\nTo solve these issues, Open Dollar introduces non-fungible vaults (NFVs), which are more flexible and reliable from a user standpoint. By using NFTs as proxies of the locked collateral, vaults become transferable and therefore no longer tied to a single account. Users also no longer need to access the protocol to interact with the CDP. They can simply sell or transfer it directly from their wallet.\nNFVs are a better option since they improve upon traditional CDPs in multiple areas, while unlocking multiple new use cases.\nAbout Open Dollar\nOpen Dollar is a DeFi lending protocol that enables borrowing against liquid staking tokens while earning staking rewards and enabling liquidity via Non-Fungible Vaults (NFVs).\nLSTs and other assets can be deposited into NFVs in order to borrow the OD stablecoin with low-interest loans, create leveraged positions, and continue to earn 100% of their staking yield. The OD token is over-collateralized and pegged to $1.00.\nOpen Dollarâ€™s NFVs are a more capital-efficient alternative to account-tied CDPs, giving depositors the freedom to trade their positions or sell to arbitrageurs on any NFT platformÂ without incurring liquidation penalties.\nOpen Dollarâ€™s minimized-governance approach ensures the longevity and fairness of the platform. The DAO, powered by the Open Dollar Governance (ODG) token, can vote to add new collateral types but is otherwise limited and cannot mint new OD tokens or change parameters such as fee distribution."},"DeFi/LSTs-and-leveraged-ETH-staking-strategies-at-DeFi-Saver":{"slug":"DeFi/LSTs-and-leveraged-ETH-staking-strategies-at-DeFi-Saver","filePath":"DeFi/LSTs and leveraged ETH staking strategies at DeFi Saver.md","title":"LSTs and leveraged ETH staking strategies at DeFi Saver","links":[],"tags":[],"content":"Source: blog.defisaver.com/lsts-and-leveraged-eth-staking/\nThe Ethereum Shanghai upgrade is live and LSTs and leveraged ETH staking strategies are now available in the DeFi Saver app! Check out this article and find out the best way to utilize this feature!\n\nThe Ethereum Shanghai upgrade, the hard fork that enables validators to withdraw their staked ETH (EIP-4895) isÂ scheduled for tomorrow (April 12th)! This is a huge event for the Ethereum stakers community and its expected to drive even more attention to (liquid) ETH staking narratives and strategies in the DeFi space.\nWeâ€™ve already seen the â€˜pegâ€™ of various liquid staking tokens tighten up after the successful Merge back in September last year, so it only makes sense for the introduction of withdrawals to further improve confidence among users of staked ETH across DeFi.\nThe number of validators running on the Beacon Chain has also increased byÂ aroundÂ 25%Â in the last 6 months, boosting the security of the Ethereum network and paving the way to an even more decentralised future.\nAt the time of writing, there is over 17m of ETH staked, representing around 15% of total ETH supply. ApproximatelyÂ 40%Â of that staked ETH is staked via pools, with Lido, a decentralised liquid staking protocol, leading the way by takingÂ more than 77%Â of the pooled-staking market share.\nToday, weâ€™ll try to give a short rundown of the most popular liquid staking protocols and how their liquid staking tokens (LSTs) are being used across DeFi (Saver).\nPopular liquid staking tokens in 2023\nA quick comparison of the three most popular liquid staking options, according to theÂ Ethereum.orgÂ criteria, boils down to this:\n\nBut letâ€™s also do a quick rundown of each of these three options separately.\nLido Finance - stETH\nAs mentioned earlier,Â Lido Finance, a decentralised liquid staking protocol launched back in December 2020, managed to become anÂ absolute leaderÂ in the pooled staking industry when it comes to the amount of ETH staked.\n\nConsequently, stETH, Lidoâ€™s liquid staking token, also has the deepest liquidity across lending markets and decentralised exchanges. Most notably, thereâ€™s Aave (v2 &amp; v3) and theÂ Curve stETH/ETH pool, which have around 1.1m of ETH (2b at the moment), and 400k of both ETH and stETH (1.5b at the moment), respectively.\nNote that there are two versions of Lidoâ€™s staked ETH tokens:Â stETHÂ andÂ wstETHÂ (wrapped stETH).\nBoth tokens follow the ERC-20 token standard, but they reflect the accrued staking rewards in different ways. The standard stETH is a rebasing token, meaning that the stETH balance increases periodically. In contrast, wstETHâ€™s balance is constant, while the token increases in value (compared to stETH).\nSince most DeFi lending protocols donâ€™t support rebasing tokens (except from Aave v2 and Curve, for example), wstETH is mostly used across decentralised apps like Maker, Compound v2 &amp; v3, Aave v3, Uniswap, etc.\nTo learn more about Lido protocol and see how Lido and its validators are performing (security-wise), we recommend checking out theirÂ docsÂ andÂ scorecard.\nRocket Pool - rETH\nRocket Pool protocol is an OG in the decentralised Ethereum staking space. Itâ€™s designed to support anyone to trustlessly stake as little as 0.01 ETH to a network of decentralised node operators.\nYou can simply stake ETH and receive rETH - RocketPoolâ€™s liquid staking token that accrues staking yield using an increasing exchange rate (increases in value).\nIn addition, RP offers users to stakeÂ 16 ETHÂ as node operators (aka Smart Nodes) in the protocol, earning rewards on their own stake fee free, plus the commissions and RPL rewards from the network, generating a higher ROI by staking in the protocol vs staking outside of it as a solo node operator.\nSmart Node providers earn RPL rewards in return for initially putting up RPL as collateral, thus insuring their node against bad behaviour.\nThis neat 16 ETH opportunity can be offered thanks to the minipool validators smart contracts. These smart contracts are created by node operators who deposit 16 ETH on their node, and receive another 16 ETH from users who stake ETH (rETH holders). After getting the 32 ETH in total, a new validator is created on the node which performs the consensus duties for that deposit to earn staking rewards.\nTo learn more about the RP protocol, check their full docsÂ here.\nCoinbase - cbETH\nCoinbase, the second largest CEX by volume, has launched their version of ETH liquid staking token calledÂ cbETHÂ back in August 2022. Until then, the only participants exploring the liquid staking game were DeFi protocols like Lido and RocketPool.\nThe cbETH is minted exclusively by Coinbase, and users can stake their ETH through the â€˜Earnâ€™ program on Coinbase, which requires them to pass the KYC and identification process, meaning that staking ETH through Coinbase is not permissionless.\nOn the other hand, since cbETH complies with the ERC-20 token standard it can be bought, sold, transferred, and used across DeFi as any other ERC-20 token on Ethereum blockchain.\nCurrently, cbETH is the second largest ETH liquid staking token by TVL, right between Lidoâ€™s stETH and RocketPoolâ€™s rETH.\nThe Peg\nSince the exposure to liquid staking tokens can be gained not just via staking directly through their respective staking providers, but also by buying them on exchanges, it could be useful to check their current â€˜pegâ€™ status.\nNamely, the LSTs are meant to keep the 1:1 ratio with the underlying ETH (or with their internal conversion rate, if not rebasing), but considering the fact that withdrawals are yet to be enabled, they usually trade at a certain discount on the open markets.\n\nThis can serve as useful info when deciding to gain exposure to some of the LSTs available on open markets, and potentially using them in DeFi afterwards.\nDifferent LSTs in DeFi lending protocols\nAs one of the most popular strategies in DeFi right now, leveraged-staking is seeing a rapid growth not just in volume but in the number of options available through multiple tokens, protocols, and even networks (L2s).\nBelow, weâ€™ve gathered all the relevant options (so far) in one place with the info about ==max leverage possible based on the Loan-To-Value available in the underlying protocols.\n\nLeveraged ETH staking on DeFi Saver\nToday, we are excited to introduce our new dedicated dashboard for aÂ 1-click leveraged ETH staking!\nYou can now seamlessly compare staking yields between various liquid staking derivatives across lending protocols (and networks), all in one place.\n\nThe new leveraged ETH staking dashboard is available here:\napp.defisaver.com/recipes/leveraged-staking\nCurrently available options cover (w)stETH, cbETH, and rETH, and so far weâ€™ve included nine unique 1-tx recipes, utilising protocols such as Aave v2 &amp; v3, Compound v3, and Morpho-Aave-v2.\nThere are also a couple of options we have in the pipeline including Morpho-Aave-v3, and other LSTs on L2s. ğŸ‘€\nWith the LST and underlying protocol of your choosing, youâ€™d be able to increase your ETH staking exposure up to 10x in a single transaction, while also effectively increasing the yield youâ€™re earning.\nLeverage staking strategy explained\nThe opportunity for this strategy lies in the spread between the staking yield that LSD tokens provide, and the ETH borrow rates on different lending protocols.\nHere is an example of a 1-tx recipe for opening a 6x leverage wstETH position on Aave v3:\n\nThe outcome of the recipe would be an Aave v3 position with 60 wstETH collateralised and 50 WETH borrowed.\nAssuming the staking yield is at 5%, the 10x leveraged staking APY distribution on Aave v3 (emode) &amp; Compound v3 would look like this.\n\nIf you are wondering what the potential risks involved in these leveraged staking strategies are, weâ€™ve previously discussed them in more details here (with a focus on stETH in Aave v2, though the same principles apply with all LSTs):\n\nRisk analysis of leveraged stETH/ETH strategy.\n\nBorrow rates go up\nLido validators (big) slashing event\nLiquidation hunting by whales\nCurve stETH/ETH pool (dis)balance (depeg)\nSC risks (including every dapp that has onboarded stETH)\n\nExplanation of each pointğŸ‘‡.\nâ€” definikola.eth (@definikola)Â April 15, 2022\n\nShifting between different leveraged staking options\nIn case better opportunities with higher APY arise, users can shift their entire positions (both collateral &amp; debt) to the protocol of their choice using ourÂ Loan ShifterÂ dashboard in one go.\n\nThough note that weâ€™d always recommend trying this in simulation first, just to make sure the outcomes are exactly what you want them to be and that your position entering the target protocol isnâ€™t affecting the potential APY noticeably.\nNew DeFi Saver Stats Page\nIf you are curious about the usage of lev-staking recipes so far (or activity on DFS in general), we recommend checking our recently released stats page at:Â stats.defisaver.com/!\n\nToday weâ€™re very glad to introduce DFS Stats.ğŸ“Š\nOur goal with DFS Stats is to provide better insights into user activity and automation usage, as well as smart contract changes throughout DeFi Saver.\nCheck it out today atÂ t.co/loT0FQaLTLÂ - or read on for more details.ğŸ§µÂ pic.twitter.com/SWC7JnEp4y\nâ€” DeFi Saver (@DeFiSaver)Â February 28, 2023\n\nAnyone can now get a quicker overview of user transactions, including automated adjustments and custom recipes being executed on DeFi Saver. This also includes these leveraged staking actions, that you can find by selecting the â€˜Stakingâ€™ filter.\n\nWe hope that the leveraged staking dashboard, all the custom recipes and the new stats portal are useful tools that help you navigate and make best use of these new strategies.\nAs always, feel free to join us in theÂ DeFi Saver discordÂ where weâ€™d love to hear all your comments, feedback and suggestions, and youâ€™ll always find us available for any questions or assistance needed.\nHappy Shanghai, everybody!"},"DeFi/Leveraged-Lending-DeFi-Strategy":{"slug":"DeFi/Leveraged-Lending-DeFi-Strategy","filePath":"DeFi/Leveraged Lending DeFi Strategy.md","title":"Leveraged Lending DeFi Strategy","links":[],"tags":[],"content":"Notes\nHelpful article for understanding how APY is calculated, but not necessarily what leveraged lending is.\nSource: simpleswap.io/learn/analytics/strategies/leveraged-lending-defi-strategy\nKey Insights\n\nLeveraged lending allows traders to maximize profits by using crypto assets as collateral toÂ borrow extra capitalÂ and open leveraged positions.\nBy maintaining a loan-to-value ratio and repaying borrowed stablecoins from DeFi lending protocols, traders canÂ increase their overall contributionÂ and achieve amplified returns.\nFollowing the steps of depositing collateral, borrowing, and repaying leveraged loans enables traders toÂ calculate a leveraged annual percentage yieldÂ for their DeFi strategies that significantly exceeds regular deposit APY.\n\nLeveraged lendingÂ is an effective strategy widely used in decentralized finance and the crypto space to maximize the profits using assets.\nWhat is Leveraged Lending\nInÂ DeFi,** leveraged lending involves using crypto assets as collateral to borrow stablecoins or another crypto.**\nBy depositing crypto tokens in a smart contract, tradersÂ can take outÂ leveraged loansÂ in various digital assetsÂ up to a certain percentage of the collateral amount.Â For example, depositing 1000 in Ethereum can allow for aÂ [crypto loan](simpleswap.io/blog/crypto-loans)Â of 500 in stablecoins DAI.Â This capital can then be used to open leveraged positions aiming to earn higher yields throughÂ DeFi strategiesÂ likeÂ yield farming.\nIf the value of deposited collateral drops due to market volatility, theÂ positions face liquidation to maintain the loanâ€™s safety. However, the leverage also multiplies any gains, so profits can outpace losses when markets move in the traderâ€™s favor. Carefully managing liquidation levels mitigates risks.\nFor DeFi users,Â leveraged lendingÂ provides accessibility to leverageÂ without centralized intermediaries. Traders profit from premium interest on loans while lenders earn stable rates of return. By automating the process through code, leveraged positionsÂ can be maintained cost-effectively at any time.\nDeposit Collateral inÂ DeFi strategies\nDeposit a certain amount of your assets into a selectedÂ lending protocol, which weâ€™ll callÂ Deposit.\nSuppose you put $3,000 into the Deposit section. The pool provides an attractiveÂ Annual Percentage Yield (APY)Â of 15%, including a 5% base income from your deposit and a 10% reward.\nIn lending protocols and DeFi,Â RewardsÂ are additional earnings users receive for participating in the system. They usually come from various sources.\nCrypto Lending Rewards\n\nProtocol Tokens\n\nSome lending protocols issue their tokens as an additional reward, representing a stake in the protocol or providing governance rights.\n\nLiquidity and Staking\n\nSome protocols incentivize participants for providing liquidity orÂ staking tokens, rewarding them withÂ additional tokensÂ for engaging in these activities.\nBesides, blockchains may provide rewards for using aÂ lending protocolÂ on their network. In the context of lending protocols and DeFi, these rewards may include cryptocurrencies distributed to participantsÂ as a thank-youÂ for active participation and interaction with the protocol on aÂ specific blockchain network.\nThus, Rewards in lending protocols serve as a mechanism toÂ stimulate user participationÂ and generate additional income for their contribution to the system.\nBorrowing Against Collateral\nAfter depositing collateral into Deposit, you have the option to borrow a portion of the funds using theÂ maximum available Loan-to-value ratio. In this example, the LTV is 80%, which allows you to borrow $2,400 from your Deposit investment.\nNow, the loanâ€™s APY is -8%, meaning you are obligated to pay 8% interest on the borrowed amount. However, you also earn a 12% APY as a reward for taking out theÂ leveraged loan.\nThus, theÂ net effect is a 4%Â APY on the loan (12% - 8%).\nRepayment of the Leveraged Loan Amount\nNext, you repay the borrowed $2,400 back into Deposit, further increasing your overall contribution to the pool.\nTotal Contribution: 3,000 (initial deposit) + 2,400 (borrowed amount) = $5,400\nThe main advantage ofÂ leveraged lendingÂ is that it allows you to significantly increase your profits compared to a regular deposit. In this example, your leveraged position in Deposit leads to a higher APY.\nYour APY for providing assets is 15%, and you provided assets 1.8 times more than your initial deposit. Meanwhile, your APY for the loan is 4%, as explained earlier.\nHow to Calculate Leveraged APY\nBelow is a leveraged APY formula.\n(APY for providing assets * Total Contribution) + (APY for the loan * Total Borrowed Amount)\nLeveraged APYÂ = (15% * 1.8) + (4% * 2.4) = 27% + 9.6% = 36.6%\nThus, by following these steps and maintaining leverage, you can achieve aÂ 36.6% APY on your assets, which is twice the APY for providing assets at 15%. You can continue to increase leverage by repeating these steps, further enhancing your profits.\nBase % + METIS Reward Tokens Protocols\nBelow are some examples of lending protocols that can be used in theÂ Leveraged LendingÂ strategy.\n\n** Aave**\n\nTheÂ AaveÂ protocolÂ is an Ethereum-based lending protocol that provides liquidity and borrowing facilities for various cryptocurrencies. Users canÂ use their assets as collateral and earn interest.\nWhat isÂ Aave crypto?Â Aave cryptocurrency refers to the LEND token, which is used for governance, staking rewards, and payment of platform fees on theÂ Aave protocol. The LEND token allows users to participate in the Aave system by voting on proposals and earning additional rewards.\nAave allows users to borrow against their cryptocurrency holdingsÂ without having to liquidate them. TheÂ Aave protocolÂ also enablesÂ flash loans, which are uncollateralized loans that must be repaid within the same blockchain transaction.\nAaveÂ appliesÂ variable interestÂ rates using a supply and demand algorithmic model.Â AaveÂ uses a native LEND token for governance, staking rewards, and payment of platform fees.\n\n\nVenus\n\nVenusÂ is aÂ lending protocolÂ on the Binance Smart Chain that allows users toÂ provide liquidity and earn interest for using their assets. The protocol has its nativeÂ Venus crypto, but users can earn yield by supplying BEP2, BEP8, and BEP20 tokens into Venus liquidity pools. TheÂ VenusÂ protocolÂ alsoÂ supports lending with collateralÂ and additional options for leverage.\nThe interest rates forÂ lending and borrowing are determined algorithmicallyÂ by theÂ Venus protocolÂ based on supply and demand. Users can access leveraged yield farming opportunities by borrowing assets to increase their positions in Venus liquidity pools.\n\n\nJustLend\n\nJustLendÂ is aÂ lending protocolÂ offering users the ability to provide liquidity, collateralized lending, and additional leverage options.\n\nBorrowers can obtain loans by putting upÂ TRX, JST, or other TRC20 tokens as collateral.Â JustLendÂ introducesÂ credit delegation, allowing any TRON user to delegate their credit limit to a borrower and earn fees on interest payments. The protocol alsoÂ features fast settlement timesÂ andÂ low feesÂ compared to Ethereum-based lending platforms."},"DeFi/Leveraged-Long-Position-on-Aave-Tutorial":{"slug":"DeFi/Leveraged-Long-Position-on-Aave-Tutorial","filePath":"DeFi/Leveraged Long Position on Aave Tutorial.md","title":"Leveraged Long Position on Aave Tutorial","links":[],"tags":[],"content":"Source: medium.com/furucombo/leveraged-long-position-tutorial-6161c9718812\n\nThis tutorial will help you to create a leveraged position onÂ Furucombo. This combination will allow you to increase your leveraged position on a lending protocol, such as Aave, to increase your long position on the market. If you are more of a visual learner, you can use ourÂ video tutorial for long positionsÂ instead.\nWhat is a Leveraged Position?\nA leveraged position is one that increases your market exposure over and above the original asset value. For example, a 2x leverage is one that has 2x more exposure than your base position. This is possible with Aave because you can borrow funds from your collateral. For example, if you have ETH as collateral, you can borrow a stable coin, such as USDC, and use that to purchase more ETH, therefore increasing your exposure to the market higher than would otherwise be possible with your original funds amount.\nHow to Create a Leveraged Long Position?\n==A leveraged long position can be created by borrowing a stable coin, and swapping that to the asset you wish to go long on (an asset you expect to increase in value). For example, if you deposit 1000 in ETH into Aave, you can borrow 800 in USDC (a stable token), and swap that USDC to ETH, creating a market exposure of $1800 in ETH. If ETH increases in value, you will have to pay back less of the value that you used to borrow from the USDC because the ETH is a higher value.\nAlways be aware that leveraged positions are subject to liquidation risk if the collateral falls below the loan-to-value ratio of the amount borrowed. The risk in this case would come from a decrease in the value of ETH (because there are less funds to pay back the borrowed funds).\nSteps to set up a New Leveraged Long Position:\n\nConnect your wallet, and select the network of your choice on the top right ofÂ create mode on Furucombo. Once connected, click the cube icon in the center of the page to get started. The first step is to make a position on Aave, and to decide which asset to use as collateral to go long on. When you have decided on which asset to deposit, simply add the â€˜Depositâ€™ cube under Aave, and make a deposit in the asset you wish to use as collateral. If you wish to go long on Ethereum, deposit Ethereum.\n\n\n\nNext we will use a â€˜Return Fundsâ€™ cube to add the aToken to the contract in order to borrow an asset in one transaction. In this example, we will add the aEthWETH token in our return funds cube. If you deposit a different asset, simply carry over the aToken and the amount into the return funds cube.\n\n\n\nNow we can borrow a stable token from Aave. We will borrow USDC in this case, but you can choose any stable token thatâ€™s available on the lending protocol of your choice. At the time of writing, ETH is worth approximately $1750, so we will borrow 75% of our LTV, therefore we will borrow 1312.50 USDC.\n\n\n\nNext we will swap the borrowed USDC to ETH to increase our leverage or exposure to the ETH asset.\n\n\n\nOnce you are happy with the numbers, you can hit â€˜approveâ€™ &amp; â€˜sendâ€™ at the bottom of the page. You have now created a leveraged position using Furucombo.\n\nIn the above example, we have made a deposit of 1ETH, borrowed USDC, and swapped that to ETH, creating a position of 1.746ETH from a deposit of 1ETH. This means the leverage created in this example is 1.746x, or 174.6%. This means that any 1% increase in Ethereum, will equal a 1.746% increase in value for the leveraged user. This is a powerful way to get additional exposure to the market. ==Also be aware of the risks of liquidation. If the value of the collateral decreases, you may be subject to liquidation risk. If that risk occurs, you can add more collateral, or perform our de-leverage strategy to reduce your market risk.\nSteps to Adjust your Leveraged Position with a Flash Loan\nYou can also use the flash loan feature to add a collateral position, and borrow an asset with that collateral to increase your exposure to the market. For example, if you have 1000 in collateral on Aave, and youâ€™ve borrowed 600, or have a debt ratio of 60%, you can use a flash loan to increase your collateral position, and use some of the extra debt you can still incur to pay back the flash loan. Using the aforementioned numbers, letâ€™s assume you want to increase your position by 1000. Assuming an ETH price of 1750, to increase the position by 1000, we need to borrow 800 (as we will borrow the other $200 from Aave in order to make up the difference) in the form of a flash loan.\n\nInsert a â€˜Flashloanâ€™ cube in the amount you wish to increase your exposure by. Based on the above example, we will take a flash loan for 0.457ETH (or $800 value)\n\n\n\nNext we will perform the same steps as mentioned above. Simply add the â€˜Depositâ€™ cube under Aave, and make a deposit in the asset you wish to use as collateral, in this case we are using WETH (note: ETH should be wrapped ahead of time using the utility cube â€˜WETHâ€™). Ensure the cubes are above the bottom flash loan cube.\n\n\n\nNow we will use a â€˜Return Fundsâ€™ cube to add the aToken to the contract in order to borrow an asset in one transaction. In this example, we will add the aEthWETH token in our return funds cube. If you deposit a different asset, simply carry over the aToken and the amount into the return funds cube.\n\n\n\nNow we can borrow a stable token from Aave. We will borrow USDC in this case, but you can choose any stable token thatâ€™s available on the lending protocol of your choice. Because we made a deposit of 800 in value, we can borrow up to approximately 80% of the value of that, which would be 640.\n\nThe other value will be made up from the extra debt we can take on from Aave, which will increase our loan-to-value ratio (thus increasing our liquidation risk, or our leverage to the market). In this example, we will borrow at least enough to pay back the flash loan. So we will borrow $850USDC, but how much you borrow will depend on your risk tolerance, collateralization ratio, etc.\n\n\nNext we will swap the borrowed USDC to ETH to increase our leverage or exposure to the ETH asset.\n\n\n\nOnce you are happy with the numbers, you can hit â€˜approveâ€™ &amp; â€˜sendâ€™ at the bottom of the page. You have now adjusted your leveraged position with a flash loan using Furucombo.\n\nTo learn more about our other position management features, click the following tutorials:\n\nLeveraged Short Position\nCollateral Swap\nDebt Swap\nDe-Leverage Position\n"},"DeFi/Your-Guide-to-the-Collateralized-Stablecoin-Landscape":{"slug":"DeFi/Your-Guide-to-the-Collateralized-Stablecoin-Landscape","filePath":"DeFi/Your Guide to the Collateralized Stablecoin Landscape.md","title":"Your Guide to the Collateralized Stablecoin Landscape","links":[],"tags":[],"content":"Source:\nmembers.delphidigital.io/reports/your-guide-to-the-collateralized-stablecoin-landscape\nNotes\nI started reading this after I Googled Tim&#039;s 1st strategy: Safest: Deposit collateral, borrow stablecoin, hold or use stablecoin for LP to earn â€œsafeâ€ yield. \nThe most important thing for a** stablecoin,** what the market cares the most about, is that it keeps its peg. Thatâ€™s why centralized stablecoins have thrived â€” they are backed by cash and US treasuries. Eg, USDC and USDT. Decentralized stablecoins, like Frax, Synthetix, Dai, are backed by more risky financial assets. But amongst the decentralized ones, the stablecoins that have the most future potential are ones that overcollateralized.\nThe safest reserves for centralized stablecoins is liquid assets in a bank account. USDT is known for having backing in commercial paper, corporate bonds, and other relatively riskier assets. These reserves resemble a traditional money market fund â€” an investment entity that invests in short-term debt instruments. TL;DR Tether uses collateral put in its protocol to purchase short term debt such as commercial paper, municipal bonds, and corporate bonds. In the event of a market panic when investors want to redeem their funds (what is redemption?) all at once, the protocol would need to give them their collateral back (is this right?) so they would need to sell short-term debt (is this right?) which means the short-term debt market would need to have liquidity.\nIntroduction\nIf youâ€™re invested in crypto assets, you have probably held stablecoins in your portfolio at some point in time. Chances are, you have also heard of several high profile stablecoin depegging events, leaving unsuspecting holders unable to redeem their stablecoins at par value.\nStablecoins have become the backbone of DeFi, with nearly $150B in cumulative market cap. Of this, over 97% are in collateralized stablecoins while the remaining portion is made up of their undercollateralized counterparts. As the name suggests, fully collateralized stablecoins are backed by some sort of collateral â€“ either fiat-collateral or crypto-collateral. Undercollateralized stablecoins, also known as algorithmic stablecoins, are either not backed by collateral at all or partially backed. ==FRAX is a notable example of a partially backed stablecoin, typically using financial incentives to encourage the market to keep the stablecoin at its peg. UST was a notable example of an uncollateralized stablecoin, and subsequently the risks of such a design.\n\nStablecoins are useful for market participants looking to avoid price volatility. Theyâ€™ve also taken on the mantle of being the main medium of exchange when moving between different assets or transferring value from one entity to another. A reliable stablecoin is one that is able to hold its peg to a certain value â€“ the most popular of which is the U.S. Dollar (USD). In this report, we explore some of the top collateralized USD stablecoins to understand the risks and benefits holders inherit while owning each of them.\nCentralized Stablecoins\n\nCentralized stablecoins are IOUs for assets attached to a legal entity. Those assets could be cash reserves in a bank account (ideal case) or other liquid assets. A key difference between centralized stablecoins and their decentralized counterparts is the custodial nature of centralized stablecoins. Notably, holders of centralized stablecoins bear counterparty risk and censorship risk. The former deals with risks associated with bankruptcy or mismanagement of collateral by the issuer, while the latter deals with censorship by issuers or governments who can coerce the issuer.\nAnother point of risk with fiat-backed coins is that issuers have disproportionate commanding power when it comes to legitimizing a blockchain fork.Â ==For example, imagine if USDC had existed on Ethereum at the same time as the occurrence of the DAO hack. Only 1 of the USDCs on either Ethereum Classic or Ethereum would be redeemable at par by Circle. Whichever Circle chooses to support is therefore critical as most protocols and developers will follow suit. This centralization of power in DeFi poses risks that reach far outside the purview of the stable asset.==\nCurrently, centralized stablecoins make up over 90% of stablecoin TVL; USDT, USDC, and BUSD consistently take the top three spots by market capitalization. We briefly explain the collateral backing and idiosyncrasies of notable coins below:\nUSDT (Tether)\nUSDT is the largest stablecoin by market capitalization issued by Tether Ltd, a company with close ties to crypto exchange Bitfinex. It experienced a mild depeg earlier this year as investors questioned Tetherâ€™s backing in the wake of Terraâ€™s collapse. The market got scared because USDT is well-documented to hold large amounts of its backing in commercial paper, corporate bonds, and other relatively riskier assetsâ€“ at least compared to its peers.\nAccording to their latest quarterly assurance report, theyâ€™ve significantly reduced their exposure to commercial paper and certificates of deposits over the last year, while beefing up their U.S. Treasury Bill holdings to almost 50%.\n\nAlthough theyâ€™ve committed to bringing down commercial paper holdings to zero, the current USDT collateral make-up still closely resembles a traditional money market fund. For the uninitiated, a money market fund is an investment entity that invests in liquid, short-term debt instruments. Money market funds are typically a safe haven for investors to part idle cash in, but may fall below par value during periods of market dislocation or panic when investors try to redeem funds all at once. And thatâ€™s something a stablecoin must take into consideration, given redemptions occur during periods of panic.\nDuring the Covid crisis in March 2020, money market funds experiencedÂ large outflowsÂ asÂ  short-term funding markets dried up. ==To quote aÂ Blackrock report, â€œfor close to two weeks there was no bid in the secondary market in the U.S. for much of the commercial paper, bank certificates of deposits, or municipal debt.â€== And these are instruments that make up a significant portion of Tetherâ€™s backing. However, Tether is not bound by theÂ same regulationsÂ traditional MMFs adhere to. Some of these include minimum liquidity levels, credit quality standards and portfolio transparency. This means Tether has somewhat free reign to invest USDT collateral assets as they see fit. Indeed, fair enough, since Tether is not actually a money market fund. However, many investors have been put off given they have only published attestations of their portfolio holdings and are yet to release a comprehensive audit.\nUSDC (Circle)\nAs mentioned earlier, the recent UST unravel caused some panic within USDT markets, causing aÂ slight depegÂ andÂ capital outflowsÂ of 9% within the same week. USDC, the stablecoin issued by Circle, has arguably benefitted from lack of confidence in certain stablecoins, growing their market share from ~25% to ~36% since the beginning of the year.\nUSDC is backed by USD denominated cash as well as short-dated U.S. Treasuries â€“ a far lower risk profile than the aforementioned Tether treasury. It has undergone annual audits since launch and provides monthly attestations of its balance sheet (compared to the less frequent quarterly attestation from Tether) verified by an independent auditor. Beyond that, they also provide weekly data on their USDC reservesÂ here, though these figures are not verified by a third party.\nOverall, the lack of fear mongering over USDC indicates market participants seem to trust it more than USDT. However, USDTâ€™s prominence on CEXs like Binance as the de facto quote asset on most trading pairs has given it an edge that is tough to usurp.\nBUSD (Binance)\nBUSD, or Binance USD, is a stablecoin developed in a partnership between Binance and Paxos. Its latest attestation shows that the collateral backing of BUSD is entirely in liquid dollars and U.S. Treasuries. Similar to USDC, Paxos has engaged an independent third party to provide monthly attestations of BUSDâ€™s reserve accounts.\nAlthough all of its reserves are currently in cash and treasuries, Paxos has no obligation to leave the BUSD reserves in those instruments. Its website states that its reserves (can be) held in either or both: (i) fiat cash in dedicated omnibus accounts at insured U.S. banks and/or (ii) U.S. Treasury bills (including through repurchase agreements and/or money-market funds invested in U.S. Treasury bills). In reality, an issuer can unilaterally change the make-up of the reserves and holders will only find out when the monthly attestation report is out.\nTUSD (Trust Token)\nTrueUSD is a stablecoin issued by Trust Token. Interestingly Trust Token appears to have the most frequent attestations of the lot, in the sense that it provides real-time updates. The on-chain live audit that can be downloaded by the publicÂ here. However the attestation report doesnâ€™t detail the breakdown of cash and cash equivalents.\nFLEXUSD (Coinflex)\nAnother unique stablecoin in this category is flexUSD, which is crypto-collateralized stablecoin backed by USDC. It is marketed as an interest bearing stablecoin that pays interest directly into their wallet of choice. Users who would like to hold flexUSD and earn interest may mint flexUSD by exchanging USDC for the stablecoin on the Coinflex website. Since flexUSD is backed by USDC, holders of flexUSD bear the custodial risk associated with Coinflex and inherit custodial risk associated with USDC.\n\nOn Jun. 23, Coinflex halted withdrawals from the exchange citing â€œextreme market conditions &amp; continued uncertainty involving a counterpartyâ€. A few days later, they revealed that one of their customers had failed to repay a $47M debt, resulting in liquidity issues for the exchange.\nThis sent the flexUSD stablecoin tumbling on fears that it was no longer fully backed. This event is another sobering reminder that when a stablecoin inherits issuer risk, it inherits the risk of the issuerâ€™s other business functions and dealings. Worse still, in the absence of transparency and proper audits and disclosures, assets in the reserve could be mismanaged or used for undisclosed activities unbeknownst to token holders.\nTo wrap up centralized stablecoins, we summarize the characteristics of the largest centralized stablecoins by market capitalization below.\n\nDecentralized Stablecoins\nDecentralized stablecoins are created to be a censorship-resistant, transparent alternative to the centralized category. They are typically crypto-collateral backed and have economic mechanisms which incentivize arbitrageurs to maintain the price around $1. Below, we will weigh out the risks and suitability of a few popular decentralized stablecoins.\nMakerDAO (DAI)\nMakerDAO is a stalwart among DeFi protocols and is currently the largest by Total Value Locked. Its native stablecoin, DAI, is created using a Collateralized Debt Position (CDP) model, and it has the highest market capitalization out of all stablecoins with on-chain custody.\nFor those new to MakerDAO, users mint DAI by depositing collateral assets into Maker vaults. Vaults have to be overcollateralized; the value of the collateral has to exceed 150% of the DAI value minted. â€œStability feesâ€ act as the borrowing rate for DAI and are charged directly to the vault owner. For a detailed read into Makerâ€™s design, you can refer to our past reportsÂ hereÂ andÂ here.\n\nInitially, DAI was backed by a single collateral asset â€“ ETH. Later, Multi Collateral DAI (MCD) was launched, allowing multiple types of crypto-collateral to be used to mint DAI. The backing of DAI has evolved dramatically over time as we see in the graph below. Maker is still making efforts to diversify its collateral base, going so far as to incorporate Real World Assets (RWA) as part of its collateral base. ==More recently, theyâ€™veÂ approvedÂ a $100M stablecoin vault for Huntingdon Valley Bank, which will use off-chain loans as collateral to mint DAI.==\nA diversified collateral make-up (as opposed to 100% ETH) implies lower systematic or asset-specific risk. ==However, one of the few criticisms of the DAI stablecoin is that its current collateral backing is comprised primarily of centralized stablecoins. Stablecoins came into prominence as collateral backing as a consequence of market turmoil. As was evident in May and Nov. 2021, crypto participants quickly sought refuge in stablecoins, with each of the events boosting DAI backing by 3.5B and 3B, respectively.==\nThe advantages of high stablecoin backing are higher stability, which is exceptionally crucial during periods of market stress (see:Â Black Monday). However, since DAI inherits all the risks of its collateral backing, it inadvertently inherits all the centralization and custodial risk of USDC. Governance proposals have raised the PSM-USDC-A debt ceiling, which further increases DAIâ€™s USDC exposure.\n\nTaking external LP tokens used as collateral into account brings up 2 interesting corollaries. For the vast majority of LP tokens in Maker vaults, the underlying tokens that make up the LP token backing are essentially USDC and DAI. This means: 1) Maker is using more DAI to mint DAI and; 2) Makerâ€™s USDC exposure is understated if one does not take the underlying LP assets into account.\nTaking into account underlying LP assets brings Makerâ€™s USDC exposure up to 66% (from 57%) and centralized stable exposure to 74% (after including USDP).Â Something interesting to note is that DAIâ€™s collateral backing resembles a â€œsafer centralized stablecoinâ€ compared to USDT since 74% is indirectly held in cash and treasuries, while USDT has less than 60% in those same assets. Another revelation is that 12% of DAI backing is in DAI, which could have severe knock-on effects if DAI depegs extensively, although we believe this to be fairly unlikely.Â \nThis is an implication of integrating Gelato Networkâ€™s Uniswap v3 LP tokens. Since the integration last September, DAIâ€™s backing via LP shares has skyrocketed. The Gelato integration enables DAI holders to earn up to 100x the fees on Uniswap v3â€™s USDC / DAI pool by leveraging their initial liquidity position. All of this is done in an automated fashion. Consequently, the USDC and DAI backing of Maker has increased as a result of the easy leverage.\nAn alternative to DAI for those uncomfortable with large amounts of centralized stable exposure is LUSD, which will be covered in another section. Weâ€™d also like to make an honorable mention forÂ RAI.\nAbracadabra (MIM)\nAbracadabra is a CDP-based stablecoin platform, similar to DAI, that uses Kashi â€“ the isolated lending market of Sushiswap. Their stablecoin, MIM, is backed by multiple assets. Users can deposit assets that range from typical blue chips like WBTC and ETH to more long-tail assets like interest-bearing tokens and SHIB. Compared to DAI, the collateral make-up of MIM is more susceptible to market risk, with just 20% of its backing in stablecoins. Strikingly, the largest asset backing MIM is FTT (FTXâ€™s token), with ~34% of Abracadabraâ€™s total backing. Naturally, this carries significant risk.\n\nBefore the Terra collapse, UST accounted for 40% of MIM collateral, with a ~40% share due to its â€œdegen boxâ€ strategy which allowed users to lever up on UST to earn Anchorâ€™s yield. T==he protocol managed to liquidate 1.3B UST but incurred bad debt to the tune of 12M==.Â Fortunately, this was not enough to render the protocol insolvent.\nNevertheless, the backlash from the bad debt resulted in MIM depegging briefly. Consequently, this ordeal serves as a warning that overcollateralized stablecoins are still susceptible to depegs, especially when they are backed primarily by risky collateral (even Aave did not allow UST to be listed as collateral).\nLiquity (LUSD)\nLUSD is the stablecoin issued by Liquity, and it has the second-highest market capitalization amongst decentralized stablecoins. LUSD is solely backed by ETH, using a CDP model that makes Liquity the only decentralized borrowing protocol that offers a single collateral asset. Furthermore, it offers a 110% collateral ratio for ETH, which is the most competitive collateralization rate on the market.\nLiquity vastly differs from its competitors in having no human governance. System parameters such as supported collateral assets, collateral ratios, and fees are governed algorithmically. Minimizing human interference arguably makes Liquity the most decentralized stablecoin protocol and the least susceptible to governance capture. At the same time, it also makes the protocol the least flexible and growth-oriented of the lot. While appeasing users who prioritize protocol safety, this approach ultimately hinders community participation and LUSD adoption.\nInterest-free loans benefit long-term borrowers who only pay a fee whenever LUSD is borrowed and redeemed. In contrast, other protocols utilize interest-rate loans which appease short-term borrowers but accrue significant fees in the long term.\nAs mentioned earlier, ETH is the only collateral asset used to mint LUSD. This philosophy stems from ETH being the most suitable asset under Liquityâ€™s risk minimization framework. In theory, a single asset collateral introduces asset-specific risk. However, ETH is arguably the most decentralized and liquid collateral asset available.\nDAIâ€™s indirect centralization risk has been enough for Synthetix to begin unwinding their DAI/sUSD wrapper for other alternatives. In proposal SIP-189, the LUSD/sUSD wrapper was introduced to prevent the possibility of SNX stakers being susceptible to a DAI depegging event stemming from USDC censoring.\n\nNear Liquityâ€™s inception, there was concern regarding LUSDâ€™s use case as almost all LUSD resided within the Stability Pool. Unsurprisingly, this resulted in illiquidity in DEXs and lending markets which made LUSD a decentralized stablecoin with low utility. However, today, the Stability Pool makes up 46% of all LUSD deposits, down from 73% in April. The reasons are two-fold. The first reason is Synthetix introducing usage by creating a LUSD/sUSD Wrapper on Optimism (1 sUSD can be minted for 1 LUSD and vice versa).\nBut also, to incentivize wrapping and create deeper liquidity in DEXs, yield farming opportunities were introduced. This resulted in Optimism amassing 14% of all LUSD, up 56% from April.\nSecondly, the Fei PSM acted as yet another sinkhole, amassing 11% of all LUSD. LUSD within the Stability Pool collapsed and hit an all-time low of 21%. This was short-lived as market turmoil in mid-June resulted in cascading liquidations within ETH-backed collateral positions. Accounting for additional LQTY rewards, liquidation rewards for Stability Pool depositors reached an all-time high of 750% APR as the pool absorbed LUSD with haste. This is evident in the above chart from the â€œVâ€ shaped reversal in mid-June.\nFurthermore, high concentrations of LUSD in the Stability Pool are not indicative of users mostly borrowing to farm LQTY and liquidation rewards. A closer analysis of the Stability Pool shines light on the different LUSD users.\n\nThere are currently 133 users who borrowed and deposited LUSD into the Stability Pool which only amounted to 11% of all users. However, 60% of all deposited LUSD were not from users who borrowed LUSD. This suggests that over 55M LUSD was publicly traded on exchanges, which is only possible through sufficient liquidity pools and demand. Furthermore, those who just borrowed made up 32% of all users but were responsible for 68% of LUSD supply. Meaning there is strong demand for the 116M LUSD circulating or being utilized elsewhere.\n==Vesta is a fork of Liquity built on Arbitrum, an L2 Optimistic Rollup. Vesta, however, has made major changes that defy Liquityâ€™s philosophy of decentralization and risk minimization. These changes include giving governance control over enabling multi-collateral asset types for minting VST (the decentralized stablecoin), fees from minting, liquidation penalties, and token incentives.\nIn Vesta, ETH is the second most utilized asset to mint VST, representing 17% of total VST minted. The largest collateral asset, quite surprisingly, is gOHM with 69% (nice) of total collateral backing.== OlympusDAO had initially provided 250K in OHM collateral to mint VST via their incubation program. But today, over 14M worth of gOHM collateral is locked with $3.6M VST minted.==\nUsing an asset like gOHM to back a stablecoin obviously carries far more risk. However, it will be interesting to keep tabs on Liquity and Vestaâ€™s growth side-by-side to see if the market validates Liquityâ€™s minimalist approach or Vestaâ€™s approach.\nAlchemix (alUSD)\n==alUSD is the stablecoin minted by Alchemix, a protocol pioneering self-repaying loans.Collateral assets in Alchemix are largely yield bearing tokens. Users deposit assets like DAI as collateral, and mint up to 50% of the collateral value in the alUSD stablecoin. On the backend, the protocol delegates the DAI to interest yielding vaults like Yearn vaults. The debtÂ  is â€œself-repayingâ€ as the yield generated from the collateral is used to automatically pay down the userâ€™s loan.\nCompared to the other protocols, the collateralization ratio to mint alUSD with ETH Is relatively high at 200%, versus Makerâ€™s 130-150%, Liquityâ€™s 110%, and Abracabraâ€™s 111%. You can look at this as the price a user pays for no stability fees, borrowing costs, and no liquidations. Alchemix has also enabled centralized stablecoins as collateral, but the USDT and USDC vault capacities are heavily underutilized, alluding again to the high collateralization ratio compared to its peers.\nAs mentioned earlier, Alchemix loans canâ€™t be liquidated. Importantly, however, itâ€™s not like that risk disappears â€“ itâ€™s just transformed into a new type of risk. Rather than users getting liquidated, that risk now appears in the alUSD peg. If the value of collateral tanks, so does the implied price of alUSD. This is somewhat minimized given Alchemix collateral is limited to stablecoins and various flavors of ETH (liquid ETH, stETH, and rETH). Users can also choose to use their collateral to pay down their loan at any point in time.\nSynthetix (sUSD)\nsUSD is a synthetic stablecoin issued by staking Synthetixâ€™s governance token, SNX. With a minimum collateralization ratio of 350%, the sUSD in existence is backed by a â€œglobal debt poolâ€ that is the counterparty to all trades on Synthetix. Unlike other collateralized stablecoins, borrowers with undercollateralized positions have a 24 hour window to save their collateral from liquidation. Furthermore, there is a 0.25% fee on burning and minting synthetic assets â€“ all of which go to SNX stakers.\nsUSD and other synthetic assets such as sBTC and sETH are pegged to their price using Chainlink and Uniswap v3 oracles. The advantages of synthetic assets over vanilla assets is the trader experience â€“ most notably, zero slippage. Mainly used in atomic swaps now, you can trade sUSD for another synthetic asset such as sETH or sBTC for the same dollar value minus fees. sUSD often acts as an intermediary asset in multi-asset trades to reduce slippage. Example: swapping DAI to BTC involves swapping DAI for sUSD, sUSD to sBTC with no slippage, and then sBTC to BTC. And all of this happens atomically, inside a single transaction.\nsUSD is one of the older decentralized stablecoins. However, its growth has been limited given the strict collateralization criteria. Additionally, minting sUSD is usually done by staking SNX and becoming a part of the protocolâ€™s global debt pool. While sUSD can be minted as a loan using ETH and LUSD collateral too, they account for just 15% of collateral in Synthetix.\nTo wrap up decentralized stablecoins, we summarize the characteristics of the largest decentralized stablecoins by market capitalization below.\n\nStability and Preference\nHow have collateralized stablecoins, both centralized and decentralized, fared in terms ofÂ  holding their peg? As a market fraught with volatility, stablecoins have proven their merit. We assess the price stability of the stablecoins on Ethereum by looking at how often theyâ€™ve deviated at least 0.01 from their 1 peg in the last month.\n\nGenerally speaking, and perhaps unsurprisingly, decentralized stablecoins experienced more deviations from the peg compared to centralized stablecoins. Those backed with more volatile collateral assets were more susceptible to going off-peg, compared to those with more stable assets backing it. DAI, for instance, rarely deviated. This is likely attributable to over 70% of its collateral backing consisting of centralized stablecoins. LUSD and MIM experienced the most deviations from peg, which is expected given their collateral backing is mostly volatile assets. LUSDâ€™s deviations more frequently occur to the upside as buyers look to take advantage of increased stability pool APRs, and borrowers buy LUSD to reduce their debt. This typically happens when the price of ETH falls rather quickly.\nDespite USDT trading as low as 0.95 post-Terra fallout, centralized stablecoins have been more successful at holding their peg on a consistent basis. When USDT sawÂ $7B of redemptions in 48H, the company successfully redeemed them at par, eventually giving arbitrageurs the confidence to step in and close the peg.\nIn terms of user concentration risk, we were surprised to find that for many stablecoins, the top two accounts/contracts hold more than 50% of the supply. These include GUSD, HUSD, alUSD, BUSD, MIM, LUSD (source: Etherscan). This concentration poses a risk to the respective stablecoin if the account/contract gets exploited.\nWhile even the more popular decentralized stablecoins seem to have centralization risk, user priorities are rooted in the true stability of the stablecoin â€“ and rightly so. From this perspective, DAI and others with significant centralized stablecoin backing seem to be making a clear trade-off in order to invigorate growth and usage.\nFrom a capital efficiency perspective, centralized stablecoins are the clear winner as they are typically backed 1:1 by the equivalent value of the backed asset. On the other hand, virtually all decentralized stablecoins that have weathered the storm are over-collateralized.\n\nUnsurprisingly, USDT and USDC are still the preferred medium of exchange on Ethereum. This is followed by DAI, which shouldnâ€™t come as much of a surprise. Between the first two, USDC comes out top in terms of total transaction value, unique users, and number of transactions. Average transaction size for USDC is almost 3 times higher than USDT, which indicates that it is more popular amongst â€œwhalesâ€. Again, this is likely attributable to their safer â€œcollateral backingâ€ which consists of US dollar cash or treasuries.\nConclusion\nOur analysis of the more widely used stablecoins suggests that the market currently prefers stability and liquidity over decentralization and capital efficiency.\nHowever, with stablecoin regulation on the horizon, it is likely a matter of time before centralized stablecoin providers start enforcing KYC/AML and other requirements â€“ a move we believe will catalyze the demand for truly decentralized money. After the failure of algorithmic stablecoins earlier this year, it seems like overcollateralized stables have a better chance of fulfilling that vision.\nStablecoins are undoubtedly a crucial and potent component of crypto infrastructure, as the de facto medium of exchange for crypto assets and â€œlegitimizerâ€ of chains in the event of forks. Having that much power concentrated in centralized entities susceptible to regulation and censorship is a significant risk for the entire crypto ecosystem.\n==With more than $130B of TVL in centralized stablecoins, the size of the pie is massive. Coincidentally, as we were writing this report, Aave announced plans to launch a new collateral-backed stablecoin, GHO. Once again, this is a sign that the stablecoin wars are just getting started as several of them start to reach escape velocity. Whether it is Aaveâ€™s GHO or an improved version of DAI or LUSD, any protocol that builds a truly decentralized and scalable stablecoin faces no small challenge, yet its success is both necessary and unparalleled"},"DeFi/Popular-Liquid-Staking-Tokens-on-Arbitrum/Popular-Liquid-Staking-Tokens-on-Arbitrum":{"slug":"DeFi/Popular-Liquid-Staking-Tokens-on-Arbitrum/Popular-Liquid-Staking-Tokens-on-Arbitrum","filePath":"DeFi/Popular Liquid Staking Tokens on Arbitrum/Popular Liquid Staking Tokens on Arbitrum.md","title":"Popular Liquid Staking Tokens on Arbitrum","links":[],"tags":[],"content":"Arbitrum is the leadingÂ Layer 2 (L2)Â network for Ethereum liquid staking tokens (LSTs), a type ofÂ derivativeÂ that unlocks liquidity in a previously illiquid Ethereum staking market.\nLSTs allow holders to use staked Ethereum across DeFi protocols while still earning yield on the underlying staked ETH. The Ethereum LST market boasts an impressive size of approximatelyÂ $28B.\nThis article will dive into three popular LSTs on Arbitrum: wstETH, rETH, and cbETH, with market capitalizations of approximatelyÂ 22B](coinmarketcap.com/currencies/steth/),Â [1.4B, andÂ $500M,Â respectively. Weâ€™ll cover their origins, token characteristics, adoption trends, and roadmaps of future planned developments.\nLido and wstETH\nOrigin Story\nLido, a liquid staking solution, was founded byÂ Konstantin Lomashuk,Â Vasiliy Shapovalov, andÂ Jordan Fish.\nLomashuk and Shapovalov are staking industry veterans. Before Lido, Lomashuk foundedÂ P2P Validator, a non-custodial staking service provider (now one of the main validators in Lidoâ€™s network), where Shapovalov was CTO. Lomashuk was also the CEO and co-founder ofÂ Satoshi Fund, a blockchain investment fund.\nFish, known in the crypto community as â€œCryptoCobainâ€ or â€œCobieâ€, is a cryptocurrency investor, trader, and influencer. With a background in computer science, he worked in roles from head of technology to head of growth in various cryptocurrency companies. He now co-hosts the crypto podcastÂ UpOnly: Chats with Crypto Experts, with Brian Krogsgard.\nIn December 2020, Lido launched on Ethereum mainnet, only a few weeks afterÂ Phase 0 of Ethereum 2.0Â commenced and Ethereum started to transition its consensus mechanism from proof-of-work to proof-of-stake. Although Ethereum is Lidoâ€™s primary focus, Lidoâ€™s LSTs are also available on Arbitrum, Polygon, Polkadot, Kusama, and Solana blockchains.\nToken Characteristics: wstETH\nLidoâ€™s staked ETH token is stETH, an ERC20 interest-bearing derivative token.Â  In order to make stETH compatible across DeFi applications and protocols, it isÂ wrappedÂ into the wstETH token. wstETH (and stETH) uses theÂ aTokenÂ model, one of two token models adopted by liquid staking tokens.\nThe aToken model was pioneered by the decentralized lending protocol Aave. Tokens that use this modelÂ rebaseÂ daily, meaning that the value of the token in a token holderâ€™s account is adjusted daily to reflect their share of staking rewards minus penalties.\nWhile the rebasable nature of aTokens enhances the UI/UX experience for token holders, it poses compatibility issues with DeFi dApps and protocols that require a constant balance mechanism.\nTo address compatibility issues, rebasable tokens are wrapped. This involves locking stETH, Lidoâ€™s staked ETH token,Â  in the wstETH contract, and minting wstETH based on aÂ share bookkeeping system. Unwrapping wstETH involves burning it, and unlocking the corresponding amount of stETH.\nAdoption and Growth Trends: stETH/wstETH\nLido is the leading solution for liquid staking on Ethereum, withÂ $24B in total-value-locked (TVL), capturingÂ 74%Â of the market share. With approximatelyÂ 9M ETHÂ deposited on the Lido network, LIDO captures a 31.92% share of all deposited ETH (29M ETHÂ in total is deposited on Ethereum).\n\nSource:Â Lido Finance Extended\nThe supply of stETH continues to grow, propelled by traders seeking a dependable and consistent source of yield. While ETH was once the preferred asset on lending platforms, stETH is now the leader. Its appeal lies in the ability to leverage stETH positions, offering more attractive returns compared to providing liquidity through stETH-ETH pairs on decentralized exchanges (DEXs).\nstETHâ€™s dominance in demand over ETH becomes evident in usage statistics following the Terra Luna collapse in May 2022. After the crash, the growth in new addresses utilizing ETH + WETH (wrapped ETH) slowed down. In contrast, demand for stETH + wstETH surged, increasing by 142%.\n\nSource:Â Glassnode Insights\nAlthough the lionâ€™s share of demand for stETH is on Ethereum mainnet, withÂ 97% of stETH collateral locked on the network, Arbitrum is the clear leader amongst Layer 2 networks, home to approximately 60k in stETH collateral â€“ twice the amount on Optimism.\nOn Arbitrum, wstETH has found significant adoption onÂ Aaveâ€™sÂ lending protocol, with 41% of collateral locked on Aave, followed by Radiant, Pendle, Balancer, and Silo.\n\nSource:Â Arbitrum ETH-LST Dominance\nRoadmap\nLido, with a market capitalization on Arbitrum of approximatelyÂ $287M, successfully leveraged itsÂ first-mover advantageÂ to establish a dominant position in the market.\nAddressing some of the primary concerns voiced by users, Lido has created aÂ planÂ to improve decentralization across its validator set and governance. This plan specifically aims to increase the diversity and size of its node operators, distribute the validator set across more geographies and jurisdictions, increase the robustness of its delegate set, and improve governance safeguards.\nRocket Pool and rETH\nOrigin Story\nIn December 2016, whileÂ Ethereum 2.0Â was still in development,Â David Rugendyke, a computer scientist and cryptocurrency miner, started planting the seeds for Rocket Pool, a decentralized base layer protocol for Ethereum staking. Drawing inspiration from Vitalikâ€™sÂ Mauve Paper, a paper that introduced Ethereum 2.0, David started to work on building Rocket Pool.\nIn May 2017, David released an Alpha version of Rocket Pool. Since Ethereum 2.0 was still in development, Rocket Pool Alpha was built on dummy Ethereum 2.0 contracts. In the protocolâ€™sÂ inaugural Medium article, David introduced the three primary components of Rocket Pool: smart contracts, smart nodes, and minipools, writing: â€œall three integrate with each other to provide a network that can automatically scale and load balance itself across multiple cloud hosting providers in any region of the world.â€\nThe RocketPool protocolÂ launched on Ethereum mainnetÂ on November 9, 2021, enabling users to participate in Ethereum staking by permissionlessly running an ETH node on Rocket Poolâ€™s network, or by participating in liquid staking with the protocolâ€™s native token, rETH.\nToken Characteristics: rETH\nUsers receiveÂ rETHÂ tokens when they deposit ETH into the Rocket Pool protocol.\nThe value of rETH represents the amount of ETH deposited into the Rocket Pool protocol plus staking rewards minus penalties. Its value is protected against node slashing and downtime by built-in insurance mechanisms inÂ RPL, the protocolâ€™s governance token.\nrETH is based on theÂ cTokenÂ model, pioneered byÂ Compound, an algorithmic autonomous interest rate protocol. As a non-rebasable token, its value does not update daily, therefore unlike aTokens (discussed previously), rETH does not need to be wrapped. It is readily compatible to be used across the DeFi ecosystem.\nAdoption and Growth: rETH\nWith a TVL ofÂ $2.85BÂ on Ethereum mainnet and deposits ofÂ 1.1M ETH, rETH captures an 8.81% market share in liquid staking, and 3.5% of total staked ETH.\nAlthough this is a markedly lower share than Lidoâ€™s 74%, rETH stands out with its unique differentiator of a strong focus on decentralization. Rocket Pool impressively hasÂ 3,486 node operators and 26,899 mini poolsÂ on its network.\nSince theÂ Atlas update, which scaled Rocket Pool by introducing 8 ETH Low Balance minipools, â€œLEB8â€, reducing the minimum requirement for running a Rocket Pool node from 16 ETH, the supply of rETH has more than quadrupled. Over the last 12 months, rETHâ€™s supply has increased from approximately 150k to 700k.\n\nSource:Â rETH supply vs. time\nInterestingly, in the first half of 2023, the supply of rETH grew three times faster than the supply of stETH!\n\nSource:Â LSTs Circulating Supply\nOn Ethereum, the Curve rETH/ETH pool and Balancer rETH/ETH pool provide theÂ main sources of liquidity backing rETHâ€™s stability, which has maintained its strong peg to ETH since withdrawals were enabled on Ethereum with theÂ Shanghai/CapellaÂ upgrade on April 12, 2023.\nrETHâ€™s adoption across DeFi is vast, supported by numerous platforms including Sommelier, Merkle, Convex Finance, Beefy, and Gamma, to name a few.\nRoadmap\nRocket Pool with a market capitalization on Arbitrum of approximatelyÂ $48M, operates with an ethos closely aligned with Ethereumâ€™s values, focusing on building a protocol that is non-custodial, permissionless, and trustless.\nIn Q2 2024, Rocket Pool plans to release its latest upgradeÂ SaturnÂ which will continue to scale the protocol by further reducing the cost to run a minipool and also by introducing Megapools. Megapools will allow for many validators to be controlled from a single smart contract, greatly reducing setup costs for validators in Rocket Poolâ€™s network.\nCoinbaseâ€™s cbETH\nOrigin Story\nCoinbase, the leading US cryptocurrency exchange founded byÂ Brian ArmstrongÂ in 2012, introduced its liquid staking token,Â cbETHÂ (Coinbase wrapped staked ETH), on August 25, 2022. Shortly after, on September 15, 2022, Ethereum completed its transition to Ethereum 2.0, known as The Merge, shifting from a proof-of-work to a proof-of-stake algorithm.\nCoinbase, as the largest centralized cryptocurrency exchange in the United States, has significant clout and reputation in the industry, specifically amongst retail and institutional users who prefer having a custodian for their assets.\ncbETH is one of the latest liquid staking tokens to hit the market. As Coinbase explains in theÂ cbETH whitepaper, it launched a liquid staking token out of necessity, referencing the risks to capital allocators of any one LST protocolÂ exceeding consensus thresholds. Coinbase highlights its rationale, writing â€œit is necessary for the liquid staking market to have strong, competing solutions with differentiated qualities.â€\ncbETH wasÂ first mintedÂ on June 12 2022 at a 1:1 ratio to staked ETH. Since then, this ratio has fluctuated, as explained in the next section.\nToken Characteristics: cbETH\ncbETHÂ represents staked ether on the Coinbase platform. When users stake Ethereum on Coinbase, they receive cbETH as a non-rebasing liquid derivative of their staked ETH.\nCoinbase runs aÂ provisioned set of validators. As a centralized provider, it retains custody of the keys that hold staked ether wrapped for cbETH. Additionally, cbETH is solely governed by Coinbase and does not have a DAO (decentralized autonomous organization) or similar governance mechanism.\ncbETH, like rETH, is based on theÂ cToken modelÂ which enables users to earn interest based on an exchange rate relative in value to the underlying asset (ETH). Tokens are minted or burned according to a floating conversion rate, which means that staking post-commission rewards, minus penalties, accrue passively.\nCoinbase made a design decision to use the cToken model, versus the aToken model.Â The tokenâ€™s whitepaperÂ explains that although aTokens allow for a more elegant UX, the tokenâ€™s value is maintained with a 1:1 mapping between the wrapped token and the underlying asset. They explain the cToken model is better for utility, efficiency, and composability since the token isÂ ERC-20Â compliant and doesnâ€™t need to be wrapped.\ncbETH Adoption and Growth\nWith a TVL ofÂ $542MÂ and Ethereum deposits ofÂ 198k, cbETH captures aÂ 1.59%Â market share in liquid staking tokens, and 0.6% of total staked ETH.\nâ€‹Interestingly, out of theÂ 1.3MÂ cbETH in supply, onlyÂ 198,000Â are deployed in the DeFi ecosystem. While the number of cbETH holders has consistently risen since its inception, reaching aroundÂ 46,000Â holders today, the minting of cbETH has exhibited volatility.\n\nSource:Â Coinbase-wrapped-staked-eth\nMost cbETH liquidity is on Uniswap and Balancer, where cbETH trades in aÂ mixed composable stable poolÂ with wstETH and rETH.Â Composable stable poolsÂ create deeper liquidity and better prices. The pool helps provide deeper liquidity and minimizes arbitrage opportunities and slippage.\ncbETH is already used widely across the DeFi ecosystem and can be found on protocols such as Convex Finance, Merkle, Beefy, Sommelier, and others.\nRoadmap\nAs the most recently launched LST of the trio weâ€™ve covered, much of Coinbaseâ€™s plans for cbETH are detailed in their whitepaper published in August of 2022.\nIn their whitepaper they detail their intentions of monitoring and supportingÂ the MergeÂ to ensure that cbETH is compatible with the new Ethereum network, as well as providing users clear guidance on how to migrate their cbETH. Their agenda further includes improving user experience with upgraded user interface and wallet functionality, providing users with more information and transparency on the performance and risks of cbETH, expanding the adoption with various DeFi protocols, and developing the cbETH community with educational as well as promotional initiatives.\nConclusion\nLidoâ€™s wstETH, Rocket Poolâ€™s rETH, and Coinbaseâ€™s cbETH, are the three most popular liquid staking tokens (LSTs) available on Arbitrum. These LSTs contribute unique features to the ecosystem, attracting users and fostering growth.\nWhile Lidoâ€™s wstETH is certainly the most popular in terms of raw numbers, some users may prefer the reward model or decentralization ethos of Rocketpoolâ€™s rETH. For users who donâ€™t mind a centralized custodian and issuer, they may choose Coinbase due to their well-established reputation in the industry as a household name. As all three are doing arguably well, there is no definitive â€œright answerâ€ as to any of them being better choices than the other.\nThe Open Dollar protocol will support wstETH and rETH from launch as collateral types to borrow our native stablecoin (OD) against. The decision whether or not to add support for cbETH or other LSTs in the future will be left toÂ our DAO, which has recently launched ahead of mainnet.\nWe are proud to be building in the Arbitrum ecosystem, supporting these trusted liquid staking tokens, and innovating on the inefficiencies of traditional collateralized debt positions (CDPs)."}}